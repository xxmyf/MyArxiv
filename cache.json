{"2023-02-24T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.12829v1","updated":"2023-02-24T18:59:51Z","published":"2023-02-24T18:59:51Z","title":"Improving Massively Multilingual ASR With Auxiliary CTC Objectives","summary":"  Multilingual Automatic Speech Recognition (ASR) models have extended the\nusability of speech technologies to a wide variety of languages. With how many\nlanguages these models have to handle, however, a key to understanding their\nimbalanced performance across different languages is to examine if the model\nactually knows which language it should transcribe. In this paper, we introduce\nour work on improving performance on FLEURS, a 102-language open ASR benchmark,\nby conditioning the entire model on language identity (LID). We investigate\ntechniques inspired from recent Connectionist Temporal Classification (CTC)\nstudies to help the model handle the large number of languages, conditioning on\nthe LID predictions of auxiliary tasks. Our experimental results demonstrate\nthe effectiveness of our technique over standard CTC/Attention-based hybrid\nmod- els. Furthermore, our state-of-the-art systems using self-supervised\nmodels with the Conformer architecture improve over the results of prior work\non FLEURS by a relative 28.4% CER. Trained models are reproducible recipes are\navailable at https://github.com/ espnet/espnet/tree/master/egs2/fleurs/asr1.\n","authors":["William Chen","Brian Yan","Jiatong Shi","Yifan Peng","Soumi Maiti","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2302.12829v1.pdf","comment":"5 pages, 1 figure, accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.12822v1","updated":"2023-02-24T18:58:06Z","published":"2023-02-24T18:58:06Z","title":"Automatic Prompt Augmentation and Selection with Chain-of-Thought from\n  Labeled Data","summary":"  Chain-of-thought prompting (CoT) advances the reasoning abilities of large\nlanguage models (LLMs) and achieves superior performance in arithmetic,\ncommonsense, and symbolic reasoning tasks. However, most CoT studies rely on\ncarefully designed human-annotated rational chains to prompt the language\nmodel, which poses challenges for real-world applications where labeled\ntraining data is available without human-annotated rational chains. This\ncreates barriers to applications of CoT prompting to these general tasks. This\npaper proposes a new strategy, Automate-CoT (Automatic Prompt Augmentation and\nSelection with Chain-of-Thought), that can bypass human engineering of CoTs by\nautomatically augmenting rational chains from a small labeled dataset, and then\npruning low-quality chains to construct a candidate pool of machine-generated\nrationale chains based on the labels. Finally, it selects the optimal\ncombination of several rationale chains from the pool for CoT prompting by\nemploying a variance-reduced policy gradient strategy to estimate the\nsignificance of each example in a black-box language model. Automate-CoT\nenables a quick adaptation of the CoT technique to different tasks.\nExperimental results demonstrate the effectiveness of our method, where\nstate-of-the-art results are achieved on arithmetic reasoning (+2.7\\%),\ncommonsense reasoning (+3.4\\%), symbolic reasoning (+3.2\\%), and non-reasoning\ntasks (+2.5\\%). Our code will be available at\nhttps://github.com/shizhediao/automate-cot.\n","authors":["KaShun Shum","Shizhe Diao","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.12822v1.pdf","comment":"22 pages, 4 figures, 13 tables"},{"id":"http://arxiv.org/abs/2302.12813v1","updated":"2023-02-24T18:48:43Z","published":"2023-02-24T18:48:43Z","title":"Check Your Facts and Try Again: Improving Large Language Models with\n  External Knowledge and Automated Feedback","summary":"  Large language models (LLMs), such as ChatGPT, are able to generate\nhuman-like, fluent responses for many downstream tasks, e.g., task-oriented\ndialog and question answering. However, applying LLMs to real-world,\nmission-critical applications remains challenging mainly due to their tendency\nto generate hallucinations and inability to use external knowledge.This paper\nproposes a LLM-Augmenter system, which augments a black-box LLM with a set of\nplug-and-play modules. Our system makes the LLM generate responses grounded in\nconsolidated external knowledge, e.g., stored in task-specific databases. It\nalso iteratively revises LLM prompts to improve model responses using feedback\ngenerated by utility functions, e.g., the factuality score of a LLM-generated\nresponse. The effectiveness of LLM-Augmenter is empirically validated on two\ntypes of mission-critical scenarios, task-oriented dialog and open-domain\nquestion answering. LLM-Augmenter significantly reduces ChatGPT's\nhallucinations without sacrificing the fluency and informativeness of its\nresponses. We make the source code and models publicly available.\n","authors":["Baolin Peng","Michel Galley","Pengcheng He","Hao Cheng","Yujia Xie","Yu Hu","Qiuyuan Huang","Lars Liden","Zhou Yu","Weizhu Chen","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2302.12813v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2302.12794v1","updated":"2023-02-24T18:10:37Z","published":"2023-02-24T18:10:37Z","title":"HULAT at SemEval-2023 Task 9: Data augmentation for pre-trained\n  transformers applied to Multilingual Tweet Intimacy Analysis","summary":"  This paper describes our participation in SemEval-2023 Task 9, Intimacy\nAnalysis of Multilingual Tweets. We fine-tune some of the most popular\ntransformer models with the training dataset and synthetic data generated by\ndifferent data augmentation techniques. During the development phase, our best\nresults were obtained by using XLM-T. Data augmentation techniques provide a\nvery slight improvement in the results. Our system ranked in the 27th position\nout of the 45 participating systems. Despite its modest results, our system\nshows promising results in languages such as Portuguese, English, and Dutch.\nAll our code is available in the repository\n\\url{https://github.com/isegura/hulat_intimacy}.\n","authors":["Isabel Segura-Bedmar"],"pdf_url":"https://arxiv.org/pdf/2302.12794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12784v1","updated":"2023-02-24T17:54:12Z","published":"2023-02-24T17:54:12Z","title":"STA: Self-controlled Text Augmentation for Improving Text\n  Classifications","summary":"  Despite recent advancements in Machine Learning, many tasks still involve\nworking in low-data regimes which can make solving natural language problems\ndifficult. Recently, a number of text augmentation techniques have emerged in\nthe field of Natural Language Processing (NLP) which can enrich the training\ndata with new examples, though they are not without their caveats. For\ninstance, simple rule-based heuristic methods are effective, but lack variation\nin semantic content and syntactic structure with respect to the original text.\nOn the other hand, more complex deep learning approaches can cause extreme\nshifts in the intrinsic meaning of the text and introduce unwanted noise into\nthe training data. To more reliably control the quality of the augmented\nexamples, we introduce a state-of-the-art approach for Self-Controlled Text\nAugmentation (STA). Our approach tightly controls the generation process by\nintroducing a self-checking procedure to ensure that generated examples retain\nthe semantic content of the original text. Experimental results on multiple\nbenchmarking datasets demonstrate that STA substantially outperforms existing\nstate-of-the-art techniques, whilst qualitative analysis reveals that the\ngenerated examples are both lexically diverse and semantically reliable.\n","authors":["Congcong Wang","Gonzalo Fiz Pontiveros","Steven Derby","Tri Kurniawan Wijaya"],"pdf_url":"https://arxiv.org/pdf/2302.12784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12766v1","updated":"2023-02-24T17:29:31Z","published":"2023-02-24T17:29:31Z","title":"Language-Driven Representation Learning for Robotics","summary":"  Recent work in visual representation learning for robotics demonstrates the\nviability of learning from large video datasets of humans performing everyday\ntasks. Leveraging methods such as masked autoencoding and contrastive learning,\nthese representations exhibit strong transfer to policy learning for visuomotor\ncontrol. But, robot learning encompasses a diverse set of problems beyond\ncontrol including grasp affordance prediction, language-conditioned imitation\nlearning, and intent scoring for human-robot collaboration, amongst others.\nFirst, we demonstrate that existing representations yield inconsistent results\nacross these tasks: masked autoencoding approaches pick up on low-level spatial\nfeatures at the cost of high-level semantics, while contrastive learning\napproaches capture the opposite. We then introduce Voltron, a framework for\nlanguage-driven representation learning from human videos and associated\ncaptions. Voltron trades off language-conditioned visual reconstruction to\nlearn low-level visual patterns, and visually-grounded language generation to\nencode high-level semantics. We also construct a new evaluation suite spanning\nfive distinct robot learning problems $\\unicode{x2013}$ a unified platform for\nholistically evaluating visual representations for robotics. Through\ncomprehensive, controlled experiments across all five problems, we find that\nVoltron's language-driven representations outperform the prior\nstate-of-the-art, especially on targeted problems requiring higher-level\nfeatures.\n","authors":["Siddharth Karamcheti","Suraj Nair","Annie S. Chen","Thomas Kollar","Chelsea Finn","Dorsa Sadigh","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2302.12766v1.pdf","comment":"30 Pages, 15 Figures"},{"id":"http://arxiv.org/abs/2302.12757v1","updated":"2023-02-24T17:15:39Z","published":"2023-02-24T17:15:39Z","title":"Ensemble knowledge distillation of self-supervised speech models","summary":"  Distilled self-supervised models have shown competitive performance and\nefficiency in recent years. However, there is a lack of experience in jointly\ndistilling multiple self-supervised speech models. In our work, we performed\nEnsemble Knowledge Distillation (EKD) on various self-supervised speech models\nsuch as HuBERT, RobustHuBERT, and WavLM. We tried two different aggregation\ntechniques, layerwise-average and layerwise-concatenation, to the\nrepresentations of different teacher models and found that the former was more\neffective. On top of that, we proposed a multiple prediction head method for\nstudent models to predict different layer outputs of multiple teacher models\nsimultaneously. The experimental results show that our method improves the\nperformance of the distilled models on four downstream speech processing tasks,\nPhoneme Recognition, Speaker Identification, Emotion Recognition, and Automatic\nSpeech Recognition in the hidden-set track of the SUPERB benchmark.\n","authors":["Kuan-Po Huang","Tzu-hsun Feng","Yu-Kuan Fu","Tsu-Yuan Hsu","Po-Chieh Yen","Wei-Cheng Tseng","Kai-Wei Chang","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2302.12757v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.12746v1","updated":"2023-02-24T16:59:54Z","published":"2023-02-24T16:59:54Z","title":"Spanish Built Factual Freectianary (Spanish-BFF): the first IA-generated\n  free dictionary","summary":"  Dictionaries are one of the oldest and most used linguistic resources.\nBuilding them is a complex task that, to the best of our knowledge, has yet to\nbe explored with generative Large Language Models (LLMs). We introduce the\n\"Spanish Built Factual Freectianary\" (Spanish-BFF) as the first Spanish\nIA-generated dictionary. This first-of-its-kind free dictionary uses GPT-3. We\nalso define future steps we aim to follow to improve this initial commitment to\nthe field, such as more additional languages.\n","authors":["Óscar García Sierra","Miguel Ortega-Martín","Alfonso Ardoiz","Juan Carlos Armenteros","Jorge Álvarez","Adrián Alonso"],"pdf_url":"https://arxiv.org/pdf/2302.12746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08562v3","updated":"2023-02-24T15:57:49Z","published":"2022-07-18T12:44:59Z","title":"DHGE: Dual-view Hyper-Relational Knowledge Graph Embedding for Link\n  Prediction and Entity Typing","summary":"  In the field of representation learning on knowledge graphs (KGs), a\nhyper-relational fact consists of a main triple and several auxiliary\nattribute-value descriptions, which is considered more comprehensive and\nspecific than a triple-based fact. However, currently available\nhyper-relational KG embedding methods in a single view are limited in\napplication because they weaken the hierarchical structure that represents the\naffiliation between entities. To overcome this limitation, we propose a\ndual-view hyper-relational KG structure (DH-KG) that contains a\nhyper-relational instance view for entities and a hyper-relational ontology\nview for concepts that are abstracted hierarchically from the entities. This\npaper defines link prediction and entity typing tasks on DH-KG for the first\ntime and constructs two DH-KG datasets, JW44K-6K, extracted from Wikidata, and\nHTDM based on medical data. Furthermore, we propose DHGE, a DH-KG embedding\nmodel based on GRAN encoders, HGNNs, and joint learning. DHGE outperforms\nbaseline models on DH-KG, according to experimental results. Finally, we\nprovide an example of how this technology can be used to treat hypertension.\nOur model and new datasets are publicly available.\n","authors":["Haoran Luo","Haihong E","Ling Tan","Gengxian Zhou","Tianyu Yao","Kaiyang Wan"],"pdf_url":"https://arxiv.org/pdf/2207.08562v3.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.12695v1","updated":"2023-02-24T15:48:23Z","published":"2023-02-24T15:48:23Z","title":"Cross-Lingual Transfer of Cognitive Processing Complexity","summary":"  When humans read a text, their eye movements are influenced by the structural\ncomplexity of the input sentences. This cognitive phenomenon holds across\nlanguages and recent studies indicate that multilingual language models utilize\nstructural similarities between languages to facilitate cross-lingual transfer.\nWe use sentence-level eye-tracking patterns as a cognitive indicator for\nstructural complexity and show that the multilingual model XLM-RoBERTa can\nsuccessfully predict varied patterns for 13 typologically diverse languages,\ndespite being fine-tuned only on English data. We quantify the sensitivity of\nthe model to structural complexity and distinguish a range of complexity\ncharacteristics. Our results indicate that the model develops a meaningful bias\ntowards sentence length but also integrates cross-lingual differences. We\nconduct a control experiment with randomized word order and find that the model\nseems to additionally capture more complex structural information.\n","authors":["Charlotte Pouw","Nora Hollenstein","Lisa Beinborn"],"pdf_url":"https://arxiv.org/pdf/2302.12695v1.pdf","comment":"Accepted at Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2302.12692v1","updated":"2023-02-24T15:35:36Z","published":"2023-02-24T15:35:36Z","title":"Boosting Transformers and Language Models for Clinical Prediction in\n  Immunotherapy","summary":"  Clinical prediction is an essential task in the healthcare industry. However,\nthe recent success of transformers, on which large language models are built,\nhas not been extended to this domain. In this research, we explore the use of\ntransformers and language models in prognostic prediction for immunotherapy\nusing real-world patients' clinical data and molecular profiles. This paper\ninvestigates the potential of transformers to improve clinical prediction\ncompared to conventional machine learning approaches and addresses the\nchallenge of few-shot learning in predicting rare disease areas. The study\nbenchmarks the efficacy of baselines and language models on prognostic\nprediction across multiple cancer types and investigates the impact of\ndifferent pretrained language models under few-shot regimes. The results\ndemonstrate significant improvements in accuracy and highlight the potential of\nNLP in clinical research to improve early detection and intervention for\ndifferent diseases. Anonymous codes are available at\n\\url{https://anonymous.4open.science/r/table2text-88ED}.\n","authors":["Zekai Chen","Mariann Micsinai Balan","Kevin Brown"],"pdf_url":"https://arxiv.org/pdf/2302.12692v1.pdf","comment":"7 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2302.12666v1","updated":"2023-02-24T14:41:48Z","published":"2023-02-24T14:41:48Z","title":"Modelling Temporal Document Sequences for Clinical ICD Coding","summary":"  Past studies on the ICD coding problem focus on predicting clinical codes\nprimarily based on the discharge summary. This covers only a small fraction of\nthe notes generated during each hospital stay and leaves potential for\nimproving performance by analysing all the available clinical notes. We propose\na hierarchical transformer architecture that uses text across the entire\nsequence of clinical notes in each hospital stay for ICD coding, and\nincorporates embeddings for text metadata such as their position, time, and\ntype of note. While using all clinical notes increases the quantity of data\nsubstantially, superconvergence can be used to reduce training costs. We\nevaluate the model on the MIMIC-III dataset. Our model exceeds the prior\nstate-of-the-art when using only discharge summaries as input, and achieves\nfurther performance improvements when all clinical notes are used as input.\n","authors":["Clarence Boon Liang Ng","Diogo Santos","Marek Rei"],"pdf_url":"https://arxiv.org/pdf/2302.12666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12640v1","updated":"2023-02-24T14:08:07Z","published":"2023-02-24T14:08:07Z","title":"In-Depth Look at Word Filling Societal Bias Measures","summary":"  Many measures of societal bias in language models have been proposed in\nrecent years. A popular approach is to use a set of word filling prompts to\nevaluate the behavior of the language models. In this work, we analyze the\nvalidity of two such measures -- StereoSet and CrowS-Pairs. We show that these\nmeasures produce unexpected and illogical results when appropriate control\ngroup samples are constructed. Based on this, we believe that they are\nproblematic and using them in the future should be reconsidered. We propose a\nway forward with an improved testing protocol. Finally, we also introduce a new\ngender bias dataset for Slovak.\n","authors":["Matúš Pikuliak","Ivana Beňová","Viktor Bachratý"],"pdf_url":"https://arxiv.org/pdf/2302.12640v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2302.12623v1","updated":"2023-02-24T13:36:11Z","published":"2023-02-24T13:36:11Z","title":"TUTORING: Instruction-Grounded Conversational Agent for Language\n  Learners","summary":"  In this paper, we propose Tutoring bot, a generative chatbot trained on a\nlarge scale of tutor-student conversations for English-language learning. To\nmimic a human tutor's behavior in language education, the tutor bot leverages\ndiverse educational instructions and grounds to each instruction as additional\ninput context for the tutor response generation. As a single instruction\ngenerally involves multiple dialogue turns to give the student sufficient\nspeaking practice, the tutor bot is required to monitor and capture when the\ncurrent instruction should be kept or switched to the next instruction. For\nthat, the tutor bot is learned to not only generate responses but also infer\nits teaching action and progress on the current conversation simultaneously by\na multi-task learning scheme. Our Tutoring bot is deployed under a\nnon-commercial use license at https://tutoringai.com.\n","authors":["Hyungjoo Chae","Minjin Kim","Chaehyeong Kim","Wonseok Jeong","Hyejoong Kim","Junmyung Lee","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2302.12623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12057v2","updated":"2023-02-24T13:16:31Z","published":"2023-02-23T14:30:23Z","title":"ProsAudit, a prosodic benchmark for self-supervised speech models","summary":"  We present ProsAudit, a benchmark in English to assess structural prosodic\nknowledge in self-supervised learning (SSL) speech models. It consists of two\nsubtasks, their corresponding metrics, an evaluation dataset. In the\nprotosyntax task, the model must correctly identify strong versus weak prosodic\nboundaries. In the lexical task, the model needs to correctly distinguish\nbetween pauses inserted between words and within words. We also provide human\nevaluation scores on this benchmark. We evaluated a series of SSL models and\nfound that they were all able to perform above chance on both tasks, even when\ntrained on an unseen language. However, non-native models performed\nsignificantly worse than native ones on the lexical task, highlighting the\nimportance of lexical knowledge in this task. We also found a clear effect of\nsize with models trained on more data performing better in the two subtasks.\n","authors":["Maureen de Seyssel","Marvin Lavechin","Hadrien Titeux","Arthur Thomas","Gwendal Virlet","Andrea Santos Revilla","Guillaume Wisniewski","Bogdan Ludusan","Emmanuel Dupoux"],"pdf_url":"https://arxiv.org/pdf/2302.12057v2.pdf","comment":"4 pages + references, 1 figure"},{"id":"http://arxiv.org/abs/2302.12611v1","updated":"2023-02-24T12:55:31Z","published":"2023-02-24T12:55:31Z","title":"CARE: Collaborative AI-Assisted Reading Environment","summary":"  Recent years have seen impressive progress in AI-assisted writing, yet the\ndevelopments in AI-assisted reading are lacking. We propose inline commentary\nas a natural vehicle for AI-based reading assistance, and present CARE: the\nfirst open integrated platform for the study of inline commentary and reading.\nCARE facilitates data collection for inline commentaries in a commonplace\ncollaborative reading environment, and provides a framework for enhancing\nreading with NLP-based assistance, such as text classification, generation or\nquestion answering. The extensible behavioral logging allows unique insights\ninto the reading and commenting behavior, and flexible configuration makes the\nplatform easy to deploy in new scenarios. To evaluate CARE in action, we apply\nthe platform in a user study dedicated to scholarly peer review. CARE\nfacilitates the data collection and study of inline commentary in NLP,\nextrinsic evaluation of NLP assistance, and application prototyping. We invite\nthe community to explore and build upon the open source implementation of CARE.\n","authors":["Dennis Zyska","Nils Dycke","Jan Buchmann","Ilia Kuznetsov","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2302.12611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12584v1","updated":"2023-02-24T11:44:24Z","published":"2023-02-24T11:44:24Z","title":"VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio\n  Features for Argument Mining","summary":"  In this paper, we describe VivesDebate-Speech, a corpus of spoken\nargumentation created to leverage audio features for argument mining tasks. The\ncreation of this corpus represents an important contribution to the\nintersection of speech processing and argument mining communities, and one of\nthe most complete publicly available resources in this topic. Moreover, we have\nperformed a set of first-of-their-kind experiments which show an improvement\nwhen integrating audio features into the argument mining pipeline. The provided\nresults can be used as a baseline for future research.\n","authors":["Ramon Ruiz-Dolz","Javier Iranzo-Sánchez"],"pdf_url":"https://arxiv.org/pdf/2302.12584v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2302.12578v1","updated":"2023-02-24T11:25:50Z","published":"2023-02-24T11:25:50Z","title":"Fairness in Language Models Beyond English: Gaps and Challenges","summary":"  With language models becoming increasingly ubiquitous, it has become\nessential to address their inequitable treatment of diverse demographic groups\nand factors. Most research on evaluating and mitigating fairness harms has been\nconcentrated on English, while multilingual models and non-English languages\nhave received comparatively little attention. In this paper, we survey\ndifferent aspects of fairness in languages beyond English and multilingual\ncontexts. This paper presents a survey of fairness in multilingual and\nnon-English contexts, highlighting the shortcomings of current research and the\ndifficulties faced by methods designed for English. We contend that the\nmultitude of diverse cultures and languages across the world makes it\ninfeasible to achieve comprehensive coverage in terms of constructing fairness\ndatasets. Thus, the measurement and mitigation of biases must evolve beyond the\ncurrent dataset-driven practices that are narrowly focused on specific\ndimensions and types of biases and, therefore, impossible to scale across\nlanguages and cultures.\n","authors":["Krithika Ramesh","Sunayana Sitaram","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2302.12578v1.pdf","comment":"Accepted to EACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2302.12569v1","updated":"2023-02-24T10:48:03Z","published":"2023-02-24T10:48:03Z","title":"Implicit Temporal Reasoning for Evidence-Based Fact-Checking","summary":"  Leveraging contextual knowledge has become standard practice in automated\nclaim verification, yet the impact of temporal reasoning has been largely\noverlooked. Our study demonstrates that time positively influences the claim\nverification process of evidence-based fact-checking. The temporal aspects and\nrelations between claims and evidence are first established through grounding\non shared timelines, which are constructed using publication dates and time\nexpressions extracted from their text. Temporal information is then provided to\nRNN-based and Transformer-based classifiers before or after claim and evidence\nencoding. Our time-aware fact-checking models surpass base models by up to 9%\nMicro F1 (64.17%) and 15% Macro F1 (47.43%) on the MultiFC dataset. They also\noutperform prior methods that explicitly model temporal relations between\nevidence. Our findings show that the presence of temporal information and the\nmanner in which timelines are constructed greatly influence how fact-checking\nmodels determine the relevance and supporting or refuting character of evidence\ndocuments.\n","authors":["Liesbeth Allein","Marlon Saelens","Ruben Cartuyvels","Marie-Francine Moens"],"pdf_url":"https://arxiv.org/pdf/2302.12569v1.pdf","comment":"The 17th Conference of the European Chapter of the Association for\n  Computational Linguistics (EACL 2023, Findings)"},{"id":"http://arxiv.org/abs/2302.05244v5","updated":"2023-02-24T10:15:45Z","published":"2023-02-10T13:49:50Z","title":"A Song of Ice and Fire: Analyzing Textual Autotelic Agents in\n  ScienceWorld","summary":"  Building open-ended agents that can autonomously discover a diversity of\nbehaviours is one of the long-standing goals of artificial intelligence. This\nchallenge can be studied in the framework of autotelic RL agents, i.e. agents\nthat learn by selecting and pursuing their own goals, self-organizing a\nlearning curriculum. Recent work identified language as a key dimension of\nautotelic learning, in particular because it enables abstract goal sampling and\nguidance from social peers for hindsight relabelling. Within this perspective,\nwe study the following open scientific questions: What is the impact of\nhindsight feedback from a social peer (e.g. selective vs. exhaustive)? How can\nthe agent learn from very rare language goal examples in its experience replay?\nHow can multiple forms of exploration be combined, and take advantage of easier\ngoals as stepping stones to reach harder ones? To address these questions, we\nuse ScienceWorld, a textual environment with rich abstract and combinatorial\nphysics. We show the importance of selectivity from the social peer's feedback;\nthat experience replay needs to over-sample examples of rare goals; and that\nfollowing self-generated goal sequences where the agent's competence is\nintermediate leads to significant improvements in final performance.\n","authors":["Laetitia Teodorescu","Xingdi Yuan","Marc-Alexandre Côté","Pierre-Yves Oudeyer"],"pdf_url":"https://arxiv.org/pdf/2302.05244v5.pdf","comment":"In review at ICML 2023"},{"id":"http://arxiv.org/abs/2302.12530v1","updated":"2023-02-24T09:29:55Z","published":"2023-02-24T09:29:55Z","title":"Dual Path Modeling for Semantic Matching by Perceiving Subtle Conflicts","summary":"  Transformer-based pre-trained models have achieved great improvements in\nsemantic matching. However, existing models still suffer from insufficient\nability to capture subtle differences. The modification, addition and deletion\nof words in sentence pairs may make it difficult for the model to predict their\nrelationship. To alleviate this problem, we propose a novel Dual Path Modeling\nFramework to enhance the model's ability to perceive subtle differences in\nsentence pairs by separately modeling affinity and difference semantics. Based\non dual-path modeling framework we design the Dual Path Modeling Network\n(DPM-Net) to recognize semantic relations. And we conduct extensive experiments\non 10 well-studied semantic matching and robustness test datasets, and the\nexperimental results show that our proposed method achieves consistent\nimprovements over baselines.\n","authors":["Chao Xue","Di Liang","Sirui Wang","Wei Wu","Jing Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.12530v1.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.12529v1","updated":"2023-02-24T09:29:40Z","published":"2023-02-24T09:29:40Z","title":"Time-aware Multiway Adaptive Fusion Network for Temporal Knowledge Graph\n  Question Answering","summary":"  Knowledge graphs (KGs) have received increasing attention due to its wide\napplications on natural language processing. However, its use case on temporal\nquestion answering (QA) has not been well-explored. Most of existing methods\nare developed based on pre-trained language models, which might not be capable\nto learn \\emph{temporal-specific} presentations of entities in terms of\ntemporal KGQA task. To alleviate this problem, we propose a novel\n\\textbf{T}ime-aware \\textbf{M}ultiway \\textbf{A}daptive (\\textbf{TMA}) fusion\nnetwork. Inspired by the step-by-step reasoning behavior of humans. For each\ngiven question, TMA first extracts the relevant concepts from the KG, and then\nfeeds them into a multiway adaptive module to produce a\n\\emph{temporal-specific} representation of the question. This representation\ncan be incorporated with the pre-trained KG embedding to generate the final\nprediction. Empirical results verify that the proposed model achieves better\nperformance than the state-of-the-art models in the benchmark dataset. Notably,\nthe Hits@1 and Hits@10 results of TMA on the CronQuestions dataset's complex\nquestions are absolutely improved by 24\\% and 10\\% compared to the\nbest-performing baseline. Furthermore, we also show that TMA employing an\nadaptive fusion mechanism can provide interpretability by analyzing the\nproportion of information in question representations.\n","authors":["Yonghao Liu","Di Liang","Fang Fang","Sirui Wang","Wei Wu","Rui Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.12529v1.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2211.06369v2","updated":"2023-02-24T09:21:39Z","published":"2022-11-11T17:40:08Z","title":"Enhancing and Adversarial: Improve ASR with Speaker Labels","summary":"  ASR can be improved by multi-task learning (MTL) with domain enhancing or\ndomain adversarial training, which are two opposite objectives with the aim to\nincrease/decrease domain variance towards domain-aware/agnostic ASR,\nrespectively. In this work, we study how to best apply these two opposite\nobjectives with speaker labels to improve conformer-based ASR. We also propose\na novel adaptive gradient reversal layer for stable and effective adversarial\ntraining without tuning effort. Detailed analysis and experimental verification\nare conducted to show the optimal positions in the ASR neural network (NN) to\napply speaker enhancing and adversarial training. We also explore their\ncombination for further improvement, achieving the same performance as\ni-vectors plus adversarial training. Our best speaker-based MTL achieves 7\\%\nrelative improvement on the Switchboard Hub5'00 set. We also investigate the\neffect of such speaker-based MTL w.r.t. cleaner dataset and weaker ASR NN.\n","authors":["Wei Zhou","Haotian Wu","Jingjing Xu","Mohammad Zeineldeen","Christoph Lüscher","Ralf Schlüter","Hermann Ney"],"pdf_url":"https://arxiv.org/pdf/2211.06369v2.pdf","comment":"accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2212.12795v2","updated":"2023-02-24T09:04:08Z","published":"2022-12-24T18:19:05Z","title":"Development of a Thermodynamics of Human Cognition and Human Culture","summary":"  Inspired by foundational studies in classical and quantum physics, and by\ninformation retrieval studies in quantum information theory, we prove that the\nnotions of 'energy' and 'entropy' can be consistently introduced in human\nlanguage and, more generally, in human culture. More explicitly, if energy is\nattributed to words according to their frequency of appearance in a text, then\nthe ensuing energy levels are distributed non-classically, namely, they obey\nBose-Einstein, rather than Maxwell-Boltzmann, statistics, as a consequence of\nthe genuinely 'quantum indistinguishability' of the words that appear in the\ntext. Secondly, the 'quantum entanglement' due to the way meaning is carried by\na text reduces the (von Neumann) entropy of the words that appear in the text,\na behaviour which cannot be explained within classical (thermodynamic or\ninformation) entropy. We claim here that this 'quantum-type behaviour is valid\nin general in human language', namely, any text is conceptually more concrete\nthan the words composing it, which entails that the entropy of the overall text\ndecreases. In addition, we provide examples taken from cognition, where\nquantization of energy appears in categorical perception, and from culture,\nwhere entities collaborate, thus 'entangle', to decrease overall entropy. We\nuse these findings to propose the development of a new 'non-classical\nthermodynamic theory' for human cognition, which also covers broad parts of\nhuman culture and its artefacts and bridges concepts with quantum physics\nentities.\n","authors":["Diederik Aerts","Jonito Aerts Arguëlles","Lester Beltran","Sandro Sozzo"],"pdf_url":"https://arxiv.org/pdf/2212.12795v2.pdf","comment":"20 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.12490v1","updated":"2023-02-24T07:10:33Z","published":"2023-02-24T07:10:33Z","title":"Improving Sentence Similarity Estimation for Unsupervised Extractive\n  Summarization","summary":"  Unsupervised extractive summarization aims to extract salient sentences from\na document as the summary without labeled data. Recent literatures mostly\nresearch how to leverage sentence similarity to rank sentences in the order of\nsalience. However, sentence similarity estimation using pre-trained language\nmodels mostly takes little account of document-level information and has a weak\ncorrelation with sentence salience ranking. In this paper, we proposed two\nnovel strategies to improve sentence similarity estimation for unsupervised\nextractive summarization. We use contrastive learning to optimize a\ndocument-level objective that sentences from the same document are more similar\nthan those from different documents. Moreover, we use mutual learning to\nenhance the relationship between sentence similarity estimation and sentence\nsalience ranking, where an extra signal amplifier is used to refine the pivotal\ninformation. Experimental results demonstrate the effectiveness of our\nstrategies.\n","authors":["Shichao Sun","Ruifeng Yuan","Wenjie Li","Sujian Li"],"pdf_url":"https://arxiv.org/pdf/2302.12490v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2202.07101v2","updated":"2023-02-24T06:18:20Z","published":"2022-02-15T00:13:05Z","title":"A Survey on Dynamic Neural Networks for Natural Language Processing","summary":"  Effectively scaling large Transformer models is a main driver of recent\nadvances in natural language processing. Dynamic neural networks, as an\nemerging research direction, are capable of scaling up neural networks with\nsub-linear increases in computation and time by dynamically adjusting their\ncomputational path based on the input. Dynamic neural networks could be a\npromising solution to the growing parameter numbers of pretrained language\nmodels, allowing both model pretraining with trillions of parameters and faster\ninference on mobile devices. In this survey, we summarize progress of three\ntypes of dynamic neural networks in NLP: skimming, mixture of experts, and\nearly exit. We also highlight current challenges in dynamic neural networks and\ndirections for future research.\n","authors":["Canwen Xu","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2202.07101v2.pdf","comment":"EACL 2023 Findings"},{"id":"http://arxiv.org/abs/2302.04415v2","updated":"2023-02-24T05:50:08Z","published":"2023-02-09T03:04:11Z","title":"Few-Shot Table-to-Text Generation with Prompt Planning and Knowledge\n  Memorization","summary":"  Pre-trained language models (PLM) have achieved remarkable advancement in\ntable-to-text generation tasks. However, the lack of labeled domain-specific\nknowledge and the topology gap between tabular data and text make it difficult\nfor PLMs to yield faithful text. Low-resource generation likewise faces unique\nchallenges in this domain. Inspired by how humans descript tabular data with\nprior knowledge, we suggest a new framework: PromptMize, which targets\ntable-to-text generation under few-shot settings. The design of our framework\nconsists of two aspects: a prompt planner and a knowledge adapter. The prompt\nplanner aims to generate a prompt signal that provides instance guidance for\nPLMs to bridge the topology gap between tabular data and text. Moreover, the\nknowledge adapter memorizes domain-specific knowledge from the unlabelled\ncorpus to supply essential information during generation. Extensive experiments\nand analyses are investigated on three open domain few-shot NLG datasets:\nhuman, song, and book. Compared with previous state-of-the-art approaches, our\nmodel achieves remarkable performance in generating quality as judged by human\nand automatic evaluations.\n","authors":["Zhixin Guo","Minyxuan Yan","Jiexing Qi","Jianping Zhou","Ziwei He","Zhouhan Lin","Guanjie Zheng","Xinbing Wang"],"pdf_url":"https://arxiv.org/pdf/2302.04415v2.pdf","comment":"not good enough we changed the contend and rename the article with a\n  new submission"},{"id":"http://arxiv.org/abs/2302.12468v1","updated":"2023-02-24T05:48:53Z","published":"2023-02-24T05:48:53Z","title":"Few-Shot Table-to-Text Generation with Prompt-based Adapter","summary":"  Pre-trained language models (PLMs) have made remarkable progress in\ntable-to-text generation tasks. However, the topological gap between tabular\ndata and text and the lack of domain-specific knowledge make it difficult for\nPLMs to produce faithful text, especially in real-world applications with\nlimited resources. In this paper, we mitigate the above challenges by\nintroducing a novel augmentation method: Prompt-based Adapter (PA), which\ntargets table-to-text generation under few-shot conditions. The core insight\ndesign of the PA is to inject prompt templates for augmenting domain-specific\nknowledge and table-related representations into the model for bridging the\nstructural gap between tabular data and descriptions through adapters. Such\nprompt-based knowledge augmentation method brings at least two benefits: (1)\nenables us to fully use the large amounts of unlabelled domain-specific\nknowledge, which can alleviate the PLMs' inherent shortcomings of lacking\ndomain knowledge; (2) allows us to design different types of tasks supporting\nthe generative challenge. Extensive experiments and analyses are conducted on\nthree open-domain few-shot NLG datasets: Humans, Books, and Songs. Compared to\nprevious state-of-the-art approaches, our model achieves superior performance\nin terms of both fluency and accuracy as judged by human and automatic\nevaluations.\n","authors":["Zhixin Guo","Minyxuan Yan","Jiexing Qi","Jianping Zhou","Ziwei He","Zhouhan Lin","Guanjie Zheng","Xinbing Wang"],"pdf_url":"https://arxiv.org/pdf/2302.12468v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2302.04415"},{"id":"http://arxiv.org/abs/2302.12461v1","updated":"2023-02-24T05:26:08Z","published":"2023-02-24T05:26:08Z","title":"Analyzing And Editing Inner Mechanisms Of Backdoored Language Models","summary":"  Recent advancements in interpretability research made transformer language\nmodels more transparent. This progress led to a better understanding of their\ninner workings for toy and naturally occurring models. However, how these\nmodels internally process sentiment changes has yet to be sufficiently\nanswered. In this work, we introduce a new interpretability tool called PCP\nablation, where we replace modules with low-rank matrices based on the\nprincipal components of their activations, reducing model parameters and their\nbehavior to essentials. We demonstrate PCP ablations on MLP and attention\nlayers in backdoored toy, backdoored large, and naturally occurring models. We\ndetermine MLPs as most important for the backdoor mechanism and use this\nknowledge to remove, insert, and modify backdoor mechanisms with engineered\nreplacements via PCP ablation.\n","authors":["Max Lamparth","Anka Reuel"],"pdf_url":"https://arxiv.org/pdf/2302.12461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12449v1","updated":"2023-02-24T04:31:18Z","published":"2023-02-24T04:31:18Z","title":"SGL-PT: A Strong Graph Learner with Graph Prompt Tuning","summary":"  Recently, much exertion has been paid to design graph self-supervised methods\nto obtain generalized pre-trained models, and adapt pre-trained models onto\ndownstream tasks through fine-tuning. However, there exists an inherent gap\nbetween pretext and downstream graph tasks, which insufficiently exerts the\nability of pre-trained models and even leads to negative transfer. Meanwhile,\nprompt tuning has seen emerging success in natural language processing by\naligning pre-training and fine-tuning with consistent training objectives. In\nthis paper, we identify the challenges for graph prompt tuning: The first is\nthe lack of a strong and universal pre-training task across sundry pre-training\nmethods in graph domain. The second challenge lies in the difficulty of\ndesigning a consistent training objective for both pre-training and downstream\ntasks. To overcome above obstacles, we propose a novel framework named SGL-PT\nwhich follows the learning strategy ``Pre-train, Prompt, and Predict''.\nSpecifically, we raise a strong and universal pre-training task coined as SGL\nthat acquires the complementary merits of generative and contrastive\nself-supervised graph learning. And aiming for graph classification task, we\nunify pre-training and fine-tuning by designing a novel verbalizer-free\nprompting function, which reformulates the downstream task in a similar format\nas pretext task. Empirical results show that our method surpasses other\nbaselines under unsupervised setting, and our prompt tuning method can greatly\nfacilitate models on biological datasets over fine-tuning methods.\n","authors":["Yun Zhu","Jianhao Guo","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2302.12449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12441v1","updated":"2023-02-24T04:03:15Z","published":"2023-02-24T04:03:15Z","title":"MUX-PLMs: Pre-training Language Models with Data Multiplexing","summary":"  Data multiplexing is a recently proposed method for improving a model's\ninference efficiency by processing multiple instances simultaneously using an\nordered representation mixture. Prior work on data multiplexing only used\ntask-specific Transformers without any pre-training, which limited their\naccuracy and generality. In this paper, we develop pre-trained multiplexed\nlanguage models (MUX-PLMs) that can be widely finetuned on any downstream task.\nOur approach includes a three-stage training procedure and novel multiplexing\nand demultiplexing modules for improving throughput and downstream task\naccuracy. We demonstrate our method on BERT and ELECTRA pre-training\nobjectives, with our MUX-BERT and MUX-ELECTRA models achieving 2x/5x inference\nspeedup with a 2-4 \\% drop in absolute performance on GLUE and 1-2 \\% drop on\ntoken-level tasks.\n","authors":["Vishvak Murahari","Ameet Deshpande","Carlos E. Jimenez","Izhak Shafran","Mingqiu Wang","Yuan Cao","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2302.12441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14502v3","updated":"2023-02-24T03:59:33Z","published":"2022-10-26T06:21:01Z","title":"SentBS: Sentence-level Beam Search for Controllable Summarization","summary":"  A wide range of control perspectives have been explored in controllable text\ngeneration. Structure-controlled summarization is recently proposed as a useful\nand interesting research direction. However, current structure-controlling\nmethods have limited effectiveness in enforcing the desired structure. To\naddress this limitation, we propose a sentence-level beam search generation\nmethod (SentBS), where evaluation is conducted throughout the generation\nprocess to select suitable sentences for subsequent generations. We experiment\nwith different combinations of decoding methods to be used as subcomponents by\nSentBS and evaluate results on the structure-controlled dataset MReD.\nExperiments show that all explored combinations for SentBS can improve the\nagreement between the generated text and the desired structure, with the best\nmethod significantly reducing the structural discrepancies suffered by the\nexisting model, by approximately 68%.\n","authors":["Chenhui Shen","Liying Cheng","Lidong Bing","Yang You","Luo Si"],"pdf_url":"https://arxiv.org/pdf/2210.14502v3.pdf","comment":"10 pages, 1 figure, accepted by EMNLP 2022"},{"id":"http://arxiv.org/abs/2302.12433v1","updated":"2023-02-24T03:28:46Z","published":"2023-02-24T03:28:46Z","title":"ProofNet: Autoformalizing and Formally Proving Undergraduate-Level\n  Mathematics","summary":"  We introduce ProofNet, a benchmark for autoformalization and formal proving\nof undergraduate-level mathematics. The ProofNet benchmarks consists of 371\nexamples, each consisting of a formal theorem statement in Lean 3, a natural\nlanguage theorem statement, and a natural language proof. The problems are\nprimarily drawn from popular undergraduate pure mathematics textbooks and cover\ntopics such as real and complex analysis, linear algebra, abstract algebra, and\ntopology. We intend for ProofNet to be a challenging benchmark that will drive\nprogress in autoformalization and automatic theorem proving. We report baseline\nresults on statement autoformalization via in-context learning. Moreover, we\nintroduce two novel statement autoformalization methods: prompt retrieval and\ndistilled backtranslation.\n","authors":["Zhangir Azerbayev","Bartosz Piotrowski","Hailey Schoelkopf","Edward W. Ayers","Dragomir Radev","Jeremy Avigad"],"pdf_url":"https://arxiv.org/pdf/2302.12433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12444v2","updated":"2023-02-24T02:53:39Z","published":"2022-10-22T13:23:02Z","title":"Weakly-Supervised Temporal Article Grounding","summary":"  Given a long untrimmed video and natural language queries, video grounding\n(VG) aims to temporally localize the semantically-aligned video segments.\nAlmost all existing VG work holds two simple but unrealistic assumptions: 1)\nAll query sentences can be grounded in the corresponding video. 2) All query\nsentences for the same video are always at the same semantic scale.\nUnfortunately, both assumptions make today's VG models fail to work in\npractice. For example, in real-world multimodal assets (eg, news articles),\nmost of the sentences in the article can not be grounded in their affiliated\nvideos, and they typically have rich hierarchical relations (ie, at different\nsemantic scales). To this end, we propose a new challenging grounding task:\nWeakly-Supervised temporal Article Grounding (WSAG). Specifically, given an\narticle and a relevant video, WSAG aims to localize all ``groundable''\nsentences to the video, and these sentences are possibly at different semantic\nscales. Accordingly, we collect the first WSAG dataset to facilitate this task:\nYouwikiHow, which borrows the inherent multi-scale descriptions in wikiHow\narticles and plentiful YouTube videos. In addition, we propose a simple but\neffective method DualMIL for WSAG, which consists of a two-level MIL loss and a\nsingle-/cross- sentence constraint loss. These training objectives are\ncarefully designed for these relaxed assumptions. Extensive ablations have\nverified the effectiveness of DualMIL.\n","authors":["Long Chen","Yulei Niu","Brian Chen","Xudong Lin","Guangxing Han","Christopher Thomas","Hammad Ayyubi","Heng Ji","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2210.12444v2.pdf","comment":"EMNLP 2022, https://github.com/zjuchenlong/WSAG"},{"id":"http://arxiv.org/abs/2302.12417v1","updated":"2023-02-24T02:45:49Z","published":"2023-02-24T02:45:49Z","title":"Emotion Prediction Oriented method with Multiple Supervisions for\n  Emotion-Cause Pair Extraction","summary":"  Emotion-cause pair extraction (ECPE) task aims to extract all the pairs of\nemotions and their causes from an unannotated emotion text. The previous works\nusually extract the emotion-cause pairs from two perspectives of emotion and\ncause. However, emotion extraction is more crucial to the ECPE task than cause\nextraction. Motivated by this analysis, we propose an end-to-end emotion-cause\nextraction approach oriented toward emotion prediction (EPO-ECPE), aiming to\nfully exploit the potential of emotion prediction to enhance emotion-cause pair\nextraction. Considering the strong dependence between emotion prediction and\nemotion-cause pair extraction, we propose a synchronization mechanism to share\ntheir improvement in the training process. That is, the improvement of emotion\nprediction can facilitate the emotion-cause pair extraction, and then the\nresults of emotion-cause pair extraction can also be used to improve the\naccuracy of emotion prediction simultaneously. For the emotion-cause pair\nextraction, we divide it into genuine pair supervision and fake pair\nsupervision, where the genuine pair supervision learns from the pairs with more\npossibility to be emotion-cause pairs. In contrast, fake pair supervision\nlearns from other pairs. In this way, the emotion-cause pairs can be extracted\ndirectly from the genuine pair, thereby reducing the difficulty of extraction.\nExperimental results show that our approach outperforms the 13 compared systems\nand achieves new state-of-the-art performance.\n","authors":["Guimin Hu","Yi Zhao","Guangming Lu"],"pdf_url":"https://arxiv.org/pdf/2302.12417v1.pdf","comment":"accepted by TASLP"},{"id":"http://arxiv.org/abs/2210.16433v2","updated":"2023-02-24T02:42:53Z","published":"2022-10-28T23:18:43Z","title":"Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language\n  Models","summary":"  Fully-parametric language models generally require a huge number of model\nparameters to store the necessary knowledge for solving multiple natural\nlanguage tasks in zero/few-shot settings. In addition, it is hard to adapt to\nthe evolving world knowledge without the costly model re-training. In this\npaper, we develop a novel semi-parametric language model architecture,\nKnowledge-in-Context (KiC), which empowers a parametric text-to-text language\nmodel with a knowledge-rich external memory. Specifically, the external memory\ncontains six different types of knowledge: entity, dictionary, commonsense,\nevent, script, and causality knowledge. For each input instance, the KiC model\nadaptively selects a knowledge type and retrieves the most helpful pieces of\nknowledge. The input instance along with its knowledge augmentation is fed into\na text-to-text model (e.g., T5) to generate the output answer, where both the\ninput and the output are in natural language forms after prompting.\nInterestingly, we find that KiC can be identified as a special\nmixture-of-experts (MoE) model, where the knowledge selector plays the role of\na router that is used to determine the sequence-to-expert assignment in MoE.\nThis key observation inspires us to develop a novel algorithm for training KiC\nwith an instance-adaptive knowledge selector. As a knowledge-rich\nsemi-parametric language model, KiC only needs a much smaller parametric part\nto achieve superior zero-shot performance on unseen tasks. By evaluating on 40+\ndifferent tasks, we show that KiC_Large with 770M parameters easily outperforms\nlarge language models (LMs) that are 4-39x larger by a large margin. We also\ndemonstrate that KiC exhibits emergent abilities at a much smaller model scale\ncompared to the fully-parametric models.\n","authors":["Xiaoman Pan","Wenlin Yao","Hongming Zhang","Dian Yu","Dong Yu","Jianshu Chen"],"pdf_url":"https://arxiv.org/pdf/2210.16433v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11752v2","updated":"2023-02-24T02:02:07Z","published":"2023-02-23T02:38:39Z","title":"VLSP2022 EVJVQA Challenge: Multilingual Visual Question Answering","summary":"  Visual Question Answering (VQA) is a challenging task of natural language\nprocessing (NLP) and computer vision (CV), attracting significant attention\nfrom researchers. English is a resource-rich language that has witnessed\nvarious developments in datasets and models for visual question answering.\nVisual question answering in other languages also would be developed for\nresources and models. In addition, there is no multilingual dataset targeting\nthe visual content of a particular country with its own objects and cultural\ncharacteristics. To address the weakness, we provide the research community\nwith a benchmark dataset named EVJVQA, including 33,000+ pairs of\nquestion-answer over three languages: Vietnamese, English, and Japanese, on\napproximately 5,000 images taken from Vietnam for evaluating multilingual VQA\nsystems or models. EVJVQA is used as a benchmark dataset for the challenge of\nmultilingual visual question answering at the 9th Workshop on Vietnamese\nLanguage and Speech Processing (VLSP 2022). This task attracted 62 participant\nteams from various universities and organizations. In this article, we present\ndetails of the organization of the challenge, an overview of the methods\nemployed by shared-task participants, and the results. The highest performances\nare 0.4392 in F1-score and 0.4009 in BLUE on the private test set. The\nmultilingual QA systems proposed by the top 2 teams use ViT for the pre-trained\nvision model and mT5 for the pre-trained language model, a powerful pre-trained\nlanguage model based on the transformer architecture. EVJVQA is a challenging\ndataset that motivates NLP and CV researchers to further explore the\nmultilingual models or systems for visual question answering systems.\n","authors":["Ngan Luu-Thuy Nguyen","Nghia Hieu Nguyen","Duong T. D Vo","Khanh Quoc Tran","Kiet Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.11752v2.pdf","comment":"VLSP2022 EVJVQA challenge"},{"id":"http://arxiv.org/abs/2302.11154v2","updated":"2023-02-24T00:50:25Z","published":"2023-02-22T05:31:26Z","title":"Open-domain Visual Entity Recognition: Towards Recognizing Millions of\n  Wikipedia Entities","summary":"  Large-scale multi-modal pre-training models such as CLIP and PaLI exhibit\nstrong generalization on various visual domains and tasks. However, existing\nimage classification benchmarks often evaluate recognition on a specific domain\n(e.g., outdoor images) or a specific task (e.g., classifying plant species),\nwhich falls short of evaluating whether pre-trained foundational models are\nuniversal visual recognizers. To address this, we formally present the task of\nOpen-domain Visual Entity recognitioN (OVEN), where a model need to link an\nimage onto a Wikipedia entity with respect to a text query. We construct\nOVEN-Wiki by re-purposing 14 existing datasets with all labels grounded onto\none single label space: Wikipedia entities. OVEN challenges models to select\namong six million possible Wikipedia entities, making it a general visual\nrecognition benchmark with the largest number of labels. Our study on\nstate-of-the-art pre-trained models reveals large headroom in generalizing to\nthe massive-scale label space. We show that a PaLI-based auto-regressive visual\nrecognition model performs surprisingly well, even on Wikipedia entities that\nhave never been seen during fine-tuning. We also find existing pretrained\nmodels yield different strengths: while PaLI-based models obtain higher overall\nperformance, CLIP-based models are better at recognizing tail entities.\n","authors":["Hexiang Hu","Yi Luan","Yang Chen","Urvashi Khandelwal","Mandar Joshi","Kenton Lee","Kristina Toutanova","Ming-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2302.11154v2.pdf","comment":"Dataset available at https://open-vision-language.github.io/oven"},{"id":"http://arxiv.org/abs/2302.12369v1","updated":"2023-02-24T00:01:41Z","published":"2023-02-24T00:01:41Z","title":"Factual Consistency Oriented Speech Recognition","summary":"  This paper presents a novel optimization framework for automatic speech\nrecognition (ASR) with the aim of reducing hallucinations produced by an ASR\nmodel. The proposed framework optimizes the ASR model to maximize an expected\nfactual consistency score between ASR hypotheses and ground-truth\ntranscriptions, where the factual consistency score is computed by a separately\ntrained estimator. Experimental results using the AMI meeting corpus and the\nVoxPopuli corpus show that the ASR model trained with the proposed framework\ngenerates ASR hypotheses that have significantly higher consistency scores with\nground-truth transcriptions while maintaining the word error rates close to\nthose of cross entropy-trained ASR models. Furthermore, it is shown that\ntraining the ASR models with the proposed framework improves the speech\nsummarization quality as measured by the factual consistency of meeting\nconversation summaries generated by a large language model.\n","authors":["Naoyuki Kanda","Takuya Yoshioka","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2302.12369v1.pdf","comment":"5 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2302.12927v1","updated":"2023-02-24T22:53:10Z","published":"2023-02-24T22:53:10Z","title":"Robot Behavior-Tree-Based Task Generation with Large Language Models","summary":"  Nowadays, the behavior tree is gaining popularity as a representation for\nrobot tasks due to its modularity and reusability. Designing behavior-tree\ntasks manually is time-consuming for robot end-users, thus there is a need for\ninvestigating automatic behavior-tree-based task generation. Prior\nbehavior-tree-based task generation approaches focus on fixed primitive tasks\nand lack generalizability to new task domains. To cope with this issue, we\npropose a novel behavior-tree-based task generation approach that utilizes\nstate-of-the-art large language models. We propose a Phase-Step prompt design\nthat enables a hierarchical-structured robot task generation and further\nintegrate it with behavior-tree-embedding-based search to set up the\nappropriate prompt. In this way, we enable an automatic and cross-domain\nbehavior-tree task generation. Our behavior-tree-based task generation approach\ndoes not require a set of pre-defined primitive tasks. End-users only need to\ndescribe an abstract desired task and our proposed approach can swiftly\ngenerate the corresponding behavior tree. A full-process case study is provided\nto demonstrate our proposed approach. An ablation study is conducted to\nevaluate the effectiveness of our Phase-Step prompts. Assessment on Phase-Step\nprompts and the limitation of large language models are presented and\ndiscussed.\n","authors":["Yue Cao","C. S. George Lee"],"pdf_url":"https://arxiv.org/pdf/2302.12927v1.pdf","comment":"The extended abstract of this paper is accepted in AAAI 2023 Spring\n  Symposium on Challenges Requiring the Combination of Machine Learning and\n  Knowledge Engineering (AAAI-MAKE 2023)"},{"id":"http://arxiv.org/abs/2302.12921v1","updated":"2023-02-24T22:38:54Z","published":"2023-02-24T22:38:54Z","title":"Pre-Finetuning for Few-Shot Emotional Speech Recognition","summary":"  Speech models have long been known to overfit individual speakers for many\nclassification tasks. This leads to poor generalization in settings where the\nspeakers are out-of-domain or out-of-distribution, as is common in production\nenvironments. We view speaker adaptation as a few-shot learning problem and\npropose investigating transfer learning approaches inspired by recent success\nwith pre-trained models in natural language tasks. We propose pre-finetuning\nspeech models on difficult tasks to distill knowledge into few-shot downstream\nclassification objectives. We pre-finetune Wav2Vec2.0 on every permutation of\nfour multiclass emotional speech recognition corpora and evaluate our\npre-finetuned models through 33,600 few-shot fine-tuning trials on the\nEmotional Speech Dataset.\n","authors":["Maximillian Chen","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2302.12921v1.pdf","comment":"5 pages, 4 figures. Code available at\n  https://github.com/maxlchen/Speech-PreFinetuning"},{"id":"http://arxiv.org/abs/2302.12903v1","updated":"2023-02-24T21:20:25Z","published":"2023-02-24T21:20:25Z","title":"NoPPA: Non-Parametric Pairwise Attention Random Walk Model for Sentence\n  Representation","summary":"  We propose a novel non-parametric/un-trainable language model, named\nNon-Parametric Pairwise Attention Random Walk Model (NoPPA), to generate\nsentence embedding only with pre-trained word embedding and pre-counted word\nfrequency. To the best we know, this study is the first successful attempt to\nbreak the constraint on bag-of-words assumption with a non-parametric attention\nmechanism. We evaluate our method on eight different downstream classification\ntasks. The experiment results show that NoPPA outperforms all kinds of\nbag-of-words-based methods in each dataset and provides a comparable or better\nperformance than the state-of-the-art non-parametric methods on average.\nFurthermore, visualization supports that NoPPA can understand contextual\ntopics, common phrases, and word causalities. Our model is available at\nhttps://github.com/JacksonWuxs/NoPPA.\n","authors":["Xuansheng Wu","Zhiyi Zhao","Ninghao Liu"],"pdf_url":"https://arxiv.org/pdf/2302.12903v1.pdf","comment":"8+2+1 pages, 3+2 figures"},{"id":"http://arxiv.org/abs/2208.06161v2","updated":"2023-02-24T20:49:54Z","published":"2022-08-12T08:15:34Z","title":"Sparse Probability of Agreement","summary":"  Measuring inter-annotator agreement is important for annotation tasks, but\nmany metrics require a fully-annotated set of data, where all annotators\nannotate all samples. We define Sparse Probability of Agreement, SPA, which\nestimates the probability of agreement when not all annotator-item-pairs are\navailable. We show that under certain conditions, SPA is an unbiased estimator,\nand we provide multiple weighing schemes for handling data with various degrees\nof annotation.\n","authors":["Jeppe Nørregaard","Leon Derczynski"],"pdf_url":"https://arxiv.org/pdf/2208.06161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.14256v3","updated":"2023-02-24T20:37:29Z","published":"2022-04-29T17:34:12Z","title":"Handling and Presenting Harmful Text in NLP Research","summary":"  Text data can pose a risk of harm. However, the risks are not fully\nunderstood, and how to handle, present, and discuss harmful text in a safe way\nremains an unresolved issue in the NLP community. We provide an analytical\nframework categorising harms on three axes: (1) the harm type (e.g.,\nmisinformation, hate speech or racial stereotypes); (2) whether a harm is\n\\textit{sought} as a feature of the research design if explicitly studying\nharmful content (e.g., training a hate speech classifier), versus\n\\textit{unsought} if harmful content is encountered when working on unrelated\nproblems (e.g., language generation or part-of-speech tagging); and (3) who it\naffects, from people (mis)represented in the data to those handling the data\nand those publishing on the data. We provide advice for practitioners, with\nconcrete steps for mitigating harm in research and in publication. To assist\nimplementation we introduce \\textsc{HarmCheck} -- a documentation standard for\nhandling and presenting harmful text in research.\n","authors":["Hannah Rose Kirk","Abeba Birhane","Bertie Vidgen","Leon Derczynski"],"pdf_url":"https://arxiv.org/pdf/2204.14256v3.pdf","comment":"in Findings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2302.11713v2","updated":"2023-02-24T19:30:27Z","published":"2023-02-23T00:33:54Z","title":"Can Pre-trained Vision and Language Models Answer Visual\n  Information-Seeking Questions?","summary":"  Large language models have demonstrated an emergent capability in answering\nknowledge intensive questions. With recent progress on web-scale visual and\nlanguage pre-training, do these models also understand how to answer visual\ninformation seeking questions? To answer this question, we present InfoSeek, a\nVisual Question Answering dataset that focuses on asking information-seeking\nquestions, where the information can not be answered by common sense knowledge.\nWe perform a multi-stage human annotation to collect a natural distribution of\nhigh-quality visual information seeking question-answer pairs. We also\nconstruct a large-scale, automatically collected dataset by combining existing\nvisual entity recognition datasets and Wikidata, which provides over one\nmillion examples for model fine-tuning and validation. Based on InfoSeek, we\nanalyzed various pre-trained Visual QA systems to gain insights into the\ncharacteristics of different pre-trained models. Our analysis shows that it is\nchallenging for the state-of-the-art multi-modal pre-trained models to answer\nvisual information seeking questions, but this capability is improved through\nfine-tuning on the automated InfoSeek dataset. We hope our analysis paves the\nway to understand and develop the next generation of multi-modal pre-training.\n","authors":["Yang Chen","Hexiang Hu","Yi Luan","Haitian Sun","Soravit Changpinyo","Alan Ritter","Ming-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2302.11713v2.pdf","comment":"Our dataset and evaluation is available at\n  https://open-vision-language.github.io/infoseek/"},{"id":"http://arxiv.org/abs/2302.12840v1","updated":"2023-02-24T18:17:38Z","published":"2023-02-24T18:17:38Z","title":"HULAT at SemEval-2023 Task 10: Data augmentation for pre-trained\n  transformers applied to the detection of sexism in social media","summary":"  This paper describes our participation in SemEval-2023 Task 10, whose goal is\nthe detection of sexism in social media. We explore some of the most popular\ntransformer models such as BERT, DistilBERT, RoBERTa, and XLNet. We also study\ndifferent data augmentation techniques to increase the training dataset. During\nthe development phase, our best results were obtained by using RoBERTa and data\naugmentation for tasks B and C. However, the use of synthetic data does not\nimprove the results for task C. We participated in the three subtasks. Our\napproach still has much room for improvement, especially in the two\nfine-grained classifications. All our code is available in the repository\nhttps://github.com/isegura/hulat_edos.\n","authors":["Isabel Segura-Bedmar"],"pdf_url":"https://arxiv.org/pdf/2302.12840v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2302.12794"},{"id":"http://arxiv.org/abs/2302.13812v1","updated":"2023-02-24T14:59:02Z","published":"2023-02-24T14:59:02Z","title":"Adapting Pre-trained Language Models for Quantum Natural Language\n  Processing","summary":"  The emerging classical-quantum transfer learning paradigm has brought a\ndecent performance to quantum computational models in many tasks, such as\ncomputer vision, by enabling a combination of quantum models and classical\npre-trained neural networks. However, using quantum computing with pre-trained\nmodels has yet to be explored in natural language processing (NLP). Due to the\nhigh linearity constraints of the underlying quantum computing infrastructures,\nexisting Quantum NLP models are limited in performance on real tasks. We fill\nthis gap by pre-training a sentence state with complex-valued BERT-like\narchitecture, and adapting it to the classical-quantum transfer learning scheme\nfor sentence classification. On quantum simulation experiments, the pre-trained\nrepresentation can bring 50\\% to 60\\% increases to the capacity of end-to-end\nquantum models.\n","authors":["Qiuchi Li","Benyou Wang","Yudong Zhu","Christina Lioma","Qun Liu"],"pdf_url":"https://arxiv.org/pdf/2302.13812v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.12828v1","updated":"2023-02-24T18:59:18Z","published":"2023-02-24T18:59:18Z","title":"SplineCam: Exact Visualization and Characterization of Deep Network\n  Geometry and Decision Boundaries","summary":"  Current Deep Network (DN) visualization and interpretability methods rely\nheavily on data space visualizations such as scoring which dimensions of the\ndata are responsible for their associated prediction or generating new data\nfeatures or samples that best match a given DN unit or representation. In this\npaper, we go one step further by developing the first provably exact method for\ncomputing the geometry of a DN's mapping - including its decision boundary -\nover a specified region of the data space. By leveraging the theory of\nContinuous Piece-Wise Linear (CPWL) spline DNs, SplineCam exactly computes a\nDNs geometry without resorting to approximations such as sampling or\narchitecture simplification. SplineCam applies to any DN architecture based on\nCPWL nonlinearities, including (leaky-)ReLU, absolute value, maxout, and\nmax-pooling and can also be applied to regression DNs such as implicit neural\nrepresentations. Beyond decision boundary visualization and characterization,\nSplineCam enables one to compare architectures, measure generalizability and\nsample from the decision boundary on or off the manifold. Project Website:\nbit.ly/splinecam.\n","authors":["Ahmed Imtiaz Humayun","Randall Balestriero","Guha Balakrishnan","Richard Baraniuk"],"pdf_url":"https://arxiv.org/pdf/2302.12828v1.pdf","comment":"11 pages, 20 figures"},{"id":"http://arxiv.org/abs/2302.12827v1","updated":"2023-02-24T18:59:15Z","published":"2023-02-24T18:59:15Z","title":"Decoupling Human and Camera Motion from Videos in the Wild","summary":"  We propose a method to reconstruct global human trajectories from videos in\nthe wild. Our optimization method decouples the camera and human motion, which\nallows us to place people in the same world coordinate frame. Most existing\nmethods do not model the camera motion; methods that rely on the background\npixels to infer 3D human motion usually require a full scene reconstruction,\nwhich is often not possible for in-the-wild videos. However, even when existing\nSLAM systems cannot recover accurate scene reconstructions, the background\npixel motion still provides enough signal to constrain the camera motion. We\nshow that relative camera estimates along with data-driven human motion priors\ncan resolve the scene scale ambiguity and recover global human trajectories.\nOur method robustly recovers the global 3D trajectories of people in\nchallenging in-the-wild videos, such as PoseTrack. We quantify our improvement\nover existing methods on 3D human dataset Egobody. We further demonstrate that\nour recovered camera scale allows us to reason about motion of multiple people\nin a shared coordinate frame, which improves performance of downstream tracking\nin PoseTrack. Code and video results can be found at\nhttps://vye16.github.io/slahmr.\n","authors":["Vickie Ye","Georgios Pavlakos","Jitendra Malik","Angjoo Kanazawa"],"pdf_url":"https://arxiv.org/pdf/2302.12827v1.pdf","comment":"Project site: https://vye16.github.io/slahmr"},{"id":"http://arxiv.org/abs/2301.08365v3","updated":"2023-02-24T18:29:19Z","published":"2023-01-20T00:05:18Z","title":"On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction","summary":"  Purpose: Acquiring fully-sampled MRI $k$-space data is time-consuming, and\ncollecting accelerated data can reduce the acquisition time. Employing 2D\nCartesian-rectilinear subsampling schemes is a conventional approach for\naccelerated acquisitions; however, this often results in imprecise\nreconstructions, even with the use of Deep Learning (DL), especially at high\nacceleration factors. Non-rectilinear or non-Cartesian trajectories can be\nimplemented in MRI scanners as alternative subsampling options. This work\ninvestigates the impact of the $k$-space subsampling scheme on the quality of\nreconstructed accelerated MRI measurements produced by trained DL models.\n  Methods: The Recurrent Variational Network (RecurrentVarNet) was used as the\nDL-based MRI-reconstruction architecture. Cartesian, fully-sampled multi-coil\n$k$-space measurements from three datasets were retrospectively subsampled with\ndifferent accelerations using eight distinct subsampling schemes: four\nCartesian-rectilinear, two Cartesian non-rectilinear, and two non-Cartesian.\nExperiments were conducted in two frameworks: scheme-specific, where a distinct\nmodel was trained and evaluated for each dataset-subsampling scheme pair, and\nmulti-scheme, where for each dataset a single model was trained on data\nrandomly subsampled by any of the eight schemes and evaluated on data\nsubsampled by all schemes.\n  Results: In both frameworks, RecurrentVarNets trained and evaluated on\nnon-rectilinearly subsampled data demonstrated superior performance,\nparticularly for high accelerations. In the multi-scheme setting,\nreconstruction performance on rectilinearly subsampled data improved when\ncompared to the scheme-specific experiments.\n  Conclusion: Our findings demonstrate the potential for using DL-based\nmethods, trained on non-rectilinearly subsampled measurements, to optimize scan\ntime and image quality.\n","authors":["George Yiasemis","Clara I. Sánchez","Jan-Jakob Sonke","Jonas Teuwen"],"pdf_url":"https://arxiv.org/pdf/2301.08365v3.pdf","comment":"22 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2302.05916v3","updated":"2023-02-24T18:27:30Z","published":"2023-02-12T13:47:26Z","title":"Video Waterdrop Removal via Spatio-Temporal Fusion in Driving Scenes","summary":"  The waterdrops on windshields during driving can cause severe visual\nobstructions, which may lead to car accidents. Meanwhile, the waterdrops can\nalso degrade the performance of a computer vision system in autonomous driving.\nTo address these issues, we propose an attention-based framework that fuses the\nspatio-temporal representations from multiple frames to restore visual\ninformation occluded by waterdrops. Due to the lack of training data for video\nwaterdrop removal, we propose a large-scale synthetic dataset with simulated\nwaterdrops in complex driving scenes on rainy days. To improve the generality\nof our proposed method, we adopt a cross-modality training strategy that\ncombines synthetic videos and real-world images. Extensive experiments show\nthat our proposed method can generalize well and achieve the best waterdrop\nremoval performance in complex real-world driving scenes.\n","authors":["Qiang Wen","Yue Wu","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2302.05916v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12798v1","updated":"2023-02-24T18:19:49Z","published":"2023-02-24T18:19:49Z","title":"3D Generative Model Latent Disentanglement via Local Eigenprojection","summary":"  Designing realistic digital humans is extremely complex. Most data-driven\ngenerative models used to simplify the creation of their underlying geometric\nshape do not offer control over the generation of local shape attributes. In\nthis paper, we overcome this limitation by introducing a novel loss function\ngrounded in spectral geometry and applicable to different neural-network-based\ngenerative models of 3D head and body meshes. Encouraging the latent variables\nof mesh variational autoencoders (VAEs) or generative adversarial networks\n(GANs) to follow the local eigenprojections of identity attributes, we improve\nlatent disentanglement and properly decouple the attribute creation.\nExperimental results show that our local eigenprojection disentangled (LED)\nmodels not only offer improved disentanglement with respect to the\nstate-of-the-art, but also maintain good generation capabilities with training\ntimes comparable to the vanilla implementations of the models.\n","authors":["Simone Foti","Bongjin Koo","Danail Stoyanov","Matthew J. Clarkson"],"pdf_url":"https://arxiv.org/pdf/2302.12798v1.pdf","comment":"Accept after minor revisions at Computer Graphics Forum 2023 (this\n  manuscript is the revised version)"},{"id":"http://arxiv.org/abs/2302.12772v1","updated":"2023-02-24T17:39:53Z","published":"2023-02-24T17:39:53Z","title":"FLSea: Underwater Visual-Inertial and Stereo-Vision Forward-Looking\n  Datasets","summary":"  Visibility underwater is challenging, and degrades as the distance between\nthe subject and camera increases, making vision tasks in the forward-looking\ndirection more difficult. We have collected underwater forward-looking\nstereo-vision and visual-inertial image sets in the Mediterranean and Red Sea.\nTo our knowledge there are no other public datasets in the underwater\nenvironment acquired with this camera-sensor orientation published with\nground-truth. These datasets are critical for the development of several\nunderwater applications, including obstacle avoidance, visual odometry, 3D\ntracking, Simultaneous Localization and Mapping (SLAM) and depth estimation.\nThe stereo datasets include synchronized stereo images in dynamic underwater\nenvironments with objects of known-size. The visual-inertial datasets contain\nmonocular images and IMU measurements, aligned with millisecond resolution\ntimestamps and objects of known size which were placed in the scene. Both\nsensor configurations allow for scale estimation, with the calibrated baseline\nin the stereo setup and the IMU in the visual-inertial setup. Ground truth\ndepth maps were created offline for both dataset types using photogrammetry.\nThe ground truth is validated with multiple known measurements placed\nthroughout the imaged environment. There are 5 stereo and 8 visual-inertial\ndatasets in total, each containing thousands of images, with a range of\ndifferent underwater visibility and ambient light conditions, natural and\nman-made structures and dynamic camera motions. The forward-looking orientation\nof the camera makes these datasets unique and ideal for testing underwater\nobstacle-avoidance algorithms and for navigation close to the seafloor in\ndynamic environments. With our datasets, we hope to encourage the advancement\nof autonomous functionality for underwater vehicles in dynamic and/or shallow\nwater environments.\n","authors":["Yelena Randall","Tali Treibitz"],"pdf_url":"https://arxiv.org/pdf/2302.12772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12766v1","updated":"2023-02-24T17:29:31Z","published":"2023-02-24T17:29:31Z","title":"Language-Driven Representation Learning for Robotics","summary":"  Recent work in visual representation learning for robotics demonstrates the\nviability of learning from large video datasets of humans performing everyday\ntasks. Leveraging methods such as masked autoencoding and contrastive learning,\nthese representations exhibit strong transfer to policy learning for visuomotor\ncontrol. But, robot learning encompasses a diverse set of problems beyond\ncontrol including grasp affordance prediction, language-conditioned imitation\nlearning, and intent scoring for human-robot collaboration, amongst others.\nFirst, we demonstrate that existing representations yield inconsistent results\nacross these tasks: masked autoencoding approaches pick up on low-level spatial\nfeatures at the cost of high-level semantics, while contrastive learning\napproaches capture the opposite. We then introduce Voltron, a framework for\nlanguage-driven representation learning from human videos and associated\ncaptions. Voltron trades off language-conditioned visual reconstruction to\nlearn low-level visual patterns, and visually-grounded language generation to\nencode high-level semantics. We also construct a new evaluation suite spanning\nfive distinct robot learning problems $\\unicode{x2013}$ a unified platform for\nholistically evaluating visual representations for robotics. Through\ncomprehensive, controlled experiments across all five problems, we find that\nVoltron's language-driven representations outperform the prior\nstate-of-the-art, especially on targeted problems requiring higher-level\nfeatures.\n","authors":["Siddharth Karamcheti","Suraj Nair","Annie S. Chen","Thomas Kollar","Chelsea Finn","Dorsa Sadigh","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2302.12766v1.pdf","comment":"30 Pages, 15 Figures"},{"id":"http://arxiv.org/abs/2302.12764v1","updated":"2023-02-24T17:28:08Z","published":"2023-02-24T17:28:08Z","title":"Modulating Pretrained Diffusion Models for Multimodal Image Synthesis","summary":"  We present multimodal conditioning modules (MCM) for enabling conditional\nimage synthesis using pretrained diffusion models. Previous multimodal\nsynthesis works rely on training networks from scratch or fine-tuning\npretrained networks, both of which are computationally expensive for large,\nstate-of-the-art diffusion models. Our method uses pretrained networks but does\nnot require any updates to the diffusion network's parameters. MCM is a small\nmodule trained to modulate the diffusion network's predictions during sampling\nusing 2D modalities (e.g., semantic segmentation maps, sketches) that were\nunseen during the original training of the diffusion model. We show that MCM\nenables user control over the spatial layout of the image and leads to\nincreased control over the image generation process. Training MCM is cheap as\nit does not require gradients from the original diffusion net, consists of only\n$\\sim$1$\\%$ of the number of parameters of the base diffusion model, and is\ntrained using only a limited number of training examples. We evaluate our\nmethod on unconditional and text-conditional models to demonstrate the improved\ncontrol over the generated images and their alignment with respect to the\nconditioning inputs.\n","authors":["Cusuh Ham","James Hays","Jingwan Lu","Krishna Kumar Singh","Zhifei Zhang","Tobias Hinz"],"pdf_url":"https://arxiv.org/pdf/2302.12764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12712v1","updated":"2023-02-24T16:15:11Z","published":"2023-02-24T16:15:11Z","title":"Amortised Invariance Learning for Contrastive Self-Supervision","summary":"  Contrastive self-supervised learning methods famously produce high quality\ntransferable representations by learning invariances to different data\naugmentations. Invariances established during pre-training can be interpreted\nas strong inductive biases. However these may or may not be helpful, depending\non if they match the invariance requirements of downstream tasks or not. This\nhas led to several attempts to learn task-specific invariances during\npre-training, however, these methods are highly compute intensive and tedious\nto train. We introduce the notion of amortised invariance learning for\ncontrastive self supervision. In the pre-training stage, we parameterize the\nfeature extractor by differentiable invariance hyper-parameters that control\nthe invariances encoded by the representation. Then, for any downstream task,\nboth linear readout and task-specific invariance requirements can be\nefficiently and effectively learned by gradient-descent. We evaluate the notion\nof amortised invariances for contrastive learning over two different\nmodalities: vision and audio, on two widely-used contrastive learning methods\nin vision: SimCLR and MoCo-v2 with popular architectures like ResNets and\nVision Transformers, and SimCLR with ResNet-18 for audio. We show that our\namortised features provide a reliable way to learn diverse downstream tasks\nwith different invariance requirements, while using a single feature and\navoiding task-specific pre-training. This provides an exciting perspective that\nopens up new horizons in the field of general purpose representation learning.\n","authors":["Ruchika Chavhan","Henry Gouk","Jan Stuehmer","Calum Heggan","Mehrdad Yaghoobi","Timothy Hospedales"],"pdf_url":"https://arxiv.org/pdf/2302.12712v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2301.13381v2","updated":"2023-02-24T15:56:45Z","published":"2023-01-31T03:06:47Z","title":"When Source-Free Domain Adaptation Meets Learning with Noisy Labels","summary":"  Recent state-of-the-art source-free domain adaptation (SFDA) methods have\nfocused on learning meaningful cluster structures in the feature space, which\nhave succeeded in adapting the knowledge from source domain to unlabeled target\ndomain without accessing the private source data. However, existing methods\nrely on the pseudo-labels generated by source models that can be noisy due to\ndomain shift. In this paper, we study SFDA from the perspective of learning\nwith label noise (LLN). Unlike the label noise in the conventional LLN\nscenario, we prove that the label noise in SFDA follows a different\ndistribution assumption. We also prove that such a difference makes existing\nLLN methods that rely on their distribution assumptions unable to address the\nlabel noise in SFDA. Empirical evidence suggests that only marginal\nimprovements are achieved when applying the existing LLN methods to solve the\nSFDA problem. On the other hand, although there exists a fundamental difference\nbetween the label noise in the two scenarios, we demonstrate theoretically that\nthe early-time training phenomenon (ETP), which has been previously observed in\nconventional label noise settings, can also be observed in the SFDA problem.\nExtensive experiments demonstrate significant improvements to existing SFDA\nalgorithms by leveraging ETP to address the label noise in SFDA.\n","authors":["Li Yi","Gezheng Xu","Pengcheng Xu","Jiaqi Li","Ruizhi Pu","Charles Ling","A. Ian McLeod","Boyu Wang"],"pdf_url":"https://arxiv.org/pdf/2301.13381v2.pdf","comment":"ICLR 2023 camera-ready"},{"id":"http://arxiv.org/abs/2302.12688v1","updated":"2023-02-24T15:26:31Z","published":"2023-02-24T15:26:31Z","title":"Video4MRI: An Empirical Study on Brain Magnetic Resonance Image\n  Analytics with CNN-based Video Classification Frameworks","summary":"  To address the problem of medical image recognition, computer vision\ntechniques like convolutional neural networks (CNN) are frequently used.\nRecently, 3D CNN-based models dominate the field of magnetic resonance image\n(MRI) analytics. Due to the high similarity between MRI data and videos, we\nconduct extensive empirical studies on video recognition techniques for MRI\nclassification to answer the questions: (1) can we directly use video\nrecognition models for MRI classification, (2) which model is more appropriate\nfor MRI, (3) are the common tricks like data augmentation in video recognition\nstill useful for MRI classification? Our work suggests that advanced video\ntechniques benefit MRI classification. In this paper, four datasets of\nAlzheimer's and Parkinson's disease recognition are utilized in experiments,\ntogether with three alternative video recognition models and data augmentation\ntechniques that are frequently applied to video tasks. In terms of efficiency,\nthe results reveal that the video framework performs better than 3D-CNN models\nby 5% - 11% with 50% - 66% less trainable parameters. This report pushes\nforward the potential fusion of 3D medical imaging and video understanding\nresearch.\n","authors":["Yuxuan Zhang","Qingzhong Wang","Jiang Bian","Yi Liu","Yanwu Xu","Dejing Dou","Haoyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2302.12688v1.pdf","comment":"Accepted by IEEE ISBI'23"},{"id":"http://arxiv.org/abs/2302.12662v1","updated":"2023-02-24T14:27:41Z","published":"2023-02-24T14:27:41Z","title":"FedDBL: Communication and Data Efficient Federated Deep-Broad Learning\n  for Histopathological Tissue Classification","summary":"  Histopathological tissue classification is a fundamental task in\ncomputational pathology. Deep learning-based models have achieved superior\nperformance but centralized training with data centralization suffers from the\nprivacy leakage problem. Federated learning (FL) can safeguard privacy by\nkeeping training samples locally, but existing FL-based frameworks require a\nlarge number of well-annotated training samples and numerous rounds of\ncommunication which hinder their practicability in the real-world clinical\nscenario. In this paper, we propose a universal and lightweight federated\nlearning framework, named Federated Deep-Broad Learning (FedDBL), to achieve\nsuperior classification performance with limited training samples and only\none-round communication. By simply associating a pre-trained deep learning\nfeature extractor, a fast and lightweight broad learning inference system and a\nclassical federated aggregation approach, FedDBL can dramatically reduce data\ndependency and improve communication efficiency. Five-fold cross-validation\ndemonstrates that FedDBL greatly outperforms the competitors with only\none-round communication and limited training samples, while it even achieves\ncomparable performance with the ones under multiple-round communications.\nFurthermore, due to the lightweight design and one-round communication, FedDBL\nreduces the communication burden from 4.6GB to only 276.5KB per client using\nthe ResNet-50 backbone at 50-round training. Since no data or deep model\nsharing across different clients, the privacy issue is well-solved and the\nmodel security is guaranteed with no model inversion attack risk. Code is\navailable at https://github.com/tianpeng-deng/FedDBL.\n","authors":["Tianpeng Deng","Yanqi Huang","Zhenwei Shi","Jiatai Lin","Qi Dou","Ke Zhao","Fang-Fang Liu","Yu-Mian Jia","Jin Wang","Bingchao Zhao","Changhong Liang","Zaiyi Liu","Xiao-jing Guo","Guoqiang Han","Xin Chen","Chu Han"],"pdf_url":"https://arxiv.org/pdf/2302.12662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12656v1","updated":"2023-02-24T14:24:58Z","published":"2023-02-24T14:24:58Z","title":"COVERED, CollabOratiVE Robot Environment Dataset for 3D Semantic\n  segmentation","summary":"  Safe human-robot collaboration (HRC) has recently gained a lot of interest\nwith the emerging Industry 5.0 paradigm. Conventional robots are being replaced\nwith more intelligent and flexible collaborative robots (cobots). Safe and\nefficient collaboration between cobots and humans largely relies on the cobot's\ncomprehensive semantic understanding of the dynamic surrounding of industrial\nenvironments. Despite the importance of semantic understanding for such\napplications, 3D semantic segmentation of collaborative robot workspaces lacks\nsufficient research and dedicated datasets. The performance limitation caused\nby insufficient datasets is called 'data hunger' problem. To overcome this\ncurrent limitation, this work develops a new dataset specifically designed for\nthis use case, named \"COVERED\", which includes point-wise annotated point\nclouds of a robotic cell. Lastly, we also provide a benchmark of current\nstate-of-the-art (SOTA) algorithm performance on the dataset and demonstrate a\nreal-time semantic segmentation of a collaborative robot workspace using a\nmulti-LiDAR system. The promising results from using the trained Deep Networks\non a real-time dynamically changing situation shows that we are on the right\ntrack. Our perception pipeline achieves 20Hz throughput with a prediction point\naccuracy of $>$96\\% and $>$92\\% mean intersection over union (mIOU) while\nmaintaining an 8Hz throughput.\n","authors":["Charith Munasinghe","Fatemeh Mohammadi Amin","Davide Scaramuzza","Hans Wernher van de Venn"],"pdf_url":"https://arxiv.org/pdf/2302.12656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11970v2","updated":"2023-02-24T13:41:35Z","published":"2023-02-23T12:40:36Z","title":"ArtiFact: A Large-Scale Dataset with Artificial and Factual Images for\n  Generalizable and Robust Synthetic Image Detection","summary":"  Synthetic image generation has opened up new opportunities but has also\ncreated threats in regard to privacy, authenticity, and security. Detecting\nfake images is of paramount importance to prevent illegal activities, and\nprevious research has shown that generative models leave unique patterns in\ntheir synthetic images that can be exploited to detect them. However, the\nfundamental problem of generalization remains, as even state-of-the-art\ndetectors encounter difficulty when facing generators never seen during\ntraining. To assess the generalizability and robustness of synthetic image\ndetectors in the face of real-world impairments, this paper presents a\nlarge-scale dataset named ArtiFact, comprising diverse generators, object\ncategories, and real-world challenges. Moreover, the proposed multi-class\nclassification scheme, combined with a filter stride reduction strategy\naddresses social platform impairments and effectively detects synthetic images\nfrom both seen and unseen generators. The proposed solution significantly\noutperforms other top teams by 8.34% on Test 1, 1.26% on Test 2, and 15.08% on\nTest 3 in the IEEE VIP Cup challenge at ICIP 2022, as measured by the accuracy\nmetric.\n","authors":["Md Awsafur Rahman","Bishmoy Paul","Najibul Haque Sarker","Zaber Ibn Abdul Hakim","Shaikh Anowarul Fattah"],"pdf_url":"https://arxiv.org/pdf/2302.11970v2.pdf","comment":"Figures High-Res"},{"id":"http://arxiv.org/abs/2302.08646v2","updated":"2023-02-24T12:34:33Z","published":"2023-02-17T01:31:53Z","title":"AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust\n  Autonomous Driving","summary":"  Object detection with on-board sensors (e.g., lidar, radar, and camera) play\na crucial role in autonomous driving (AD), and these sensors complement each\nother in modalities. While crowdsensing may potentially exploit these sensors\n(of huge quantity) to derive more comprehensive knowledge, \\textit{federated\nlearning} (FL) appears to be the necessary tool to reach this potential: it\nenables autonomous vehicles (AVs) to train machine learning models without\nexplicitly sharing raw sensory data. However, the multimodal sensors introduce\nvarious data heterogeneity across distributed AVs (e.g., label quantity skews\nand varied modalities), posing critical challenges to effective FL. To this\nend, we present AutoFed as a heterogeneity-aware FL framework to fully exploit\nmultimodal sensory data on AVs and thus enable robust AD. Specifically, we\nfirst propose a novel model leveraging pseudo-labeling to avoid mistakenly\ntreating unlabeled objects as the background. We also propose an\nautoencoder-based data imputation method to fill missing data modality (of\ncertain AVs) with the available ones. To further reconcile the heterogeneity,\nwe finally present a client selection mechanism exploiting the similarities\namong client models to improve both training stability and convergence rate.\nOur experiments on benchmark dataset confirm that AutoFed substantially\nimproves over status quo approaches in both precision and recall, while\ndemonstrating strong robustness to adverse weather conditions.\n","authors":["Tianyue Zheng","Ang Li","Zhe Chen","Hongbo Wang","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2302.08646v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12593v1","updated":"2023-02-24T12:11:05Z","published":"2023-02-24T12:11:05Z","title":"Effect of Lossy Compression Algorithms on Face Image Quality and\n  Recognition","summary":"  Lossy face image compression can degrade the image quality and the utility\nfor the purpose of face recognition. This work investigates the effect of lossy\nimage compression on a state-of-the-art face recognition model, and on multiple\nface image quality assessment models. The analysis is conducted over a range of\nspecific image target sizes. Four compression types are considered, namely\nJPEG, JPEG 2000, downscaled PNG, and notably the new JPEG XL format. Frontal\ncolor images from the ColorFERET database were used in a Region Of Interest\n(ROI) variant and a portrait variant. We primarily conclude that JPEG XL allows\nfor superior mean and worst case face recognition performance especially at\nlower target sizes, below approximately 5kB for the ROI variant, while there\nappears to be no critical advantage among the compression types at higher\ntarget sizes. Quality assessments from modern models correlate well overall\nwith the compression effect on face recognition performance.\n","authors":["Torsten Schlett","Sebastian Schachner","Christian Rathgeb","Juan Tapia","Christoph Busch"],"pdf_url":"https://arxiv.org/pdf/2302.12593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12591v1","updated":"2023-02-24T12:04:46Z","published":"2023-02-24T12:04:46Z","title":"Classification of structural building damage grades from multi-temporal\n  photogrammetric point clouds using a machine learning model trained on\n  virtual laser scanning data","summary":"  Automatic damage assessment based on UAV-derived 3D point clouds can provide\nfast information on the damage situation after an earthquake. However, the\nassessment of multiple damage grades is challenging due to the variety in\ndamage patterns and limited transferability of existing methods to other\ngeographic regions or data sources. We present a novel approach to\nautomatically assess multi-class building damage from real-world multi-temporal\npoint clouds using a machine learning model trained on virtual laser scanning\n(VLS) data. We (1) identify object-specific change features, (2) separate\nchanged and unchanged building parts, (3) train a random forest machine\nlearning model with VLS data based on object-specific change features, and (4)\nuse the classifier to assess building damage in real-world point clouds from\nphotogrammetry-based dense image matching (DIM). We evaluate classifiers\ntrained on different input data with respect to their capacity to classify\nthree damage grades (heavy, extreme, destruction) in pre- and post-event DIM\npoint clouds of a real earthquake event. Our approach is transferable with\nrespect to multi-source input point clouds used for training (VLS) and\napplication (DIM) of the model. We further achieve geographic transferability\nof the model by training it on simulated data of geometric change which\ncharacterises relevant damage grades across different geographic regions. The\nmodel yields high multi-target classification accuracies (overall accuracy:\n92.0% - 95.1%). Its performance improves only slightly when using real-world\nregion-specific training data (< 3% higher overall accuracies) and when using\nreal-world region-specific training data (< 2% higher overall accuracies). We\nconsider our approach relevant for applications where timely information on the\ndamage situation is required and sufficient real-world training data is not\navailable.\n","authors":["Vivien Zahs","Katharina Anders","Julia Kohns","Alexander Stark","Bernhard Höfle"],"pdf_url":"https://arxiv.org/pdf/2302.12591v1.pdf","comment":"29 pages, 12 figures"},{"id":"http://arxiv.org/abs/2302.12589v1","updated":"2023-02-24T11:56:57Z","published":"2023-02-24T11:56:57Z","title":"Revisiting Modality Imbalance In Multimodal Pedestrian Detection","summary":"  Multimodal learning, particularly for pedestrian detection, has recently\nreceived emphasis due to its capability to function equally well in several\ncritical autonomous driving scenarios such as low-light, night-time, and\nadverse weather conditions. However, in most cases, the training distribution\nlargely emphasizes the contribution of one specific input that makes the\nnetwork biased towards one modality. Hence, the generalization of such models\nbecomes a significant problem where the non-dominant input modality during\ntraining could be contributing more to the course of inference. Here, we\nintroduce a novel training setup with regularizer in the multimodal\narchitecture to resolve the problem of this disparity between the modalities.\nSpecifically, our regularizer term helps to make the feature fusion method more\nrobust by considering both the feature extractors equivalently important during\nthe training to extract the multimodal distribution which is referred to as\nremoving the imbalance problem. Furthermore, our decoupling concept of output\nstream helps the detection task by sharing the spatial sensitive information\nmutually. Extensive experiments of the proposed method on KAIST and UTokyo\ndatasets shows improvement of the respective state-of-the-art performance.\n","authors":["Arindam Das","Sudip Das","Ganesh Sistu","Jonathan Horgan","Ujjwal Bhattacharya","Edward Jones","Martin Glavin","Ciarán Eising"],"pdf_url":"https://arxiv.org/pdf/2302.12589v1.pdf","comment":"5 pages, 3 figure, 4 tables"},{"id":"http://arxiv.org/abs/2106.03503v2","updated":"2023-02-24T11:14:37Z","published":"2021-06-07T10:46:26Z","title":"The Distance Transform and its Computation","summary":"  Distance transformation is an image processing technique used for many\ndifferent applications. Related to a binary image, the general idea is to\ndetermine the distance of all background points to the nearest object point (or\nvice versa). In this tutorial, different approaches are explained in detail and\ncompared using examples. Corresponding source code is provided to facilitate\nown investigations. A particular objective of this tutorial is to clarify the\ndifference between arbitrary distance transforms and exact Euclidean distance\ntransformations.\n","authors":["Tilo Strutz"],"pdf_url":"https://arxiv.org/pdf/2106.03503v2.pdf","comment":"24 pages, 22 figures, 1 table, 9 listings"},{"id":"http://arxiv.org/abs/2302.12571v1","updated":"2023-02-24T10:52:08Z","published":"2023-02-24T10:52:08Z","title":"3D PETCT Tumor Lesion Segmentation via GCN Refinement","summary":"  Whole-body PET/CT scan is an important tool for diagnosing various\nmalignancies (e.g., malignant melanoma, lymphoma, or lung cancer), and accurate\nsegmentation of tumors is a key part for subsequent treatment. In recent years,\nCNN-based segmentation methods have been extensively investigated. However,\nthese methods often give inaccurate segmentation results, such as\nover-segmentation and under-segmentation. Therefore, to address such issues, we\npropose a post-processing method based on a graph convolutional neural network\n(GCN) to refine inaccurate segmentation parts and improve the overall\nsegmentation accuracy. Firstly, nnUNet is used as an initial segmentation\nframework, and the uncertainty in the segmentation results is analyzed.\nCertainty and uncertainty nodes establish the nodes of a graph neural network.\nEach node and its 6 neighbors form an edge, and 32 nodes are randomly selected\nfor uncertain nodes to form edges. The highly uncertain nodes are taken as the\nsubsequent refinement targets. Secondly, the nnUNet result of the certainty\nnodes is used as label to form a semi-supervised graph network problem, and the\nuncertainty part is optimized through training the GCN network to improve the\nsegmentation performance. This describes our proposed nnUNet-GCN segmentation\nframework. We perform tumor segmentation experiments on the PET/CT dataset in\nthe MICCIA2022 autoPET challenge. Among them, 30 cases are randomly selected\nfor testing, and the experimental results show that the false positive rate is\neffectively reduced with nnUNet-GCN refinement. In quantitative analysis, there\nis an improvement of 2.12 % on the average Dice score, 6.34 on 95 % Hausdorff\nDistance (HD95), and 1.72 on average symmetric surface distance (ASSD). The\nquantitative and qualitative evaluation results show that GCN post-processing\nmethods can effectively improve tumor segmentation performance.\n","authors":["Hengzhi Xue","Qingqing Fang","Yudong Yao","Yueyang Teng"],"pdf_url":"https://arxiv.org/pdf/2302.12571v1.pdf","comment":"10 pages,5 figures,38 reference"},{"id":"http://arxiv.org/abs/2302.03014v3","updated":"2023-02-24T10:50:28Z","published":"2023-02-06T18:54:14Z","title":"Detection and Localization of Melanoma Skin Cancer in Histopathological\n  Whole Slide Images","summary":"  Melanoma diagnosed and treated in its early stages can increase the survival\nrate. A projected increase in skin cancer incidents and a dearth of\ndermatopathologists have emphasized the need for computational pathology\n(CPATH) systems. CPATH systems with deep learning (DL) models have the\npotential to identify the presence of melanoma by exploiting underlying\nmorphological and cellular features. This paper proposes a DL method to detect\nmelanoma and distinguish between normal skin and benign/malignant melanocytic\nlesions in Whole Slide Images (WSI). Our method detects lesions with high\naccuracy and localizes them on a WSI to identify potential regions of interest\nfor pathologists. Interestingly, our DL method relies on using a single CNN\nnetwork to create localization maps first and use them to perform slide-level\npredictions to determine patients who have melanoma. Our best model provides\nfavorable patch-wise classification results with a 0.992 F1 score and 0.99\nsensitivity on unseen data. The source code is\nhttps://github.com/RogerAmundsen/Melanoma-Diagnosis-and-Localization-from-Whole-Slide-Images-using-Convolutional-Neural-Networks.\n","authors":["Neel Kanwal","Roger Amundsen","Helga Hardardottir","Luca Tomasetti","Erling Sandoy Undersrud","Emiel A. M. Janssen","Kjersti Engan"],"pdf_url":"https://arxiv.org/pdf/2302.03014v3.pdf","comment":"Submitted to EUSIPCO 23"},{"id":"http://arxiv.org/abs/2212.08490v4","updated":"2023-02-24T10:36:58Z","published":"2022-12-16T14:02:12Z","title":"LOCT: A Lightweight Network Using OC-Transformer for Extracting\n  Buildings and Roads from UAV Aerial Remote Sensing Images","summary":"  Semantic segmentation for extracting buildings and roads, from unmanned\naerial vehicle (UAV) remote sensing images by deep learning becomes a more\nefficient and convenient method than traditional manual segmentation in\nsurveying and mapping field. In order to make the model lightweight and improve\nthe model accuracy, A Lightweight Network Using OC-Transformer (LOCT) for\nBuildings and Roads from UAV Aerial Remote Sensing Images is proposed. The\nproposed network adopts an encoder-decoder architecture in which a Lightweight\nDensely Connected Network (LDCNet) is developed as the encoder. In the decoder\npart, the dual multi-scale context modules which consist of the Atrous Spatial\nPyramid Pooling module (ASPP) and the Object Contextual Transformer module\n(OC-Transformer) are designed to capture more context information from feature\nmaps of UAV remote sensing images. Between ASPP and OC-Transformer, a Feature\nPyramid Network (FPN) module is used to and fuse multi-scale features\nextracting from ASPP. A private dataset of remote sensing images taken by UAV\nwhich contains 2431 training sets, 945 validation sets, and 475 test sets is\nconstructed. The proposed model performs well on this dataset, with only 1.4M\nparameters and 5.48G floating-point operations (FLOPs), achieving an mean\nintersection-over-union ratio (mIoU) of 71.12%. More extensive experiments on\nthe public LoveDA dataset and CITY-OSM dataset to further verify the\neffectiveness of the proposed model with excellent results on mIoU of 65.27%\nand 74.39%, respectively. The source code will be made available on\nhttps://github.com/GtLinyer/LOCT .\n","authors":["Xiaoxiang Han","Yiman Liu","Gang Liu","Yuanjie Lin","Qiaohong Liu"],"pdf_url":"https://arxiv.org/pdf/2212.08490v4.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2302.12562v1","updated":"2023-02-24T10:31:29Z","published":"2023-02-24T10:31:29Z","title":"A Knowledge Distillation framework for Multi-Organ Segmentation of\n  Medaka Fish in Tomographic Image","summary":"  Morphological atlases are an important tool in organismal studies, and modern\nhigh-throughput Computed Tomography (CT) facilities can produce hundreds of\nfull-body high-resolution volumetric images of organisms. However, creating an\natlas from these volumes requires accurate organ segmentation. In the last\ndecade, machine learning approaches have achieved incredible results in image\nsegmentation tasks, but they require large amounts of annotated data for\ntraining. In this paper, we propose a self-training framework for multi-organ\nsegmentation in tomographic images of Medaka fish. We utilize the\npseudo-labeled data from a pretrained Teacher model and adopt a Quality\nClassifier to refine the pseudo-labeled data. Then, we introduce a pixel-wise\nknowledge distillation method to prevent overfitting to the pseudo-labeled data\nand improve the segmentation performance. The experimental results demonstrate\nthat our method improves mean Intersection over Union (IoU) by 5.9% on the full\ndataset and enables keeping the quality while using three times less markup.\n","authors":["Jwalin Bhatt","Yaroslav Zharov","Sungho Suh","Tilo Baumbach","Vincent Heuveline","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2302.12562v1.pdf","comment":"Accepted at IEEE International Symposium on Biomedical Imaging 2023\n  (ISBI 2023)"},{"id":"http://arxiv.org/abs/2302.12552v1","updated":"2023-02-24T10:14:35Z","published":"2023-02-24T10:14:35Z","title":"Deep Learning for Video-Text Retrieval: a Review","summary":"  Video-Text Retrieval (VTR) aims to search for the most relevant video related\nto the semantics in a given sentence, and vice versa. In general, this\nretrieval task is composed of four successive steps: video and textual feature\nrepresentation extraction, feature embedding and matching, and objective\nfunctions. In the last, a list of samples retrieved from the dataset is ranked\nbased on their matching similarities to the query. In recent years, significant\nand flourishing progress has been achieved by deep learning techniques,\nhowever, VTR is still a challenging task due to the problems like how to learn\nan efficient spatial-temporal video feature and how to narrow the cross-modal\ngap. In this survey, we review and summarize over 100 research papers related\nto VTR, demonstrate state-of-the-art performance on several commonly\nbenchmarked datasets, and discuss potential challenges and directions, with the\nexpectation to provide some insights for researchers in the field of video-text\nretrieval.\n","authors":["Cunjuan Zhu","Qi Jia","Wei Chen","Yanming Guo","Yu Liu"],"pdf_url":"https://arxiv.org/pdf/2302.12552v1.pdf","comment":"International Journal of Multimedia Information Retrieval (IJMIR)"},{"id":"http://arxiv.org/abs/2205.01614v3","updated":"2023-02-24T09:58:08Z","published":"2022-05-03T16:48:31Z","title":"Automatic Segmentation of Aircraft Dents in Point Clouds","summary":"  Dents on the aircraft skin are frequent and may easily go undetected during\nairworthiness checks, as their inspection process is tedious and extremely\nsubject to human factors and environmental conditions. Nowadays, 3D scanning\ntechnologies are being proposed for more reliable, human-independent\nmeasurements, yet the process of inspection and reporting remains laborious and\ntime consuming because data acquisition and validation are still carried out by\nthe engineer. For full automation of dent inspection, the acquired point cloud\ndata must be analysed via a reliable segmentation algorithm, releasing humans\nfrom the search and evaluation of damage. This paper reports on two\ndevelopments towards automated dent inspection. The first is a method to\ngenerate a synthetic dataset of dented surfaces to train a fully convolutional\nneural network. The training of machine learning algorithms needs a substantial\nvolume of dent data, which is not readily available. Dents are thus simulated\nin random positions and shapes, within criteria and definitions of a Boeing 737\nstructural repair manual. The noise distribution from the scanning apparatus is\nthen added to reflect the complete process of 3D point acquisition on the\ntraining. The second proposition is a surface fitting strategy to convert 3D\npoint clouds to 2.5D. This allows higher resolution point clouds to be\nprocessed with a small amount of memory compared with state-of-the-art methods\ninvolving 3D sampling approaches. Simulations with available ground truth data\nshow that the proposed technique reaches an intersection-over-union of over\n80%. Experiments over dent samples prove an effective detection of dents with a\nspeed of over 500 000 points per second.\n","authors":["Pasquale Lafiosca","Ip-Shing Fan","Nicolas P. Avdelidis"],"pdf_url":"https://arxiv.org/pdf/2205.01614v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12532v1","updated":"2023-02-24T09:36:31Z","published":"2023-02-24T09:36:31Z","title":"Pose-Controllable 3D Facial Animation Synthesis using Hierarchical\n  Audio-Vertex Attention","summary":"  Most of the existing audio-driven 3D facial animation methods suffered from\nthe lack of detailed facial expression and head pose, resulting in\nunsatisfactory experience of human-robot interaction. In this paper, a novel\npose-controllable 3D facial animation synthesis method is proposed by utilizing\nhierarchical audio-vertex attention. To synthesize real and detailed\nexpression, a hierarchical decomposition strategy is proposed to encode the\naudio signal into both a global latent feature and a local vertex-wise control\nfeature. Then the local and global audio features combined with vertex spatial\nfeatures are used to predict the final consistent facial animation via a graph\nconvolutional neural network by fusing the intrinsic spatial topology structure\nof the face model and the corresponding semantic feature of the audio. To\naccomplish pose-controllable animation, we introduce a novel pose attribute\naugmentation method by utilizing the 2D talking face technique. Experimental\nresults indicate that the proposed method can produce more realistic facial\nexpressions and head posture movements. Qualitative and quantitative\nexperiments show that the proposed method achieves competitive performance\nagainst state-of-the-art methods.\n","authors":["Bin Liu","Xiaolin Wei","Bo Li","Junjie Cao","Yu-Kun Lai"],"pdf_url":"https://arxiv.org/pdf/2302.12532v1.pdf","comment":"15 pages, 12 figures"},{"id":"http://arxiv.org/abs/2212.10988v3","updated":"2023-02-24T08:49:57Z","published":"2022-12-21T12:50:31Z","title":"Attention-Aware Anime Line Drawing Colorization","summary":"  Automatic colorization of anime line drawing has attracted much attention in\nrecent years since it can substantially benefit the animation industry.\nUser-hint based methods are the mainstream approach for line drawing\ncolorization, while reference-based methods offer a more intuitive approach.\nNevertheless, although reference-based methods can improve feature aggregation\nof the reference image and the line drawing, the colorization results are not\ncompelling in terms of color consistency or semantic correspondence. In this\npaper, we introduce an attention-based model for anime line drawing\ncolorization, in which a channel-wise and spatial-wise Convolutional Attention\nmodule is used to improve the ability of the encoder for feature extraction and\nkey area perception, and a Stop-Gradient Attention module with cross-attention\nand self-attention is used to tackle the cross-domain long-range dependency\nproblem. Extensive experiments show that our method outperforms other SOTA\nmethods, with more accurate line structure and semantic color information.\n","authors":["Yu Cao","Hao Tian","P. Y. Mok"],"pdf_url":"https://arxiv.org/pdf/2212.10988v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12505v1","updated":"2023-02-24T08:16:16Z","published":"2023-02-24T08:16:16Z","title":"Spatial Bias for Attention-free Non-local Neural Networks","summary":"  In this paper, we introduce the spatial bias to learn global knowledge\nwithout self-attention in convolutional neural networks. Owing to the limited\nreceptive field, conventional convolutional neural networks suffer from\nlearning long-range dependencies. Non-local neural networks have struggled to\nlearn global knowledge, but unavoidably have too heavy a network design due to\nthe self-attention operation. Therefore, we propose a fast and lightweight\nspatial bias that efficiently encodes global knowledge without self-attention\non convolutional neural networks. Spatial bias is stacked on the feature map\nand convolved together to adjust the spatial structure of the convolutional\nfeatures. Therefore, we learn the global knowledge on the convolution layer\ndirectly with very few additional resources. Our method is very fast and\nlightweight due to the attention-free non-local method while improving the\nperformance of neural networks considerably. Compared to non-local neural\nnetworks, the spatial bias use about 10 times fewer parameters while achieving\ncomparable performance with 1.6 ~ 3.3 times more throughput on a very little\nbudget. Furthermore, the spatial bias can be used with conventional non-local\nneural networks to further improve the performance of the backbone model. We\nshow that the spatial bias achieves competitive performance that improves the\nclassification accuracy by +0.79% and +1.5% on ImageNet-1K and cifar100\ndatasets. Additionally, we validate our method on the MS-COCO and ADE20K\ndatasets for downstream tasks involving object detection and semantic\nsegmentation.\n","authors":["Junhyung Go","Jongbin Ryu"],"pdf_url":"https://arxiv.org/pdf/2302.12505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12495v1","updated":"2023-02-24T07:29:13Z","published":"2023-02-24T07:29:13Z","title":"Data fusion of satellite imagery for generation of daily cloud free\n  images at high resolution level","summary":"  In this paper we discuss a new variational approach to the Date Fusion\nproblem of multi-spectral satellite images from Sentinel-2 and MODIS that have\nbeen captured at different resolution level and, arguably, on different days.\nThe crucial point of our approach that the MODIS image is cloud-free whereas\nthe images from Sentinel-2 can be corrupted by clouds or noise.\n","authors":["Natalya Ivanchuk","Peter Kogut","Petro Martyniuk"],"pdf_url":"https://arxiv.org/pdf/2302.12495v1.pdf","comment":"29 pages, 12 figures"},{"id":"http://arxiv.org/abs/2302.12491v1","updated":"2023-02-24T07:17:15Z","published":"2023-02-24T07:17:15Z","title":"Joint Learning of Blind Super-Resolution and Crack Segmentation for\n  Realistic Degraded Images","summary":"  This paper proposes crack segmentation augmented by super resolution (SR)\nwith deep neural networks. In the proposed method, a SR network is jointly\ntrained with a binary segmentation network in an end-to-end manner. This joint\nlearning allows the SR network to be optimized for improving segmentation\nresults. For realistic scenarios, the SR network is extended from non-blind to\nblind for processing a low-resolution image degraded by unknown blurs. The\njoint network is improved by our proposed two extra paths that further\nencourage the mutual optimization between SR and segmentation. Comparative\nexperiments with SoTA segmentation methods demonstrate the superiority of our\njoint learning, and various ablation studies prove the effects of our\ncontributions.\n","authors":["Yuki Kondoa","Norimichi Ukita"],"pdf_url":"https://arxiv.org/pdf/2302.12491v1.pdf","comment":"We have submitted this paper to Automation in Construction. The code\n  used in this paper will be made public"},{"id":"http://arxiv.org/abs/2302.12482v1","updated":"2023-02-24T06:48:29Z","published":"2023-02-24T06:48:29Z","title":"Disease Severity Regression with Continuous Data Augmentation","summary":"  Disease severity regression by a convolutional neural network (CNN) for\nmedical images requires a sufficient number of image samples labeled with\nseverity levels. Conditional generative adversarial network (cGAN)-based data\naugmentation (DA) is a possible solution, but it encounters two issues. The\nfirst issue is that existing cGANs cannot deal with real-valued severity levels\nas their conditions, and the second is that the severity of the generated\nimages is not fully reliable. We propose continuous DA as a solution to the two\nissues. Our method uses continuous severity GAN to generate images at\nreal-valued severity levels and dataset-disjoint multi-objective optimization\nto deal with the second issue. Our method was evaluated for estimating\nulcerative colitis (UC) severity of endoscopic images and achieved higher\nclassification performance than conventional DA methods.\n","authors":["Shumpei Takezaki","Kiyohito Tanaka","Seiichi Uchida","Takeaki Kadota"],"pdf_url":"https://arxiv.org/pdf/2302.12482v1.pdf","comment":"Accepted at ISBI2023"},{"id":"http://arxiv.org/abs/2302.12477v1","updated":"2023-02-24T06:37:36Z","published":"2023-02-24T06:37:36Z","title":"Frequency and Scale Perspectives of Feature Extraction","summary":"  Convolutional neural networks (CNNs) have achieved superior performance but\nstill lack clarity about the nature and properties of feature extraction. In\nthis paper, by analyzing the sensitivity of neural networks to frequencies and\nscales, we find that neural networks not only have low- and medium-frequency\nbiases but also prefer different frequency bands for different classes, and the\nscale of objects influences the preferred frequency bands. These observations\nlead to the hypothesis that neural networks must learn the ability to extract\nfeatures at various scales and frequencies. To corroborate this hypothesis, we\npropose a network architecture based on Gaussian derivatives, which extracts\nfeatures by constructing scale space and employing partial derivatives as local\nfeature extraction operators to separate high-frequency information. This\nmanually designed method of extracting features from different scales allows\nour GSSDNets to achieve comparable accuracy with vanilla networks on various\ndatasets.\n","authors":["Liangqi Zhang","Yihao Luo","Xiang Cao","Haibo Shen","Tianjiang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.12477v1.pdf","comment":"5 pages, 5 figures; ICASSP 2023"},{"id":"http://arxiv.org/abs/2209.07007v2","updated":"2023-02-24T06:07:37Z","published":"2022-09-15T02:34:39Z","title":"Gromov-Wasserstein Autoencoders","summary":"  Variational Autoencoder (VAE)-based generative models offer flexible\nrepresentation learning by incorporating meta-priors, general premises\nconsidered beneficial for downstream tasks. However, the incorporated\nmeta-priors often involve ad-hoc model deviations from the original likelihood\narchitecture, causing undesirable changes in their training. In this paper, we\npropose a novel representation learning method, Gromov-Wasserstein Autoencoders\n(GWAE), which directly matches the latent and data distributions using the\nvariational autoencoding scheme. Instead of likelihood-based objectives, GWAE\nmodels minimize the Gromov-Wasserstein (GW) metric between the trainable prior\nand given data distributions. The GW metric measures the distance\nstructure-oriented discrepancy between distributions even with different\ndimensionalities, which provides a direct measure between the latent and data\nspaces. By restricting the prior family, we can introduce meta-priors into the\nlatent space without changing their objective. The empirical comparisons with\nVAE-based models show that GWAE models work in two prominent meta-priors,\ndisentanglement and clustering, with their GW objective unchanged.\n","authors":["Nao Nakagawa","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2209.07007v2.pdf","comment":"38 pages, 9 tables, 13 figures; accepted at ICLR2023"},{"id":"http://arxiv.org/abs/2205.04329v2","updated":"2023-02-24T05:55:06Z","published":"2022-05-09T14:33:06Z","title":"SAN-Net: Learning Generalization to Unseen Sites for Stroke Lesion\n  Segmentation with Self-Adaptive Normalization","summary":"  There are considerable interests in automatic stroke lesion segmentation on\nmagnetic resonance (MR) images in the medical imaging field, as stroke is an\nimportant cerebrovascular disease. Although deep learning-based models have\nbeen proposed for this task, generalizing these models to unseen sites is\ndifficult due to not only the large inter-site discrepancy among different\nscanners, imaging protocols, and populations, but also the variations in stroke\nlesion shape, size, and location. To tackle this issue, we introduce a\nself-adaptive normalization network, termed SAN-Net, to achieve adaptive\ngeneralization on unseen sites for stroke lesion segmentation. Motivated by\ntraditional z-score normalization and dynamic network, we devise a masked\nadaptive instance normalization (MAIN) to minimize inter-site discrepancies,\nwhich standardizes input MR images from different sites into a site-unrelated\nstyle by dynamically learning affine parameters from the input; \\ie, MAIN can\naffinely transform the intensity values. Then, we leverage a gradient reversal\nlayer to force the U-net encoder to learn site-invariant representation with a\nsite classifier, which further improves the model generalization in conjunction\nwith MAIN. Finally, inspired by the ``pseudosymmetry'' of the human brain, we\nintroduce a simple yet effective data augmentation technique, termed\nsymmetry-inspired data augmentation (SIDA), that can be embedded within SAN-Net\nto double the sample size while halving memory consumption. Experimental\nresults on the benchmark Anatomical Tracings of Lesions After Stroke (ATLAS)\nv1.2 dataset, which includes MR images from 9 different sites, demonstrate that\nunder the ``leave-one-site-out'' setting, the proposed SAN-Net outperforms\nrecently published methods in terms of quantitative metrics and qualitative\ncomparisons.\n","authors":["Weiyi Yu","Zhizhong Huang","Junping Zhang","Hongming Shan"],"pdf_url":"https://arxiv.org/pdf/2205.04329v2.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.12469v1","updated":"2023-02-24T05:54:34Z","published":"2023-02-24T05:54:34Z","title":"Unsupervised Discovery of Semantic Latent Directions in Diffusion Models","summary":"  Despite the success of diffusion models (DMs), we still lack a thorough\nunderstanding of their latent space. While image editing with GANs builds upon\nlatent space, DMs rely on editing the conditions such as text prompts. We\npresent an unsupervised method to discover interpretable editing directions for\nthe latent variables $\\mathbf{x}_t \\in \\mathcal{X}$ of DMs. Our method adopts\nRiemannian geometry between $\\mathcal{X}$ and the intermediate feature maps\n$\\mathcal{H}$ of the U-Nets to provide a deep understanding over the\ngeometrical structure of $\\mathcal{X}$. The discovered semantic latent\ndirections mostly yield disentangled attribute changes, and they are globally\nconsistent across different samples. Furthermore, editing in earlier timesteps\nedits coarse attributes, while ones in later timesteps focus on high-frequency\ndetails. We define the curvedness of a line segment between samples to show\nthat $\\mathcal{X}$ is a curved manifold. Experiments on different baselines and\ndatasets demonstrate the effectiveness of our method even on Stable Diffusion.\nOur source code will be publicly available for the future researchers.\n","authors":["Yong-Hyun Park","Mingi Kwon","Junghyo Jo","Youngjung Uh"],"pdf_url":"https://arxiv.org/pdf/2302.12469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07603v2","updated":"2023-02-24T05:46:02Z","published":"2022-12-15T03:26:53Z","title":"Text-Guided Mask-free Local Image Retouching","summary":"  In the realm of multi-modality, text-guided image retouching techniques\nemerged with the advent of deep learning. Most currently available text-guided\nmethods, however, rely on object-level supervision to constrain the region that\nmay be modified. This not only makes it more challenging to develop these\nalgorithms, but it also limits how widely deep learning can be used for image\nretouching. In this paper, we offer a text-guided mask-free image retouching\napproach that yields consistent results to address this concern. In order to\nperform image retouching without mask supervision, our technique can construct\nplausible and edge-sharp masks based on the text for each object in the image.\nExtensive experiments have shown that our method can produce high-quality,\naccurate images based on spoken language. The source code will be released\nsoon.\n","authors":["Zerun Liu","Fan Zhang","Jingxuan He","Jin Wang","Zhangye Wang","Lechao Cheng"],"pdf_url":"https://arxiv.org/pdf/2212.07603v2.pdf","comment":"7 pages, 6 figures, 1 table"},{"id":"http://arxiv.org/abs/2302.12464v1","updated":"2023-02-24T05:43:03Z","published":"2023-02-24T05:43:03Z","title":"RGI: robust GAN-inversion for mask-free image inpainting and\n  unsupervised pixel-wise anomaly detection","summary":"  Generative adversarial networks (GANs), trained on a large-scale image\ndataset, can be a good approximator of the natural image manifold.\nGAN-inversion, using a pre-trained generator as a deep generative prior, is a\npromising tool for image restoration under corruptions. However, the\nperformance of GAN-inversion can be limited by a lack of robustness to unknown\ngross corruptions, i.e., the restored image might easily deviate from the\nground truth. In this paper, we propose a Robust GAN-inversion (RGI) method\nwith a provable robustness guarantee to achieve image restoration under unknown\n\\textit{gross} corruptions, where a small fraction of pixels are completely\ncorrupted. Under mild assumptions, we show that the restored image and the\nidentified corrupted region mask converge asymptotically to the ground truth.\nMoreover, we extend RGI to Relaxed-RGI (R-RGI) for generator fine-tuning to\nmitigate the gap between the GAN learned manifold and the true image manifold\nwhile avoiding trivial overfitting to the corrupted input image, which further\nimproves the image restoration and corrupted region mask identification\nperformance. The proposed RGI/R-RGI method unifies two important applications\nwith state-of-the-art (SOTA) performance: (i) mask-free semantic inpainting,\nwhere the corruptions are unknown missing regions, the restored background can\nbe used to restore the missing content; (ii) unsupervised pixel-wise anomaly\ndetection, where the corruptions are unknown anomalous regions, the retrieved\nmask can be used as the anomalous region's segmentation mask.\n","authors":["Shancong Mou","Xiaoyi Gu","Meng Cao","Haoping Bai","Ping Huang","Jiulong Shan","Jianjun Shi"],"pdf_url":"https://arxiv.org/pdf/2302.12464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12237v2","updated":"2023-02-24T03:13:56Z","published":"2023-02-23T18:57:01Z","title":"Learning Neural Volumetric Representations of Dynamic Humans in Minutes","summary":"  This paper addresses the challenge of quickly reconstructing free-viewpoint\nvideos of dynamic humans from sparse multi-view videos. Some recent works\nrepresent the dynamic human as a canonical neural radiance field (NeRF) and a\nmotion field, which are learned from videos through differentiable rendering.\nBut the per-scene optimization generally requires hours. Other generalizable\nNeRF models leverage learned prior from datasets and reduce the optimization\ntime by only finetuning on new scenes at the cost of visual fidelity. In this\npaper, we propose a novel method for learning neural volumetric videos of\ndynamic humans from sparse view videos in minutes with competitive visual\nquality. Specifically, we define a novel part-based voxelized human\nrepresentation to better distribute the representational power of the network\nto different human parts. Furthermore, we propose a novel 2D motion\nparameterization scheme to increase the convergence rate of deformation field\nlearning. Experiments demonstrate that our model can be learned 100 times\nfaster than prior per-scene optimization methods while being competitive in the\nrendering quality. Training our model on a $512 \\times 512$ video with 100\nframes typically takes about 5 minutes on a single RTX 3090 GPU. The code will\nbe released on our project page: https://zju3dv.github.io/instant_nvr\n","authors":["Chen Geng","Sida Peng","Zhen Xu","Hujun Bao","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.12237v2.pdf","comment":"Project page: https://zju3dv.github.io/instant_nvr"},{"id":"http://arxiv.org/abs/2210.12444v2","updated":"2023-02-24T02:53:39Z","published":"2022-10-22T13:23:02Z","title":"Weakly-Supervised Temporal Article Grounding","summary":"  Given a long untrimmed video and natural language queries, video grounding\n(VG) aims to temporally localize the semantically-aligned video segments.\nAlmost all existing VG work holds two simple but unrealistic assumptions: 1)\nAll query sentences can be grounded in the corresponding video. 2) All query\nsentences for the same video are always at the same semantic scale.\nUnfortunately, both assumptions make today's VG models fail to work in\npractice. For example, in real-world multimodal assets (eg, news articles),\nmost of the sentences in the article can not be grounded in their affiliated\nvideos, and they typically have rich hierarchical relations (ie, at different\nsemantic scales). To this end, we propose a new challenging grounding task:\nWeakly-Supervised temporal Article Grounding (WSAG). Specifically, given an\narticle and a relevant video, WSAG aims to localize all ``groundable''\nsentences to the video, and these sentences are possibly at different semantic\nscales. Accordingly, we collect the first WSAG dataset to facilitate this task:\nYouwikiHow, which borrows the inherent multi-scale descriptions in wikiHow\narticles and plentiful YouTube videos. In addition, we propose a simple but\neffective method DualMIL for WSAG, which consists of a two-level MIL loss and a\nsingle-/cross- sentence constraint loss. These training objectives are\ncarefully designed for these relaxed assumptions. Extensive ablations have\nverified the effectiveness of DualMIL.\n","authors":["Long Chen","Yulei Niu","Brian Chen","Xudong Lin","Guangxing Han","Christopher Thomas","Hammad Ayyubi","Heng Ji","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2210.12444v2.pdf","comment":"EMNLP 2022, https://github.com/zjuchenlong/WSAG"},{"id":"http://arxiv.org/abs/2302.12420v1","updated":"2023-02-24T02:51:09Z","published":"2023-02-24T02:51:09Z","title":"An Iterative Classification and Semantic Segmentation Network for Old\n  Landslide Detection Using High-Resolution Remote Sensing Images","summary":"  Huge challenges exist for old landslide detection because their morphology\nfeatures have been partially or strongly transformed over a long time and have\nlittle difference from their surrounding. Besides, small-sample problem also\nrestrict in-depth learning.\n  In this paper, an iterative classification and semantic segmentation network\n(ICSSN) is developed, which can greatly enhance both object-level and\npixel-level classification performance by iteratively upgrading the feature\nextractor shared by two network. An object-level contrastive learning (OCL)\nstrategy is employed in the object classification sub-network featuring a\nsiamese network to realize the global features extraction, and a\nsub-object-level contrastive learning (SOCL) paradigm is designed in the\nsemantic segmentation sub-network to efficiently extract salient features from\nboundaries of landslides. Moreover, an iterative training strategy is\nelaborated to fuse features in semantic space such that both object-level and\npixel-level classification performance are improved.\n  The proposed ICSSN is evaluated on the real landslide data set, and the\nexperimental results show that ICSSN can greatly improve the classification and\nsegmentation accuracy of old landslide detection. For the semantic segmentation\ntask, compared to the baseline, the F1 score increases from 0.5054 to 0.5448,\nthe mIoU improves from 0.6405 to 0.6610, the landslide IoU improved from 0.3381\nto 0.3743, and the object-level detection accuracy of old landslides is\nenhanced from 0.55 to 0.9. For the object classification task, the F1 score\nincreases from 0.8846 to 0.9230, and the accuracy score is up from 0.8375 to\n0.8875.\n","authors":["Zili Lu","Yuexing Peng","Wei Li","Junchuan Yu","Daqing Ge","Wei Xiang"],"pdf_url":"https://arxiv.org/pdf/2302.12420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12416v1","updated":"2023-02-24T02:44:39Z","published":"2023-02-24T02:44:39Z","title":"A Convolutional Vision Transformer for Semantic Segmentation of\n  Side-Scan Sonar Data","summary":"  Distinguishing among different marine benthic habitat characteristics is of\nkey importance in a wide set of seabed operations ranging from installations of\noil rigs to laying networks of cables and monitoring the impact of humans on\nmarine ecosystems. The Side-Scan Sonar (SSS) is a widely used imaging sensor in\nthis regard. It produces high-resolution seafloor maps by logging the\nintensities of sound waves reflected back from the seafloor. In this work, we\nleverage these acoustic intensity maps to produce pixel-wise categorization of\ndifferent seafloor types. We propose a novel architecture adapted from the\nVision Transformer (ViT) in an encoder-decoder framework. Further, in doing so,\nthe applicability of ViTs is evaluated on smaller datasets. To overcome the\nlack of CNN-like inductive biases, thereby making ViTs more conducive to\napplications in low data regimes, we propose a novel feature extraction module\nto replace the Multi-layer Perceptron (MLP) block within transformer layers and\na novel module to extract multiscale patch embeddings. A lightweight decoder is\nalso proposed to complement this design in order to further boost multiscale\nfeature extraction. With the modified architecture, we achieve state-of-the-art\nresults and also meet real-time computational requirements. We make our code\navailable at ~\\url{https://github.com/hayatrajani/s3seg-vit\n","authors":["Hayat Rajani","Nuno Gracias","Rafael Garcia"],"pdf_url":"https://arxiv.org/pdf/2302.12416v1.pdf","comment":"Submitted to Ocean Engineering special issue \"Autonomous Marine\n  Robotics Operations\""},{"id":"http://arxiv.org/abs/2301.00970v2","updated":"2023-02-24T02:23:08Z","published":"2023-01-03T06:47:31Z","title":"Benchmarking the Robustness of LiDAR Semantic Segmentation Models","summary":"  When using LiDAR semantic segmentation models for safety-critical\napplications such as autonomous driving, it is essential to understand and\nimprove their robustness with respect to a large range of LiDAR corruptions. In\nthis paper, we aim to comprehensively analyze the robustness of LiDAR semantic\nsegmentation models under various corruptions. To rigorously evaluate the\nrobustness and generalizability of current approaches, we propose a new\nbenchmark called SemanticKITTI-C, which features 16 out-of-domain LiDAR\ncorruptions in three groups, namely adverse weather, measurement noise and\ncross-device discrepancy. Then, we systematically investigate 11 LiDAR semantic\nsegmentation models, especially spanning different input representations (e.g.,\npoint clouds, voxels, projected images, and etc.), network architectures and\ntraining schemes. Through this study, we obtain two insights: 1) We find out\nthat the input representation plays a crucial role in robustness. Specifically,\nunder specific corruptions, different representations perform variously. 2)\nAlthough state-of-the-art methods on LiDAR semantic segmentation achieve\npromising results on clean data, they are less robust when dealing with noisy\ndata. Finally, based on the above observations, we design a robust LiDAR\nsegmentation model (RLSeg) which greatly boosts the robustness with simple but\neffective modifications. It is promising that our benchmark, comprehensive\nanalysis, and observations can boost future research in robust LiDAR semantic\nsegmentation for safety-critical applications.\n","authors":["Xu Yan","Chaoda Zheng","Zhen Li","Shuguang Cui","Dengxin Dai"],"pdf_url":"https://arxiv.org/pdf/2301.00970v2.pdf","comment":"The benchmark will be made available at\n  https://yanx27.github.io/RobustLidarSeg/"},{"id":"http://arxiv.org/abs/2302.12400v1","updated":"2023-02-24T02:03:41Z","published":"2023-02-24T02:03:41Z","title":"Towards Stable Test-Time Adaptation in Dynamic Wild World","summary":"  Test-time adaptation (TTA) has shown to be effective at tackling distribution\nshifts between training and testing data by adapting a given model on test\nsamples. However, the online model updating of TTA may be unstable and this is\noften a key obstacle preventing existing TTA methods from being deployed in the\nreal world. Specifically, TTA may fail to improve or even harm the model\nperformance when test data have: 1) mixed distribution shifts, 2) small batch\nsizes, and 3) online imbalanced label distribution shifts, which are quite\ncommon in practice. In this paper, we investigate the unstable reasons and find\nthat the batch norm layer is a crucial factor hindering TTA stability.\nConversely, TTA can perform more stably with batch-agnostic norm layers, \\ie,\ngroup or layer norm. However, we observe that TTA with group and layer norms\ndoes not always succeed and still suffers many failure cases. By digging into\nthe failure cases, we find that certain noisy test samples with large gradients\nmay disturb the model adaption and result in collapsed trivial solutions, \\ie,\nassigning the same class label for all samples. To address the above collapse\nissue, we propose a sharpness-aware and reliable entropy minimization method,\ncalled SAR, for further stabilizing TTA from two aspects: 1) remove partial\nnoisy samples with large gradients, 2) encourage model weights to go to a flat\nminimum so that the model is robust to the remaining noisy samples. Promising\nresults demonstrate that SAR performs more stably over prior methods and is\ncomputationally efficient under the above wild test scenarios.\n","authors":["Shuaicheng Niu","Jiaxiang Wu","Yifan Zhang","Zhiquan Wen","Yaofo Chen","Peilin Zhao","Mingkui Tan"],"pdf_url":"https://arxiv.org/pdf/2302.12400v1.pdf","comment":"accepted by International Conference on Learning Representations\n  (ICLR) 2023 as Notable-Top-5%; 27 pages, 10 figures, 18 tables"},{"id":"http://arxiv.org/abs/2212.07048v2","updated":"2023-02-24T01:56:07Z","published":"2022-12-14T05:48:58Z","title":"PD-Quant: Post-Training Quantization based on Prediction Difference\n  Metric","summary":"  As a neural network compression technique, post-training quantization (PTQ)\ntransforms a pre-trained model into a quantized model using a lower-precision\ndata type. However, the prediction accuracy will decrease because of the\nquantization noise, especially in extremely low-bit settings. How to determine\nthe appropriate quantization parameters (e.g., scaling factors and rounding of\nweights) is the main problem facing now. Many existing methods determine the\nquantization parameters by minimizing the distance between features before and\nafter quantization. Using this distance as the metric to optimize the\nquantization parameters only considers local information. We analyze the\nproblem of minimizing local metrics and indicate that it would not result in\noptimal quantization parameters. Furthermore, the quantized model suffers from\noverfitting due to the small number of calibration samples in PTQ. In this\npaper, we propose PD-Quant to solve the problems. PD-Quant uses the information\nof differences between network prediction before and after quantization to\ndetermine the quantization parameters. To mitigate the overfitting problem,\nPD-Quant adjusts the distribution of activations in PTQ. Experiments show that\nPD-Quant leads to better quantization parameters and improves the prediction\naccuracy of quantized models, especially in low-bit settings. For example,\nPD-Quant pushes the accuracy of ResNet-18 up to 53.08% and RegNetX-600MF up to\n40.92% in weight 2-bit activation 2-bit. The code will be released at\nhttps://github.com/hustvl/PD-Quant.\n","authors":["Jiawei Liu","Lin Niu","Zhihang Yuan","Dawei Yang","Xinggang Wang","Wenyu Liu"],"pdf_url":"https://arxiv.org/pdf/2212.07048v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12393v1","updated":"2023-02-24T01:47:13Z","published":"2023-02-24T01:47:13Z","title":"Blind Omnidirectional Image Quality Assessment: Integrating Local\n  Statistics and Global Semantics","summary":"  Omnidirectional image quality assessment (OIQA) aims to predict the\nperceptual quality of omnidirectional images that cover the whole\n180$\\times$360$^{\\circ}$ viewing range of the visual environment. Here we\npropose a blind/no-reference OIQA method named S$^2$ that bridges the gap\nbetween low-level statistics and high-level semantics of omnidirectional\nimages. Specifically, statistic and semantic features are extracted in separate\npaths from multiple local viewports and the hallucinated global omnidirectional\nimage, respectively. A quality regression along with a weighting process is\nthen followed that maps the extracted quality-aware features to a perceptual\nquality prediction. Experimental results demonstrate that the proposed S$^2$\nmethod offers highly competitive performance against state-of-the-art methods.\n","authors":["Wei Zhou","Zhou Wang"],"pdf_url":"https://arxiv.org/pdf/2302.12393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14927v4","updated":"2023-02-24T01:41:32Z","published":"2022-09-29T16:45:43Z","title":"Spotlight: Mobile UI Understanding using Vision-Language Models with a\n  Focus","summary":"  Mobile UI understanding is important for enabling various interaction tasks\nsuch as UI automation and accessibility. Previous mobile UI modeling often\ndepends on the view hierarchy information of a screen, which directly provides\nthe structural data of the UI, with the hope to bypass challenging tasks of\nvisual modeling from screen pixels. However, view hierarchies are not always\navailable, and are often corrupted with missing object descriptions or\nmisaligned structure information. As a result, despite the use of view\nhierarchies could offer short-term gains, it may ultimately hinder the\napplicability and performance of the model. In this paper, we propose\nSpotlight, a vision-only approach for mobile UI understanding. Specifically, we\nenhance a vision-language model that only takes the screenshot of the UI and a\nregion of interest on the screen -- the focus -- as the input. This general\narchitecture of Spotlight is easily scalable and capable of performing a range\nof UI modeling tasks. Our experiments show that our model establishes SoTA\nresults on several representative UI tasks and outperforms previous methods\nthat use both screenshots and view hierarchies as inputs. Furthermore, we\nexplore multi-task learning and few-shot prompting capacities of the proposed\nmodels, demonstrating promising results in the multi-task learning direction.\n","authors":["Gang Li","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2209.14927v4.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2209.04145v6","updated":"2023-02-24T01:38:20Z","published":"2022-09-09T06:54:21Z","title":"ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation","summary":"  Text-guided 3D shape generation remains challenging due to the absence of\nlarge paired text-shape data, the substantial semantic gap between these two\nmodalities, and the structural complexity of 3D shapes. This paper presents a\nnew framework called Image as Stepping Stone (ISS) for the task by introducing\n2D image as a stepping stone to connect the two modalities and to eliminate the\nneed for paired text-shape data. Our key contribution is a two-stage\nfeature-space-alignment approach that maps CLIP features to shapes by\nharnessing a pre-trained single-view reconstruction (SVR) model with multi-view\nsupervisions: first map the CLIP image feature to the detail-rich shape space\nin the SVR model, then map the CLIP text feature to the shape space and\noptimize the mapping by encouraging CLIP consistency between the input text and\nthe rendered images. Further, we formulate a text-guided shape stylization\nmodule to dress up the output shapes with novel textures. Beyond existing works\non 3D shape generation from text, our new approach is general for creating\nshapes in a broad range of categories, without requiring paired text-shape\ndata. Experimental results manifest that our approach outperforms the\nstate-of-the-arts and our baselines in terms of fidelity and consistency with\ntext. Further, our approach can stylize the generated shapes with both\nrealistic and fantasy structures and textures.\n","authors":["Zhengzhe Liu","Peng Dai","Ruihui Li","Xiaojuan Qi","Chi-Wing Fu"],"pdf_url":"https://arxiv.org/pdf/2209.04145v6.pdf","comment":"ICLR 2023 spotlight"},{"id":"http://arxiv.org/abs/2302.11154v2","updated":"2023-02-24T00:50:25Z","published":"2023-02-22T05:31:26Z","title":"Open-domain Visual Entity Recognition: Towards Recognizing Millions of\n  Wikipedia Entities","summary":"  Large-scale multi-modal pre-training models such as CLIP and PaLI exhibit\nstrong generalization on various visual domains and tasks. However, existing\nimage classification benchmarks often evaluate recognition on a specific domain\n(e.g., outdoor images) or a specific task (e.g., classifying plant species),\nwhich falls short of evaluating whether pre-trained foundational models are\nuniversal visual recognizers. To address this, we formally present the task of\nOpen-domain Visual Entity recognitioN (OVEN), where a model need to link an\nimage onto a Wikipedia entity with respect to a text query. We construct\nOVEN-Wiki by re-purposing 14 existing datasets with all labels grounded onto\none single label space: Wikipedia entities. OVEN challenges models to select\namong six million possible Wikipedia entities, making it a general visual\nrecognition benchmark with the largest number of labels. Our study on\nstate-of-the-art pre-trained models reveals large headroom in generalizing to\nthe massive-scale label space. We show that a PaLI-based auto-regressive visual\nrecognition model performs surprisingly well, even on Wikipedia entities that\nhave never been seen during fine-tuning. We also find existing pretrained\nmodels yield different strengths: while PaLI-based models obtain higher overall\nperformance, CLIP-based models are better at recognizing tail entities.\n","authors":["Hexiang Hu","Yi Luan","Yang Chen","Urvashi Khandelwal","Mandar Joshi","Kenton Lee","Kristina Toutanova","Ming-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2302.11154v2.pdf","comment":"Dataset available at https://open-vision-language.github.io/oven"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2205.15436v3","updated":"2023-02-24T17:54:15Z","published":"2022-05-30T21:21:38Z","title":"Uncertainty Quantification for Fairness in Two-Stage Recommender Systems","summary":"  Many large-scale recommender systems consist of two stages. The first stage\nefficiently screens the complete pool of items for a small subset of promising\ncandidates, from which the second-stage model curates the final\nrecommendations. In this paper, we investigate how to ensure group fairness to\nthe items in this two-stage architecture. In particular, we find that existing\nfirst-stage recommenders might select an irrecoverably unfair set of candidates\nsuch that there is no hope for the second-stage recommender to deliver fair\nrecommendations. To this end, motivated by recent advances in uncertainty\nquantification, we propose two threshold-policy selection rules that can\nprovide distribution-free and finite-sample guarantees on fairness in\nfirst-stage recommenders. More concretely, given any relevance model of queries\nand items and a point-wise lower confidence bound on the expected number of\nrelevant items for each threshold-policy, the two rules find near-optimal sets\nof candidates that contain enough relevant items in expectation from each group\nof items. To instantiate the rules, we demonstrate how to derive such\nconfidence bounds from potentially partial and biased user feedback data, which\nare abundant in many large-scale recommender systems. In addition, we provide\nboth finite-sample and asymptotic analyses of how close the two threshold\nselection rules are to the optimal thresholds. Beyond this theoretical\nanalysis, we show empirically that these two rules can consistently select\nenough relevant items from each group while minimizing the size of the\ncandidate sets for a wide range of settings.\n","authors":["Lequn Wang","Thorsten Joachims"],"pdf_url":"https://arxiv.org/pdf/2205.15436v3.pdf","comment":"ACM Conference on Web Search and Data Mining (WSDM), 2023"},{"id":"http://arxiv.org/abs/2302.12131v2","updated":"2023-02-24T12:49:29Z","published":"2023-02-23T16:13:02Z","title":"Automated Statement Extraction from Press Briefings","summary":"  Scientific press briefings are a valuable information source. They consist of\nalternating expert speeches, questions from the audience and their answers.\nTherefore, they can contribute to scientific and fact-based media coverage.\nEven though press briefings are highly informative, extracting statements\nrelevant to individual journalistic tasks is challenging and time-consuming. To\nsupport this task, an automated statement extraction system is proposed. Claims\nare used as the main feature to identify statements in press briefing\ntranscripts. The statement extraction task is formulated as a four-step\nprocedure. First, the press briefings are split into sentences and passages,\nthen claim sentences are identified through sequence classification.\nSubsequently, topics are detected, and the sentences are filtered to improve\nthe coherence and assess the length of the statements.\n  The results indicate that claim detection can be used to identify statements\nin press briefings. While many statements can be extracted automatically with\nthis system, they are not always as coherent as needed to be understood without\ncontext and may need further review by knowledgeable persons.\n","authors":["Jüri Keller","Meik Bittkowski","Philipp Schaer"],"pdf_url":"https://arxiv.org/pdf/2302.12131v2.pdf","comment":"Datenbanksysteme f\\\"ur Business, Technologie und Web (BTW 2023)"},{"id":"http://arxiv.org/abs/2302.12574v1","updated":"2023-02-24T10:58:31Z","published":"2023-02-24T10:58:31Z","title":"Naver Labs Europe (SPLADE) @ TREC Deep Learning 2022","summary":"  This paper describes our participation to the 2022 TREC Deep Learning\nchallenge. We submitted runs to all four tasks, with a focus on the full\nretrieval passage task. The strategy is almost the same as 2021, with first\nstage retrieval being based around SPLADE, with some added ensembling with\nColBERTv2 and DocT5. We also use the same strategy of last year for the second\nstage, with an ensemble of re-rankers trained using hard negatives selected by\nSPLADE. Initial result analysis show that the strategy is still strong, but is\nstill unclear to us what next steps should we take.\n","authors":["Carlos Lassance","Stéphane Clinchant"],"pdf_url":"https://arxiv.org/pdf/2302.12574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12427v1","updated":"2023-02-24T03:14:10Z","published":"2023-02-24T03:14:10Z","title":"Slate-Aware Ranking for Recommendation","summary":"  We see widespread adoption of slate recommender systems, where an ordered\nitem list is fed to the user based on the user interests and items' content.\nFor each recommendation, the user can select one or several items from the list\nfor further interaction. In this setting, the significant impact on user\nbehaviors from the mutual influence among the items is well understood. The\nexisting methods add another step of slate re-ranking after the ranking stage\nof recommender systems, which considers the mutual influence among recommended\nitems to re-rank and generate the recommendation results so as to maximize the\nexpected overall utility. However, to model the complex interaction of multiple\nrecommended items, the re-ranking stage usually can just handle dozens of\ncandidates because of the constraint of limited hardware resource and system\nlatency. Therefore, the ranking stage is still essential for most applications\nto provide high-quality candidate set for the re-ranking stage. In this paper,\nwe propose a solution named Slate-Aware ranking (SAR) for the ranking stage. By\nimplicitly considering the relations among the slate items, it significantly\nenhances the quality of the re-ranking stage's candidate set and boosts the\nrelevance and diversity of the overall recommender systems. Both experiments\nwith the public datasets and internal online A/B testing are conducted to\nverify its effectiveness.\n","authors":["Yi Ren","Xiao Han","Xu Zhao","Shenzheng Zhang","Yan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.12427v1.pdf","comment":"Accepted as long paper by WSDM'2023 conference, 9 pages, 4figures"},{"id":"http://arxiv.org/abs/2302.12372v1","updated":"2023-02-24T00:24:17Z","published":"2023-02-24T00:24:17Z","title":"Keyword Decisions in Sponsored Search Advertising: A Literature Review\n  and Research Agenda","summary":"  In sponsored search advertising (SSA), keywords serve as the basic unit of\nbusiness model, linking three stakeholders: consumers, advertisers and search\nengines. This paper presents an overarching framework for keyword decisions\nthat highlights the touchpoints in search advertising management, including\nfour levels of keyword decisions, i.e., domain-specific keyword pool\ngeneration, keyword targeting, keyword assignment and grouping, and keyword\nadjustment. Using this framework, we review the state-of-the-art research\nliterature on keyword decisions with respect to techniques, input features and\nevaluation metrics. Finally, we discuss evolving issues and identify potential\ngaps that exist in the literature and outline novel research perspectives for\nfuture exploration.\n","authors":["Yanwu Yang","Huiran Li"],"pdf_url":"https://arxiv.org/pdf/2302.12372v1.pdf","comment":"88 pages, 3 figures, 15 tables"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.12828v1","updated":"2023-02-24T18:59:18Z","published":"2023-02-24T18:59:18Z","title":"SplineCam: Exact Visualization and Characterization of Deep Network\n  Geometry and Decision Boundaries","summary":"  Current Deep Network (DN) visualization and interpretability methods rely\nheavily on data space visualizations such as scoring which dimensions of the\ndata are responsible for their associated prediction or generating new data\nfeatures or samples that best match a given DN unit or representation. In this\npaper, we go one step further by developing the first provably exact method for\ncomputing the geometry of a DN's mapping - including its decision boundary -\nover a specified region of the data space. By leveraging the theory of\nContinuous Piece-Wise Linear (CPWL) spline DNs, SplineCam exactly computes a\nDNs geometry without resorting to approximations such as sampling or\narchitecture simplification. SplineCam applies to any DN architecture based on\nCPWL nonlinearities, including (leaky-)ReLU, absolute value, maxout, and\nmax-pooling and can also be applied to regression DNs such as implicit neural\nrepresentations. Beyond decision boundary visualization and characterization,\nSplineCam enables one to compare architectures, measure generalizability and\nsample from the decision boundary on or off the manifold. Project Website:\nbit.ly/splinecam.\n","authors":["Ahmed Imtiaz Humayun","Randall Balestriero","Guha Balakrishnan","Richard Baraniuk"],"pdf_url":"https://arxiv.org/pdf/2302.12828v1.pdf","comment":"11 pages, 20 figures"},{"id":"http://arxiv.org/abs/2302.12826v1","updated":"2023-02-24T18:59:13Z","published":"2023-02-24T18:59:13Z","title":"Permutation-Invariant Set Autoencoders with Fixed-Size Embeddings for\n  Multi-Agent Learning","summary":"  The problem of permutation-invariant learning over set representations is\nparticularly relevant in the field of multi-agent systems -- a few potential\napplications include unsupervised training of aggregation functions in graph\nneural networks (GNNs), neural cellular automata on graphs, and prediction of\nscenes with multiple objects. Yet existing approaches to set encoding and\ndecoding tasks present a host of issues, including non-permutation-invariance,\nfixed-length outputs, reliance on iterative methods, non-deterministic outputs,\ncomputationally expensive loss functions, and poor reconstruction accuracy. In\nthis paper we introduce a Permutation-Invariant Set Autoencoder (PISA), which\ntackles these problems and produces encodings with significantly lower\nreconstruction error than existing baselines. PISA also provides other\ndesirable properties, including a similarity-preserving latent space, and the\nability to insert or remove elements from the encoding. After evaluating PISA\nagainst baseline methods, we demonstrate its usefulness in a multi-agent\napplication. Using PISA as a subcomponent, we introduce a novel GNN\narchitecture which serves as a generalised communication scheme, allowing\nagents to use communication to gain full observability of a system.\n","authors":["Ryan Kortvelesy","Steven Morad","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2302.12826v1.pdf","comment":"AAMAS 2023"},{"id":"http://arxiv.org/abs/2302.12823v1","updated":"2023-02-24T18:58:11Z","published":"2023-02-24T18:58:11Z","title":"Generative Models of Huge Objects","summary":"  This work initiates the systematic study of explicit distributions that are\nindistinguishable from a single exponential-size combinatorial object. In this\nwe extend the work of Goldreich, Goldwasser and Nussboim (SICOMP 2010) that\nfocused on the implementation of huge objects that are indistinguishable from\nthe uniform distribution, satisfying some global properties (which they coined\ntruthfulness). Indistinguishability from a single object is motivated by the\nstudy of generative models in learning theory and regularity lemmas in graph\ntheory. Problems that are well understood in the setting of pseudorandomness\npresent significant challenges and at times are impossible when considering\ngenerative models of huge objects.\n  We demonstrate the versatility of this study by providing a learning\nalgorithm for huge indistinguishable objects in several natural settings\nincluding: dense functions and graphs with a truthfulness requirement on the\nnumber of ones in the function or edges in the graphs, and a version of the\nweak regularity lemma for sparse graphs that satisfy some global properties.\nThese and other results generalize basic pseudorandom objects as well as\nnotions introduced in algorithmic fairness. The results rely on notions and\ntechniques from a variety of areas including learning theory, complexity\ntheory, cryptography, and game theory.\n","authors":["Lunjia Hu","Inbal Livni-Navon","Omer Reingold"],"pdf_url":"https://arxiv.org/pdf/2302.12823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12814v1","updated":"2023-02-24T18:49:10Z","published":"2023-02-24T18:49:10Z","title":"GraphSR: A Data Augmentation Algorithm for Imbalanced Node\n  Classification","summary":"  Graph neural networks (GNNs) have achieved great success in node\nclassification tasks. However, existing GNNs naturally bias towards the\nmajority classes with more labelled data and ignore those minority classes with\nrelatively few labelled ones. The traditional techniques often resort\nover-sampling methods, but they may cause overfitting problem. More recently,\nsome works propose to synthesize additional nodes for minority classes from the\nlabelled nodes, however, there is no any guarantee if those generated nodes\nreally stand for the corresponding minority classes. In fact, improperly\nsynthesized nodes may result in insufficient generalization of the algorithm.\nTo resolve the problem, in this paper we seek to automatically augment the\nminority classes from the massive unlabelled nodes of the graph. Specifically,\nwe propose \\textit{GraphSR}, a novel self-training strategy to augment the\nminority classes with significant diversity of unlabelled nodes, which is based\non a Similarity-based selection module and a Reinforcement Learning(RL)\nselection module. The first module finds a subset of unlabelled nodes which are\nmost similar to those labelled minority nodes, and the second one further\ndetermines the representative and reliable nodes from the subset via RL\ntechnique. Furthermore, the RL-based module can adaptively determine the\nsampling scale according to current training data. This strategy is general and\ncan be easily combined with different GNNs models. Our experiments demonstrate\nthe proposed approach outperforms the state-of-the-art baselines on various\nclass-imbalanced datasets.\n","authors":["Mengting Zhou","Zhiguo Gong"],"pdf_url":"https://arxiv.org/pdf/2302.12814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12808v1","updated":"2023-02-24T18:41:48Z","published":"2023-02-24T18:41:48Z","title":"Linearization Algorithms for Fully Composite Optimization","summary":"  In this paper, we study first-order algorithms for solving fully composite\noptimization problems over bounded sets. We treat the differentiable and\nnon-differentiable parts of the objective separately, linearizing only the\nsmooth components. This provides us with new generalizations of the classical\nand accelerated Frank-Wolfe methods, that are applicable to non-differentiable\nproblems whenever we can access the structure of the objective. We prove global\ncomplexity bounds for our algorithms that are optimal in several settings.\n","authors":["Maria-Luiza Vladarean","Nikita Doikov","Martin Jaggi","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2302.12808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12798v1","updated":"2023-02-24T18:19:49Z","published":"2023-02-24T18:19:49Z","title":"3D Generative Model Latent Disentanglement via Local Eigenprojection","summary":"  Designing realistic digital humans is extremely complex. Most data-driven\ngenerative models used to simplify the creation of their underlying geometric\nshape do not offer control over the generation of local shape attributes. In\nthis paper, we overcome this limitation by introducing a novel loss function\ngrounded in spectral geometry and applicable to different neural-network-based\ngenerative models of 3D head and body meshes. Encouraging the latent variables\nof mesh variational autoencoders (VAEs) or generative adversarial networks\n(GANs) to follow the local eigenprojections of identity attributes, we improve\nlatent disentanglement and properly decouple the attribute creation.\nExperimental results show that our local eigenprojection disentangled (LED)\nmodels not only offer improved disentanglement with respect to the\nstate-of-the-art, but also maintain good generation capabilities with training\ntimes comparable to the vanilla implementations of the models.\n","authors":["Simone Foti","Bongjin Koo","Danail Stoyanov","Matthew J. Clarkson"],"pdf_url":"https://arxiv.org/pdf/2302.12798v1.pdf","comment":"Accept after minor revisions at Computer Graphics Forum 2023 (this\n  manuscript is the revised version)"},{"id":"http://arxiv.org/abs/2302.12794v1","updated":"2023-02-24T18:10:37Z","published":"2023-02-24T18:10:37Z","title":"HULAT at SemEval-2023 Task 9: Data augmentation for pre-trained\n  transformers applied to Multilingual Tweet Intimacy Analysis","summary":"  This paper describes our participation in SemEval-2023 Task 9, Intimacy\nAnalysis of Multilingual Tweets. We fine-tune some of the most popular\ntransformer models with the training dataset and synthetic data generated by\ndifferent data augmentation techniques. During the development phase, our best\nresults were obtained by using XLM-T. Data augmentation techniques provide a\nvery slight improvement in the results. Our system ranked in the 27th position\nout of the 45 participating systems. Despite its modest results, our system\nshows promising results in languages such as Portuguese, English, and Dutch.\nAll our code is available in the repository\n\\url{https://github.com/isegura/hulat_intimacy}.\n","authors":["Isabel Segura-Bedmar"],"pdf_url":"https://arxiv.org/pdf/2302.12794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.13060v2","updated":"2023-02-24T18:09:25Z","published":"2021-10-25T15:57:16Z","title":"Uniformly Conservative Exploration in Reinforcement Learning","summary":"  A key challenge to deploying reinforcement learning in practice is avoiding\nexcessive (harmful) exploration in individual episodes. We propose a natural\nconstraint on exploration -- \\textit{uniformly} outperforming a conservative\npolicy (adaptively estimated from all data observed thus far), up to a\nper-episode exploration budget. We design a novel algorithm that uses a UCB\nreinforcement learning policy for exploration, but overrides it as needed to\nsatisfy our exploration constraint with high probability. Importantly, to\nensure unbiased exploration across the state space, our algorithm adaptively\ndetermines when to explore. We prove that our approach remains conservative\nwhile minimizing regret in the tabular setting. We experimentally validate our\nresults on a sepsis treatment task and an HIV treatment task, demonstrating\nthat our algorithm can learn while ensuring good performance compared to the\nbaseline policy for every patient; the latter task also demonstrates that our\napproach extends to continuous state spaces via deep reinforcement learning.\n","authors":["Wanqiao Xu","Jason Yecheng Ma","Kan Xu","Hamsa Bastani","Osbert Bastani"],"pdf_url":"https://arxiv.org/pdf/2110.13060v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.14485v3","updated":"2023-02-24T17:58:53Z","published":"2022-05-28T16:59:46Z","title":"Noise-Aware Statistical Inference with Differentially Private Synthetic\n  Data","summary":"  While generation of synthetic data under differential privacy (DP) has\nreceived a lot of attention in the data privacy community, analysis of\nsynthetic data has received much less. Existing work has shown that simply\nanalysing DP synthetic data as if it were real does not produce valid\ninferences of population-level quantities. For example, confidence intervals\nbecome too narrow, which we demonstrate with a simple experiment. We tackle\nthis problem by combining synthetic data analysis techniques from the field of\nmultiple imputation (MI), and synthetic data generation using noise-aware (NA)\nBayesian modeling into a pipeline NA+MI that allows computing accurate\nuncertainty estimates for population-level quantities from DP synthetic data.\nTo implement NA+MI for discrete data generation using the values of marginal\nqueries, we develop a novel noise-aware synthetic data generation algorithm\nNAPSU-MQ using the principle of maximum entropy. Our experiments demonstrate\nthat the pipeline is able to produce accurate confidence intervals from DP\nsynthetic data. The intervals become wider with tighter privacy to accurately\ncapture the additional uncertainty stemming from DP noise.\n","authors":["Ossi Räisä","Joonas Jälkö","Samuel Kaski","Antti Honkela"],"pdf_url":"https://arxiv.org/pdf/2205.14485v3.pdf","comment":"24 pages, 14 figures"},{"id":"http://arxiv.org/abs/2205.15436v3","updated":"2023-02-24T17:54:15Z","published":"2022-05-30T21:21:38Z","title":"Uncertainty Quantification for Fairness in Two-Stage Recommender Systems","summary":"  Many large-scale recommender systems consist of two stages. The first stage\nefficiently screens the complete pool of items for a small subset of promising\ncandidates, from which the second-stage model curates the final\nrecommendations. In this paper, we investigate how to ensure group fairness to\nthe items in this two-stage architecture. In particular, we find that existing\nfirst-stage recommenders might select an irrecoverably unfair set of candidates\nsuch that there is no hope for the second-stage recommender to deliver fair\nrecommendations. To this end, motivated by recent advances in uncertainty\nquantification, we propose two threshold-policy selection rules that can\nprovide distribution-free and finite-sample guarantees on fairness in\nfirst-stage recommenders. More concretely, given any relevance model of queries\nand items and a point-wise lower confidence bound on the expected number of\nrelevant items for each threshold-policy, the two rules find near-optimal sets\nof candidates that contain enough relevant items in expectation from each group\nof items. To instantiate the rules, we demonstrate how to derive such\nconfidence bounds from potentially partial and biased user feedback data, which\nare abundant in many large-scale recommender systems. In addition, we provide\nboth finite-sample and asymptotic analyses of how close the two threshold\nselection rules are to the optimal thresholds. Beyond this theoretical\nanalysis, we show empirically that these two rules can consistently select\nenough relevant items from each group while minimizing the size of the\ncandidate sets for a wide range of settings.\n","authors":["Lequn Wang","Thorsten Joachims"],"pdf_url":"https://arxiv.org/pdf/2205.15436v3.pdf","comment":"ACM Conference on Web Search and Data Mining (WSDM), 2023"},{"id":"http://arxiv.org/abs/2302.12784v1","updated":"2023-02-24T17:54:12Z","published":"2023-02-24T17:54:12Z","title":"STA: Self-controlled Text Augmentation for Improving Text\n  Classifications","summary":"  Despite recent advancements in Machine Learning, many tasks still involve\nworking in low-data regimes which can make solving natural language problems\ndifficult. Recently, a number of text augmentation techniques have emerged in\nthe field of Natural Language Processing (NLP) which can enrich the training\ndata with new examples, though they are not without their caveats. For\ninstance, simple rule-based heuristic methods are effective, but lack variation\nin semantic content and syntactic structure with respect to the original text.\nOn the other hand, more complex deep learning approaches can cause extreme\nshifts in the intrinsic meaning of the text and introduce unwanted noise into\nthe training data. To more reliably control the quality of the augmented\nexamples, we introduce a state-of-the-art approach for Self-Controlled Text\nAugmentation (STA). Our approach tightly controls the generation process by\nintroducing a self-checking procedure to ensure that generated examples retain\nthe semantic content of the original text. Experimental results on multiple\nbenchmarking datasets demonstrate that STA substantially outperforms existing\nstate-of-the-art techniques, whilst qualitative analysis reveals that the\ngenerated examples are both lexically diverse and semantically reliable.\n","authors":["Congcong Wang","Gonzalo Fiz Pontiveros","Steven Derby","Tri Kurniawan Wijaya"],"pdf_url":"https://arxiv.org/pdf/2302.12784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12780v1","updated":"2023-02-24T17:52:12Z","published":"2023-02-24T17:52:12Z","title":"Provably Efficient Neural Offline Reinforcement Learning via Perturbed\n  Rewards","summary":"  We propose a novel offline reinforcement learning (RL) algorithm, namely\nValue Iteration with Perturbed Rewards (VIPeR) which amalgamates the randomized\nvalue function idea with the pessimism principle. Most current offline RL\nalgorithms explicitly construct statistical confidence regions to obtain\npessimism via lower confidence bounds (LCB), which cannot easily scale to\ncomplex problems where a neural network is used to estimate the value\nfunctions. Instead, VIPeR implicitly obtains pessimism by simply perturbing the\noffline data multiple times with carefully-designed i.i.d Gaussian noises to\nlearn an ensemble of estimated state-action values and acting greedily to the\nminimum of the ensemble. The estimated state-action values are obtained by\nfitting a parametric model (e.g. neural networks) to the perturbed datasets\nusing gradient descent. As a result, VIPeR only needs $\\mathcal{O}(1)$ time\ncomplexity for action selection while LCB-based algorithms require at least\n$\\Omega(K^2)$, where $K$ is the total number of trajectories in the offline\ndata. We also propose a novel data splitting technique that helps remove the\npotentially large log covering number in the learning bound. We prove that\nVIPeR yields a provable uncertainty quantifier with overparameterized neural\nnetworks and achieves an $\\tilde{\\mathcal{O}}\\left( \\frac{ \\kappa H^{5/2}\n\\tilde{d} }{\\sqrt{K}} \\right)$ sub-optimality where $\\tilde{d}$ is the\neffective dimension, $H$ is the horizon length and $\\kappa$ measures the\ndistributional shift. We corroborate the statistical and computational\nefficiency of VIPeR with an empirical evaluation in a wide set of synthetic and\nreal-world datasets. To the best of our knowledge, VIPeR is the first offline\nRL algorithm that is both provably and computationally efficient in general\nMarkov decision processes (MDPs) with neural network function approximation.\n","authors":["Thanh Nguyen-Tang","Raman Arora"],"pdf_url":"https://arxiv.org/pdf/2302.12780v1.pdf","comment":"top-25%-noble ICLR'23; code:\n  https://github.com/thanhnguyentang/neural-offline-rl"},{"id":"http://arxiv.org/abs/2208.13058v2","updated":"2023-02-24T17:35:25Z","published":"2022-08-27T17:37:35Z","title":"Adversarial Robustness for Tabular Data through Cost and Utility\n  Awareness","summary":"  Many safety-critical applications of machine learning, such as fraud or abuse\ndetection, use data in tabular domains. Adversarial examples can be\nparticularly damaging for these applications. Yet, existing works on\nadversarial robustness primarily focus on machine-learning models in image and\ntext domains. We argue that, due to the differences between tabular data and\nimages or text, existing threat models are not suitable for tabular domains.\nThese models do not capture that the costs of an attack could be more\nsignificant than imperceptibility, or that the adversary could assign different\nvalues to the utility obtained from deploying different adversarial examples.\nWe demonstrate that, due to these differences, the attack and defense methods\nused for images and text cannot be directly applied to tabular settings. We\naddress these issues by proposing new cost and utility-aware threat models that\nare tailored to the adversarial capabilities and constraints of attackers\ntargeting tabular domains. We introduce a framework that enables us to design\nattack and defense mechanisms that result in models protected against cost and\nutility-aware adversaries, for example, adversaries constrained by a certain\nfinancial budget. We show that our approach is effective on three datasets\ncorresponding to applications for which adversarial examples can have economic\nand social implications.\n","authors":["Klim Kireev","Bogdan Kulynych","Carmela Troncoso"],"pdf_url":"https://arxiv.org/pdf/2208.13058v2.pdf","comment":"The first two authors contributed equally. To appear in the\n  proceedings of NDSS 2023"},{"id":"http://arxiv.org/abs/2302.12766v1","updated":"2023-02-24T17:29:31Z","published":"2023-02-24T17:29:31Z","title":"Language-Driven Representation Learning for Robotics","summary":"  Recent work in visual representation learning for robotics demonstrates the\nviability of learning from large video datasets of humans performing everyday\ntasks. Leveraging methods such as masked autoencoding and contrastive learning,\nthese representations exhibit strong transfer to policy learning for visuomotor\ncontrol. But, robot learning encompasses a diverse set of problems beyond\ncontrol including grasp affordance prediction, language-conditioned imitation\nlearning, and intent scoring for human-robot collaboration, amongst others.\nFirst, we demonstrate that existing representations yield inconsistent results\nacross these tasks: masked autoencoding approaches pick up on low-level spatial\nfeatures at the cost of high-level semantics, while contrastive learning\napproaches capture the opposite. We then introduce Voltron, a framework for\nlanguage-driven representation learning from human videos and associated\ncaptions. Voltron trades off language-conditioned visual reconstruction to\nlearn low-level visual patterns, and visually-grounded language generation to\nencode high-level semantics. We also construct a new evaluation suite spanning\nfive distinct robot learning problems $\\unicode{x2013}$ a unified platform for\nholistically evaluating visual representations for robotics. Through\ncomprehensive, controlled experiments across all five problems, we find that\nVoltron's language-driven representations outperform the prior\nstate-of-the-art, especially on targeted problems requiring higher-level\nfeatures.\n","authors":["Siddharth Karamcheti","Suraj Nair","Annie S. Chen","Thomas Kollar","Chelsea Finn","Dorsa Sadigh","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2302.12766v1.pdf","comment":"30 Pages, 15 Figures"},{"id":"http://arxiv.org/abs/2202.09340v2","updated":"2023-02-24T17:24:54Z","published":"2022-02-18T18:07:54Z","title":"Learning Physics-Informed Neural Networks without Stacked\n  Back-propagation","summary":"  Physics-Informed Neural Network (PINN) has become a commonly used machine\nlearning approach to solve partial differential equations (PDE). But, facing\nhigh-dimensional secondorder PDE problems, PINN will suffer from severe\nscalability issues since its loss includes second-order derivatives, the\ncomputational cost of which will grow along with the dimension during stacked\nback-propagation. In this work, we develop a novel approach that can\nsignificantly accelerate the training of Physics-Informed Neural Networks. In\nparticular, we parameterize the PDE solution by the Gaussian smoothed model and\nshow that, derived from Stein's Identity, the second-order derivatives can be\nefficiently calculated without back-propagation. We further discuss the model\ncapacity and provide variance reduction methods to address key limitations in\nthe derivative estimation. Experimental results show that our proposed method\ncan achieve competitive error compared to standard PINN training but is\nsignificantly faster. Our code is released at\nhttps://github.com/LithiumDA/PINN-without-Stacked-BP.\n","authors":["Di He","Shanda Li","Wenlei Shi","Xiaotian Gao","Jia Zhang","Jiang Bian","Liwei Wang","Tie-Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2202.09340v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.12758v1","updated":"2023-02-24T17:16:37Z","published":"2023-02-24T17:16:37Z","title":"Defending Against Backdoor Attacks by Layer-wise Feature Analysis","summary":"  Training deep neural networks (DNNs) usually requires massive training data\nand computational resources. Users who cannot afford this may prefer to\noutsource training to a third party or resort to publicly available pre-trained\nmodels. Unfortunately, doing so facilitates a new training-time attack (i.e.,\nbackdoor attack) against DNNs. This attack aims to induce misclassification of\ninput samples containing adversary-specified trigger patterns. In this paper,\nwe first conduct a layer-wise feature analysis of poisoned and benign samples\nfrom the target class. We find out that the feature difference between benign\nand poisoned samples tends to be maximum at a critical layer, which is not\nalways the one typically used in existing defenses, namely the layer before\nfully-connected layers. We also demonstrate how to locate this critical layer\nbased on the behaviors of benign samples. We then propose a simple yet\neffective method to filter poisoned samples by analyzing the feature\ndifferences between suspicious and benign samples at the critical layer. We\nconduct extensive experiments on two benchmark datasets, which confirm the\neffectiveness of our defense.\n","authors":["Najeeb Moharram Jebreel","Josep Domingo-Ferrer","Yiming Li"],"pdf_url":"https://arxiv.org/pdf/2302.12758v1.pdf","comment":"This paper is accepted by PAKDD 2023"},{"id":"http://arxiv.org/abs/2206.03827v6","updated":"2023-02-24T17:06:41Z","published":"2022-06-08T11:50:23Z","title":"Fast Kernel Methods for Generic Lipschitz Losses via $p$-Sparsified\n  Sketches","summary":"  Kernel methods are learning algorithms that enjoy solid theoretical\nfoundations while suffering from important computational limitations.\nSketching, which consists in looking for solutions among a subspace of reduced\ndimension, is a well studied approach to alleviate these computational burdens.\nHowever, statistically-accurate sketches, such as the Gaussian one, usually\ncontain few null entries, such that their application to kernel methods and\ntheir non-sparse Gram matrices remains slow in practice. In this paper, we show\nthat sparsified Gaussian (and Rademacher) sketches still produce\ntheoretically-valid approximations while allowing for important time and space\nsavings thanks to an efficient \\emph{decomposition trick}. To support our\nmethod, we derive excess risk bounds for both single and multiple output kernel\nproblems, with generic Lipschitz losses, hereby providing new guarantees for a\nwide range of applications, from robust regression to multiple quantile\nregression. Our theoretical results are complemented with experiments showing\nthe empirical superiority of our approach over SOTA sketching methods.\n","authors":["Tamim El Ahmad","Pierre Laforgue","Florence d'Alché-Buc"],"pdf_url":"https://arxiv.org/pdf/2206.03827v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12749v1","updated":"2023-02-24T17:03:51Z","published":"2023-02-24T17:03:51Z","title":"SurvivalGAN: Generating Time-to-Event Data for Survival Analysis","summary":"  Synthetic data is becoming an increasingly promising technology, and\nsuccessful applications can improve privacy, fairness, and data\ndemocratization. While there are many methods for generating synthetic tabular\ndata, the task remains non-trivial and unexplored for specific scenarios. One\nsuch scenario is survival data. Here, the key difficulty is censoring: for some\ninstances, we are not aware of the time of event, or if one even occurred.\nImbalances in censoring and time horizons cause generative models to experience\nthree new failure modes specific to survival analysis: (1) generating too few\nat-risk members; (2) generating too many at-risk members; and (3) censoring too\nearly. We formalize these failure modes and provide three new generative\nmetrics to quantify them. Following this, we propose SurvivalGAN, a generative\nmodel that handles survival data firstly by addressing the imbalance in the\ncensoring and event horizons, and secondly by using a dedicated mechanism for\napproximating time-to-event/censoring. We evaluate this method via extensive\nexperiments on medical datasets. SurvivalGAN outperforms multiple baselines at\ngenerating survival data, and in particular addresses the failure modes as\nmeasured by the new metrics, in addition to improving downstream performance of\nsurvival models trained on the synthetic data.\n","authors":["Alexander Norcliffe","Bogdan Cebere","Fergus Imrie","Pietro Lio","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2302.12749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12744v1","updated":"2023-02-24T16:54:47Z","published":"2023-02-24T16:54:47Z","title":"Detection of anomalously emitting ships through deviations from\n  predicted TROPOMI NO2 retrievals","summary":"  Starting from 2021, more demanding $\\text{NO}_\\text{x}$ emission restrictions\nwere introduced for ships operating in the North and Baltic Sea waters. Since\nall methods currently used for ship compliance monitoring are financially and\ntime demanding, it is important to prioritize the inspection of ships that have\nhigh chances of being non-compliant. The current state-of-the-art approach for\na large-scale ship $\\text{NO}_\\text{2}$ estimation is a supervised machine\nlearning-based segmentation of ship plumes on TROPOMI images. However,\nchallenging data annotation and insufficiently complex ship emission proxy used\nfor the validation limit the applicability of the model for ship compliance\nmonitoring. In this study, we present a method for the automated selection of\npotentially non-compliant ships using a combination of machine learning models\non TROPOMI/S5P satellite data. It is based on a proposed regression model\npredicting the amount of $\\text{NO}_\\text{2}$ that is expected to be produced\nby a ship with certain properties operating in the given atmospheric\nconditions. The model does not require manual labeling and is validated with\nTROPOMI data directly. The differences between the predicted and actual amount\nof produced $\\text{NO}_\\text{2}$ are integrated over different observations of\nthe same ship in time and are used as a measure of the inspection worthiness of\na ship. To assure the robustness of the results, we compare the obtained\nresults with the results of the previously developed segmentation-based method.\nShips that are also highly deviating in accordance with the segmentation method\nrequire further attention. If no other explanations can be found by checking\nthe TROPOMI data, the respective ships are advised to be the candidates for\ninspection.\n","authors":["Solomiia Kurchaba","Jasper van Vliet","Fons J. Verbeek","Cor J. Veenman"],"pdf_url":"https://arxiv.org/pdf/2302.12744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09986v2","updated":"2023-02-24T16:52:13Z","published":"2022-11-18T02:19:28Z","title":"Pandering in a Flexible Representative Democracy","summary":"  In representative democracies, the election of new representatives in regular\nelection cycles is meant to prevent corruption and other misbehavior by elected\nofficials and to keep them accountable in service of the ``will of the people.\"\nThis democratic ideal can be undermined when candidates are dishonest when\ncampaigning for election over these multiple cycles or rounds of voting. Much\nof the work on COMSOC to date has investigated strategic actions in only a\nsingle round. We introduce a novel formal model of \\emph{pandering}, or\nstrategic preference reporting by candidates seeking to be elected, and examine\nthe resilience of two democratic voting systems to pandering within a single\nround and across multiple rounds. The two voting systems we compare are\nRepresentative Democracy (RD) and Flexible Representative Democracy (FRD). For\neach voting system, our analysis centers on the types of strategies candidates\nemploy and how voters update their views of candidates based on how the\ncandidates have pandered in the past. We provide theoretical results on the\ncomplexity of pandering in our setting for a single cycle, formulate our\nproblem for multiple cycles as a Markov Decision Process, and use reinforcement\nlearning to study the effects of pandering by both single candidates and groups\nof candidates across a number of rounds.\n","authors":["Xiaolin Sun","Jacob Masur","Ben Abramowitz","Nicholas Mattei","Zizhan Zheng"],"pdf_url":"https://arxiv.org/pdf/2211.09986v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12736v1","updated":"2023-02-24T16:44:46Z","published":"2023-02-24T16:44:46Z","title":"Balanced Off-Policy Evaluation for Personalized Pricing","summary":"  We consider a personalized pricing problem in which we have data consisting\nof feature information, historical pricing decisions, and binary realized\ndemand. The goal is to perform off-policy evaluation for a new personalized\npricing policy that maps features to prices. Methods based on inverse\npropensity weighting (including doubly robust methods) for off-policy\nevaluation may perform poorly when the logging policy has little exploration or\nis deterministic, which is common in pricing applications. Building on the\nbalanced policy evaluation framework of Kallus (2018), we propose a new\napproach tailored to pricing applications. The key idea is to compute an\nestimate that minimizes the worst-case mean squared error or maximizes a\nworst-case lower bound on policy performance, where in both cases the\nworst-case is taken with respect to a set of possible revenue functions. We\nestablish theoretical convergence guarantees and empirically demonstrate the\nadvantage of our approach using a real-world pricing dataset.\n","authors":["Adam N. Elmachtoub","Vishal Gupta","Yunfan Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.12736v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12735v1","updated":"2023-02-24T16:44:15Z","published":"2023-02-24T16:44:15Z","title":"Regulating Clients' Noise Adding in Federated Learning without\n  Verification","summary":"  In federated learning (FL), clients cooperatively train a global model\nwithout revealing their raw data but gradients or parameters, while the local\ninformation can still be disclosed from local outputs transmitted to the\nparameter server. With such privacy concerns, a client may overly add\nartificial noise to his local updates to compromise the global model training,\nand we prove the selfish noise adding leads to an infinite price of anarchy\n(PoA). This paper proposes a novel pricing mechanism to regulate\nprivacy-sensitive clients without verifying their parameter updates, unlike\nexisting privacy mechanisms that assume the server's full knowledge of added\nnoise. Without knowing the ground truth, our mechanism reaches the social\noptimum to best balance the global training error and privacy loss, according\nto the difference between a client's updated parameter and all clients' average\nparameter. We also improve the FL convergence bound by refining the aggregation\nrule at the server to account for different clients' noise variances. Moreover,\nwe extend our pricing scheme to fit incomplete information of clients' privacy\nsensitivities, ensuring their truthful type reporting and the system's ex-ante\nbudget balance. Simulations show that our pricing scheme greatly improves the\nsystem performance especially when clients have diverse privacy sensitivities.\n","authors":["Shu Hong","Lingjie Duan"],"pdf_url":"https://arxiv.org/pdf/2302.12735v1.pdf","comment":"7 pages, to appear in IEEE ICC 2023"},{"id":"http://arxiv.org/abs/2301.02080v3","updated":"2023-02-24T16:42:09Z","published":"2023-01-05T14:26:55Z","title":"Semantic match: Debugging feature attribution methods in XAI for\n  healthcare","summary":"  The recent spike in certified Artificial Intelligence (AI) tools for\nhealthcare has renewed the debate around adoption of this technology. One\nthread of such debate concerns Explainable AI (XAI) and its promise to render\nAI devices more transparent and trustworthy. A few voices active in the medical\nAI space have expressed concerns on the reliability of Explainable AI\ntechniques and especially feature attribution methods, questioning their use\nand inclusion in guidelines and standards. Despite valid concerns, we argue\nthat existing criticism on the viability of post-hoc local explainability\nmethods throws away the baby with the bathwater by generalizing a problem that\nis specific to image data. We begin by characterizing the problem as a lack of\nsemantic match between explanations and human understanding. To understand when\nfeature importance can be used reliably, we introduce a distinction between\nfeature importance of low- and high-level features. We argue that for data\ntypes where low-level features come endowed with a clear semantics, such as\ntabular data like Electronic Health Records (EHRs), semantic match can be\nobtained, and thus feature attribution methods can still be employed in a\nmeaningful and useful way. Finally, we sketch a procedure to test whether\nsemantic match has been achieved.\n","authors":["Giovanni Cinà","Tabea E. Röber","Rob Goedhart","Ş. İlker Birbil"],"pdf_url":"https://arxiv.org/pdf/2301.02080v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11486v2","updated":"2023-02-24T16:26:31Z","published":"2022-05-23T17:40:31Z","title":"Robust and Agnostic Learning of Conditional Distributional Treatment\n  Effects","summary":"  The conditional average treatment effect (CATE) is the best measure of\nindividual causal effects given baseline covariates. However, the CATE only\ncaptures the (conditional) average, and can overlook risks and tail events,\nwhich are important to treatment choice. In aggregate analyses, this is usually\naddressed by measuring the distributional treatment effect (DTE), such as\ndifferences in quantiles or tail expectations between treatment groups.\nHypothetically, one can similarly fit conditional quantile regressions in each\ntreatment group and take their difference, but this would not be robust to\nmisspecification or provide agnostic best-in-class predictions. We provide a\nnew robust and model-agnostic methodology for learning the conditional DTE\n(CDTE) for a class of problems that includes conditional quantile treatment\neffects, conditional super-quantile treatment effects, and conditional\ntreatment effects on coherent risk measures given by $f$-divergences. Our\nmethod is based on constructing a special pseudo-outcome and regressing it on\ncovariates using any regression learner. Our method is model-agnostic in that\nit can provide the best projection of CDTE onto the regression model class. Our\nmethod is robust in that even if we learn these nuisances nonparametrically at\nvery slow rates, we can still learn CDTEs at rates that depend on the class\ncomplexity and even conduct inferences on linear projections of CDTEs. We\ninvestigate the behavior of our proposal in simulations, as well as in a case\nstudy of 401(k) eligibility effects on wealth.\n","authors":["Nathan Kallus","Miruna Oprescu"],"pdf_url":"https://arxiv.org/pdf/2205.11486v2.pdf","comment":"24 pages, 6 figures, AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.12721v1","updated":"2023-02-24T16:20:40Z","published":"2023-02-24T16:20:40Z","title":"LightTS: Lightweight Time Series Classification with Adaptive Ensemble\n  Distillation -- Extended Version","summary":"  Due to the sweeping digitalization of processes, increasingly vast amounts of\ntime series data are being produced. Accurate classification of such time\nseries facilitates decision making in multiple domains. State-of-the-art\nclassification accuracy is often achieved by ensemble learning where results\nare synthesized from multiple base models. This characteristic implies that\nensemble learning needs substantial computing resources, preventing their use\nin resource-limited environments, such as in edge devices. To extend the\napplicability of ensemble learning, we propose the LightTS framework that\ncompresses large ensembles into lightweight models while ensuring competitive\naccuracy. First, we propose adaptive ensemble distillation that assigns\nadaptive weights to different base models such that their varying\nclassification capabilities contribute purposefully to the training of the\nlightweight model. Second, we propose means of identifying Pareto optimal\nsettings w.r.t. model accuracy and model size, thus enabling users with a space\nbudget to select the most accurate lightweight model. We report on experiments\nusing 128 real-world time series sets and different types of base models that\njustify key decisions in the design of LightTS and provide evidence that\nLightTS is able to outperform competitors.\n","authors":["David Campos","Miao Zhang","Bin Yang","Tung Kieu","Chenjuan Guo","Christian S. Jensen"],"pdf_url":"https://arxiv.org/pdf/2302.12721v1.pdf","comment":"15 pages. An extended version of \"LightTS: Lightweight Time Series\n  Classification with Adaptive Ensemble Distillation\" accepted at SIGMOD 2023"},{"id":"http://arxiv.org/abs/2302.12716v1","updated":"2023-02-24T16:16:41Z","published":"2023-02-24T16:16:41Z","title":"Supervised Hierarchical Clustering using Graph Neural Networks for\n  Speaker Diarization","summary":"  Conventional methods for speaker diarization involve windowing an audio file\ninto short segments to extract speaker embeddings, followed by an unsupervised\nclustering of the embeddings. This multi-step approach generates speaker\nassignments for each segment. In this paper, we propose a novel Supervised\nHierArchical gRaph Clustering algorithm (SHARC) for speaker diarization where\nwe introduce a hierarchical structure using Graph Neural Network (GNN) to\nperform supervised clustering. The supervision allows the model to update the\nrepresentations and directly improve the clustering performance, thus enabling\na single-step approach for diarization. In the proposed work, the input segment\nembeddings are treated as nodes of a graph with the edge weights corresponding\nto the similarity scores between the nodes. We also propose an approach to\njointly update the embedding extractor and the GNN model to perform end-to-end\nspeaker diarization (E2E-SHARC). During inference, the hierarchical clustering\nis performed using node densities and edge existence probabilities to merge the\nsegments until convergence. In the diarization experiments, we illustrate that\nthe proposed E2E-SHARC approach achieves 53% and 44% relative improvements over\nthe baseline systems on benchmark datasets like AMI and Voxconverse,\nrespectively.\n","authors":["Prachi Singh","Amrit Kaul","Sriram Ganapathy"],"pdf_url":"https://arxiv.org/pdf/2302.12716v1.pdf","comment":"5 pages including references. Accepted in ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.12715v1","updated":"2023-02-24T16:16:19Z","published":"2023-02-24T16:16:19Z","title":"Hiding Data Helps: On the Benefits of Masking for Sparse Coding","summary":"  Sparse coding refers to modeling a signal as sparse linear combinations of\nthe elements of a learned dictionary. Sparse coding has proven to be a\nsuccessful and interpretable approach in many applications, such as signal\nprocessing, computer vision, and medical imaging. While this success has\nspurred much work on sparse coding with provable guarantees, work on the\nsetting where the learned dictionary is larger (or \\textit{over-realized}) with\nrespect to the ground truth is comparatively nascent. Existing theoretical\nresults in the over-realized regime are limited to the case of noise-less data.\n  In this paper, we show that for over-realized sparse coding in the presence\nof noise, minimizing the standard dictionary learning objective can fail to\nrecover the ground-truth dictionary, regardless of the magnitude of the signal\nin the data-generating process. Furthermore, drawing from the growing body of\nwork on self-supervised learning, we propose a novel masking objective and we\nprove that minimizing this new objective can recover the ground-truth\ndictionary. We corroborate our theoretical results with experiments across\nseveral parameter regimes, showing that our proposed objective enjoys better\nempirical performance than the standard reconstruction objective.\n","authors":["Muthu Chidambaram","Chenwei Wu","Yu Cheng","Rong Ge"],"pdf_url":"https://arxiv.org/pdf/2302.12715v1.pdf","comment":"21 pages, 3 figures"},{"id":"http://arxiv.org/abs/2207.08562v3","updated":"2023-02-24T15:57:49Z","published":"2022-07-18T12:44:59Z","title":"DHGE: Dual-view Hyper-Relational Knowledge Graph Embedding for Link\n  Prediction and Entity Typing","summary":"  In the field of representation learning on knowledge graphs (KGs), a\nhyper-relational fact consists of a main triple and several auxiliary\nattribute-value descriptions, which is considered more comprehensive and\nspecific than a triple-based fact. However, currently available\nhyper-relational KG embedding methods in a single view are limited in\napplication because they weaken the hierarchical structure that represents the\naffiliation between entities. To overcome this limitation, we propose a\ndual-view hyper-relational KG structure (DH-KG) that contains a\nhyper-relational instance view for entities and a hyper-relational ontology\nview for concepts that are abstracted hierarchically from the entities. This\npaper defines link prediction and entity typing tasks on DH-KG for the first\ntime and constructs two DH-KG datasets, JW44K-6K, extracted from Wikidata, and\nHTDM based on medical data. Furthermore, we propose DHGE, a DH-KG embedding\nmodel based on GRAN encoders, HGNNs, and joint learning. DHGE outperforms\nbaseline models on DH-KG, according to experimental results. Finally, we\nprovide an example of how this technology can be used to treat hypertension.\nOur model and new datasets are publicly available.\n","authors":["Haoran Luo","Haihong E","Ling Tan","Gengxian Zhou","Tianyu Yao","Kaiyang Wan"],"pdf_url":"https://arxiv.org/pdf/2207.08562v3.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2301.13381v2","updated":"2023-02-24T15:56:45Z","published":"2023-01-31T03:06:47Z","title":"When Source-Free Domain Adaptation Meets Learning with Noisy Labels","summary":"  Recent state-of-the-art source-free domain adaptation (SFDA) methods have\nfocused on learning meaningful cluster structures in the feature space, which\nhave succeeded in adapting the knowledge from source domain to unlabeled target\ndomain without accessing the private source data. However, existing methods\nrely on the pseudo-labels generated by source models that can be noisy due to\ndomain shift. In this paper, we study SFDA from the perspective of learning\nwith label noise (LLN). Unlike the label noise in the conventional LLN\nscenario, we prove that the label noise in SFDA follows a different\ndistribution assumption. We also prove that such a difference makes existing\nLLN methods that rely on their distribution assumptions unable to address the\nlabel noise in SFDA. Empirical evidence suggests that only marginal\nimprovements are achieved when applying the existing LLN methods to solve the\nSFDA problem. On the other hand, although there exists a fundamental difference\nbetween the label noise in the two scenarios, we demonstrate theoretically that\nthe early-time training phenomenon (ETP), which has been previously observed in\nconventional label noise settings, can also be observed in the SFDA problem.\nExtensive experiments demonstrate significant improvements to existing SFDA\nalgorithms by leveraging ETP to address the label noise in SFDA.\n","authors":["Li Yi","Gezheng Xu","Pengcheng Xu","Jiaqi Li","Ruizhi Pu","Charles Ling","A. Ian McLeod","Boyu Wang"],"pdf_url":"https://arxiv.org/pdf/2301.13381v2.pdf","comment":"ICLR 2023 camera-ready"},{"id":"http://arxiv.org/abs/2209.04766v3","updated":"2023-02-24T15:54:20Z","published":"2022-09-11T01:39:29Z","title":"Towards Sparsification of Graph Neural Networks","summary":"  As real-world graphs expand in size, larger GNN models with billions of\nparameters are deployed. High parameter count in such models makes training and\ninference on graphs expensive and challenging. To reduce the computational and\nmemory costs of GNNs, optimization methods such as pruning the redundant nodes\nand edges in input graphs have been commonly adopted. However, model\ncompression, which directly targets the sparsification of model layers, has\nbeen mostly limited to traditional Deep Neural Networks (DNNs) used for tasks\nsuch as image classification and object detection. In this paper, we utilize\ntwo state-of-the-art model compression methods (1) train and prune and (2)\nsparse training for the sparsification of weight layers in GNNs. We evaluate\nand compare the efficiency of both methods in terms of accuracy, training\nsparsity, and training FLOPs on real-world graphs. Our experimental results\nshow that on the ia-email, wiki-talk, and stackoverflow datasets for link\nprediction, sparse training with much lower training FLOPs achieves a\ncomparable accuracy with the train and prune method. On the brain dataset for\nnode classification, sparse training uses a lower number FLOPs (less than 1/7\nFLOPs of train and prune method) and preserves a much better accuracy\nperformance under extreme model sparsity.\n","authors":["Hongwu Peng","Deniz Gurevin","Shaoyi Huang","Tong Geng","Weiwen Jiang","Omer Khan","Caiwen Ding"],"pdf_url":"https://arxiv.org/pdf/2209.04766v3.pdf","comment":"ICCD 2022 Paper"},{"id":"http://arxiv.org/abs/2302.12695v1","updated":"2023-02-24T15:48:23Z","published":"2023-02-24T15:48:23Z","title":"Cross-Lingual Transfer of Cognitive Processing Complexity","summary":"  When humans read a text, their eye movements are influenced by the structural\ncomplexity of the input sentences. This cognitive phenomenon holds across\nlanguages and recent studies indicate that multilingual language models utilize\nstructural similarities between languages to facilitate cross-lingual transfer.\nWe use sentence-level eye-tracking patterns as a cognitive indicator for\nstructural complexity and show that the multilingual model XLM-RoBERTa can\nsuccessfully predict varied patterns for 13 typologically diverse languages,\ndespite being fine-tuned only on English data. We quantify the sensitivity of\nthe model to structural complexity and distinguish a range of complexity\ncharacteristics. Our results indicate that the model develops a meaningful bias\ntowards sentence length but also integrates cross-lingual differences. We\nconduct a control experiment with randomized word order and find that the model\nseems to additionally capture more complex structural information.\n","authors":["Charlotte Pouw","Nora Hollenstein","Lisa Beinborn"],"pdf_url":"https://arxiv.org/pdf/2302.12695v1.pdf","comment":"Accepted at Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2302.12693v1","updated":"2023-02-24T15:36:51Z","published":"2023-02-24T15:36:51Z","title":"Wasserstein Projection Pursuit of Non-Gaussian Signals","summary":"  We consider the general dimensionality reduction problem of locating in a\nhigh-dimensional data cloud, a $k$-dimensional non-Gaussian subspace of\ninteresting features. We use a projection pursuit approach -- we search for\nmutually orthogonal unit directions which maximise the 2-Wasserstein distance\nof the empirical distribution of data-projections along these directions from a\nstandard Gaussian. Under a generative model, where there is a underlying\n(unknown) low-dimensional non-Gaussian subspace, we prove rigorous statistical\nguarantees on the accuracy of approximating this unknown subspace by the\ndirections found by our projection pursuit approach. Our results operate in the\nregime where the data dimensionality is comparable to the sample size, and thus\nsupplement the recent literature on the non-feasibility of locating interesting\ndirections via projection pursuit in the complementary regime where the data\ndimensionality is much larger than the sample size.\n","authors":["Satyaki Mukherjee","Soumendu Sundar Mukherjee","Debarghya Ghoshdastidar"],"pdf_url":"https://arxiv.org/pdf/2302.12693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12692v1","updated":"2023-02-24T15:35:36Z","published":"2023-02-24T15:35:36Z","title":"Boosting Transformers and Language Models for Clinical Prediction in\n  Immunotherapy","summary":"  Clinical prediction is an essential task in the healthcare industry. However,\nthe recent success of transformers, on which large language models are built,\nhas not been extended to this domain. In this research, we explore the use of\ntransformers and language models in prognostic prediction for immunotherapy\nusing real-world patients' clinical data and molecular profiles. This paper\ninvestigates the potential of transformers to improve clinical prediction\ncompared to conventional machine learning approaches and addresses the\nchallenge of few-shot learning in predicting rare disease areas. The study\nbenchmarks the efficacy of baselines and language models on prognostic\nprediction across multiple cancer types and investigates the impact of\ndifferent pretrained language models under few-shot regimes. The results\ndemonstrate significant improvements in accuracy and highlight the potential of\nNLP in clinical research to improve early detection and intervention for\ndifferent diseases. Anonymous codes are available at\n\\url{https://anonymous.4open.science/r/table2text-88ED}.\n","authors":["Zekai Chen","Mariann Micsinai Balan","Kevin Brown"],"pdf_url":"https://arxiv.org/pdf/2302.12692v1.pdf","comment":"7 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2302.12689v1","updated":"2023-02-24T15:29:43Z","published":"2023-02-24T15:29:43Z","title":"GANterfactual-RL: Understanding Reinforcement Learning Agents'\n  Strategies through Visual Counterfactual Explanations","summary":"  Counterfactual explanations are a common tool to explain artificial\nintelligence models. For Reinforcement Learning (RL) agents, they answer \"Why\nnot?\" or \"What if?\" questions by illustrating what minimal change to a state is\nneeded such that an agent chooses a different action. Generating counterfactual\nexplanations for RL agents with visual input is especially challenging because\nof their large state spaces and because their decisions are part of an\noverarching policy, which includes long-term decision-making. However, research\nfocusing on counterfactual explanations, specifically for RL agents with visual\ninput, is scarce and does not go beyond identifying defective agents. It is\nunclear whether counterfactual explanations are still helpful for more complex\ntasks like analyzing the learned strategies of different agents or choosing a\nfitting agent for a specific task. We propose a novel but simple method to\ngenerate counterfactual explanations for RL agents by formulating the problem\nas a domain transfer problem which allows the use of adversarial learning\ntechniques like StarGAN. Our method is fully model-agnostic and we demonstrate\nthat it outperforms the only previous method in several computational metrics.\nFurthermore, we show in a user study that our method performs best when\nanalyzing which strategies different agents pursue.\n","authors":["Tobias Huber","Maximilian Demmler","Silvan Mertes","Matthew L. Olson","Elisabeth André"],"pdf_url":"https://arxiv.org/pdf/2302.12689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12688v1","updated":"2023-02-24T15:26:31Z","published":"2023-02-24T15:26:31Z","title":"Video4MRI: An Empirical Study on Brain Magnetic Resonance Image\n  Analytics with CNN-based Video Classification Frameworks","summary":"  To address the problem of medical image recognition, computer vision\ntechniques like convolutional neural networks (CNN) are frequently used.\nRecently, 3D CNN-based models dominate the field of magnetic resonance image\n(MRI) analytics. Due to the high similarity between MRI data and videos, we\nconduct extensive empirical studies on video recognition techniques for MRI\nclassification to answer the questions: (1) can we directly use video\nrecognition models for MRI classification, (2) which model is more appropriate\nfor MRI, (3) are the common tricks like data augmentation in video recognition\nstill useful for MRI classification? Our work suggests that advanced video\ntechniques benefit MRI classification. In this paper, four datasets of\nAlzheimer's and Parkinson's disease recognition are utilized in experiments,\ntogether with three alternative video recognition models and data augmentation\ntechniques that are frequently applied to video tasks. In terms of efficiency,\nthe results reveal that the video framework performs better than 3D-CNN models\nby 5% - 11% with 50% - 66% less trainable parameters. This report pushes\nforward the potential fusion of 3D medical imaging and video understanding\nresearch.\n","authors":["Yuxuan Zhang","Qingzhong Wang","Jiang Bian","Yi Liu","Yanwu Xu","Dejing Dou","Haoyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2302.12688v1.pdf","comment":"Accepted by IEEE ISBI'23"},{"id":"http://arxiv.org/abs/2208.05424v4","updated":"2023-02-24T15:24:51Z","published":"2022-08-08T16:54:01Z","title":"Physics-Constrained Deep Learning for Climate Downscaling","summary":"  The availability of reliable, high-resolution climate and weather data is\nimportant to inform long-term decisions on climate adaptation and mitigation\nand to guide rapid responses to extreme events. Forecasting models are limited\nby computational costs and, therefore, often generate coarse-resolution\npredictions. Statistical downscaling, including super-resolution methods from\ndeep learning, can provide an efficient method of upsampling low-resolution\ndata. However, despite achieving visually compelling results in some cases,\nsuch models frequently violate conservation laws when predicting physical\nvariables. In order to conserve physical quantities, we develop methods that\nguarantee physical constraints are satisfied by a deep learning downscaling\nmodel while also improving their performance according to traditional metrics.\nWe compare different constraining approaches and demonstrate their\napplicability across different neural architectures as well as a variety of\nclimate and weather datasets. Besides enabling faster and more accurate climate\npredictions, we also show that our novel methodologies can improve\nsuper-resolution for satellite data and standard datasets.\n","authors":["Paula Harder","Venkatesh Ramesh","Alex Hernandez-Garcia","Qidong Yang","Prasanna Sattigeri","Daniela Szwarcman","Campbell Watson","David Rolnick"],"pdf_url":"https://arxiv.org/pdf/2208.05424v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03851v2","updated":"2023-02-24T15:22:26Z","published":"2022-12-07T18:45:33Z","title":"Computing linear sections of varieties: quantum entanglement, tensor\n  decompositions and beyond","summary":"  We study the problem of finding elements in the intersection of an arbitrary\nconic variety in $\\mathbb{F}^n$ with a given linear subspace (where\n$\\mathbb{F}$ can be the real or complex field). This problem captures a rich\nfamily of algorithmic problems under different choices of the variety. The\nspecial case of the variety consisting of rank-1 matrices already has strong\nconnections to central problems in different areas like quantum information\ntheory and tensor decompositions. This problem is known to be NP-hard in the\nworst-case, even for the variety of rank-1 matrices.\n  Surprisingly, despite these hardness results we give efficient algorithms\nthat solve this problem for \"typical\" subspaces. Here, the subspace $U\n\\subseteq \\mathbb{F}^n$ is chosen generically of a certain dimension,\npotentially with some generic elements of the variety contained in it. Our main\nalgorithmic result is a polynomial time algorithm that recovers all the\nelements of $U$ that lie in the variety, under some mild non-degeneracy\nassumptions on the variety. As corollaries, we obtain the following results:\n  $\\bullet$ Uniqueness results and polynomial time algorithms for generic\ninstances of a broad class of low-rank decomposition problems that go beyond\ntensor decompositions. Here, we recover a decomposition of the form\n$\\sum_{i=1}^R v_i \\otimes w_i$, where the $v_i$ are elements of the given\nvariety $X$. This implies new algorithmic results even in the special case of\ntensor decompositions.\n  $\\bullet$ Polynomial time algorithms for several entangled subspaces problems\nin quantum entanglement, including determining $r$-entanglement, complete\nentanglement, and genuine entanglement of a subspace. While all of these\nproblems are NP-hard in the worst case, our algorithm solves them in polynomial\ntime for generic subspaces of dimension up to a constant multiple of the\nmaximum possible.\n","authors":["Nathaniel Johnston","Benjamin Lovitz","Aravindan Vijayaraghavan"],"pdf_url":"https://arxiv.org/pdf/2212.03851v2.pdf","comment":"46 pages. V2: Minor improvements to presentation, mainly in sections\n  1, 3, and 7. Comments welcome!"},{"id":"http://arxiv.org/abs/2302.12685v1","updated":"2023-02-24T15:21:39Z","published":"2023-02-24T15:21:39Z","title":"Active Membership Inference Attack under Local Differential Privacy in\n  Federated Learning","summary":"  Federated learning (FL) was originally regarded as a framework for\ncollaborative learning among clients with data privacy protection through a\ncoordinating server. In this paper, we propose a new active membership\ninference (AMI) attack carried out by a dishonest server in FL. In AMI attacks,\nthe server crafts and embeds malicious parameters into global models to\neffectively infer whether a target data sample is included in a client's\nprivate training data or not. By exploiting the correlation among data features\nthrough a non-linear decision boundary, AMI attacks with a certified guarantee\nof success can achieve severely high success rates under rigorous local\ndifferential privacy (LDP) protection; thereby exposing clients' training data\nto significant privacy risk. Theoretical and experimental results on several\nbenchmark datasets show that adding sufficient privacy-preserving noise to\nprevent our attack would significantly damage FL's model utility.\n","authors":["Truc Nguyen","Phung Lai","Khang Tran","NhatHai Phan","My T. Thai"],"pdf_url":"https://arxiv.org/pdf/2302.12685v1.pdf","comment":"To be published at AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.12683v1","updated":"2023-02-24T15:15:32Z","published":"2023-02-24T15:15:32Z","title":"Intersectional Fairness: A Fractal Approach","summary":"  The issue of fairness in AI has received an increasing amount of attention in\nrecent years. The problem can be approached by looking at different protected\nattributes (e.g., ethnicity, gender, etc) independently, but fairness for\nindividual protected attributes does not imply intersectional fairness. In this\nwork, we frame the problem of intersectional fairness within a geometrical\nsetting. We project our data onto a hypercube, and split the analysis of\nfairness by levels, where each level encodes the number of protected attributes\nwe are intersecting over. We prove mathematically that, while fairness does not\npropagate \"down\" the levels, it does propagate \"up\" the levels. This means that\nensuring fairness for all subgroups at the lowest intersectional level (e.g.,\nblack women, white women, black men and white men), will necessarily result in\nfairness for all the above levels, including each of the protected attributes\n(e.g., ethnicity and gender) taken independently. We also derive a formula\ndescribing the variance of the set of estimated success rates on each level,\nunder the assumption of perfect fairness. Using this theoretical finding as a\nbenchmark, we define a family of metrics which capture overall intersectional\nbias. Finally, we propose that fairness can be metaphorically thought of as a\n\"fractal\" problem. In fractals, patterns at the smallest scale repeat at a\nlarger scale. We see from this example that tackling the problem at the lowest\npossible level, in a bottom-up manner, leads to the natural emergence of fair\nAI. We suggest that trustworthiness is necessarily an emergent, fractal and\nrelational property of the AI system.\n","authors":["Giulio Filippi","Sara Zannone","Adriano Koshiyama"],"pdf_url":"https://arxiv.org/pdf/2302.12683v1.pdf","comment":"18 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.12682v1","updated":"2023-02-24T15:15:07Z","published":"2023-02-24T15:15:07Z","title":"A DeepONet Multi-Fidelity Approach for Residual Learning in Reduced\n  Order Modeling","summary":"  In the present work, we introduce a novel approach to enhance the precision\nof reduced order models by exploiting a multi-fidelity perspective and\nDeepONets. Reduced models provide a real-time numerical approximation by\nsimplifying the original model. The error introduced by such operation is\nusually neglected and sacrificed in order to reach a fast computation. We\npropose to couple the model reduction to a machine learning residual learning,\nsuch that the above-mentioned error can be learnt by a neural network and\ninferred for new predictions. We emphasize that the framework maximizes the\nexploitation of the high-fidelity information, using it for building the\nreduced order model and for learning the residual. In this work we explore the\nintegration of proper orthogonal decomposition (POD), and gappy POD for sensors\ndata, with the recent DeepONet architecture. Numerical investigations for a\nparametric benchmark function and a nonlinear parametric Navier-Stokes problem\nare presented.\n","authors":["Nicola Demo","Marco Tezzele","Gianluigi Rozza"],"pdf_url":"https://arxiv.org/pdf/2302.12682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06359v2","updated":"2023-02-24T15:07:53Z","published":"2023-02-13T13:45:50Z","title":"Fixing Overconfidence in Dynamic Neural Networks","summary":"  Dynamic neural networks are a recent technique that promises a remedy for the\nincreasing size of modern deep learning models by dynamically adapting their\ncomputational cost to the difficulty of the input samples. In this way, the\nmodel can adjust to a limited computational budget. However, the poor quality\nof uncertainty estimates in deep learning models makes it difficult to\ndistinguish between hard and easy samples. To address this challenge, we\npresent a computationally efficient approach for post-hoc uncertainty\nquantification in dynamic neural networks. We show that adequately quantifying\nand accounting for both aleatoric and epistemic uncertainty through a\nprobabilistic treatment of the last layers improves the predictive performance\nand aids decision-making when determining the computational budget. In the\nexperiments, we show improvements on CIFAR-100 and ImageNet in terms of\naccuracy, capturing uncertainty, and calibration error.\n","authors":["Lassi Meronen","Martin Trapp","Andrea Pilzer","Le Yang","Arno Solin"],"pdf_url":"https://arxiv.org/pdf/2302.06359v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10952v3","updated":"2023-02-24T15:01:07Z","published":"2022-10-20T01:55:59Z","title":"Autoencoded sparse Bayesian in-IRT factorization, calibration, and\n  amortized inference for the Work Disability Functional Assessment Battery","summary":"  The Work Disability Functional Assessment Battery (WD-FAB) is a\nmultidimensional item response theory (IRT) instrument designed for assessing\nwork-related mental and physical function based on responses to an item bank.\nIn prior iterations it was developed using traditional means -- linear\nfactorization and null hypothesis statistical testing for item\npartitioning/selection, and finally, posthoc calibration of disjoint\nunidimensional IRT models. As a result, the WD-FAB, like many other IRT\ninstruments, is a posthoc model. Its item partitioning, based on exploratory\nfactor analysis, is blind to the final nonlinear IRT model and is not performed\nin a manner consistent with goodness of fit to the final model. In this\nmanuscript, we develop a Bayesian hierarchical model for self-consistently\nperforming the following simultaneous tasks: scale factorization, item\nselection, parameter identification, and response scoring. This method uses\nsparsity-based shrinkage to obviate the linear factorization and null\nhypothesis statistical tests that are usually required for developing\nmultidimensional IRT models, so that item partitioning is consistent with the\nultimate nonlinear factor model. We also analogize our multidimensional IRT\nmodel to probabilistic autoencoders, specifying an encoder function that\namortizes the inference of ability parameters from item responses. The encoder\nfunction is equivalent to the \"VBE\" step in a stochastic variational Bayesian\nexpectation maximization (VBEM) procedure that we use for approxiamte Bayesian\ninference on the entire model. We use the method on a sample of WD-FAB item\nresponses and compare the resulting item discriminations to those obtained\nusing the traditional posthoc method.\n","authors":["Joshua C. Chang","Carson C. Chow","Julia Porcino"],"pdf_url":"https://arxiv.org/pdf/2210.10952v3.pdf","comment":"Camera-ready AISTATS 2023 version, previously appearing at AAAI AI4SG\n  2023"},{"id":"http://arxiv.org/abs/2302.12670v1","updated":"2023-02-24T14:50:47Z","published":"2023-02-24T14:50:47Z","title":"Personalized Pricing with Invalid Instrumental Variables:\n  Identification, Estimation, and Policy Learning","summary":"  Pricing based on individual customer characteristics is widely used to\nmaximize sellers' revenues. This work studies offline personalized pricing\nunder endogeneity using an instrumental variable approach. Standard\ninstrumental variable methods in causal inference/econometrics either focus on\na discrete treatment space or require the exclusion restriction of instruments\nfrom having a direct effect on the outcome, which limits their applicability in\npersonalized pricing. In this paper, we propose a new policy learning method\nfor Personalized pRicing using Invalid iNsTrumental variables (PRINT) for\ncontinuous treatment that allow direct effects on the outcome. Specifically,\nrelying on the structural models of revenue and price, we establish the\nidentifiability condition of an optimal pricing strategy under endogeneity with\nthe help of invalid instrumental variables. Based on this new identification,\nwhich leads to solving conditional moment restrictions with generalized\nresidual functions, we construct an adversarial min-max estimator and learn an\noptimal pricing strategy. Furthermore, we establish an asymptotic regret bound\nto find an optimal pricing strategy. Finally, we demonstrate the effectiveness\nof the proposed method via extensive simulation studies as well as a real data\napplication from an US online auto loan company.\n","authors":["Rui Miao","Zhengling Qi","Cong Shi","Lin Lin"],"pdf_url":"https://arxiv.org/pdf/2302.12670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12668v1","updated":"2023-02-24T14:48:28Z","published":"2023-02-24T14:48:28Z","title":"Improving the Data Efficiency of Multi-Objective Quality-Diversity\n  through Gradient Assistance and Crowding Exploration","summary":"  Quality-Diversity (QD) algorithms have recently gained traction as\noptimisation methods due to their effectiveness at escaping local optima and\ncapability of generating wide-ranging and high-performing solutions. Recently,\nMulti-Objective MAP-Elites (MOME) extended the QD paradigm to the\nmulti-objective setting by maintaining a Pareto front in each cell of a\nmap-elites grid. MOME achieved a global performance that competed with NSGA-II\nand SPEA2, two well-established Multi-Objective Evolutionary Algorithms (MOEA),\nwhile also acquiring a diverse repertoire of solutions. However, MOME is\nlimited by non-directed genetic search mechanisms which struggle in\nhigh-dimensional search spaces. In this work, we present Multi-Objective\nMAP-Elites with Policy-Gradient Assistance and Crowding-based Exploration\n(MOME-PGX): a new QD algorithm that extends MOME to improve its data efficiency\nand performance. MOME-PGX uses gradient-based optimisation to efficiently drive\nsolutions towards higher performance. It also introduces crowding-based\nmechanisms to create an improved exploration strategy and to encourage\nuniformity across Pareto fronts. We evaluate MOME-PGX in four simulated robot\nlocomotion tasks and demonstrate that it converges faster and to a higher\nperformance than all other baselines. We show that MOME-PGX is between 4.3 and\n42 times more data-efficient than MOME and doubles the performance of MOME,\nNSGA-II and SPEA2 in challenging environments.\n","authors":["Hannah Janmohamed","Thomas Pierrot","Antoine Cully"],"pdf_url":"https://arxiv.org/pdf/2302.12668v1.pdf","comment":"Submitted to GECCO 2023"},{"id":"http://arxiv.org/abs/2302.12666v1","updated":"2023-02-24T14:41:48Z","published":"2023-02-24T14:41:48Z","title":"Modelling Temporal Document Sequences for Clinical ICD Coding","summary":"  Past studies on the ICD coding problem focus on predicting clinical codes\nprimarily based on the discharge summary. This covers only a small fraction of\nthe notes generated during each hospital stay and leaves potential for\nimproving performance by analysing all the available clinical notes. We propose\na hierarchical transformer architecture that uses text across the entire\nsequence of clinical notes in each hospital stay for ICD coding, and\nincorporates embeddings for text metadata such as their position, time, and\ntype of note. While using all clinical notes increases the quantity of data\nsubstantially, superconvergence can be used to reduce training costs. We\nevaluate the model on the MIMIC-III dataset. Our model exceeds the prior\nstate-of-the-art when using only discharge summaries as input, and achieves\nfurther performance improvements when all clinical notes are used as input.\n","authors":["Clarence Boon Liang Ng","Diogo Santos","Marek Rei"],"pdf_url":"https://arxiv.org/pdf/2302.12666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08480v2","updated":"2023-02-24T14:28:08Z","published":"2022-08-17T18:49:53Z","title":"Nearly Optimal Latent State Decoding in Block MDPs","summary":"  We investigate the problems of model estimation and reward-free learning in\nepisodic Block MDPs. In these MDPs, the decision maker has access to rich\nobservations or contexts generated from a small number of latent states. We are\nfirst interested in estimating the latent state decoding function (the mapping\nfrom the observations to latent states) based on data generated under a fixed\nbehavior policy. We derive an information-theoretical lower bound on the error\nrate for estimating this function and present an algorithm approaching this\nfundamental limit. In turn, our algorithm also provides estimates of all the\ncomponents of the MDP. We then study the problem of learning near-optimal\npolicies in the reward-free framework. Based on our efficient model estimation\nalgorithm, we show that we can infer a policy converging (as the number of\ncollected samples grows large) to the optimal policy at the best possible rate.\nInterestingly, our analysis provides necessary and sufficient conditions under\nwhich exploiting the block structure yields improvements in the sample\ncomplexity for identifying near-optimal policies. When these conditions are\nmet, the sample complexity in the minimax reward-free setting is improved by a\nmultiplicative factor $n$, where $n$ is the number of possible contexts.\n","authors":["Yassir Jedra","Junghyun Lee","Alexandre Proutière","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2208.08480v2.pdf","comment":"Y. Jedra and J. Lee contributed equally; 100 pages, 3 figures;\n  Accepted to the 26th International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2023)"},{"id":"http://arxiv.org/abs/2302.12244v2","updated":"2023-02-24T14:03:24Z","published":"2023-02-23T18:58:36Z","title":"To the Noise and Back: Diffusion for Shared Autonomy","summary":"  Shared autonomy is an operational concept in which a user and an autonomous\nagent collaboratively control a robotic system. It provides a number of\nadvantages over the extremes of full-teleoperation and full-autonomy in many\nsettings. Traditional approaches to shared autonomy rely on knowledge of the\nenvironment dynamics, a discrete space of user goals that is known a priori, or\nknowledge of the user's policy -- assumptions that are unrealistic in many\ndomains. Recent works relax some of these assumptions by formulating shared\nautonomy with model-free deep reinforcement learning (RL). In particular, they\nno longer need knowledge of the goal space (e.g., that the goals are discrete\nor constrained) or environment dynamics. However, they need knowledge of a\ntask-specific reward function to train the policy. Unfortunately, such reward\nspecification can be a difficult and brittle process. On top of that, the\nformulations inherently rely on human-in-the-loop training, and that\nnecessitates them to prepare a policy that mimics users' behavior. In this\npaper, we present a new approach to shared autonomy that employs a modulation\nof the forward and reverse diffusion process of diffusion models. Our approach\ndoes not assume known environment dynamics or the space of user goals, and in\ncontrast to previous work, it does not require any reward feedback, nor does it\nrequire access to the user's policy during training. Instead, our framework\nlearns a distribution over a space of desired behaviors. It then employs a\ndiffusion model to translate the user's actions to a sample from this\ndistribution. Crucially, we show that it is possible to carry out this process\nin a manner that preserves the user's control authority. We evaluate our\nframework on a series of challenging continuous control tasks, and analyze its\nability to effectively correct user actions while maintaining their autonomy.\n","authors":["Takuma Yoneda","Luzhe Sun","and Ge Yang","Bradly Stadie","Matthew Walter"],"pdf_url":"https://arxiv.org/pdf/2302.12244v2.pdf","comment":"https://diffusion-for-shared-autonomy.github.io/"},{"id":"http://arxiv.org/abs/2302.12636v1","updated":"2023-02-24T13:55:33Z","published":"2023-02-24T13:55:33Z","title":"Streamlining Multimodal Data Fusion in Wireless Communication and Sensor\n  Networks","summary":"  This paper presents a novel approach for multimodal data fusion based on the\nVector-Quantized Variational Autoencoder (VQVAE) architecture. The proposed\nmethod is simple yet effective in achieving excellent reconstruction\nperformance on paired MNIST-SVHN data and WiFi spectrogram data. Additionally,\nthe multimodal VQVAE model is extended to the 5G communication scenario, where\nan end-to-end Channel State Information (CSI) feedback system is implemented to\ncompress data transmitted between the base-station (eNodeB) and User Equipment\n(UE), without significant loss of performance. The proposed model learns a\ndiscriminative compressed feature space for various types of input data (CSI,\nspectrograms, natural images, etc), making it a suitable solution for\napplications with limited computational resources.\n","authors":["Mohammud J. Bocus","Xiaoyang Wang","Robert. J. Piechocki"],"pdf_url":"https://arxiv.org/pdf/2302.12636v1.pdf","comment":"10 pages, 12 figures, 3 tables, under review in IEEE Transactions on\n  Cognitive Communications and Networking"},{"id":"http://arxiv.org/abs/2302.11970v2","updated":"2023-02-24T13:41:35Z","published":"2023-02-23T12:40:36Z","title":"ArtiFact: A Large-Scale Dataset with Artificial and Factual Images for\n  Generalizable and Robust Synthetic Image Detection","summary":"  Synthetic image generation has opened up new opportunities but has also\ncreated threats in regard to privacy, authenticity, and security. Detecting\nfake images is of paramount importance to prevent illegal activities, and\nprevious research has shown that generative models leave unique patterns in\ntheir synthetic images that can be exploited to detect them. However, the\nfundamental problem of generalization remains, as even state-of-the-art\ndetectors encounter difficulty when facing generators never seen during\ntraining. To assess the generalizability and robustness of synthetic image\ndetectors in the face of real-world impairments, this paper presents a\nlarge-scale dataset named ArtiFact, comprising diverse generators, object\ncategories, and real-world challenges. Moreover, the proposed multi-class\nclassification scheme, combined with a filter stride reduction strategy\naddresses social platform impairments and effectively detects synthetic images\nfrom both seen and unseen generators. The proposed solution significantly\noutperforms other top teams by 8.34% on Test 1, 1.26% on Test 2, and 15.08% on\nTest 3 in the IEEE VIP Cup challenge at ICIP 2022, as measured by the accuracy\nmetric.\n","authors":["Md Awsafur Rahman","Bishmoy Paul","Najibul Haque Sarker","Zaber Ibn Abdul Hakim","Shaikh Anowarul Fattah"],"pdf_url":"https://arxiv.org/pdf/2302.11970v2.pdf","comment":"Figures High-Res"},{"id":"http://arxiv.org/abs/2210.13937v2","updated":"2023-02-24T13:40:00Z","published":"2022-10-25T11:47:33Z","title":"Multi-Fidelity Bayesian Optimization with Unreliable Information Sources","summary":"  Bayesian optimization (BO) is a powerful framework for optimizing black-box,\nexpensive-to-evaluate functions. Over the past decade, many algorithms have\nbeen proposed to integrate cheaper, lower-fidelity approximations of the\nobjective function into the optimization process, with the goal of converging\ntowards the global optimum at a reduced cost. This task is generally referred\nto as multi-fidelity Bayesian optimization (MFBO). However, MFBO algorithms can\nlead to higher optimization costs than their vanilla BO counterparts,\nespecially when the low-fidelity sources are poor approximations of the\nobjective function, therefore defeating their purpose. To address this issue,\nwe propose rMFBO (robust MFBO), a methodology to make any GP-based MFBO scheme\nrobust to the addition of unreliable information sources. rMFBO comes with a\ntheoretical guarantee that its performance can be bound to its vanilla BO\nanalog, with high controllable probability. We demonstrate the effectiveness of\nthe proposed methodology on a number of numerical benchmarks, outperforming\nearlier MFBO methods on unreliable sources. We expect rMFBO to be particularly\nuseful to reliably include human experts with varying knowledge within BO\nprocesses.\n","authors":["Petrus Mikkola","Julien Martinelli","Louis Filstroff","Samuel Kaski"],"pdf_url":"https://arxiv.org/pdf/2210.13937v2.pdf","comment":"Accepted for publication at AISTATS 2023. Code available at\n  https://github.com/AaltoPML/rMFBO"},{"id":"http://arxiv.org/abs/2302.12619v1","updated":"2023-02-24T13:30:35Z","published":"2023-02-24T13:30:35Z","title":"T-Phenotype: Discovering Phenotypes of Predictive Temporal Patterns in\n  Disease Progression","summary":"  Clustering time-series data in healthcare is crucial for clinical phenotyping\nto understand patients' disease progression patterns and to design treatment\nguidelines tailored to homogeneous patient subgroups. While rich temporal\ndynamics enable the discovery of potential clusters beyond static correlations,\ntwo major challenges remain outstanding: i) discovery of predictive patterns\nfrom many potential temporal correlations in the multi-variate time-series data\nand ii) association of individual temporal patterns to the target label\ndistribution that best characterizes the underlying clinical progression. To\naddress such challenges, we develop a novel temporal clustering method,\nT-Phenotype, to discover phenotypes of predictive temporal patterns from\nlabeled time-series data. We introduce an efficient representation learning\napproach in frequency domain that can encode variable-length,\nirregularly-sampled time-series into a unified representation space, which is\nthen applied to identify various temporal patterns that potentially contribute\nto the target label using a new notion of path-based similarity. Throughout the\nexperiments on synthetic and real-world datasets, we show that T-Phenotype\nachieves the best phenotype discovery performance over all the evaluated\nbaselines. We further demonstrate the utility of T-Phenotype by uncovering\nclinically meaningful patient subgroups characterized by unique temporal\npatterns.\n","authors":["Yuchao Qin","Mihaela van der Schaar","Changhee Lee"],"pdf_url":"https://arxiv.org/pdf/2302.12619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12617v1","updated":"2023-02-24T13:26:03Z","published":"2023-02-24T13:26:03Z","title":"Leveraging Jumpy Models for Planning and Fast Learning in Robotic\n  Domains","summary":"  In this paper we study the problem of learning multi-step dynamics prediction\nmodels (jumpy models) from unlabeled experience and their utility for fast\ninference of (high-level) plans in downstream tasks. In particular we propose\nto learn a jumpy model alongside a skill embedding space offline, from\npreviously collected experience for which no labels or reward annotations are\nrequired. We then investigate several options of harnessing those learned\ncomponents in combination with model-based planning or model-free reinforcement\nlearning (RL) to speed up learning on downstream tasks. We conduct a set of\nexperiments in the RGB-stacking environment, showing that planning with the\nlearned skills and the associated model can enable zero-shot generalization to\nnew tasks, and can further speed up training of policies via reinforcement\nlearning. These experiments demonstrate that jumpy models which incorporate\ntemporal abstraction can facilitate planning in long-horizon tasks in which\nstandard dynamics models fail.\n","authors":["Jingwei Zhang","Jost Tobias Springenberg","Arunkumar Byravan","Leonard Hasenclever","Abbas Abdolmaleki","Dushyant Rao","Nicolas Heess","Martin Riedmiller"],"pdf_url":"https://arxiv.org/pdf/2302.12617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01716v2","updated":"2023-02-24T12:59:48Z","published":"2022-11-03T11:08:41Z","title":"Discussion of Features for Acoustic Anomaly Detection under Industrial\n  Disturbing Noise in an End-of-Line Test of Geared Motors","summary":"  In the end-of-line test of geared motors, the evaluation of product qual-ity\nis important. Due to time constraints and the high diversity of variants,\nacous-tic measurements are more economical than vibration measurements.\nHowever, the acoustic data is affected by industrial disturbing noise.\nTherefore, the aim of this study is to investigate the robustness of features\nused for anomaly detection in geared motor end-of-line testing. A real-world\ndataset with typical faults and acoustic disturbances is recorded by an\nacoustic array. This includes industrial noise from the production and\nsystematically produced disturbances, used to compare the robustness. Overall,\nit is proposed to apply features extracted from a log-envelope spectrum\ntogether with psychoacoustic features. The anomaly de-tection is done by using\nthe isolation forest or the more universal bagging random miner. Most\ndisturbances can be circumvented, while the use of a hammer or air pressure\noften causes problems. In general, these results are important for condi-tion\nmonitoring tasks that are based on acoustic or vibration measurements.\nFur-thermore, a real-world problem description is presented to improve common\nsig-nal processing and machine learning tasks.\n","authors":["Peter Wissbrock","David Pelkmann","Yvonne Richter"],"pdf_url":"https://arxiv.org/pdf/2211.01716v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2302.12606v1","updated":"2023-02-24T12:47:58Z","published":"2023-02-24T12:47:58Z","title":"Retrospective Uncertainties for Deep Models using Vine Copulas","summary":"  Despite the major progress of deep models as learning machines, uncertainty\nestimation remains a major challenge. Existing solutions rely on modified loss\nfunctions or architectural changes. We propose to compensate for the lack of\nbuilt-in uncertainty estimates by supplementing any network, retrospectively,\nwith a subsequent vine copula model, in an overall compound we call Vine-Copula\nNeural Network (VCNN). Through synthetic and real-data experiments, we show\nthat VCNNs could be task (regression/classification) and architecture\n(recurrent, fully connected) agnostic while providing reliable and\nbetter-calibrated uncertainty estimates, comparable to state-of-the-art\nbuilt-in uncertainty solutions.\n","authors":["Nataša Tagasovska","Firat Ozdemir","Axel Brando"],"pdf_url":"https://arxiv.org/pdf/2302.12606v1.pdf","comment":"Accepted at AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.12604v1","updated":"2023-02-24T12:40:28Z","published":"2023-02-24T12:40:28Z","title":"Neural Laplace Control for Continuous-time Delayed Systems","summary":"  Many real-world offline reinforcement learning (RL) problems involve\ncontinuous-time environments with delays. Such environments are characterized\nby two distinctive features: firstly, the state x(t) is observed at irregular\ntime intervals, and secondly, the current action a(t) only affects the future\nstate x(t + g) with an unknown delay g > 0. A prime example of such an\nenvironment is satellite control where the communication link between earth and\na satellite causes irregular observations and delays. Existing offline RL\nalgorithms have achieved success in environments with irregularly observed\nstates in time or known delays. However, environments involving both irregular\nobservations in time and unknown delays remains an open and challenging\nproblem. To this end, we propose Neural Laplace Control, a continuous-time\nmodel-based offline RL method that combines a Neural Laplace dynamics model\nwith a model predictive control (MPC) planner--and is able to learn from an\noffline dataset sampled with irregular time intervals from an environment that\nhas a inherent unknown constant delay. We show experimentally on\ncontinuous-time delayed environments it is able to achieve near expert policy\nperformance.\n","authors":["Samuel Holt","Alihan Hüyük","Zhaozhi Qian","Hao Sun","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2302.12604v1.pdf","comment":"Proceedings of the 26th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2023, Valencia, Spain. PMLR: Volume\n  206. Copyright 2023 by the author(s)"},{"id":"http://arxiv.org/abs/2302.08646v2","updated":"2023-02-24T12:34:33Z","published":"2023-02-17T01:31:53Z","title":"AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust\n  Autonomous Driving","summary":"  Object detection with on-board sensors (e.g., lidar, radar, and camera) play\na crucial role in autonomous driving (AD), and these sensors complement each\nother in modalities. While crowdsensing may potentially exploit these sensors\n(of huge quantity) to derive more comprehensive knowledge, \\textit{federated\nlearning} (FL) appears to be the necessary tool to reach this potential: it\nenables autonomous vehicles (AVs) to train machine learning models without\nexplicitly sharing raw sensory data. However, the multimodal sensors introduce\nvarious data heterogeneity across distributed AVs (e.g., label quantity skews\nand varied modalities), posing critical challenges to effective FL. To this\nend, we present AutoFed as a heterogeneity-aware FL framework to fully exploit\nmultimodal sensory data on AVs and thus enable robust AD. Specifically, we\nfirst propose a novel model leveraging pseudo-labeling to avoid mistakenly\ntreating unlabeled objects as the background. We also propose an\nautoencoder-based data imputation method to fill missing data modality (of\ncertain AVs) with the available ones. To further reconcile the heterogeneity,\nwe finally present a client selection mechanism exploiting the similarities\namong client models to improve both training stability and convergence rate.\nOur experiments on benchmark dataset confirm that AutoFed substantially\nimproves over status quo approaches in both precision and recall, while\ndemonstrating strong robustness to adverse weather conditions.\n","authors":["Tianyue Zheng","Ang Li","Zhe Chen","Hongbo Wang","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2302.08646v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12599v1","updated":"2023-02-24T12:33:55Z","published":"2023-02-24T12:33:55Z","title":"A Machine Learning Approach for Hierarchical Classification of Software\n  Requirements","summary":"  Context: Classification of software requirements into different categories is\na critically important task in requirements engineering (RE). Developing\nmachine learning (ML) approaches for requirements classification has attracted\ngreat interest in the RE community since the 2000s. Objective: This paper aims\nto address two related problems that have been challenging real-world\napplications of ML approaches: the problems of class imbalance and high\ndimensionality with low sample size data (HDLSS). These problems can greatly\ndegrade the classification performance of ML methods. Method: The paper\nproposes HC4RC, a novel ML approach for multiclass classification of\nrequirements. HC4RC solves the aforementioned problems through\nsemantic-role-based feature selection, dataset decomposition and hierarchical\nclassification. We experimentally compare the effectiveness of HC4RC with three\nclosely related approaches - two of which are based on a traditional\nstatistical classification model whereas one uses an advanced deep learning\nmodel. Results: Our experiment shows: 1) The class imbalance and HDLSS problems\npresent a challenge to both traditional and advanced ML approaches. 2) The\nHC4RC approach is simple to use and can effectively address the class imbalance\nand HDLSS problems compared to similar approaches. Conclusion: This paper makes\nan important practical contribution to addressing the class imbalance and HDLSS\nproblems in multiclass classification of software requirements.\n","authors":["Manal Binkhonain","Liping Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.12599v1.pdf","comment":"36 pages, 3 tables, 4 figures"},{"id":"http://arxiv.org/abs/2302.12598v1","updated":"2023-02-24T12:21:30Z","published":"2023-02-24T12:21:30Z","title":"Dynamic Graph Convolution Network with Spatio-Temporal Attention Fusion\n  for Traffic Flow Prediction","summary":"  Accurate and real-time traffic state prediction is of great practical\nimportance for urban traffic control and web mapping services (e.g. Google\nMaps). With the support of massive data, deep learning methods have shown their\npowerful capability in capturing the complex spatio-temporal patterns of road\nnetworks. However, existing approaches use independent components to model\ntemporal and spatial dependencies and thus ignore the heterogeneous\ncharacteristics of traffic flow that vary with time and space. In this paper,\nwe propose a novel dynamic graph convolution network with spatio-temporal\nattention fusion. The method not only captures local spatio-temporal\ninformation that changes over time, but also comprehensively models\nlong-distance and multi-scale spatio-temporal patterns based on the fusion\nmechanism of temporal and spatial attention. This design idea can greatly\nimprove the spatio-temporal perception of the model. We conduct extensive\nexperiments in 4 real-world datasets to demonstrate that our model achieves\nstate-of-the-art performance compared to 22 baseline models.\n","authors":["Xunlian Luo","Chunjiang Zhu","Detian Zhang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2302.12598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.03668v4","updated":"2023-02-24T11:46:01Z","published":"2022-03-04T14:16:50Z","title":"A Typology for Exploring the Mitigation of Shortcut Behavior","summary":"  As machine learning models become increasingly larger, trained weakly\nsupervised on large, possibly uncurated data sets, it becomes increasingly\nimportant to establish mechanisms for inspecting, interacting, and revising\nmodels to mitigate learning shortcuts and guarantee their learned knowledge is\naligned with human knowledge. The recently proposed XIL framework was developed\nfor this purpose, and several such methods have been introduced, each with\nindividual motivations and methodological details. In this work, we provide a\nunification of various XIL methods into a single typology by establishing a\ncommon set of basic modules. In doing so, we pave the way for a principled\ncomparison of existing, but, importantly, also future XIL approaches. In\naddition, we discuss existing and introduce novel measures and benchmarks for\nevaluating the overall abilities of a XIL method. Given this extensive toolbox,\nincluding our typology, measures, and benchmarks, we finally compare several\nrecent XIL methods methodologically and quantitatively. In our evaluations, all\nmethods prove to revise a model successfully. However, we found remarkable\ndifferences in individual benchmark tasks, revealing valuable\napplication-relevant aspects for integrating these benchmarks in developing\nfuture methods.\n","authors":["Felix Friedrich","Wolfgang Stammer","Patrick Schramowski","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2203.03668v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16189v2","updated":"2023-02-24T11:33:42Z","published":"2022-10-28T14:56:18Z","title":"Preferential Subsampling for Stochastic Gradient Langevin Dynamics","summary":"  Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to\ntraditional MCMC, by constructing an unbiased estimate of the gradient of the\nlog-posterior with a small, uniformly-weighted subsample of the data. While\nefficient to compute, the resulting gradient estimator may exhibit a high\nvariance and impact sampler performance. The problem of variance control has\nbeen traditionally addressed by constructing a better stochastic gradient\nestimator, often using control variates. We propose to use a discrete,\nnon-uniform probability distribution to preferentially subsample data points\nthat have a greater impact on the stochastic gradient. In addition, we present\na method of adaptively adjusting the subsample size at each iteration of the\nalgorithm, so that we increase the subsample size in areas of the sample space\nwhere the gradient is harder to estimate. We demonstrate that such an approach\ncan maintain the same level of accuracy while substantially reducing the\naverage subsample size that is used.\n","authors":["Srshti Putcha","Christopher Nemeth","Paul Fearnhead"],"pdf_url":"https://arxiv.org/pdf/2210.16189v2.pdf","comment":"22 pages, 5 figures. To appear in the proceedings of AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.12580v1","updated":"2023-02-24T11:27:39Z","published":"2023-02-24T11:27:39Z","title":"Membership Inference Attacks against Synthetic Data through Overfitting\n  Detection","summary":"  Data is the foundation of most science. Unfortunately, sharing data can be\nobstructed by the risk of violating data privacy, impeding research in fields\nlike healthcare. Synthetic data is a potential solution. It aims to generate\ndata that has the same distribution as the original data, but that does not\ndisclose information about individuals. Membership Inference Attacks (MIAs) are\na common privacy attack, in which the attacker attempts to determine whether a\nparticular real sample was used for training of the model. Previous works that\npropose MIAs against generative models either display low performance -- giving\nthe false impression that data is highly private -- or need to assume access to\ninternal generative model parameters -- a relatively low-risk scenario, as the\ndata publisher often only releases synthetic data, not the model. In this work\nwe argue for a realistic MIA setting that assumes the attacker has some\nknowledge of the underlying data distribution. We propose DOMIAS, a\ndensity-based MIA model that aims to infer membership by targeting local\noverfitting of the generative model. Experimentally we show that DOMIAS is\nsignificantly more successful at MIA than previous work, especially at\nattacking uncommon samples. The latter is disconcerting since these samples may\ncorrespond to underrepresented groups. We also demonstrate how DOMIAS' MIA\nperformance score provides an interpretable metric for privacy, giving data\npublishers a new tool for achieving the desired privacy-utility trade-off in\ntheir synthetic data.\n","authors":["Boris van Breugel","Hao Sun","Zhaozhi Qian","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2302.12580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12578v1","updated":"2023-02-24T11:25:50Z","published":"2023-02-24T11:25:50Z","title":"Fairness in Language Models Beyond English: Gaps and Challenges","summary":"  With language models becoming increasingly ubiquitous, it has become\nessential to address their inequitable treatment of diverse demographic groups\nand factors. Most research on evaluating and mitigating fairness harms has been\nconcentrated on English, while multilingual models and non-English languages\nhave received comparatively little attention. In this paper, we survey\ndifferent aspects of fairness in languages beyond English and multilingual\ncontexts. This paper presents a survey of fairness in multilingual and\nnon-English contexts, highlighting the shortcomings of current research and the\ndifficulties faced by methods designed for English. We contend that the\nmultitude of diverse cultures and languages across the world makes it\ninfeasible to achieve comprehensive coverage in terms of constructing fairness\ndatasets. Thus, the measurement and mitigation of biases must evolve beyond the\ncurrent dataset-driven practices that are narrowly focused on specific\ndimensions and types of biases and, therefore, impossible to scale across\nlanguages and cultures.\n","authors":["Krithika Ramesh","Sunayana Sitaram","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2302.12578v1.pdf","comment":"Accepted to EACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2211.15226v2","updated":"2023-02-24T11:25:22Z","published":"2022-11-28T11:24:51Z","title":"RAMP: A Flat Nanosecond Optical Network and MPI Operations for\n  Distributed Deep Learning Systems","summary":"  Distributed deep learning (DDL) systems strongly depend on network\nperformance. Current electronic packet switched (EPS) network architectures and\ntechnologies suffer from variable diameter topologies, low-bisection bandwidth\nand over-subscription affecting completion time of communication and collective\noperations.\n  We introduce a near-exascale, full-bisection bandwidth, all-to-all,\nsingle-hop, all-optical network architecture with nanosecond reconfiguration\ncalled RAMP, which supports large-scale distributed and parallel computing\nsystems (12.8~Tbps per node for up to 65,536 nodes).\n  For the first time, a custom RAMP-x MPI strategy and a network transcoder is\nproposed to run MPI collective operations across the optical circuit switched\n(OCS) network in a schedule-less and contention-less manner. RAMP achieves\n7.6-171$\\times$ speed-up in completion time across all MPI operations compared\nto realistic EPS and OCS counterparts. It can also deliver a 1.3-16$\\times$ and\n7.8-58$\\times$ reduction in Megatron and DLRM training time respectively} while\noffering 42-53$\\times$ and 3.3-12.4$\\times$ improvement in energy consumption\nand cost respectively.\n","authors":["Alessandro Ottino","Joshua Benjamin","Georgios Zervas"],"pdf_url":"https://arxiv.org/pdf/2211.15226v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.03047v2","updated":"2023-02-24T11:19:12Z","published":"2022-10-06T16:52:38Z","title":"Conditional Feature Importance for Mixed Data","summary":"  Despite the popularity of feature importance (FI) measures in interpretable\nmachine learning, the statistical adequacy of these methods is rarely\ndiscussed. From a statistical perspective, a major distinction is between\nanalyzing a variable's importance before and after adjusting for covariates -\ni.e., between $\\textit{marginal}$ and $\\textit{conditional}$ measures. Our work\ndraws attention to this rarely acknowledged, yet crucial distinction and\nshowcases its implications. Further, we reveal that for testing conditional FI,\nonly few methods are available and practitioners have hitherto been severely\nrestricted in method application due to mismatching data requirements. Most\nreal-world data exhibits complex feature dependencies and incorporates both\ncontinuous and categorical data (mixed data). Both properties are oftentimes\nneglected by conditional FI measures. To fill this gap, we propose to combine\nthe conditional predictive impact (CPI) framework with sequential knockoff\nsampling. The CPI enables conditional FI measurement that controls for any\nfeature dependencies by sampling valid knockoffs - hence, generating synthetic\ndata with similar statistical properties - for the data to be analyzed.\nSequential knockoffs were deliberately designed to handle mixed data and thus\nallow us to extend the CPI approach to such datasets. We demonstrate through\nnumerous simulations and a real-world example that our proposed workflow\ncontrols type I error, achieves high power and is in line with results given by\nother conditional FI measures, whereas marginal FI metrics result in misleading\ninterpretations. Our findings highlight the necessity of developing\nstatistically adequate, specialized methods for mixed data.\n","authors":["Kristin Blesch","David S. Watson","Marvin N. Wright"],"pdf_url":"https://arxiv.org/pdf/2210.03047v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09399v2","updated":"2023-02-24T11:10:49Z","published":"2022-08-19T15:29:43Z","title":"Diffusion-based Time Series Imputation and Forecasting with Structured\n  State Space Models","summary":"  The imputation of missing values represents a significant obstacle for many\nreal-world data analysis pipelines. Here, we focus on time series data and put\nforward SSSD, an imputation model that relies on two emerging technologies,\n(conditional) diffusion models as state-of-the-art generative models and\nstructured state space models as internal model architecture, which are\nparticularly suited to capture long-term dependencies in time series data. We\ndemonstrate that SSSD matches or even exceeds state-of-the-art probabilistic\nimputation and forecasting performance on a broad range of data sets and\ndifferent missingness scenarios, including the challenging blackout-missing\nscenarios, where prior approaches failed to provide meaningful results.\n","authors":["Juan Miguel Lopez Alcaraz","Nils Strodthoff"],"pdf_url":"https://arxiv.org/pdf/2208.09399v2.pdf","comment":"36 pages, 13 figures. Version published by Transactions on Machine\n  Learning Research in 2022 (TMLR ISSN 2835-8856)\n  https://openreview.net/forum?id=hHiIbk7ApW. Source code under\n  https://github.com/AI4HealthUOL/SSSD"},{"id":"http://arxiv.org/abs/2302.03014v3","updated":"2023-02-24T10:50:28Z","published":"2023-02-06T18:54:14Z","title":"Detection and Localization of Melanoma Skin Cancer in Histopathological\n  Whole Slide Images","summary":"  Melanoma diagnosed and treated in its early stages can increase the survival\nrate. A projected increase in skin cancer incidents and a dearth of\ndermatopathologists have emphasized the need for computational pathology\n(CPATH) systems. CPATH systems with deep learning (DL) models have the\npotential to identify the presence of melanoma by exploiting underlying\nmorphological and cellular features. This paper proposes a DL method to detect\nmelanoma and distinguish between normal skin and benign/malignant melanocytic\nlesions in Whole Slide Images (WSI). Our method detects lesions with high\naccuracy and localizes them on a WSI to identify potential regions of interest\nfor pathologists. Interestingly, our DL method relies on using a single CNN\nnetwork to create localization maps first and use them to perform slide-level\npredictions to determine patients who have melanoma. Our best model provides\nfavorable patch-wise classification results with a 0.992 F1 score and 0.99\nsensitivity on unseen data. The source code is\nhttps://github.com/RogerAmundsen/Melanoma-Diagnosis-and-Localization-from-Whole-Slide-Images-using-Convolutional-Neural-Networks.\n","authors":["Neel Kanwal","Roger Amundsen","Helga Hardardottir","Luca Tomasetti","Erling Sandoy Undersrud","Emiel A. M. Janssen","Kjersti Engan"],"pdf_url":"https://arxiv.org/pdf/2302.03014v3.pdf","comment":"Submitted to EUSIPCO 23"},{"id":"http://arxiv.org/abs/2302.12565v1","updated":"2023-02-24T10:32:30Z","published":"2023-02-24T10:32:30Z","title":"Variational Linearized Laplace Approximation for Bayesian Deep Learning","summary":"  Pre-trained deep neural networks can be adapted to perform uncertainty\nestimation by transforming them into Bayesian neural networks via methods such\nas Laplace approximation (LA) or its linearized form (LLA), among others. To\nmake these methods more tractable, the generalized Gauss-Newton (GGN)\napproximation is often used. However, due to complex inefficiency difficulties,\nboth LA and LLA rely on further approximations, such as Kronecker-factored or\ndiagonal approximate GGN matrices, which can affect the results. To address\nthese issues, we propose a new method for scaling LLA using a variational\nsparse Gaussian Process (GP) approximation based on the dual RKHS of GPs. Our\nmethod retains the predictive mean of the original model while allowing for\nefficient stochastic optimization and scalability in both the number of\nparameters and the size of the training dataset. Moreover, its training cost is\nindependent of the number of training points, improving over previously\nexisting methods. Our preliminary experiments indicate that it outperforms\nalready existing efficient variants of LLA, such as accelerated LLA (ELLA),\nbased on the Nystr\\\"om approximation.\n","authors":["Luis A. Ortega","Simón Rodríguez Santana","Daniel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2302.12565v1.pdf","comment":"First draft version"},{"id":"http://arxiv.org/abs/2302.12563v1","updated":"2023-02-24T10:31:45Z","published":"2023-02-24T10:31:45Z","title":"Retrieved Sequence Augmentation for Protein Representation Learning","summary":"  Protein language models have excelled in a variety of tasks, ranging from\nstructure prediction to protein engineering. However, proteins are highly\ndiverse in functions and structures, and current state-of-the-art models\nincluding the latest version of AlphaFold rely on Multiple Sequence Alignments\n(MSA) to feed in the evolutionary knowledge. Despite their success, heavy\ncomputational overheads, as well as the de novo and orphan proteins remain\ngreat challenges in protein representation learning. In this work, we show that\nMSAaugmented models inherently belong to retrievalaugmented methods. Motivated\nby this finding, we introduce Retrieved Sequence Augmentation(RSA) for protein\nrepresentation learning without additional alignment or pre-processing. RSA\nlinks query protein sequences to a set of sequences with similar structures or\nproperties in the database and combines these sequences for downstream\nprediction. We show that protein language models benefit from the retrieval\nenhancement on both structure prediction and property prediction tasks, with a\n5% improvement on MSA Transformer on average while being 373 times faster. In\naddition, we show that our model can transfer to new protein domains better and\noutperforms MSA Transformer on de novo protein prediction. Our study fills a\nmuch-encountered gap in protein prediction and brings us a step closer to\ndemystifying the domain knowledge needed to understand protein sequences. Code\nis available on https://github.com/HKUNLP/RSA.\n","authors":["Chang Ma","Haiteng Zhao","Lin Zheng","Jiayi Xin","Qintong Li","Lijun Wu","Zhihong Deng","Yang Lu","Qi Liu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.12563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12562v1","updated":"2023-02-24T10:31:29Z","published":"2023-02-24T10:31:29Z","title":"A Knowledge Distillation framework for Multi-Organ Segmentation of\n  Medaka Fish in Tomographic Image","summary":"  Morphological atlases are an important tool in organismal studies, and modern\nhigh-throughput Computed Tomography (CT) facilities can produce hundreds of\nfull-body high-resolution volumetric images of organisms. However, creating an\natlas from these volumes requires accurate organ segmentation. In the last\ndecade, machine learning approaches have achieved incredible results in image\nsegmentation tasks, but they require large amounts of annotated data for\ntraining. In this paper, we propose a self-training framework for multi-organ\nsegmentation in tomographic images of Medaka fish. We utilize the\npseudo-labeled data from a pretrained Teacher model and adopt a Quality\nClassifier to refine the pseudo-labeled data. Then, we introduce a pixel-wise\nknowledge distillation method to prevent overfitting to the pseudo-labeled data\nand improve the segmentation performance. The experimental results demonstrate\nthat our method improves mean Intersection over Union (IoU) by 5.9% on the full\ndataset and enables keeping the quality while using three times less markup.\n","authors":["Jwalin Bhatt","Yaroslav Zharov","Sungho Suh","Tilo Baumbach","Vincent Heuveline","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2302.12562v1.pdf","comment":"Accepted at IEEE International Symposium on Biomedical Imaging 2023\n  (ISBI 2023)"},{"id":"http://arxiv.org/abs/2207.06687v2","updated":"2023-02-24T10:30:29Z","published":"2022-07-14T06:34:21Z","title":"Breaking Correlation Shift via Conditional Invariant Regularizer","summary":"  Recently, generalization on out-of-distribution (OOD) data with correlation\nshift has attracted great attentions. The correlation shift is caused by the\nspurious attributes that correlate to the class label, as the correlation\nbetween them may vary in training and test data. For such a problem, we show\nthat given the class label, the models that are conditionally independent of\nspurious attributes are OOD generalizable. Based on this, a metric Conditional\nSpurious Variation (CSV) which controls the OOD generalization error, is\nproposed to measure such conditional independence. To improve the OOD\ngeneralization, we regularize the training process with the proposed CSV. Under\nmild assumptions, our training objective can be formulated as a\nnonconvex-concave mini-max problem. An algorithm with a provable convergence\nrate is proposed to solve the problem. Extensive empirical results verify our\nalgorithm's efficacy in improving OOD generalization.\n","authors":["Mingyang Yi","Ruoyu Wang","Jiachen Sun","Zhenguo Li","Zhi-Ming Ma"],"pdf_url":"https://arxiv.org/pdf/2207.06687v2.pdf","comment":"Published in ICLR-2023"},{"id":"http://arxiv.org/abs/2302.12559v1","updated":"2023-02-24T10:24:03Z","published":"2023-02-24T10:24:03Z","title":"From Noisy Fixed-Point Iterations to Private ADMM for Centralized and\n  Federated Learning","summary":"  We study differentially private (DP) machine learning algorithms as instances\nof noisy fixed-point iterations, in order to derive privacy and utility results\nfrom this well-studied framework. We show that this new perspective recovers\npopular private gradient-based methods like DP-SGD and provides a principled\nway to design and analyze new private optimization algorithms in a flexible\nmanner. Focusing on the widely-used Alternating Directions Method of\nMultipliers (ADMM) method, we use our general framework to derive novel private\nADMM algorithms for centralized, federated and fully decentralized learning.\nFor these three algorithms, we establish strong privacy guarantees leveraging\nprivacy amplification by iteration and by subsampling. Finally, we provide\nutility guarantees using a unified analysis that exploits a recent linear\nconvergence result for noisy fixed-point iterations.\n","authors":["Edwige Cyffers","Aurelien Bellet","Debabrota Basu"],"pdf_url":"https://arxiv.org/pdf/2302.12559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05244v5","updated":"2023-02-24T10:15:45Z","published":"2023-02-10T13:49:50Z","title":"A Song of Ice and Fire: Analyzing Textual Autotelic Agents in\n  ScienceWorld","summary":"  Building open-ended agents that can autonomously discover a diversity of\nbehaviours is one of the long-standing goals of artificial intelligence. This\nchallenge can be studied in the framework of autotelic RL agents, i.e. agents\nthat learn by selecting and pursuing their own goals, self-organizing a\nlearning curriculum. Recent work identified language as a key dimension of\nautotelic learning, in particular because it enables abstract goal sampling and\nguidance from social peers for hindsight relabelling. Within this perspective,\nwe study the following open scientific questions: What is the impact of\nhindsight feedback from a social peer (e.g. selective vs. exhaustive)? How can\nthe agent learn from very rare language goal examples in its experience replay?\nHow can multiple forms of exploration be combined, and take advantage of easier\ngoals as stepping stones to reach harder ones? To address these questions, we\nuse ScienceWorld, a textual environment with rich abstract and combinatorial\nphysics. We show the importance of selectivity from the social peer's feedback;\nthat experience replay needs to over-sample examples of rare goals; and that\nfollowing self-generated goal sequences where the agent's competence is\nintermediate leads to significant improvements in final performance.\n","authors":["Laetitia Teodorescu","Xingdi Yuan","Marc-Alexandre Côté","Pierre-Yves Oudeyer"],"pdf_url":"https://arxiv.org/pdf/2302.05244v5.pdf","comment":"In review at ICML 2023"},{"id":"http://arxiv.org/abs/2302.12553v1","updated":"2023-02-24T10:14:53Z","published":"2023-02-24T10:14:53Z","title":"Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice\n  Polytopes","summary":"  We prove that the set of functions representable by ReLU neural networks with\ninteger weights strictly increases with the network depth while allowing\narbitrary width. More precisely, we show that $\\lceil\\log_2(n)\\rceil$ hidden\nlayers are indeed necessary to compute the maximum of $n$ numbers, matching\nknown upper bounds. Our results are based on the known duality between neural\nnetworks and Newton polytopes via tropical geometry. The integrality assumption\nimplies that these Newton polytopes are lattice polytopes. Then, our depth\nlower bounds follow from a parity argument on the normalized volume of faces of\nsuch polytopes.\n","authors":["Christian Haase","Christoph Hertrich","Georg Loho"],"pdf_url":"https://arxiv.org/pdf/2302.12553v1.pdf","comment":"ICLR 2023 conference paper"},{"id":"http://arxiv.org/abs/2302.12545v1","updated":"2023-02-24T09:59:29Z","published":"2023-02-24T09:59:29Z","title":"Hybrid machine-learned homogenization: Bayesian data mining and\n  convolutional neural networks","summary":"  Beyond the generally deployed features for microstructure property prediction\nthis study aims to improve the machine learned prediction by developing novel\nfeature descriptors. Therefore, Bayesian infused data mining is conducted to\nacquire samples containing characteristics inexplicable to the current feature\nset, and suitable feature descriptors to describe these characteristics are\nproposed. The iterative development of feature descriptors resulted in 37 novel\nfeatures, being able to reduce the prediction error by roughly one third. To\nfurther improve the predictive model, convolutional neural networks (Conv Nets)\nare deployed to generate auxiliary features in a supervised machine learning\nmanner. The Conv Nets were able to outperform the feature based approach. A key\ningredient for that is a newly proposed data augmentation scheme and the\ndevelopment of so-called deep inception modules. A combination of the feature\nbased approach and the convolutional neural network leads to a hybrid neural\nnetwork: A parallel deployment of the both neural network archetypes in a\nsingle model achieved a relative rooted mean squared error below 1%, more than\nhalving the error compared to prior models operating on the same data. The\nhybrid neural network was found powerful enough to be extended to predict\nvariable material parameters, from a low to high phase contrast, while allowing\nfor arbitrary microstructure geometry at the same time.\n","authors":["Julian Lißner","Felix Fritzen"],"pdf_url":"https://arxiv.org/pdf/2302.12545v1.pdf","comment":"submitted to 'Computational Mechanics - Springer'"},{"id":"http://arxiv.org/abs/2205.01614v3","updated":"2023-02-24T09:58:08Z","published":"2022-05-03T16:48:31Z","title":"Automatic Segmentation of Aircraft Dents in Point Clouds","summary":"  Dents on the aircraft skin are frequent and may easily go undetected during\nairworthiness checks, as their inspection process is tedious and extremely\nsubject to human factors and environmental conditions. Nowadays, 3D scanning\ntechnologies are being proposed for more reliable, human-independent\nmeasurements, yet the process of inspection and reporting remains laborious and\ntime consuming because data acquisition and validation are still carried out by\nthe engineer. For full automation of dent inspection, the acquired point cloud\ndata must be analysed via a reliable segmentation algorithm, releasing humans\nfrom the search and evaluation of damage. This paper reports on two\ndevelopments towards automated dent inspection. The first is a method to\ngenerate a synthetic dataset of dented surfaces to train a fully convolutional\nneural network. The training of machine learning algorithms needs a substantial\nvolume of dent data, which is not readily available. Dents are thus simulated\nin random positions and shapes, within criteria and definitions of a Boeing 737\nstructural repair manual. The noise distribution from the scanning apparatus is\nthen added to reflect the complete process of 3D point acquisition on the\ntraining. The second proposition is a surface fitting strategy to convert 3D\npoint clouds to 2.5D. This allows higher resolution point clouds to be\nprocessed with a small amount of memory compared with state-of-the-art methods\ninvolving 3D sampling approaches. Simulations with available ground truth data\nshow that the proposed technique reaches an intersection-over-union of over\n80%. Experiments over dent samples prove an effective detection of dents with a\nspeed of over 500 000 points per second.\n","authors":["Pasquale Lafiosca","Ip-Shing Fan","Nicolas P. Avdelidis"],"pdf_url":"https://arxiv.org/pdf/2205.01614v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11883v2","updated":"2023-02-24T09:54:40Z","published":"2023-02-23T09:42:21Z","title":"PIFON-EPT: MR-Based Electrical Property Tomography Using\n  Physics-Informed Fourier Networks","summary":"  \\textit{Objective:} In this paper, we introduce Physics-Informed Fourier\nNetworks (PIFONs) for Electrical Properties (EP) Tomography (EPT). Our novel\ndeep learning-based method is capable of learning EPs globally by solving an\ninverse scattering problem based on noisy and/or incomplete magnetic resonance\n(MR) measurements. \\textit{Methods:} We use two separate fully-connected neural\nnetworks, namely $B_1^{+}$ Net and EP Net, to learn the $B_1^{+}$ field and EPs\nat any location. A random Fourier features mapping is embedded into $B_1^{+}$\nNet, which allows it to learn the $B_1^{+}$ field more efficiently. These two\nneural networks are trained jointly by minimizing the combination of a\nphysics-informed loss and a data mismatch loss via gradient descent.\n\\textit{Results:} We showed that PIFON-EPT could provide physically consistent\nreconstructions of EPs and transmit field in the whole domain of interest even\nwhen half of the noisy MR measurements of the entire volume was missing. The\naverage error was $2.49\\%$, $4.09\\%$ and $0.32\\%$ for the relative\npermittivity, conductivity and $B_{1}^{+}$, respectively, over the entire\nvolume of the phantom. In experiments that admitted a zero assumption of $B_z$,\nPIFON-EPT could yield accurate EP predictions near the interface between\nregions of different EP values without requiring any boundary conditions.\n\\textit{Conclusion:} This work demonstrated the feasibility of PIFON-EPT,\nsuggesting it could be an accurate and effective method for electrical\nproperties estimation. \\textit{Significance:} PIFON-EPT can efficiently\nde-noise MR measurements, which shows the potential to improve other MR-based\nEPT techniques. Furthermore, it is the first time that MR-based EPT methods can\nreconstruct the EPs and $B_{1}^{+}$ field simultaneously from incomplete\nsimulated noisy MR measurements.\n","authors":["Xinling Yu","José E. C. Serrallés","Ilias I. Giannakopoulos","Ziyue Liu","Luca Daniel","Riccardo Lattanzi","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.11883v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2301.03988v2","updated":"2023-02-24T09:53:40Z","published":"2023-01-09T10:52:35Z","title":"SantaCoder: don't reach for the stars!","summary":"  The BigCode project is an open-scientific collaboration working on the\nresponsible development of large language models for code. This tech report\ndescribes the progress of the collaboration until December 2022, outlining the\ncurrent state of the Personally Identifiable Information (PII) redaction\npipeline, the experiments conducted to de-risk the model architecture, and the\nexperiments investigating better preprocessing methods for the training data.\nWe train 1.1B parameter models on the Java, JavaScript, and Python subsets of\nThe Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find\nthat more aggressive filtering of near-duplicates can further boost performance\nand, surprisingly, that selecting files from repositories with 5+ GitHub stars\ndeteriorates performance significantly. Our best model outperforms previous\nopen-source multilingual code generation models (InCoder-6.7B and\nCodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java,\nJavaScript, and Python portions of MultiPL-E, despite being a substantially\nsmaller model. All models are released under an OpenRAIL license at\nhttps://hf.co/bigcode.\n","authors":["Loubna Ben Allal","Raymond Li","Denis Kocetkov","Chenghao Mou","Christopher Akiki","Carlos Munoz Ferrandis","Niklas Muennighoff","Mayank Mishra","Alex Gu","Manan Dey","Logesh Kumar Umapathi","Carolyn Jane Anderson","Yangtian Zi","Joel Lamy Poirier","Hailey Schoelkopf","Sergey Troshin","Dmitry Abulkhanov","Manuel Romero","Michael Lappert","Francesco De Toni","Bernardo García del Río","Qian Liu","Shamik Bose","Urvashi Bhattacharyya","Terry Yue Zhuo","Ian Yu","Paulo Villegas","Marco Zocca","Sourab Mangrulkar","David Lansky","Huu Nguyen","Danish Contractor","Luis Villa","Jia Li","Dzmitry Bahdanau","Yacine Jernite","Sean Hughes","Daniel Fried","Arjun Guha","Harm de Vries","Leandro von Werra"],"pdf_url":"https://arxiv.org/pdf/2301.03988v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12538v1","updated":"2023-02-24T09:49:43Z","published":"2023-02-24T09:49:43Z","title":"UnbiasedNets: A Dataset Diversification Framework for Robustness Bias\n  Alleviation in Neural Networks","summary":"  Performance of trained neural network (NN) models, in terms of testing\naccuracy, has improved remarkably over the past several years, especially with\nthe advent of deep learning. However, even the most accurate NNs can be biased\ntoward a specific output classification due to the inherent bias in the\navailable training datasets, which may propagate to the real-world\nimplementations. This paper deals with the robustness bias, i.e., the bias\nexhibited by the trained NN by having a significantly large robustness to noise\nfor a certain output class, as compared to the remaining output classes. The\nbias is shown to result from imbalanced datasets, i.e., the datasets where all\noutput classes are not equally represented. Towards this, we propose the\nUnbiasedNets framework, which leverages K-means clustering and the NN's noise\ntolerance to diversify the given training dataset, even from relatively smaller\ndatasets. This generates balanced datasets and reduces the bias within the\ndatasets themselves. To the best of our knowledge, this is the first framework\ncatering to the robustness bias problem in NNs. We use real-world datasets to\ndemonstrate the efficacy of the UnbiasedNets for data diversification, in case\nof both binary and multi-label classifiers. The results are compared to\nwell-known tools aimed at generating balanced datasets, and illustrate how\nexisting works have limited success while addressing the robustness bias. In\ncontrast, UnbiasedNets provides a notable improvement over existing works,\nwhile even reducing the robustness bias significantly in some cases, as\nobserved by comparing the NNs trained on the diversified and original datasets.\n","authors":["Mahum Naseer","Bharath Srinivas Prabakaran","Osman Hasan","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2302.12538v1.pdf","comment":"Springer Machine Learning 2023"},{"id":"http://arxiv.org/abs/2302.12537v1","updated":"2023-02-24T09:46:00Z","published":"2023-02-24T09:46:00Z","title":"Why Target Networks Stabilise Temporal Difference Methods","summary":"  Integral to recent successes in deep reinforcement learning has been a class\nof temporal difference methods that use infrequently updated target values for\npolicy evaluation in a Markov Decision Process. Yet a complete theoretical\nexplanation for the effectiveness of target networks remains elusive. In this\nwork, we provide an analysis of this popular class of algorithms, to finally\nanswer the question: `why do target networks stabilise TD learning'? To do so,\nwe formalise the notion of a partially fitted policy evaluation method, which\ndescribes the use of target networks and bridges the gap between fitted methods\nand semigradient temporal difference algorithms. Using this framework we are\nable to uniquely characterise the so-called deadly triad - the use of TD\nupdates with (nonlinear) function approximation and off-policy data - which\noften leads to nonconvergent algorithms. This insight leads us to conclude that\nthe use of target networks can mitigate the effects of poor conditioning in the\nJacobian of the TD update. Instead, we show that under mild regularity\nconditions and a well tuned target network update frequency, convergence can be\nguaranteed even in the extremely challenging off-policy sampling and nonlinear\nfunction approximation setting.\n","authors":["Mattie Fellows","Matthew J. A. Smith","Shimon Whiteson"],"pdf_url":"https://arxiv.org/pdf/2302.12537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12533v1","updated":"2023-02-24T09:38:41Z","published":"2023-02-24T09:38:41Z","title":"HUST bearing: a practical dataset for ball bearing fault diagnosis","summary":"  In this work, we introduce a practical dataset named HUST bearing, that\nprovides a large set of vibration data on different ball bearings. This dataset\ncontains 90 raw vibration data of 6 types of defects (inner crack, outer crack,\nball crack, and their 2-combinations) on 5 types of bearing at 3 working\nconditions with the sample rate of 51,200 samples per second. We established\nthe envelope analysis and order tracking analysis on the introduced dataset to\nallow an initial evaluation of the data. A number of classical machine learning\nclassification methods are used to identify bearing faults of the dataset using\nfeatures in different domains. The typical advanced unsupervised transfer\nlearning algorithms also perform to observe the transferability of knowledge\namong parts of the dataset. The experimental results of examined methods on the\ndataset gain divergent accuracy up to 100% on classification task and 60-80% on\nunsupervised transfer learning task.\n","authors":["Nguyen Duc Thuan","Hoang Si Hong"],"pdf_url":"https://arxiv.org/pdf/2302.12533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13715v2","updated":"2023-02-24T09:23:52Z","published":"2022-11-24T17:04:45Z","title":"Trust Your $\\nabla$: Gradient-based Intervention Targeting for Causal\n  Discovery","summary":"  Inferring causal structure from data is a challenging task of fundamental\nimportance in science. Observational data are often insufficient to identify a\nsystem's causal structure uniquely. While conducting interventions (i.e.,\nexperiments) can improve the identifiability, such samples are usually\nchallenging and expensive to obtain. Hence, experimental design approaches for\ncausal discovery aim to minimize the number of interventions by estimating the\nmost informative intervention target. In this work, we propose a novel\nGradient-based Intervention Targeting method, abbreviated GIT, that 'trusts'\nthe gradient estimator of a gradient-based causal discovery framework to\nprovide signals for the intervention acquisition function. We provide extensive\nexperiments in simulated and real-world datasets and demonstrate that GIT\nperforms on par with competitive baselines, surpassing them in the low-data\nregime.\n","authors":["Mateusz Olko","Michał Zając","Aleksandra Nowak","Nino Scherrer","Yashas Annadani","Stefan Bauer","Łukasz Kuciński","Piotr Miłoś"],"pdf_url":"https://arxiv.org/pdf/2211.13715v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06369v2","updated":"2023-02-24T09:21:39Z","published":"2022-11-11T17:40:08Z","title":"Enhancing and Adversarial: Improve ASR with Speaker Labels","summary":"  ASR can be improved by multi-task learning (MTL) with domain enhancing or\ndomain adversarial training, which are two opposite objectives with the aim to\nincrease/decrease domain variance towards domain-aware/agnostic ASR,\nrespectively. In this work, we study how to best apply these two opposite\nobjectives with speaker labels to improve conformer-based ASR. We also propose\na novel adaptive gradient reversal layer for stable and effective adversarial\ntraining without tuning effort. Detailed analysis and experimental verification\nare conducted to show the optimal positions in the ASR neural network (NN) to\napply speaker enhancing and adversarial training. We also explore their\ncombination for further improvement, achieving the same performance as\ni-vectors plus adversarial training. Our best speaker-based MTL achieves 7\\%\nrelative improvement on the Switchboard Hub5'00 set. We also investigate the\neffect of such speaker-based MTL w.r.t. cleaner dataset and weaker ASR NN.\n","authors":["Wei Zhou","Haotian Wu","Jingjing Xu","Mohammad Zeineldeen","Christoph Lüscher","Ralf Schlüter","Hermann Ney"],"pdf_url":"https://arxiv.org/pdf/2211.06369v2.pdf","comment":"accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.12526v1","updated":"2023-02-24T09:18:27Z","published":"2023-02-24T09:18:27Z","title":"Model-Based Uncertainty in Value Functions","summary":"  We consider the problem of quantifying uncertainty over expected cumulative\nrewards in model-based reinforcement learning. In particular, we focus on\ncharacterizing the variance over values induced by a distribution over MDPs.\nPrevious work upper bounds the posterior variance over values by solving a\nso-called uncertainty Bellman equation, but the over-approximation may result\nin inefficient exploration. We propose a new uncertainty Bellman equation whose\nsolution converges to the true posterior variance over values and explicitly\ncharacterizes the gap in previous work. Moreover, our uncertainty\nquantification technique is easily integrated into common exploration\nstrategies and scales naturally beyond the tabular setting by using standard\ndeep reinforcement learning architectures. Experiments in difficult exploration\ntasks, both in tabular and continuous control settings, show that our sharper\nuncertainty estimates improve sample-efficiency.\n","authors":["Carlos E. Luis","Alessandro G. Bottero","Julia Vinogradska","Felix Berkenkamp","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2302.12526v1.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2301.04182v2","updated":"2023-02-24T09:13:40Z","published":"2023-01-10T19:27:11Z","title":"schlably: A Python Framework for Deep Reinforcement Learning Based\n  Scheduling Experiments","summary":"  Research on deep reinforcement learning (DRL) based production scheduling\n(PS) has gained a lot of attention in recent years, primarily due to the high\ndemand for optimizing scheduling problems in diverse industry settings.\nNumerous studies are carried out and published as stand-alone experiments that\noften vary only slightly with respect to problem setups and solution\napproaches. The programmatic core of these experiments is typically very\nsimilar. Despite this fact, no standardized and resilient framework for\nexperimentation on PS problems with DRL algorithms could be established so far.\nIn this paper, we introduce schlably, a Python-based framework that provides\nresearchers a comprehensive toolset to facilitate the development of PS\nsolution strategies based on DRL. schlably eliminates the redundant overhead\nwork that the creation of a sturdy and flexible backbone requires and increases\nthe comparability and reusability of conducted research work.\n","authors":["Constantin Waubert de Puiseau","Jannik Peters","Christian Dörpelkus","Hasan Tercan","Tobias Meisen"],"pdf_url":"https://arxiv.org/pdf/2301.04182v2.pdf","comment":"currently under review for SoftwareX"},{"id":"http://arxiv.org/abs/2302.12520v1","updated":"2023-02-24T09:13:17Z","published":"2023-02-24T09:13:17Z","title":"A Novel Demand Response Model and Method for Peak Reduction in Smart\n  Grids -- PowerTAC","summary":"  One of the widely used peak reduction methods in smart grids is demand\nresponse, where one analyzes the shift in customers' (agents') usage patterns\nin response to the signal from the distribution company. Often, these signals\nare in the form of incentives offered to agents. This work studies the effect\nof incentives on the probabilities of accepting such offers in a real-world\nsmart grid simulator, PowerTAC. We first show that there exists a function that\ndepicts the probability of an agent reducing its load as a function of the\ndiscounts offered to them. We call it reduction probability (RP). RP function\nis further parametrized by the rate of reduction (RR), which can differ for\neach agent. We provide an optimal algorithm, MJS--ExpResponse, that outputs the\ndiscounts to each agent by maximizing the expected reduction under a budget\nconstraint. When RRs are unknown, we propose a Multi-Armed Bandit (MAB) based\nonline algorithm, namely MJSUCB--ExpResponse, to learn RRs. Experimentally we\nshow that it exhibits sublinear regret. Finally, we showcase the efficacy of\nthe proposed algorithm in mitigating demand peaks in a real-world smart grid\nsystem using the PowerTAC simulator as a test bed.\n","authors":["Sanjay Chandlekar","Arthik Boroju","Shweta Jain","Sujit Gujar"],"pdf_url":"https://arxiv.org/pdf/2302.12520v1.pdf","comment":"11 pages, 5 figures, 2 tables, Accepted as an Extended Abstract in\n  AAMAS'23"},{"id":"http://arxiv.org/abs/2302.05686v2","updated":"2023-02-24T09:02:08Z","published":"2023-02-11T12:49:46Z","title":"A High-dimensional Convergence Theorem for U-statistics with\n  Applications to Kernel-based Testing","summary":"  We prove a convergence theorem for U-statistics of degree two, where the data\ndimension $d$ is allowed to scale with sample size $n$. We find that the\nlimiting distribution of a U-statistic undergoes a phase transition from the\nnon-degenerate Gaussian limit to the degenerate limit, regardless of its\ndegeneracy and depending only on a moment ratio. A surprising consequence is\nthat a non-degenerate U-statistic in high dimensions can have a non-Gaussian\nlimit with a larger variance and asymmetric distribution. Our bounds are valid\nfor any finite $n$ and $d$, independent of individual eigenvalues of the\nunderlying function, and dimension-independent under a mild assumption. As an\napplication, we apply our theory to two popular kernel-based distribution\ntests, MMD and KSD, whose high-dimensional performance has been challenging to\nstudy. In a simple empirical setting, our results correctly predict how the\ntest power at a fixed threshold scales with $d$ and the bandwidth.\n","authors":["Kevin H. Huang","Xing Liu","Andrew B. Duncan","Axel Gandy"],"pdf_url":"https://arxiv.org/pdf/2302.05686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12003v2","updated":"2023-02-24T08:46:20Z","published":"2023-02-12T13:27:34Z","title":"Robust Representation Learning by Clustering with Bisimulation Metrics\n  for Visual Reinforcement Learning with Distractions","summary":"  Recent work has shown that representation learning plays a critical role in\nsample-efficient reinforcement learning (RL) from pixels. Unfortunately, in\nreal-world scenarios, representation learning is usually fragile to\ntask-irrelevant distractions such as variations in background or viewpoint. To\ntackle this problem, we propose a novel clustering-based approach, namely\nClustering with Bisimulation Metrics (CBM), which learns robust representations\nby grouping visual observations in the latent space. Specifically, CBM\nalternates between two steps: (1) grouping observations by measuring their\nbisimulation distances to the learned prototypes; (2) learning a set of\nprototypes according to the current cluster assignments. Computing cluster\nassignments with bisimulation metrics enables CBM to capture task-relevant\ninformation, as bisimulation metrics quantify the behavioral similarity between\nobservations. Moreover, CBM encourages the consistency of representations\nwithin each group, which facilitates filtering out task-irrelevant information\nand thus induces robust representations against distractions. An appealing\nfeature is that CBM can achieve sample-efficient representation learning even\nif multiple distractions exist simultaneously.Experiments demonstrate that CBM\nsignificantly improves the sample efficiency of popular visual RL algorithms\nand achieves state-of-the-art performance on both multiple and single\ndistraction settings. The code is available at\nhttps://github.com/MIRALab-USTC/RL-CBM.\n","authors":["Qiyuan Liu","Qi Zhou","Rui Yang","Jie Wang"],"pdf_url":"https://arxiv.org/pdf/2302.12003v2.pdf","comment":"Accepted to AAAI 2023"},{"id":"http://arxiv.org/abs/2302.12510v1","updated":"2023-02-24T08:46:01Z","published":"2023-02-24T08:46:01Z","title":"DyBit: Dynamic Bit-Precision Numbers for Efficient Quantized Neural\n  Network Inference","summary":"  To accelerate the inference of deep neural networks (DNNs), quantization with\nlow-bitwidth numbers is actively researched. A prominent challenge is to\nquantize the DNN models into low-bitwidth numbers without significant accuracy\ndegradation, especially at very low bitwidths (< 8 bits). This work targets an\nadaptive data representation with variable-length encoding called DyBit. DyBit\ncan dynamically adjust the precision and range of separate bit-field to be\nadapted to the DNN weights/activations distribution. We also propose a\nhardware-aware quantization framework with a mixed-precision accelerator to\ntrade-off the inference accuracy and speedup. Experimental results demonstrate\nthat the inference accuracy via DyBit is 1.997% higher than the\nstate-of-the-art at 4-bit quantization, and the proposed framework can achieve\nup to 8.1x speedup compared with the original model.\n","authors":["Jiajun Zhou","Jiajun Wu","Yizhao Gao","Yuhao Ding","Chaofan Tao","Boyu Li","Fengbin Tu","Kwang-Ting Cheng","Hayden Kwok-Hay So","Ngai Wong"],"pdf_url":"https://arxiv.org/pdf/2302.12510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12509v1","updated":"2023-02-24T08:41:19Z","published":"2023-02-24T08:41:19Z","title":"Personalizing Federated Learning with Over-the-Air Computations","summary":"  Federated edge learning is a promising technology to deploy intelligence at\nthe edge of wireless networks in a privacy-preserving manner. Under such a\nsetting, multiple clients collaboratively train a global generic model under\nthe coordination of an edge server. But the training efficiency is often\nthrottled by challenges arising from limited communication and data\nheterogeneity. This paper presents a distributed training paradigm that employs\nanalog over-the-air computation to address the communication bottleneck.\nAdditionally, we leverage a bi-level optimization framework to personalize the\nfederated learning model so as to cope with the data heterogeneity issue. As a\nresult, it enhances the generalization and robustness of each client's local\nmodel. We elaborate on the model training procedure and its advantages over\nconventional frameworks. We provide a convergence analysis that theoretically\ndemonstrates the training efficiency. We also conduct extensive experiments to\nvalidate the efficacy of the proposed framework.\n","authors":["Zihan Chen","Zeshen Li","Howard H. Yang","Tony Q. S. Quek"],"pdf_url":"https://arxiv.org/pdf/2302.12509v1.pdf","comment":"5 pages. Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2202.02096v4","updated":"2023-02-24T08:22:50Z","published":"2022-02-04T12:08:31Z","title":"To Impute or not to Impute? Missing Data in Treatment Effect Estimation","summary":"  Missing data is a systemic problem in practical scenarios that causes noise\nand bias when estimating treatment effects. This makes treatment effect\nestimation from data with missingness a particularly tricky endeavour. A key\nreason for this is that standard assumptions on missingness are rendered\ninsufficient due to the presence of an additional variable, treatment, besides\nthe input (e.g. an individual) and the label (e.g. an outcome). The treatment\nvariable introduces additional complexity with respect to why some variables\nare missing that is not fully explored by previous work. In our work we\nintroduce mixed confounded missingness (MCM), a new missingness mechanism where\nsome missingness determines treatment selection and other missingness is\ndetermined by treatment selection. Given MCM, we show that naively imputing all\ndata leads to poor performing treatment effects models, as the act of\nimputation effectively removes information necessary to provide unbiased\nestimates. However, no imputation at all also leads to biased estimates, as\nmissingness determined by treatment introduces bias in covariates. Our solution\nis selective imputation, where we use insights from MCM to inform precisely\nwhich variables should be imputed and which should not. We empirically\ndemonstrate how various learners benefit from selective imputation compared to\nother solutions for missing data. We highlight that our experiments encompass\nboth average treatment effects and conditional average treatment effects.\n","authors":["Jeroen Berrevoets","Fergus Imrie","Trent Kyono","James Jordon","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2202.02096v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12504v1","updated":"2023-02-24T08:10:23Z","published":"2023-02-24T08:10:23Z","title":"Recovering Sparse and Interpretable Subgroups with Heterogeneous\n  Treatment Effects with Censored Time-to-Event Outcomes","summary":"  Studies involving both randomized experiments as well as observational data\ntypically involve time-to-event outcomes such as time-to-failure, death or\nonset of an adverse condition. Such outcomes are typically subject to censoring\ndue to loss of follow-up and established statistical practice involves\ncomparing treatment efficacy in terms of hazard ratios between the treated and\ncontrol groups. In this paper we propose a statistical approach to recovering\nsparse phenogroups (or subtypes) that demonstrate differential treatment\neffects as compared to the study population. Our approach involves modelling\nthe data as a mixture while enforcing parameter shrinkage through structured\nsparsity regularization. We propose a novel inference procedure for the\nproposed model and demonstrate its efficacy in recovering sparse phenotypes\nacross large landmark real world clinical studies in cardiovascular health.\n","authors":["Chirag Nagpal","Vedant Sanil","Artur Dubrawski"],"pdf_url":"https://arxiv.org/pdf/2302.12504v1.pdf","comment":"Presented as an extended abstract at the Machine Learning for Health\n  Symposium (ML4H) 2022"},{"id":"http://arxiv.org/abs/2302.12503v1","updated":"2023-02-24T08:09:23Z","published":"2023-02-24T08:09:23Z","title":"FedPDC:Federated Learning for Public Dataset Correction","summary":"  As people pay more and more attention to privacy protection, Federated\nLearning (FL), as a promising distributed machine learning paradigm, is\nreceiving more and more attention. However, due to the biased distribution of\ndata on devices in real life, federated learning has lower classification\naccuracy than traditional machine learning in Non-IID scenarios. Although there\nare many optimization algorithms, the local model aggregation in the parameter\nserver is still relatively traditional. In this paper, a new algorithm FedPDC\nis proposed to optimize the aggregation mode of local models and the loss\nfunction of local training by using the shared data sets in some industries. In\nmany benchmark experiments, FedPDC can effectively improve the accuracy of the\nglobal model in the case of extremely unbalanced data distribution, while\nensuring the privacy of the client data. At the same time, the accuracy\nimprovement of FedPDC does not bring additional communication costs.\n","authors":["Yuquan Zhang","Yongquan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.12503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16028v3","updated":"2023-02-24T08:06:43Z","published":"2022-11-29T08:52:29Z","title":"JaCappella Corpus: A Japanese a Cappella Vocal Ensemble Corpus","summary":"  We construct a corpus of Japanese a cappella vocal ensembles (jaCappella\ncorpus) for vocal ensemble separation and synthesis. It consists of 35\ncopyright-cleared vocal ensemble songs and their audio recordings of individual\nvoice parts. These songs were arranged from out-of-copyright Japanese\nchildren's songs and have six voice parts (lead vocal, soprano, alto, tenor,\nbass, and vocal percussion). They are divided into seven subsets, each of which\nfeatures typical characteristics of a music genre such as jazz and enka. The\nvariety in genre and voice part match vocal ensembles recently widespread in\nsocial media services such as YouTube, although the main targets of\nconventional vocal ensemble datasets are choral singing made up of soprano,\nalto, tenor, and bass. Experimental evaluation demonstrates that our corpus is\na challenging resource for vocal ensemble separation. Our corpus is available\non our project page (https://tomohikonakamura.github.io/jaCappella_corpus/).\n","authors":["Tomohiko Nakamura","Shinnosuke Takamichi","Naoko Tanji","Satoru Fukayama","Hiroshi Saruwatari"],"pdf_url":"https://arxiv.org/pdf/2211.16028v3.pdf","comment":"Accepted for ICASSP2023"},{"id":"http://arxiv.org/abs/2209.00195v3","updated":"2023-02-24T08:01:23Z","published":"2022-09-01T03:27:33Z","title":"To Store or Not? Online Data Selection for Federated Learning with\n  Limited Storage","summary":"  Machine learning models have been deployed in mobile networks to deal with\nmassive data from different layers to enable automated network management and\nintelligence on devices. To overcome high communication cost and severe privacy\nconcerns of centralized machine learning, federated learning (FL) has been\nproposed to achieve distributed machine learning among networked devices. While\nthe computation and communication limitation has been widely studied, the\nimpact of on-device storage on the performance of FL is still not explored.\nWithout an effective data selection policy to filter the massive streaming data\non devices, classical FL can suffer from much longer model training time\n($4\\times$) and significant inference accuracy reduction ($7\\%$), observed in\nour experiments. In this work, we take the first step to consider the online\ndata selection for FL with limited on-device storage. We first define a new\ndata valuation metric for data evaluation and selection in FL with theoretical\nguarantees for speeding up model convergence and enhancing final model\naccuracy, simultaneously. We further design {\\ttfamily ODE}, a framework of\n\\textbf{O}nline \\textbf{D}ata s\\textbf{E}lection for FL, to coordinate\nnetworked devices to store valuable data samples. Experimental results on one\nindustrial dataset and three public datasets show the remarkable advantages of\n{\\ttfamily ODE} over the state-of-the-art approaches. Particularly, on the\nindustrial dataset, {\\ttfamily ODE} achieves as high as $2.5\\times$ speedup of\ntraining time and $6\\%$ increase in inference accuracy, and is robust to\nvarious factors in practical environments.\n","authors":["Chen Gong","Zhenzhe Zheng","Yunfeng Shao","Bingshuai Li","Fan Wu","Guihai Chen"],"pdf_url":"https://arxiv.org/pdf/2209.00195v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10010v2","updated":"2023-02-24T07:55:51Z","published":"2022-08-22T01:47:07Z","title":"NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs","summary":"  While Graph Neural Networks (GNNs) have demonstrated their efficacy in\ndealing with non-Euclidean structural data, they are difficult to be deployed\nin real applications due to the scalability constraint imposed by multi-hop\ndata dependency. Existing methods attempt to address this scalability issue by\ntraining multi-layer perceptrons (MLPs) exclusively on node content features\nusing labels derived from trained GNNs. Even though the performance of MLPs can\nbe significantly improved, two issues prevent MLPs from outperforming GNNs and\nbeing used in practice: the ignorance of graph structural information and the\nsensitivity to node feature noises. In this paper, we propose to learn\nNOise-robust Structure-aware MLPs On Graphs (NOSMOG) to overcome the\nchallenges. Specifically, we first complement node content with position\nfeatures to help MLPs capture graph structural information. We then design a\nnovel representational similarity distillation strategy to inject structural\nnode similarities into MLPs. Finally, we introduce the adversarial feature\naugmentation to ensure stable learning against feature noises and further\nimprove performance. Extensive experiments demonstrate that NOSMOG outperforms\nGNNs and the state-of-the-art method in both transductive and inductive\nsettings across seven datasets, while maintaining a competitive inference\nefficiency. Codes are available at https://github.com/meettyj/NOSMOG.\n","authors":["Yijun Tian","Chuxu Zhang","Zhichun Guo","Xiangliang Zhang","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2208.10010v2.pdf","comment":"NeurIPS 2022 GLFrontiers"},{"id":"http://arxiv.org/abs/2206.00801v4","updated":"2023-02-24T07:47:22Z","published":"2022-06-02T00:01:27Z","title":"Indeterminacy and Strong Identifiability in Generative Models","summary":"  Most modern probabilistic generative models, such as the variational\nautoencoder (VAE), have certain indeterminacies that are unresolvable even with\nan infinite amount of data. Different tasks tolerate different indeterminacies,\nhowever recent applications have indicated the need for strongly identifiable\nmodels, in which an observation corresponds to a unique latent code. Progress\nhas been made towards reducing model indeterminacies while maintaining\nflexibility, and recent work excludes many--but not all--indeterminacies. In\nthis work, we motivate model-identifiability in terms of task-identifiability,\nthen construct a theoretical framework for analyzing the indeterminacies of\nlatent variable models, which enables their precise characterization in terms\nof the generator function and prior distribution spaces. We reveal that strong\nidentifiability is possible even with highly flexible nonlinear generators, and\ngive two such examples. One is a straightforward modification of iVAE\n(arXiv:1907.04809 [stat.ML]); the other uses triangular monotonic maps, leading\nto novel connections between optimal transport and identifiability.\n","authors":["Quanhan Xi","Benjamin Bloem-Reddy"],"pdf_url":"https://arxiv.org/pdf/2206.00801v4.pdf","comment":"AISTATS 2023 Camera Ready"},{"id":"http://arxiv.org/abs/2302.12498v1","updated":"2023-02-24T07:35:38Z","published":"2023-02-24T07:35:38Z","title":"Scalable Unbalanced Sobolev Transport for Measures on a Graph","summary":"  Optimal transport (OT) is a popular and powerful tool for comparing\nprobability measures. However, OT suffers a few drawbacks: (i) input measures\nrequired to have the same mass, (ii) a high computational complexity, and (iii)\nindefiniteness which limits its applications on kernel-dependent algorithmic\napproaches. To tackle issues (ii)--(iii), Le et al. (2022) recently proposed\nSobolev transport for measures on a graph having the same total mass by\nleveraging the graph structure over supports. In this work, we consider\nmeasures that may have different total mass and are supported on a graph metric\nspace. To alleviate the disadvantages (i)--(iii) of OT, we propose a novel and\nscalable approach to extend Sobolev transport for this unbalanced setting where\nmeasures may have different total mass. We show that the proposed unbalanced\nSobolev transport (UST) admits a closed-form formula for fast computation, and\nit is also negative definite. Additionally, we derive geometric structures for\nthe UST and establish relations between our UST and other transport distances.\nWe further exploit the negative definiteness to design positive definite\nkernels and evaluate them on various simulations to illustrate their fast\ncomputation and comparable performances against other transport baselines for\nunbalanced measures on a graph.\n","authors":["Tam Le","Truyen Nguyen","Kenji Fukumizu"],"pdf_url":"https://arxiv.org/pdf/2302.12498v1.pdf","comment":"to appear in AISTATS 2023. arXiv admin note: text overlap with\n  arXiv:2101.09756"},{"id":"http://arxiv.org/abs/2208.13305v2","updated":"2023-02-24T07:24:25Z","published":"2022-08-28T22:44:07Z","title":"Neural Network Approximation of Continuous Functions in High Dimensions\n  with Applications to Inverse Problems","summary":"  The remarkable successes of neural networks in a huge variety of inverse\nproblems have fueled their adoption in disciplines ranging from medical imaging\nto seismic analysis over the past decade. However, the high dimensionality of\nsuch inverse problems has simultaneously left current theory, which predicts\nthat networks should scale exponentially in the dimension of the problem,\nunable to explain why the seemingly small networks used in these settings work\nas well as they do in practice. To reduce this gap between theory and practice,\nwe provide a general method for bounding the complexity required for a neural\nnetwork to approximate a H\\\"older (or uniformly) continuous function defined on\na high-dimensional set with a low-complexity structure. The approach is based\non the observation that the existence of a Johnson-Lindenstrauss embedding\n$A\\in\\mathbb{R}^{d\\times D}$ of a given high-dimensional set\n$S\\subset\\mathbb{R}^D$ into a low dimensional cube $[-M,M]^d$ implies that for\nany H\\\"older (or uniformly) continuous function $f:S\\to\\mathbb{R}^p$, there\nexists a H\\\"older (or uniformly) continuous function\n$g:[-M,M]^d\\to\\mathbb{R}^p$ such that $g(Ax)=f(x)$ for all $x\\in S$. Hence, if\none has a neural network which approximates $g:[-M,M]^d\\to\\mathbb{R}^p$, then a\nlayer can be added that implements the JL embedding $A$ to obtain a neural\nnetwork that approximates $f:S\\to\\mathbb{R}^p$. By pairing JL embedding results\nalong with results on approximation of H\\\"older (or uniformly) continuous\nfunctions by neural networks, one then obtains results which bound the\ncomplexity required for a neural network to approximate H\\\"older (or uniformly)\ncontinuous functions on high dimensional sets. The end result is a general\ntheoretical framework which can then be used to better explain the observed\nempirical successes of smaller networks in a wider variety of inverse problems\nthan current theory allows.\n","authors":["Santhosh Karnik","Rongrong Wang","Mark Iwen"],"pdf_url":"https://arxiv.org/pdf/2208.13305v2.pdf","comment":"22 pages, 1 figure"},{"id":"http://arxiv.org/abs/2302.12493v1","updated":"2023-02-24T07:21:41Z","published":"2023-02-24T07:21:41Z","title":"SEO: Safety-Aware Energy Optimization Framework for Multi-Sensor Neural\n  Controllers at the Edge","summary":"  Runtime energy management has become quintessential for multi-sensor\nautonomous systems at the edge for achieving high performance given the\nplatform constraints. Typical for such systems, however, is to have their\ncontrollers designed with formal guarantees on safety that precede in priority\nsuch optimizations, which in turn limits their application in real settings. In\nthis paper, we propose a novel energy optimization framework that is aware of\nthe autonomous system's safety state, and leverages it to regulate the\napplication of energy optimization methods so that the system's formal safety\nproperties are preserved. In particular, through the formal characterization of\na system's safety state as a dynamic processing deadline, the computing\nworkloads of the underlying models can be adapted accordingly. For our\nexperiments, we model two popular runtime energy optimization methods,\noffloading and gating, and simulate an autonomous driving system (ADS) use-case\nin the CARLA simulation environment with performance characterizations obtained\nfrom the standard Nvidia Drive PX2 ADS platform. Our results demonstrate that\nthrough a formal awareness of the perceived risks in the test case scenario,\nenergy efficiency gains are still achieved (reaching 89.9%) while maintaining\nthe desired safety properties.\n","authors":["Mohanad Odema","James Ferlez","Yasser Shoukry","Mohammad Abdullah Al Faruque"],"pdf_url":"https://arxiv.org/pdf/2302.12493v1.pdf","comment":"Accepted to the 60th ACM/IEEE Design Automation Conference (DAC 2023)"},{"id":"http://arxiv.org/abs/2302.11135v2","updated":"2023-02-24T06:59:57Z","published":"2023-02-22T04:02:50Z","title":"Semi-Supervised Approach for Early Stuck Sign Detection in Drilling\n  Operations","summary":"  A real-time stuck pipe prediction methodology is proposed in this paper. We\nassume early signs of stuck pipe to be apparent when the drilling data behavior\ndeviates from that from normal drilling operations. The definition of normalcy\nchanges with drill string configuration or geological conditions. Here, a\ndepth-domain data representation is adopted to capture the localized normal\nbehavior. Several models, based on auto-encoder and variational auto-encoders,\nare trained on regular drilling data extracted from actual drilling data. When\nthe trained model is applied to data sets before stuck incidents, eight\nincidents showed large reconstruction errors. These results suggest better\nperformance than the previously reported supervised approach. Inter-comparison\nof various models reveals the robustness of our approach. The model performance\ndepends on the featured parameter suggesting the need for multiple models in\nactual operation.\n","authors":["Andres Hernandez-Matamoros","Kohei Sugawara","Tatsuya Kaneko","Ryota Wada","Masahiko Ozaki"],"pdf_url":"https://arxiv.org/pdf/2302.11135v2.pdf","comment":"There is a conflict interest between authors"},{"id":"http://arxiv.org/abs/2302.12480v1","updated":"2023-02-24T06:44:19Z","published":"2023-02-24T06:44:19Z","title":"Robust Weight Signatures: Gaining Robustness as Easy as Patching\n  Weights?","summary":"  Given a robust model trained to be resilient to one or multiple types of\ndistribution shifts (e.g., natural image corruptions), how is that \"robustness\"\nencoded in the model weights, and how easily can it be disentangled and/or\n\"zero-shot\" transferred to some other models? This paper empirically suggests a\nsurprisingly simple answer: linearly - by straightforward model weight\narithmetic! We start by drawing several key observations: (1)assuming that we\ntrain the same model architecture on both a clean dataset and its corrupted\nversion, resultant weights mostly differ in shallow layers; (2)the weight\ndifference after projection, which we call \"Robust Weight Signature\" (RWS),\nappears to be discriminative and indicative of different corruption types;\n(3)for the same corruption type, the RWSs obtained by one model architecture\nare highly consistent and transferable across different datasets.\n  We propose a minimalistic model robustness \"patching\" framework that carries\na model trained on clean data together with its pre-extracted RWSs. In this\nway, injecting certain robustness to the model is reduced to directly adding\nthe corresponding RWS to its weight. We verify our proposed framework to be\nremarkably (1)lightweight. since RWSs concentrate on the shallowest few layers\nand we further show they can be painlessly quantized, storing an RWS is up to\n13 x more compact than storing the full weight copy; (2)in-situ adjustable.\nRWSs can be appended as needed and later taken off to restore the intact clean\nmodel. We further demonstrate one can linearly re-scale the RWS to control the\npatched robustness strength; (3)composable. Multiple RWSs can be added\nsimultaneously to patch more comprehensive robustness at once; and\n(4)transferable. Even when the clean model backbone is continually adapted or\nupdated, RWSs remain as effective patches due to their outstanding\ncross-dataset transferability.\n","authors":["Ruisi Cai","Zhenyu Zhang","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.12480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07101v2","updated":"2023-02-24T06:18:20Z","published":"2022-02-15T00:13:05Z","title":"A Survey on Dynamic Neural Networks for Natural Language Processing","summary":"  Effectively scaling large Transformer models is a main driver of recent\nadvances in natural language processing. Dynamic neural networks, as an\nemerging research direction, are capable of scaling up neural networks with\nsub-linear increases in computation and time by dynamically adjusting their\ncomputational path based on the input. Dynamic neural networks could be a\npromising solution to the growing parameter numbers of pretrained language\nmodels, allowing both model pretraining with trillions of parameters and faster\ninference on mobile devices. In this survey, we summarize progress of three\ntypes of dynamic neural networks in NLP: skimming, mixture of experts, and\nearly exit. We also highlight current challenges in dynamic neural networks and\ndirections for future research.\n","authors":["Canwen Xu","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2202.07101v2.pdf","comment":"EACL 2023 Findings"},{"id":"http://arxiv.org/abs/1906.11985v3","updated":"2023-02-24T06:15:45Z","published":"2019-06-27T22:39:35Z","title":"Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond","summary":"  In this paper, we provide near-optimal accelerated first-order methods for\nminimizing a broad class of smooth nonconvex functions that are strictly\nunimodal on all lines through a minimizer. This function class, which we call\nthe class of smooth quasar-convex functions, is parameterized by a constant\n$\\gamma \\in (0,1]$, where $\\gamma = 1$ encompasses the classes of smooth convex\nand star-convex functions, and smaller values of $\\gamma$ indicate that the\nfunction can be \"more nonconvex.\" We develop a variant of accelerated gradient\ndescent that computes an $\\epsilon$-approximate minimizer of a smooth\n$\\gamma$-quasar-convex function with at most $O(\\gamma^{-1} \\epsilon^{-1/2}\n\\log(\\gamma^{-1} \\epsilon^{-1}))$ total function and gradient evaluations. We\nalso derive a lower bound of $\\Omega(\\gamma^{-1} \\epsilon^{-1/2})$ on the\nworst-case number of gradient evaluations required by any deterministic\nfirst-order method, showing that, up to a logarithmic factor, no deterministic\nfirst-order method can improve upon ours.\n","authors":["Oliver Hinder","Aaron Sidford","Nimit S. Sohoni"],"pdf_url":"https://arxiv.org/pdf/1906.11985v3.pdf","comment":"48 pages. Published as a conference paper at COLT 2020"},{"id":"http://arxiv.org/abs/2209.07007v2","updated":"2023-02-24T06:07:37Z","published":"2022-09-15T02:34:39Z","title":"Gromov-Wasserstein Autoencoders","summary":"  Variational Autoencoder (VAE)-based generative models offer flexible\nrepresentation learning by incorporating meta-priors, general premises\nconsidered beneficial for downstream tasks. However, the incorporated\nmeta-priors often involve ad-hoc model deviations from the original likelihood\narchitecture, causing undesirable changes in their training. In this paper, we\npropose a novel representation learning method, Gromov-Wasserstein Autoencoders\n(GWAE), which directly matches the latent and data distributions using the\nvariational autoencoding scheme. Instead of likelihood-based objectives, GWAE\nmodels minimize the Gromov-Wasserstein (GW) metric between the trainable prior\nand given data distributions. The GW metric measures the distance\nstructure-oriented discrepancy between distributions even with different\ndimensionalities, which provides a direct measure between the latent and data\nspaces. By restricting the prior family, we can introduce meta-priors into the\nlatent space without changing their objective. The empirical comparisons with\nVAE-based models show that GWAE models work in two prominent meta-priors,\ndisentanglement and clustering, with their GW objective unchanged.\n","authors":["Nao Nakagawa","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2209.07007v2.pdf","comment":"38 pages, 9 tables, 13 figures; accepted at ICLR2023"},{"id":"http://arxiv.org/abs/2203.16668v2","updated":"2023-02-24T05:52:30Z","published":"2022-03-30T20:43:43Z","title":"Flexible and Efficient Contextual Bandits with Heterogeneous Treatment\n  Effect Oracles","summary":"  Contextual bandit algorithms often estimate reward models to inform\ndecision-making. However, true rewards can contain action-independent\nredundancies that are not relevant for decision-making. We show it is more\ndata-efficient to estimate any function that explains the reward differences\nbetween actions, that is, the treatment effects. Motivated by this observation,\nbuilding on recent work on oracle-based bandit algorithms, we provide the first\nreduction of contextual bandits to general-purpose heterogeneous treatment\neffect estimation, and we design a simple and computationally efficient\nalgorithm based on this reduction. Our theoretical and experimental results\ndemonstrate that heterogeneous treatment effect estimation in contextual\nbandits offers practical advantages over reward estimation, including more\nefficient model estimation and greater flexibility to model misspecification.\n","authors":["Aldo Gael Carranza","Sanath Kumar Krishnamurthy","Susan Athey"],"pdf_url":"https://arxiv.org/pdf/2203.16668v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12465v1","updated":"2023-02-24T05:43:47Z","published":"2023-02-24T05:43:47Z","title":"PaGE-Link: Path-based Graph Neural Network Explanation for Heterogeneous\n  Link Prediction","summary":"  Transparency and accountability have become major concerns for black-box\nmachine learning (ML) models. Proper explanations for the model behavior\nincrease model transparency and help researchers develop more accountable\nmodels. Graph neural networks (GNN) have recently shown superior performance in\nmany graph ML problems than traditional methods, and explaining them has\nattracted increased interest. However, GNN explanation for link prediction (LP)\nis lacking in the literature. LP is an essential GNN task and corresponds to\nweb applications like recommendation and sponsored search on web. Given\nexisting GNN explanation methods only address node/graph-level tasks, we\npropose Path-based GNN Explanation for heterogeneous Link prediction\n(PaGE-Link) that generates explanations with connection interpretability,\nenjoys model scalability, and handles graph heterogeneity. Qualitatively,\nPaGE-Link can generate explanations as paths connecting a node pair, which\nnaturally captures connections between the two nodes and easily transfer to\nhuman-interpretable explanations. Quantitatively, explanations generated by\nPaGE-Link improve AUC for recommendation on citation and user-item graphs by 9\n- 35% and are chosen as better by 78.79% of responses in human evaluation.\n","authors":["Shichang Zhang","Jiani Zhang","Xiang Song","Soji Adeshina","Da Zheng","Christos Faloutsos","Yizhou Sun"],"pdf_url":"https://arxiv.org/pdf/2302.12465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10890v2","updated":"2023-02-24T05:35:48Z","published":"2023-02-05T21:48:42Z","title":"Learning Interpretable Low-dimensional Representation via Physical\n  Symmetry","summary":"  Interpretable representation learning has been playing a key role in creative\nintelligent systems. In the music domain, current learning algorithms can\nsuccessfully learn various features such as pitch, timbre, chord, texture, etc.\nHowever, most methods rely heavily on music domain knowledge. It remains an\nopen question what general computational principles give rise to interpretable\nrepresentations, especially low-dim factors that agree with human perception.\nIn this study, we take inspiration from modern physics and use physical\nsymmetry as a self-consistency constraint for the latent space. Specifically,\nit requires the prior model that characterises the dynamics of the latent\nstates to be equivariant with respect to certain group transformations. We show\nthat physical symmetry leads the model to learn a linear pitch factor from\nunlabelled monophonic music audio in a self-supervised fashion. In addition,\nthe same methodology can be applied to computer vision, learning a 3D Cartesian\nspace from videos of a simple moving object without labels. Furthermore,\nphysical symmetry naturally leads to representation augmentation, a new\ntechnique which improves sample efficiency.\n","authors":["Xuanjie Liu","Daniel Chin","Yichen Huang","Gus Xia"],"pdf_url":"https://arxiv.org/pdf/2302.10890v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12461v1","updated":"2023-02-24T05:26:08Z","published":"2023-02-24T05:26:08Z","title":"Analyzing And Editing Inner Mechanisms Of Backdoored Language Models","summary":"  Recent advancements in interpretability research made transformer language\nmodels more transparent. This progress led to a better understanding of their\ninner workings for toy and naturally occurring models. However, how these\nmodels internally process sentiment changes has yet to be sufficiently\nanswered. In this work, we introduce a new interpretability tool called PCP\nablation, where we replace modules with low-rank matrices based on the\nprincipal components of their activations, reducing model parameters and their\nbehavior to essentials. We demonstrate PCP ablations on MLP and attention\nlayers in backdoored toy, backdoored large, and naturally occurring models. We\ndetermine MLPs as most important for the backdoor mechanism and use this\nknowledge to remove, insert, and modify backdoor mechanisms with engineered\nreplacements via PCP ablation.\n","authors":["Max Lamparth","Anka Reuel"],"pdf_url":"https://arxiv.org/pdf/2302.12461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12456v1","updated":"2023-02-24T05:14:27Z","published":"2023-02-24T05:14:27Z","title":"Logarithmic Switching Cost in Reinforcement Learning beyond Linear MDPs","summary":"  In many real-life reinforcement learning (RL) problems, deploying new\npolicies is costly. In those scenarios, algorithms must solve exploration\n(which requires adaptivity) while switching the deployed policy sparsely (which\nlimits adaptivity). In this paper, we go beyond the existing state-of-the-art\non this problem that focused on linear Markov Decision Processes (MDPs) by\nconsidering linear Bellman-complete MDPs with low inherent Bellman error. We\npropose the ELEANOR-LowSwitching algorithm that achieves the near-optimal\nregret with a switching cost logarithmic in the number of episodes and linear\nin the time-horizon $H$ and feature dimension $d$. We also prove a lower bound\nproportional to $dH$ among all algorithms with sublinear regret. In addition,\nwe show the ``doubling trick'' used in ELEANOR-LowSwitching can be further\nleveraged for the generalized linear function approximation, under which we\ndesign a sample-efficient algorithm with near-optimal switching cost.\n","authors":["Dan Qiao","Ming Yin","Yu-Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.12456v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2110.08432v3","updated":"2023-02-24T05:11:24Z","published":"2021-10-16T01:18:50Z","title":"Meta-Learning with Adjoint Methods","summary":"  Model Agnostic Meta Learning (MAML) is widely used to find a good\ninitialization for a family of tasks. Despite its success, a critical challenge\nin MAML is to calculate the gradient w.r.t. the initialization of a long\ntraining trajectory for the sampled tasks, because the computation graph can\nrapidly explode and the computational cost is very expensive. To address this\nproblem, we propose Adjoint MAML (A-MAML). We view gradient descent in the\ninner optimization as the evolution of an Ordinary Differential Equation (ODE).\nTo efficiently compute the gradient of the validation loss w.r.t. the\ninitialization, we use the adjoint method to construct a companion, backward\nODE. To obtain the gradient w.r.t. the initialization, we only need to run the\nstandard ODE solver twice -- one is forward in time that evolves a long\ntrajectory of gradient flow for the sampled task; the other is backward and\nsolves the adjoint ODE. We need not create or expand any intermediate\ncomputational graphs, adopt aggressive approximations, or impose proximal\nregularizers in the training loss. Our approach is cheap, accurate, and\nadaptable to different trajectory lengths. We demonstrate the advantage of our\napproach in both synthetic and real-world meta-learning tasks.\n","authors":["Shibo Li","Zheng Wang","Akil Narayan","Robert Kirby","Shandian Zhe"],"pdf_url":"https://arxiv.org/pdf/2110.08432v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12453v1","updated":"2023-02-24T05:07:05Z","published":"2023-02-24T05:07:05Z","title":"Inducing Neural Collapse in Deep Long-tailed Learning","summary":"  Although deep neural networks achieve tremendous success on various\nclassification tasks, the generalization ability drops sheer when training\ndatasets exhibit long-tailed distributions. One of the reasons is that the\nlearned representations (i.e. features) from the imbalanced datasets are less\neffective than those from balanced datasets. Specifically, the learned\nrepresentation under class-balanced distribution will present the Neural\nCollapse (NC) phenomena. NC indicates the features from the same category are\nclose to each other and from different categories are maximally distant,\nshowing an optimal linear separable state of classification. However, the\npattern differs on imbalanced datasets and is partially responsible for the\nreduced performance of the model. In this work, we propose two explicit feature\nregularization terms to learn high-quality representation for class-imbalanced\ndata. With the proposed regularization, NC phenomena will appear under the\nclass-imbalanced distribution, and the generalization ability can be\nsignificantly improved. Our method is easily implemented, highly effective, and\ncan be plugged into most existing methods. The extensive experimental results\non widely-used benchmarks show the effectiveness of our method\n","authors":["Xuantong Liu","Jianfeng Zhang","Tianyang Hu","He Cao","Lujia Pan","Yuan Yao"],"pdf_url":"https://arxiv.org/pdf/2302.12453v1.pdf","comment":"accepted by AISTATS 2023"},{"id":"http://arxiv.org/abs/2212.10048v3","updated":"2023-02-24T04:49:07Z","published":"2022-12-20T07:44:48Z","title":"Asynchronous Distributed Bilevel Optimization","summary":"  Bilevel optimization plays an essential role in many machine learning tasks,\nranging from hyperparameter optimization to meta-learning. Existing studies on\nbilevel optimization, however, focus on either centralized or synchronous\ndistributed setting. The centralized bilevel optimization approaches require\ncollecting massive amount of data to a single server, which inevitably incur\nsignificant communication expenses and may give rise to data privacy risks.\nSynchronous distributed bilevel optimization algorithms, on the other hand,\noften face the straggler problem and will immediately stop working if a few\nworkers fail to respond. As a remedy, we propose Asynchronous Distributed\nBilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel\noptimization problems with both nonconvex upper-level and lower-level objective\nfunctions, and its convergence is theoretically guaranteed. Furthermore, it is\nrevealed through theoretic analysis that the iteration complexity of ADBO to\nobtain the $\\epsilon$-stationary point is upper bounded by\n$\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public\ndatasets have been conducted to elucidate the effectiveness and efficiency of\nthe proposed ADBO.\n","authors":["Yang Jiao","Kai Yang","Tiancheng Wu","Dongjin Song","Chengtao Jian"],"pdf_url":"https://arxiv.org/pdf/2212.10048v3.pdf","comment":"Accepted at ICLR2023"},{"id":"http://arxiv.org/abs/2211.02927v3","updated":"2023-02-24T04:33:23Z","published":"2022-11-05T15:37:51Z","title":"Unsupervised Machine Learning for Explainable Health Care Fraud\n  Detection","summary":"  The US federal government spends more than a trillion dollars per year on\nhealth care, largely provided by private third parties and reimbursed by the\ngovernment. A major concern in this system is overbilling, waste and fraud by\nproviders, who face incentives to misreport on their claims in order to receive\nhigher payments. In this paper, we develop novel machine learning tools to\nidentify providers that overbill Medicare, the US federal health insurance\nprogram for elderly adults and the disabled. Using large-scale Medicare claims\ndata, we identify patterns consistent with fraud or overbilling among inpatient\nhospitalizations. Our proposed approach for Medicare fraud detection is fully\nunsupervised, not relying on any labeled training data, and is explainable to\nend users, providing reasoning and interpretable insights into the potentially\nsuspicious behavior of the flagged providers. Data from the Department of\nJustice on providers facing anti-fraud lawsuits and several case studies\nvalidate our approach and findings both quantitatively and qualitatively.\n","authors":["Shubhranshu Shekhar","Jetson Leder-Luis","Leman Akoglu"],"pdf_url":"https://arxiv.org/pdf/2211.02927v3.pdf","comment":"NBER Working paper #30946"},{"id":"http://arxiv.org/abs/2109.10476v3","updated":"2023-02-24T04:31:46Z","published":"2021-09-22T01:37:08Z","title":"Self-Supervised Learning to Prove Equivalence Between Straight-Line\n  Programs via Rewrite Rules","summary":"  We target the problem of automatically synthesizing proofs of semantic\nequivalence between two programs made of sequences of statements. We represent\nprograms using abstract syntax trees (AST), where a given set of\nsemantics-preserving rewrite rules can be applied on a specific AST pattern to\ngenerate a transformed and semantically equivalent program. In our system, two\nprograms are equivalent if there exists a sequence of application of these\nrewrite rules that leads to rewriting one program into the other. We propose a\nneural network architecture based on a transformer model to generate proofs of\nequivalence between program pairs. The system outputs a sequence of rewrites,\nand the validity of the sequence is simply checked by verifying it can be\napplied. If no valid sequence is produced by the neural network, the system\nreports the programs as non-equivalent, ensuring by design no programs may be\nincorrectly reported as equivalent. Our system is fully implemented for a given\ngrammar which can represent straight-line programs with function calls and\nmultiple types. To efficiently train the system to generate such sequences, we\ndevelop an original incremental training technique, named self-supervised\nsample selection. We extensively study the effectiveness of this novel training\napproach on proofs of increasing complexity and length. Our system, S4Eq,\nachieves 97% proof success on a curated dataset of 10,000 pairs of equivalent\nprograms\n","authors":["Steve Kommrusch","Martin Monperrus","Louis-Noël Pouchet"],"pdf_url":"https://arxiv.org/pdf/2109.10476v3.pdf","comment":"30 pages including appendix"},{"id":"http://arxiv.org/abs/2302.12449v1","updated":"2023-02-24T04:31:18Z","published":"2023-02-24T04:31:18Z","title":"SGL-PT: A Strong Graph Learner with Graph Prompt Tuning","summary":"  Recently, much exertion has been paid to design graph self-supervised methods\nto obtain generalized pre-trained models, and adapt pre-trained models onto\ndownstream tasks through fine-tuning. However, there exists an inherent gap\nbetween pretext and downstream graph tasks, which insufficiently exerts the\nability of pre-trained models and even leads to negative transfer. Meanwhile,\nprompt tuning has seen emerging success in natural language processing by\naligning pre-training and fine-tuning with consistent training objectives. In\nthis paper, we identify the challenges for graph prompt tuning: The first is\nthe lack of a strong and universal pre-training task across sundry pre-training\nmethods in graph domain. The second challenge lies in the difficulty of\ndesigning a consistent training objective for both pre-training and downstream\ntasks. To overcome above obstacles, we propose a novel framework named SGL-PT\nwhich follows the learning strategy ``Pre-train, Prompt, and Predict''.\nSpecifically, we raise a strong and universal pre-training task coined as SGL\nthat acquires the complementary merits of generative and contrastive\nself-supervised graph learning. And aiming for graph classification task, we\nunify pre-training and fine-tuning by designing a novel verbalizer-free\nprompting function, which reformulates the downstream task in a similar format\nas pretext task. Empirical results show that our method surpasses other\nbaselines under unsupervised setting, and our prompt tuning method can greatly\nfacilitate models on biological datasets over fine-tuning methods.\n","authors":["Yun Zhu","Jianhao Guo","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2302.12449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12448v1","updated":"2023-02-24T04:29:44Z","published":"2023-02-24T04:29:44Z","title":"Subspace based Federated Unlearning","summary":"  Federated learning (FL) enables multiple clients to train a machine learning\nmodel collaboratively without exchanging their local data. Federated unlearning\nis an inverse FL process that aims to remove a specified target client's\ncontribution in FL to satisfy the user's right to be forgotten. Most existing\nfederated unlearning algorithms require the server to store the history of the\nparameter updates, which is not applicable in scenarios where the server\nstorage resource is constrained. In this paper, we propose a\nsimple-yet-effective subspace based federated unlearning method, dubbed SFU,\nthat lets the global model perform gradient ascent in the orthogonal space of\ninput gradient spaces formed by other clients to eliminate the target client's\ncontribution without requiring additional storage. Specifically, the server\nfirst collects the gradients generated from the target client after performing\ngradient ascent, and the input representation matrix is computed locally by the\nremaining clients. We also design a differential privacy method to protect the\nprivacy of the representation matrix. Then the server merges those\nrepresentation matrices to get the input gradient subspace and updates the\nglobal model in the orthogonal subspace of the input gradient subspace to\ncomplete the forgetting task with minimal model performance degradation.\nExperiments on MNIST, CIFAR10, and CIFAR100 show that SFU outperforms several\nstate-of-the-art (SOTA) federated unlearning algorithms by a large margin in\nvarious settings.\n","authors":["Guanghao Li","Li Shen","Yan Sun","Yue Hu","Han Hu","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.12448v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2302.01020v2","updated":"2023-02-24T04:24:56Z","published":"2023-02-02T11:15:07Z","title":"Meta Learning in Decentralized Neural Networks: Towards More General AI","summary":"  Meta-learning usually refers to a learning algorithm that learns from other\nlearning algorithms. The problem of uncertainty in the predictions of neural\nnetworks shows that the world is only partially predictable and a learned\nneural network cannot generalize to its ever-changing surrounding environments.\nTherefore, the question is how a predictive model can represent multiple\npredictions simultaneously. We aim to provide a fundamental understanding of\nlearning to learn in the contents of Decentralized Neural Networks\n(Decentralized NNs) and we believe this is one of the most important questions\nand prerequisites to building an autonomous intelligence machine. To this end,\nwe shall demonstrate several pieces of evidence for tackling the problems above\nwith Meta Learning in Decentralized NNs. In particular, we will present three\ndifferent approaches to building such a decentralized learning system: (1)\nlearning from many replica neural networks, (2) building the hierarchy of\nneural networks for different functions, and (3) leveraging different modality\nexperts to learn cross-modal representations.\n","authors":["Yuwei Sun"],"pdf_url":"https://arxiv.org/pdf/2302.01020v2.pdf","comment":"Accepted for AAAI 2023 Doctoral Consortium"},{"id":"http://arxiv.org/abs/2302.12445v1","updated":"2023-02-24T04:11:18Z","published":"2023-02-24T04:11:18Z","title":"Decoupling the All-Reduce Primitive for Accelerating Distributed Deep\n  Learning","summary":"  Communication scheduling has been shown to be effective in accelerating\ndistributed training, which enables all-reduce communications to be overlapped\nwith backpropagation computations. This has been commonly adopted in popular\ndistributed deep learning frameworks. However, there exist two fundamental\nproblems: (1) excessive startup latency proportional to the number of workers\nfor each all-reduce operation; (2) it only achieves sub-optimal training\nperformance due to the dependency and synchronization requirement of the\nfeed-forward computation in the next iteration. We propose a novel scheduling\nalgorithm, DeAR, that decouples the all-reduce primitive into two continuous\noperations, which overlaps with both backpropagation and feed-forward\ncomputations without extra communications. We further design a practical tensor\nfusion algorithm to improve the training performance. Experimental results with\nfive popular models show that DeAR achieves up to 83% and 15% training speedup\nover the state-of-the-art solutions on a 64-GPU cluster with 10Gb/s Ethernet\nand 100Gb/s InfiniBand interconnects, respectively.\n","authors":["Lin Zhang","Shaohuai Shi","Xiaowen Chu","Wei Wang","Bo Li","Chengjian Liu"],"pdf_url":"https://arxiv.org/pdf/2302.12445v1.pdf","comment":"12 pages, 11 figures"},{"id":"http://arxiv.org/abs/2302.12444v1","updated":"2023-02-24T04:10:54Z","published":"2023-02-24T04:10:54Z","title":"On the Training Instability of Shuffling SGD with Batch Normalization","summary":"  We uncover how SGD interacts with batch normalization and can exhibit\nundesirable training dynamics such as divergence. More precisely, we study how\nSingle Shuffle (SS) and Random Reshuffle (RR) -- two widely used variants of\nSGD -- interact surprisingly differently in the presence of batch\nnormalization: RR leads to much more stable evolution of training loss than SS.\nAs a concrete example, for regression using a linear network with batch\nnormalization, we prove that SS and RR converge to distinct global optima that\nare \"distorted\" away from gradient descent. Thereafter, for classification we\ncharacterize conditions under which training divergence for SS and RR can, and\ncannot occur. We present explicit constructions to show how SS leads to\ndistorted optima in regression and divergence for classification, whereas RR\navoids both distortion and divergence. We validate our results by confirming\nthem empirically in realistic settings, and conclude that the separation\nbetween SS and RR used with batch normalization is relevant in practice.\n","authors":["David X. Wu","Chulhee Yun","Suvrit Sra"],"pdf_url":"https://arxiv.org/pdf/2302.12444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12441v1","updated":"2023-02-24T04:03:15Z","published":"2023-02-24T04:03:15Z","title":"MUX-PLMs: Pre-training Language Models with Data Multiplexing","summary":"  Data multiplexing is a recently proposed method for improving a model's\ninference efficiency by processing multiple instances simultaneously using an\nordered representation mixture. Prior work on data multiplexing only used\ntask-specific Transformers without any pre-training, which limited their\naccuracy and generality. In this paper, we develop pre-trained multiplexed\nlanguage models (MUX-PLMs) that can be widely finetuned on any downstream task.\nOur approach includes a three-stage training procedure and novel multiplexing\nand demultiplexing modules for improving throughput and downstream task\naccuracy. We demonstrate our method on BERT and ELECTRA pre-training\nobjectives, with our MUX-BERT and MUX-ELECTRA models achieving 2x/5x inference\nspeedup with a 2-4 \\% drop in absolute performance on GLUE and 1-2 \\% drop on\ntoken-level tasks.\n","authors":["Vishvak Murahari","Ameet Deshpande","Carlos E. Jimenez","Izhak Shafran","Mingqiu Wang","Yuan Cao","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2302.12441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12432v1","updated":"2023-02-24T03:24:04Z","published":"2023-02-24T03:24:04Z","title":"Graph Neural Networks with Learnable and Optimal Polynomial Bases","summary":"  Polynomial filters, a kind of Graph Neural Networks, typically use a\npredetermined polynomial basis and learn the coefficients from the training\ndata. It has been observed that the effectiveness of the model is highly\ndependent on the property of the polynomial basis. Consequently, two natural\nand fundamental questions arise: Can we learn a suitable polynomial basis from\nthe training data? Can we determine the optimal polynomial basis for a given\ngraph and node features?\n  In this paper, we propose two spectral GNN models that provide positive\nanswers to the questions posed above. First, inspired by Favard's Theorem, we\npropose the FavardGNN model, which learns a polynomial basis from the space of\nall possible orthonormal bases. Second, we examine the supposedly unsolvable\ndefinition of optimal polynomial basis from Wang & Zhang (2022) and propose a\nsimple model, OptBasisGNN, which computes the optimal basis for a given graph\nstructure and graph signal. Extensive experiments are conducted to demonstrate\nthe effectiveness of our proposed models.\n","authors":["Yuhe Guo","Zhewei Wei"],"pdf_url":"https://arxiv.org/pdf/2302.12432v1.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.12431v1","updated":"2023-02-24T03:18:45Z","published":"2023-02-24T03:18:45Z","title":"Flexible Phase Dynamics for Bio-Plausible Contrastive Learning","summary":"  Many learning algorithms used as normative models in neuroscience or as\ncandidate approaches for learning on neuromorphic chips learn by contrasting\none set of network states with another. These Contrastive Learning (CL)\nalgorithms are traditionally implemented with rigid, temporally non-local, and\nperiodic learning dynamics that could limit the range of physical systems\ncapable of harnessing CL. In this study, we build on recent work exploring how\nCL might be implemented by biological or neurmorphic systems and show that this\nform of learning can be made temporally local, and can still function even if\nmany of the dynamical requirements of standard training procedures are relaxed.\nThanks to a set of general theorems corroborated by numerical experiments\nacross several CL models, our results provide theoretical foundations for the\nstudy and development of CL methods for biological and neuromorphic neural\nnetworks.\n","authors":["Ezekiel Williams","Colin Bredenberg","Guillaume Lajoie"],"pdf_url":"https://arxiv.org/pdf/2302.12431v1.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.12426v1","updated":"2023-02-24T03:13:12Z","published":"2023-02-24T03:13:12Z","title":"Statistical Analysis of Karcher Means for Random Restricted PSD Matrices","summary":"  Non-asymptotic statistical analysis is often missing for modern\ngeometry-aware machine learning algorithms due to the possibly intricate\nnon-linear manifold structure. This paper studies an intrinsic mean model on\nthe manifold of restricted positive semi-definite matrices and provides a\nnon-asymptotic statistical analysis of the Karcher mean. We also consider a\ngeneral extrinsic signal-plus-noise model, under which a deterministic error\nbound of the Karcher mean is provided. As an application, we show that the\ndistributed principal component analysis algorithm, LRC-dPCA, achieves the same\nperformance as the full sample PCA algorithm. Numerical experiments lend strong\nsupport to our theories.\n","authors":["Hengchao Chen","Xiang Li","Qiang Sun"],"pdf_url":"https://arxiv.org/pdf/2302.12426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06077v2","updated":"2023-02-24T03:13:04Z","published":"2022-11-11T09:16:25Z","title":"Overparameterized random feature regression with nearly orthogonal data","summary":"  We investigate the properties of random feature ridge regression (RFRR) given\nby a two-layer neural network with random Gaussian initialization. We study the\nnon-asymptotic behaviors of the RFRR with nearly orthogonal deterministic\nunit-length input data vectors in the overparameterized regime, where the width\nof the first layer is much larger than the sample size. Our analysis shows\nhigh-probability non-asymptotic concentration results for the training errors,\ncross-validations, and generalization errors of RFRR centered around their\nrespective values for a kernel ridge regression (KRR). This KRR is derived from\nan expected kernel generated by a nonlinear random feature map. We then\napproximate the performance of the KRR by a polynomial kernel matrix obtained\nfrom the Hermite polynomial expansion of the activation function, whose degree\nonly depends on the orthogonality among different data points. This polynomial\nkernel determines the asymptotic behavior of the RFRR and the KRR. Our results\nhold for a wide variety of activation functions and input data sets that\nexhibit nearly orthogonal properties. Based on these approximations, we obtain\na lower bound for the generalization error of the RFRR for a nonlinear\nstudent-teacher model.\n","authors":["Zhichao Wang","Yizhe Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.06077v2.pdf","comment":"38 pages. to appear in AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.12419v1","updated":"2023-02-24T02:50:18Z","published":"2023-02-24T02:50:18Z","title":"A Targeted Accuracy Diagnostic for Variational Approximations","summary":"  Variational Inference (VI) is an attractive alternative to Markov Chain Monte\nCarlo (MCMC) due to its computational efficiency in the case of large datasets\nand/or complex models with high-dimensional parameters. However, evaluating the\naccuracy of variational approximations remains a challenge. Existing methods\ncharacterize the quality of the whole variational distribution, which is almost\nalways poor in realistic applications, even if specific posterior functionals\nsuch as the component-wise means or variances are accurate. Hence, these\ndiagnostics are of practical value only in limited circumstances. To address\nthis issue, we propose the TArgeted Diagnostic for Distribution Approximation\nAccuracy (TADDAA), which uses many short parallel MCMC chains to obtain lower\nbounds on the error of each posterior functional of interest. We also develop a\nreliability check for TADDAA to determine when the lower bounds should not be\ntrusted. Numerical experiments validate the practical utility and computational\nefficiency of our approach on a range of synthetic distributions and real-data\nexamples, including sparse logistic regression and Bayesian neural network\nmodels.\n","authors":["Yu Wang","Mikołaj Kasprzak","Jonathan H. Huggins"],"pdf_url":"https://arxiv.org/pdf/2302.12419v1.pdf","comment":"Code to reproduce all of our experiments is available at\n  https://github.com/TARPS-group/TADDAA"},{"id":"http://arxiv.org/abs/2302.06299v2","updated":"2023-02-24T02:46:46Z","published":"2023-02-13T11:56:45Z","title":"Homophily-oriented Heterogeneous Graph Rewiring","summary":"  With the rapid development of the World Wide Web (WWW), heterogeneous graphs\n(HG) have explosive growth. Recently, heterogeneous graph neural network (HGNN)\nhas shown great potential in learning on HG. Current studies of HGNN mainly\nfocus on some HGs with strong homophily properties (nodes connected by\nmeta-path tend to have the same labels), while few discussions are made in\nthose that are less homophilous. Recently, there have been many works on\nhomogeneous graphs with heterophily. However, due to heterogeneity, it is\nnon-trivial to extend their approach to deal with HGs with heterophily. In this\nwork, based on empirical observations, we propose a meta-path-induced metric to\nmeasure the homophily degree of a HG. We also find that current HGNNs may have\ndegenerated performance when handling HGs with less homophilous properties.\nThus it is essential to increase the generalization ability of HGNNs on\nnon-homophilous HGs. To this end, we propose HDHGR, a homophily-oriented deep\nheterogeneous graph rewiring approach that modifies the HG structure to\nincrease the performance of HGNN. We theoretically verify HDHGR. In addition,\nexperiments on real-world HGs demonstrate the effectiveness of HDHGR, which\nbrings at most more than 10% relative gain.\n","authors":["Jiayan Guo","Lun Du","Wendong Bi","Qiang Fu","Xiaojun Ma","Xu Chen","Shi Han","Dongmei Zhang","Yan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.06299v2.pdf","comment":"Accepted by WWW 2023"},{"id":"http://arxiv.org/abs/2302.12416v1","updated":"2023-02-24T02:44:39Z","published":"2023-02-24T02:44:39Z","title":"A Convolutional Vision Transformer for Semantic Segmentation of\n  Side-Scan Sonar Data","summary":"  Distinguishing among different marine benthic habitat characteristics is of\nkey importance in a wide set of seabed operations ranging from installations of\noil rigs to laying networks of cables and monitoring the impact of humans on\nmarine ecosystems. The Side-Scan Sonar (SSS) is a widely used imaging sensor in\nthis regard. It produces high-resolution seafloor maps by logging the\nintensities of sound waves reflected back from the seafloor. In this work, we\nleverage these acoustic intensity maps to produce pixel-wise categorization of\ndifferent seafloor types. We propose a novel architecture adapted from the\nVision Transformer (ViT) in an encoder-decoder framework. Further, in doing so,\nthe applicability of ViTs is evaluated on smaller datasets. To overcome the\nlack of CNN-like inductive biases, thereby making ViTs more conducive to\napplications in low data regimes, we propose a novel feature extraction module\nto replace the Multi-layer Perceptron (MLP) block within transformer layers and\na novel module to extract multiscale patch embeddings. A lightweight decoder is\nalso proposed to complement this design in order to further boost multiscale\nfeature extraction. With the modified architecture, we achieve state-of-the-art\nresults and also meet real-time computational requirements. We make our code\navailable at ~\\url{https://github.com/hayatrajani/s3seg-vit\n","authors":["Hayat Rajani","Nuno Gracias","Rafael Garcia"],"pdf_url":"https://arxiv.org/pdf/2302.12416v1.pdf","comment":"Submitted to Ocean Engineering special issue \"Autonomous Marine\n  Robotics Operations\""},{"id":"http://arxiv.org/abs/2302.12407v1","updated":"2023-02-24T02:15:42Z","published":"2023-02-24T02:15:42Z","title":"HyperAttack: Multi-Gradient-Guided White-box Adversarial Structure\n  Attack of Hypergraph Neural Networks","summary":"  Hypergraph neural networks (HGNN) have shown superior performance in various\ndeep learning tasks, leveraging the high-order representation ability to\nformulate complex correlations among data by connecting two or more nodes\nthrough hyperedge modeling. Despite the well-studied adversarial attacks on\nGraph Neural Networks (GNN), there is few study on adversarial attacks against\nHGNN, which leads to a threat to the safety of HGNN applications. In this\npaper, we introduce HyperAttack, the first white-box adversarial attack\nframework against hypergraph neural networks. HyperAttack conducts a white-box\nstructure attack by perturbing hyperedge link status towards the target node\nwith the guidance of both gradients and integrated gradients. We evaluate\nHyperAttack on the widely-used Cora and PubMed datasets and three hypergraph\nneural networks with typical hypergraph modeling techniques. Compared to\nstate-of-the-art white-box structural attack methods for GNN, HyperAttack\nachieves a 10-20X improvement in time efficiency while also increasing attack\nsuccess rates by 1.3%-3.7%. The results show that HyperAttack can achieve\nefficient adversarial attacks that balance effectiveness and time costs.\n","authors":["Chao Hu","Ruishi Yu","Binqi Zeng","Yu Zhan","Ying Fu","Quan Zhang","Rongkai Liu","Heyuan Shi"],"pdf_url":"https://arxiv.org/pdf/2302.12407v1.pdf","comment":"10+2pages,9figures"},{"id":"http://arxiv.org/abs/2302.12403v1","updated":"2023-02-24T02:09:33Z","published":"2023-02-24T02:09:33Z","title":"Prioritized Trace Selection: Towards High-Performance DRL-based Network\n  Controllers","summary":"  Deep Reinforcement Learning (DRL) based controllers offer high performance in\na variety of network environments. However, simulator-based training of DRL\ncontrollers using highly skewed datasets of real-world traces often results in\npoor performance in the wild. In this paper, we put forward a generalizable\nsolution for training high-performance DRL controllers in simulators --\nPrioritized Trace Selection (PTS). PTS employs an automated three-stage\nprocess. First, we identify critical features that determine trace behavior.\nSecond, we classify the traces into clusters. Finally, we dynamically identify\nand prioritize the salient clusters during training.\n  PTS does not require any changes to the DRL workflow. It can work across both\non-policy and off-policy DRL algorithms. We use Adaptive Bit Rate selection and\nCongestion Control as representative applications to show that PTS offers\nbetter performance in simulation and real-world, across multiple controllers\nand DRL algorithms. Our novel ABR controller, Gelato, trained with PTS\noutperforms state-of-the-art controllers on the real-world live-streaming\nplatform, Puffer, reducing stalls by 59% and significantly improving average\nvideo quality.\n","authors":["Sagar Patel","Junyang Zhang","Sangeetha Abdu Jyothi","Nina Narodytska"],"pdf_url":"https://arxiv.org/pdf/2302.12403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12400v1","updated":"2023-02-24T02:03:41Z","published":"2023-02-24T02:03:41Z","title":"Towards Stable Test-Time Adaptation in Dynamic Wild World","summary":"  Test-time adaptation (TTA) has shown to be effective at tackling distribution\nshifts between training and testing data by adapting a given model on test\nsamples. However, the online model updating of TTA may be unstable and this is\noften a key obstacle preventing existing TTA methods from being deployed in the\nreal world. Specifically, TTA may fail to improve or even harm the model\nperformance when test data have: 1) mixed distribution shifts, 2) small batch\nsizes, and 3) online imbalanced label distribution shifts, which are quite\ncommon in practice. In this paper, we investigate the unstable reasons and find\nthat the batch norm layer is a crucial factor hindering TTA stability.\nConversely, TTA can perform more stably with batch-agnostic norm layers, \\ie,\ngroup or layer norm. However, we observe that TTA with group and layer norms\ndoes not always succeed and still suffers many failure cases. By digging into\nthe failure cases, we find that certain noisy test samples with large gradients\nmay disturb the model adaption and result in collapsed trivial solutions, \\ie,\nassigning the same class label for all samples. To address the above collapse\nissue, we propose a sharpness-aware and reliable entropy minimization method,\ncalled SAR, for further stabilizing TTA from two aspects: 1) remove partial\nnoisy samples with large gradients, 2) encourage model weights to go to a flat\nminimum so that the model is robust to the remaining noisy samples. Promising\nresults demonstrate that SAR performs more stably over prior methods and is\ncomputationally efficient under the above wild test scenarios.\n","authors":["Shuaicheng Niu","Jiaxiang Wu","Yifan Zhang","Zhiquan Wen","Yaofo Chen","Peilin Zhao","Mingkui Tan"],"pdf_url":"https://arxiv.org/pdf/2302.12400v1.pdf","comment":"accepted by International Conference on Learning Representations\n  (ICLR) 2023 as Notable-Top-5%; 27 pages, 10 figures, 18 tables"},{"id":"http://arxiv.org/abs/2301.05974v2","updated":"2023-02-24T01:52:25Z","published":"2023-01-14T21:02:58Z","title":"Compress Then Test: Powerful Kernel Testing in Near-linear Time","summary":"  Kernel two-sample testing provides a powerful framework for distinguishing\nany pair of distributions based on $n$ sample points. However, existing kernel\ntests either run in $n^2$ time or sacrifice undue power to improve runtime. To\naddress these shortcomings, we introduce Compress Then Test (CTT), a new\nframework for high-powered kernel testing based on sample compression. CTT\ncheaply approximates an expensive test by compressing each $n$ point sample\ninto a small but provably high-fidelity coreset. For standard kernels and\nsubexponential distributions, CTT inherits the statistical behavior of a\nquadratic-time test -- recovering the same optimal detection boundary -- while\nrunning in near-linear time. We couple these advances with cheaper permutation\ntesting, justified by new power analyses; improved time-vs.-quality guarantees\nfor low-rank approximation; and a fast aggregation procedure for identifying\nespecially discriminating kernels. In our experiments with real and simulated\ndata, CTT and its extensions provide 20--200x speed-ups over state-of-the-art\napproximate MMD tests with no loss of power.\n","authors":["Carles Domingo-Enrich","Raaz Dwivedi","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2301.05974v2.pdf","comment":"Accepted as a paper at AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.12392v1","updated":"2023-02-24T01:46:13Z","published":"2023-02-24T01:46:13Z","title":"Better Predict the Dynamic of Geometry of In-Pit Stockpiles Using\n  Geospatial Data and Polygon Models","summary":"  Modelling stockpile is a key factor of a project economic and operation in\nmining, because not all the mined ores are not able to mill for many reasons.\nFurther, the financial value of the ore in the stockpile needs to be reflected\non the balance sheet. Therefore, automatically tracking the frontiers of the\nstockpile facilitates the mine scheduling engineers to calculate the tonnage of\nthe ore remaining in the stockpile. This paper suggests how the dynamic of\nstockpile shape changes caused by dumping and reclaiming operations can be\ninferred using polygon models. The presented work also demonstrates how the\ngeometry of stockpiles can be inferred in the absence of reclaimed bucket\ninformation, in which case the reclaim polygons are established using the\ndiggers GPS positional data at the time of truck loading. This work further\ncompares two polygon models for creating 2D shapes.\n","authors":["Mehala. Balamurali","Konstantin M. Seiler"],"pdf_url":"https://arxiv.org/pdf/2302.12392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12391v1","updated":"2023-02-24T01:43:17Z","published":"2023-02-24T01:43:17Z","title":"PITS: Variational Pitch Inference without Fundamental Frequency for\n  End-to-End Pitch-controllable TTS","summary":"  Previous pitch-controllable text-to-speech (TTS) models rely on directly\nmodeling fundamental frequency, leading to low variance in synthesized speech.\nTo address this issue, we propose PITS, an end-to-end pitch-controllable TTS\nmodel that utilizes variational inference to model pitch. Based on VITS, PITS\nincorporates the Yingram encoder, the Yingram decoder, and adversarial training\nof pitch-shifted synthesis to achieve pitch-controllability. Experiments\ndemonstrate that PITS generates high-quality speech that is indistinguishable\nfrom ground truth speech and has high pitch-controllability without quality\ndegradation. Code and audio samples will be available at\nhttps://github.com/anonymous-pits/pits.\n","authors":["Junhyeok Lee","Wonbin Jung","Hyunjae Cho","Jaeyeon Kim"],"pdf_url":"https://arxiv.org/pdf/2302.12391v1.pdf","comment":"5 pages, preprint"},{"id":"http://arxiv.org/abs/2209.14927v4","updated":"2023-02-24T01:41:32Z","published":"2022-09-29T16:45:43Z","title":"Spotlight: Mobile UI Understanding using Vision-Language Models with a\n  Focus","summary":"  Mobile UI understanding is important for enabling various interaction tasks\nsuch as UI automation and accessibility. Previous mobile UI modeling often\ndepends on the view hierarchy information of a screen, which directly provides\nthe structural data of the UI, with the hope to bypass challenging tasks of\nvisual modeling from screen pixels. However, view hierarchies are not always\navailable, and are often corrupted with missing object descriptions or\nmisaligned structure information. As a result, despite the use of view\nhierarchies could offer short-term gains, it may ultimately hinder the\napplicability and performance of the model. In this paper, we propose\nSpotlight, a vision-only approach for mobile UI understanding. Specifically, we\nenhance a vision-language model that only takes the screenshot of the UI and a\nregion of interest on the screen -- the focus -- as the input. This general\narchitecture of Spotlight is easily scalable and capable of performing a range\nof UI modeling tasks. Our experiments show that our model establishes SoTA\nresults on several representative UI tasks and outperforms previous methods\nthat use both screenshots and view hierarchies as inputs. Furthermore, we\nexplore multi-task learning and few-shot prompting capacities of the proposed\nmodels, demonstrating promising results in the multi-task learning direction.\n","authors":["Gang Li","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2209.14927v4.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2206.03597v3","updated":"2023-02-24T01:39:54Z","published":"2022-06-07T21:30:58Z","title":"Meta-Learning Parameterized Skills","summary":"  We propose a novel parameterized skill-learning algorithm that aims to learn\ntransferable parameterized skills and synthesize them into a new action space\nthat supports efficient learning in long-horizon tasks. We propose to leverage\noff-policy Meta-RL combined with a trajectory-centric smoothness term to learn\na set of parameterized skills. Our agent can use these learned skills to\nconstruct a three-level hierarchical framework that models a\nTemporally-extended Parameterized Action Markov Decision Process. We\nempirically demonstrate that the proposed algorithms enable an agent to solve a\nset of difficult long-horizon (obstacle-course and robot manipulation) tasks.\n","authors":["Haotian Fu","Shangqun Yu","Saket Tiwari","Michael Littman","George Konidaris"],"pdf_url":"https://arxiv.org/pdf/2206.03597v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12388v1","updated":"2023-02-24T01:29:21Z","published":"2023-02-24T01:29:21Z","title":"TrafFormer: A Transformer Model for Prediction Long-term Traffic","summary":"  Traffic prediction is a flourishing research field due to its importance in\nhuman mobility in the urban space. Despite this, existing studies only focus on\nshort-term prediction of up to few hours in advance, with most being up to one\nhour only. Long-term traffic prediction can enable more comprehensive,\ninformed, and proactive measures against traffic congestion and is therefore an\nimportant task to explore. In this paper, we explore the task of long-term\ntraffic prediction; where we predict traffic up to 24 hours in advance. We note\nthe weaknesses of existing models--which are based on recurrent structures--for\nlong-term traffic prediction and propose a modified Transformer model\n``TrafFormer\". Experiments comparing our model with existing hybrid neural\nnetwork models show the superiority of our model.\n","authors":["David Alexander Tedjopurnomo","Farhana M. Choudhury","A. K. Qin"],"pdf_url":"https://arxiv.org/pdf/2302.12388v1.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.10651v3","updated":"2023-02-24T01:05:59Z","published":"2023-01-25T15:48:00Z","title":"Overcoming Prior Misspecification in Online Learning to Rank","summary":"  The recent literature on online learning to rank (LTR) has established the\nutility of prior knowledge to Bayesian ranking bandit algorithms. However, a\nmajor limitation of existing work is the requirement for the prior used by the\nalgorithm to match the true prior. In this paper, we propose and analyze\nadaptive algorithms that address this issue and additionally extend these\nresults to the linear and generalized linear models. We also consider scalar\nrelevance feedback on top of click feedback. Moreover, we demonstrate the\nefficacy of our algorithms using both synthetic and real-world experiments.\n","authors":["Javad Azizi","Ofer Meshi","Masrour Zoghi","Maryam Karimzadehgan"],"pdf_url":"https://arxiv.org/pdf/2301.10651v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.01714v6","updated":"2023-02-24T01:05:03Z","published":"2021-04-04T23:49:15Z","title":"Detecting of multi-modality in probabilistic regression models","summary":"  This paper focuses on building of models of stochastic systems with aleatoric\nuncertainty. The nature of the considered systems is such that the identical\ninputs can result in different outputs, i.e. the output is a random variable.\nThe suggested in this paper algorithm targets an identification of multi-modal\nproperties of the output distributions, even when they depend on the inputs and\nvary significantly throughout the dataset. This ability of the suggested method\nto recognise complex and not only bell-shaped distributions follows from its\nconstruction and is backed up by provided experimental results. In general, the\nsuggested method belongs to the category of boosted ensemble learning\ntechniques, where the single deterministic component can be an\narbitrarily-chosen regression model. The algorithm does not require any special\nproperties of the chosen regression model, other than having descriptive\ncapabilities with some expected accuracy for the training data type.\n","authors":["Andrew Polar","Michael Poluektov"],"pdf_url":"https://arxiv.org/pdf/2104.01714v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12383v1","updated":"2023-02-24T01:03:56Z","published":"2023-02-24T01:03:56Z","title":"Generalization Analysis for Contrastive Representation Learning","summary":"  Recently, contrastive learning has found impressive success in advancing the\nstate of the art in solving various machine learning tasks. However, the\nexisting generalization analysis is very limited or even not meaningful. In\nparticular, the existing generalization error bounds depend linearly on the\nnumber $k$ of negative examples while it was widely shown in practice that\nchoosing a large $k$ is necessary to guarantee good generalization of\ncontrastive learning in downstream tasks. In this paper, we establish novel\ngeneralization bounds for contrastive learning which do not depend on $k$, up\nto logarithmic terms. Our analysis uses structural results on empirical\ncovering numbers and Rademacher complexities to exploit the Lipschitz\ncontinuity of loss functions. For self-bounding Lipschitz loss functions, we\nfurther improve our results by developing optimistic bounds which imply fast\nrates in a low noise condition. We apply our results to learning with both\nlinear representation and nonlinear representation by deep neural networks, for\nboth of which we derive Rademacher complexity bounds to get improved\ngeneralization bounds.\n","authors":["Yunwen Lei","Tianbao Yang","Yiming Ying","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.12383v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12378v1","updated":"2023-02-24T00:49:43Z","published":"2023-02-24T00:49:43Z","title":"Cosmic Microwave Background Recovery: A Graph-Based Bayesian\n  Convolutional Network Approach","summary":"  The cosmic microwave background (CMB) is a significant source of knowledge\nabout the origin and evolution of our universe. However, observations of the\nCMB are contaminated by foreground emissions, obscuring the CMB signal and\nreducing its efficacy in constraining cosmological parameters. We employ deep\nlearning as a data-driven approach to CMB cleaning from multi-frequency\nfull-sky maps. In particular, we develop a graph-based Bayesian convolutional\nneural network based on the U-Net architecture that predicts cleaned CMB with\npixel-wise uncertainty estimates. We demonstrate the potential of this\ntechnique on realistic simulated data based on the Planck mission. We show that\nour model accurately recovers the cleaned CMB sky map and resulting angular\npower spectrum while identifying regions of uncertainty. Finally, we discuss\nthe current challenges and the path forward for deploying our model for CMB\nrecovery on real observations.\n","authors":["Jadie Adams","Steven Lu","Krzysztof M. Gorski","Graca Rocha","Kiri L. Wagstaff"],"pdf_url":"https://arxiv.org/pdf/2302.12378v1.pdf","comment":"Published at the Thirty-fifth Annual Conference on Innovative\n  Applications of Artificial Intelligence (IAAI-23). 7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.12372v1","updated":"2023-02-24T00:24:17Z","published":"2023-02-24T00:24:17Z","title":"Keyword Decisions in Sponsored Search Advertising: A Literature Review\n  and Research Agenda","summary":"  In sponsored search advertising (SSA), keywords serve as the basic unit of\nbusiness model, linking three stakeholders: consumers, advertisers and search\nengines. This paper presents an overarching framework for keyword decisions\nthat highlights the touchpoints in search advertising management, including\nfour levels of keyword decisions, i.e., domain-specific keyword pool\ngeneration, keyword targeting, keyword assignment and grouping, and keyword\nadjustment. Using this framework, we review the state-of-the-art research\nliterature on keyword decisions with respect to techniques, input features and\nevaluation metrics. Finally, we discuss evolving issues and identify potential\ngaps that exist in the literature and outline novel research perspectives for\nfuture exploration.\n","authors":["Yanwu Yang","Huiran Li"],"pdf_url":"https://arxiv.org/pdf/2302.12372v1.pdf","comment":"88 pages, 3 figures, 15 tables"},{"id":"http://arxiv.org/abs/2109.14181v2","updated":"2023-02-24T00:03:36Z","published":"2021-09-29T03:53:15Z","title":"Anderson Acceleration as a Krylov Method with Application to Asymptotic\n  Convergence Analysis","summary":"  Anderson acceleration (AA) is widely used for accelerating the convergence of\nnonlinear fixed-point methods $x_{k+1}=q(x_{k})$, $x_k \\in \\mathbb{R}^n$, but\nlittle is known about how to quantify the convergence acceleration provided by\nAA. As a roadway towards gaining more understanding of convergence acceleration\nby AA, we study AA($m$), i.e., Anderson acceleration with finite window size\n$m$, applied to the case of linear fixed-point iterations $x_{k+1}=M x_{k}+b$.\nWe write AA($m$) as a Krylov method with polynomial residual update formulas,\nand derive recurrence relations for the AA($m$) polynomials. Writing AA($m$) as\na Krylov method immediately implies that $k$ iterations of AA($m$) cannot\nproduce a smaller residual than $k$ iterations of GMRES without restart (but\nwithout implying anything about the relative convergence speed of (windowed)\nAA($m$) versus restarted GMRES($m$)). We find that the AA($m$) residual\npolynomials observe a periodic memory effect where increasing powers of the\nerror iteration matrix $M$ act on the initial residual as the iteration number\nincreases. We derive several further results based on these polynomial residual\nupdate formulas, including orthogonality relations, a lower bound on the AA(1)\nacceleration coefficient $\\beta_k$, and explicit nonlinear recursions for the\nAA(1) residuals and residual polynomials that do not include the acceleration\ncoefficient $\\beta_k$. Using these recurrence relations we also derive new\nresidual convergence bounds for AA(1) in the linear case, demonstrating how the\nper-iteration residual reduction $||r_{k+1}||/||r_{k}||$ depends strongly on\nthe residual reduction in the previous iteration and on the angle between the\nprior residual vectors $r_k$ and $r_{k-1}$. We apply these results to study the\ninfluence of the initial guess on the asymptotic convergence factor of AA(1),\nand to study AA(1) residual convergence patterns.\n","authors":["Hans De Sterck","Yunhui He","Oliver A. Krzysik"],"pdf_url":"https://arxiv.org/pdf/2109.14181v2.pdf","comment":"this version resubmitted to journal on Nov 22, 2022"},{"id":"http://arxiv.org/abs/2302.12370v1","updated":"2023-02-24T00:02:24Z","published":"2023-02-24T00:02:24Z","title":"Best-of-Three-Worlds Linear Bandit Algorithm with Variance-Adaptive\n  Regret Bounds","summary":"  This paper proposes a linear bandit algorithm that is adaptive to\nenvironments at two different levels of hierarchy. At the higher level, the\nproposed algorithm adapts to a variety of types of environments. More\nprecisely, it achieves best-of-three-worlds regret bounds, i.e., of\n${O}(\\sqrt{T \\log T})$ for adversarial environments and of $O(\\frac{\\log\nT}{\\Delta_{\\min}} + \\sqrt{\\frac{C \\log T}{\\Delta_{\\min}}})$ for stochastic\nenvironments with adversarial corruptions, where $T$, $\\Delta_{\\min}$, and $C$\ndenote, respectively, the time horizon, the minimum sub-optimality gap, and the\ntotal amount of the corruption. Note that polynomial factors in the\ndimensionality are omitted here. At the lower level, in each of the adversarial\nand stochastic regimes, the proposed algorithm adapts to certain environmental\ncharacteristics, thereby performing better. The proposed algorithm has\ndata-dependent regret bounds that depend on all of the cumulative loss for the\noptimal action, the total quadratic variation, and the path-length of the loss\nvector sequence. In addition, for stochastic environments, the proposed\nalgorithm has a variance-adaptive regret bound of $O(\\frac{\\sigma^2 \\log\nT}{\\Delta_{\\min}})$ as well, where $\\sigma^2$ denotes the maximum variance of\nthe feedback loss. The proposed algorithm is based on the SCRiBLe algorithm. By\nincorporating into this a new technique we call scaled-up sampling, we obtain\nhigh-level adaptability, and by incorporating the technique of optimistic\nonline learning, we obtain low-level adaptability.\n","authors":["Shinji Ito","Kei Takemura"],"pdf_url":"https://arxiv.org/pdf/2302.12370v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2212.10988v3","updated":"2023-02-24T08:49:57Z","published":"2022-12-21T12:50:31Z","title":"Attention-Aware Anime Line Drawing Colorization","summary":"  Automatic colorization of anime line drawing has attracted much attention in\nrecent years since it can substantially benefit the animation industry.\nUser-hint based methods are the mainstream approach for line drawing\ncolorization, while reference-based methods offer a more intuitive approach.\nNevertheless, although reference-based methods can improve feature aggregation\nof the reference image and the line drawing, the colorization results are not\ncompelling in terms of color consistency or semantic correspondence. In this\npaper, we introduce an attention-based model for anime line drawing\ncolorization, in which a channel-wise and spatial-wise Convolutional Attention\nmodule is used to improve the ability of the encoder for feature extraction and\nkey area perception, and a Stop-Gradient Attention module with cross-attention\nand self-attention is used to tackle the cross-domain long-range dependency\nproblem. Extensive experiments show that our method outperforms other SOTA\nmethods, with more accurate line structure and semantic color information.\n","authors":["Yu Cao","Hao Tian","P. Y. Mok"],"pdf_url":"https://arxiv.org/pdf/2212.10988v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12444v2","updated":"2023-02-24T02:53:39Z","published":"2022-10-22T13:23:02Z","title":"Weakly-Supervised Temporal Article Grounding","summary":"  Given a long untrimmed video and natural language queries, video grounding\n(VG) aims to temporally localize the semantically-aligned video segments.\nAlmost all existing VG work holds two simple but unrealistic assumptions: 1)\nAll query sentences can be grounded in the corresponding video. 2) All query\nsentences for the same video are always at the same semantic scale.\nUnfortunately, both assumptions make today's VG models fail to work in\npractice. For example, in real-world multimodal assets (eg, news articles),\nmost of the sentences in the article can not be grounded in their affiliated\nvideos, and they typically have rich hierarchical relations (ie, at different\nsemantic scales). To this end, we propose a new challenging grounding task:\nWeakly-Supervised temporal Article Grounding (WSAG). Specifically, given an\narticle and a relevant video, WSAG aims to localize all ``groundable''\nsentences to the video, and these sentences are possibly at different semantic\nscales. Accordingly, we collect the first WSAG dataset to facilitate this task:\nYouwikiHow, which borrows the inherent multi-scale descriptions in wikiHow\narticles and plentiful YouTube videos. In addition, we propose a simple but\neffective method DualMIL for WSAG, which consists of a two-level MIL loss and a\nsingle-/cross- sentence constraint loss. These training objectives are\ncarefully designed for these relaxed assumptions. Extensive ablations have\nverified the effectiveness of DualMIL.\n","authors":["Long Chen","Yulei Niu","Brian Chen","Xudong Lin","Guangxing Han","Christopher Thomas","Hammad Ayyubi","Heng Ji","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2210.12444v2.pdf","comment":"EMNLP 2022, https://github.com/zjuchenlong/WSAG"},{"id":"http://arxiv.org/abs/2302.12393v1","updated":"2023-02-24T01:47:13Z","published":"2023-02-24T01:47:13Z","title":"Blind Omnidirectional Image Quality Assessment: Integrating Local\n  Statistics and Global Semantics","summary":"  Omnidirectional image quality assessment (OIQA) aims to predict the\nperceptual quality of omnidirectional images that cover the whole\n180$\\times$360$^{\\circ}$ viewing range of the visual environment. Here we\npropose a blind/no-reference OIQA method named S$^2$ that bridges the gap\nbetween low-level statistics and high-level semantics of omnidirectional\nimages. Specifically, statistic and semantic features are extracted in separate\npaths from multiple local viewports and the hallucinated global omnidirectional\nimage, respectively. A quality regression along with a weighting process is\nthen followed that maps the extracted quality-aware features to a perceptual\nquality prediction. Experimental results demonstrate that the proposed S$^2$\nmethod offers highly competitive performance against state-of-the-art methods.\n","authors":["Wei Zhou","Zhou Wang"],"pdf_url":"https://arxiv.org/pdf/2302.12393v1.pdf","comment":null}]},"2023-02-27T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.14045v1","updated":"2023-02-27T18:55:27Z","published":"2023-02-27T18:55:27Z","title":"Language Is Not All You Need: Aligning Perception with Language Models","summary":"  A big convergence of language, multimodal perception, action, and world\nmodeling is a key step toward artificial general intelligence. In this work, we\nintroduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive\ngeneral modalities, learn in context (i.e., few-shot), and follow instructions\n(i.e., zero-shot). Specifically, we train Kosmos-1 from scratch on web-scale\nmultimodal corpora, including arbitrarily interleaved text and images,\nimage-caption pairs, and text data. We evaluate various settings, including\nzero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range\nof tasks without any gradient updates or finetuning. Experimental results show\nthat Kosmos-1 achieves impressive performance on (i) language understanding,\ngeneration, and even OCR-free NLP (directly fed with document images), (ii)\nperception-language tasks, including multimodal dialogue, image captioning,\nvisual question answering, and (iii) vision tasks, such as image recognition\nwith descriptions (specifying classification via text instructions). We also\nshow that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge\nfrom language to multimodal, and from multimodal to language. In addition, we\nintroduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning\ncapability of MLLMs.\n","authors":["Shaohan Huang","Li Dong","Wenhui Wang","Yaru Hao","Saksham Singhal","Shuming Ma","Tengchao Lv","Lei Cui","Owais Khan Mohammed","Qiang Liu","Kriti Aggarwal","Zewen Chi","Johan Bjorck","Vishrav Chaudhary","Subhojit Som","Xia Song","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2302.14045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14036v1","updated":"2023-02-27T18:47:55Z","published":"2023-02-27T18:47:55Z","title":"Text-only domain adaptation for end-to-end ASR using integrated\n  text-to-mel-spectrogram generator","summary":"  We propose an end-to-end ASR system that can be trained on transcribed speech\ndata, text data, or a mixture of both. For text-only training, our extended ASR\nmodel uses an integrated auxiliary TTS block that creates mel spectrograms from\nthe text. This block contains a conventional non-autoregressive\ntext-to-mel-spectrogram generator augmented with a GAN enhancer to improve the\nspectrogram quality. The proposed system can improve the accuracy of the ASR\nmodel on a new domain by using text-only data, and allows to significantly\nsurpass conventional audio-text training by using large text corpora.\n","authors":["Vladimir Bataev","Roman Korostik","Evgeny Shabalin","Vitaly Lavrukhin","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2302.14036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14035v1","updated":"2023-02-27T18:45:18Z","published":"2023-02-27T18:45:18Z","title":"The ROOTS Search Tool: Data Transparency for LLMs","summary":"  ROOTS is a 1.6TB multilingual text corpus developed for the training of\nBLOOM, currently the largest language model explicitly accompanied by\ncommensurate data governance efforts. In continuation of these efforts, we\npresent the ROOTS Search Tool: a search engine over the entire ROOTS corpus\noffering both fuzzy and exact search capabilities. ROOTS is the largest corpus\nto date that can be investigated this way. The ROOTS Search Tool is\nopen-sourced and available on Hugging Face Spaces. We describe our\nimplementation and the possible use cases of our tool.\n","authors":["Aleksandra Piktus","Christopher Akiki","Paulo Villegas","Hugo Laurençon","Gérard Dupont","Alexandra Sasha Luccioni","Yacine Jernite","Anna Rogers"],"pdf_url":"https://arxiv.org/pdf/2302.14035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14030v1","updated":"2023-02-27T18:41:48Z","published":"2023-02-27T18:41:48Z","title":"Multimodal Speech Recognition for Language-Guided Embodied Agents","summary":"  Benchmarks for language-guided embodied agents typically assume text-based\ninstructions, but deployed agents will encounter spoken instructions. While\nAutomatic Speech Recognition (ASR) models can bridge the input gap, erroneous\nASR transcripts can hurt the agents' ability to complete tasks. In this work,\nwe propose training a multimodal ASR model to reduce errors in transcribing\nspoken instructions by considering the accompanying visual context. We train\nour model on a dataset of spoken instructions, synthesized from the ALFRED task\ncompletion dataset, where we simulate acoustic noise by systematically masking\nspoken words. We find that utilizing visual observations facilitates masked\nword recovery, with multimodal ASR models recovering up to 30% more masked\nwords than unimodal baselines. We also find that a text-trained embodied agent\nsuccessfully completes tasks more often by following transcribed instructions\nfrom multimodal ASR models.\n","authors":["Allen Chang","Xiaoyuan Zhu","Aarav Monga","Seoho Ahn","Tejas Srinivasan","Jesse Thomason"],"pdf_url":"https://arxiv.org/pdf/2302.14030v1.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.14022v1","updated":"2023-02-27T18:27:42Z","published":"2023-02-27T18:27:42Z","title":"Diacritic Recognition Performance in Arabic ASR","summary":"  We present an analysis of diacritic recognition performance in Arabic\nAutomatic Speech Recognition (ASR) systems. As most existing Arabic speech\ncorpora do not contain all diacritical marks, which represent short vowels and\nother phonetic information in Arabic script, current state-of-the-art ASR\nmodels do not produce full diacritization in their output. Automatic text-based\ndiacritization has previously been employed both as a pre-processing step to\ntrain diacritized ASR, or as a post-processing step to diacritize the resulting\nASR hypotheses. It is generally believed that input diacritization degrades ASR\nperformance, but no systematic evaluation of ASR diacritization performance,\nindependent of ASR performance, has been conducted to date. In this paper, we\nattempt to experimentally clarify whether input diacritiztation indeed degrades\nASR quality, and to compare the diacritic recognition performance against\ntext-based diacritization as a post-processing step. We start with pre-trained\nArabic ASR models and fine-tune them on transcribed speech data with different\ndiacritization conditions: manual, automatic, and no diacritization. We isolate\ndiacritic recognition performance from the overall ASR performance using\ncoverage and precision metrics. We find that ASR diacritization significantly\noutperforms text-based diacritization in post-processing, particularly when the\nASR model is fine-tuned with manually diacritized transcripts.\n","authors":["Hanan Aldarmaki","Ahmad Ghannam"],"pdf_url":"https://arxiv.org/pdf/2302.14022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14021v1","updated":"2023-02-27T18:25:19Z","published":"2023-02-27T18:25:19Z","title":"Quantifying Valence and Arousal in Text with Multilingual Pre-trained\n  Transformers","summary":"  The analysis of emotions expressed in text has numerous applications. In\ncontrast to categorical analysis, focused on classifying emotions according to\na pre-defined set of common classes, dimensional approaches can offer a more\nnuanced way to distinguish between different emotions. Still, dimensional\nmethods have been less studied in the literature. Considering a valence-arousal\ndimensional space, this work assesses the use of pre-trained Transformers to\npredict these two dimensions on a continuous scale, with input texts from\nmultiple languages and domains. We specifically combined multiple annotated\ndatasets from previous studies, corresponding to either emotional lexica or\nshort text documents, and evaluated models of multiple sizes and trained under\ndifferent settings. Our results show that model size can have a significant\nimpact on the quality of predictions, and that by fine-tuning a large model we\ncan confidently predict valence and arousal in multiple languages. We make\navailable the code, models, and supporting data.\n","authors":["Gonçalo Azevedo Mendes","Bruno Martins"],"pdf_url":"https://arxiv.org/pdf/2302.14021v1.pdf","comment":"Accepted at the 45th European Conference on Information Retrieval\n  (ECIR'23), full paper track"},{"id":"http://arxiv.org/abs/2302.14017v1","updated":"2023-02-27T18:18:13Z","published":"2023-02-27T18:18:13Z","title":"Full Stack Optimization of Transformer Inference: a Survey","summary":"  Recent advances in state-of-the-art DNN architecture design have been moving\ntoward Transformer models. These models achieve superior accuracy across a wide\nrange of applications. This trend has been consistent over the past several\nyears since Transformer models were originally introduced. However, the amount\nof compute and bandwidth required for inference of recent Transformer models is\ngrowing at a significant rate, and this has made their deployment in\nlatency-sensitive applications challenging. As such, there has been an\nincreased focus on making Transformer models more efficient, with methods that\nrange from changing the architecture design, all the way to developing\ndedicated domain-specific accelerators. In this work, we survey different\napproaches for efficient Transformer inference, including: (i) analysis and\nprofiling of the bottlenecks in existing Transformer architectures and their\nsimilarities and differences with previous convolutional models; (ii)\nimplications of Transformer architecture on hardware, including the impact of\nnon-linear operations such as Layer Normalization, Softmax, and GELU, as well\nas linear operations, on hardware design; (iii) approaches for optimizing a\nfixed Transformer architecture; (iv) challenges in finding the right mapping\nand scheduling of operations for Transformer models; and (v) approaches for\noptimizing Transformer models by adapting the architecture using neural\narchitecture search. Finally, we perform a case study by applying the surveyed\noptimizations on Gemmini, the open-source, full-stack DNN accelerator\ngenerator, and we show how each of these approaches can yield improvements,\ncompared to previous benchmark results on Gemmini. Among other things, we find\nthat a full-stack co-design approach with the aforementioned methods can result\nin up to 88.7x speedup with a minimal performance degradation for Transformer\ninference.\n","authors":["Sehoon Kim","Coleman Hooper","Thanakul Wattanawong","Minwoo Kang","Ruohan Yan","Hasan Genc","Grace Dinh","Qijing Huang","Kurt Keutzer","Michael W. Mahoney","Yakun Sophia Shao","Amir Gholami"],"pdf_url":"https://arxiv.org/pdf/2302.14017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14003v1","updated":"2023-02-27T17:47:53Z","published":"2023-02-27T17:47:53Z","title":"Systematic Rectification of Language Models via Dead-end Analysis","summary":"  With adversarial or otherwise normal prompts, existing large language models\n(LLM) can be pushed to generate toxic discourses. One way to reduce the risk of\nLLMs generating undesired discourses is to alter the training of the LLM. This\ncan be very restrictive due to demanding computation requirements. Other\nmethods rely on rule-based or prompt-based token elimination, which are limited\nas they dismiss future tokens and the overall meaning of the complete\ndiscourse. Here, we center detoxification on the probability that the finished\ndiscourse is ultimately considered toxic. That is, at each point, we advise\nagainst token selections proportional to how likely a finished text from this\npoint will be toxic. To this end, we formally extend the dead-end theory from\nthe recent reinforcement learning (RL) literature to also cover uncertain\noutcomes. Our approach, called rectification, utilizes a separate but\nsignificantly smaller model for detoxification, which can be applied to diverse\nLLMs as long as they share the same vocabulary. Importantly, our method does\nnot require access to the internal representations of the LLM, but only the\ntoken probability distribution at each decoding step. This is crucial as many\nLLMs today are hosted in servers and only accessible through APIs. When applied\nto various LLMs, including GPT-3, our approach significantly improves the\ngenerated discourse compared to the base LLMs and other techniques in terms of\nboth the overall language and detoxification performance.\n","authors":["Meng Cao","Mehdi Fatemi","Jackie Chi Kit Cheung","Samira Shabanian"],"pdf_url":"https://arxiv.org/pdf/2302.14003v1.pdf","comment":"The Eleventh International Conference on Learning Representations,\n  ICLR'23"},{"id":"http://arxiv.org/abs/2302.12829v2","updated":"2023-02-27T17:47:31Z","published":"2023-02-24T18:59:51Z","title":"Improving Massively Multilingual ASR With Auxiliary CTC Objectives","summary":"  Multilingual Automatic Speech Recognition (ASR) models have extended the\nusability of speech technologies to a wide variety of languages. With how many\nlanguages these models have to handle, however, a key to understanding their\nimbalanced performance across different languages is to examine if the model\nactually knows which language it should transcribe. In this paper, we introduce\nour work on improving performance on FLEURS, a 102-language open ASR benchmark,\nby conditioning the entire model on language identity (LID). We investigate\ntechniques inspired from recent Connectionist Temporal Classification (CTC)\nstudies to help the model handle the large number of languages, conditioning on\nthe LID predictions of auxiliary tasks. Our experimental results demonstrate\nthe effectiveness of our technique over standard CTC/Attention-based hybrid\nmodels. Furthermore, our state-of-the-art systems using self-supervised models\nwith the Conformer architecture improve over the results of prior work on\nFLEURS by a relative 28.4% CER. Trained models and reproducible recipes are\navailable at https://github.com/espnet/espnet/tree/master/egs2/fleurs/asr1 .\n","authors":["William Chen","Brian Yan","Jiatong Shi","Yifan Peng","Soumi Maiti","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2302.12829v2.pdf","comment":"5 pages, 1 figure, accepted at ICASSP 2023; fixed typo and URL in\n  abstract"},{"id":"http://arxiv.org/abs/2204.10938v3","updated":"2023-02-27T17:22:15Z","published":"2022-04-22T21:46:52Z","title":"A Multi-level Alignment Training Scheme for Video-and-Language Grounding","summary":"  To solve video-and-language grounding tasks, the key is for the network to\nunderstand the connection between the two modalities. For a pair of video and\nlanguage description, their semantic relation is reflected by their encodings'\nsimilarity. A good multi-modality encoder should be able to well capture both\ninputs' semantics and encode them in the shared feature space where embedding\ndistance gets properly translated into their semantic similarity. In this work,\nwe focused on this semantic connection between video and language, and\ndeveloped a multi-level alignment training scheme to directly shape the\nencoding process. Global and segment levels of video-language alignment pairs\nwere designed, based on the information similarity ranging from high-level\ncontext to fine-grained semantics. The contrastive loss was used to contrast\nthe encodings' similarities between the positive and negative alignment pairs,\nand to ensure the network is trained in such a way that similar information is\nencoded closely in the shared feature space while information of different\nsemantics is kept apart. Our multi-level alignment training can be applied to\nvarious video-and-language grounding tasks. Together with the task-specific\ntraining loss, our framework achieved comparable performance to previous\nstate-of-the-arts on multiple video QA and retrieval datasets.\n","authors":["Yubo Zhang","Feiyang Niu","Qing Ping","Govind Thattai"],"pdf_url":"https://arxiv.org/pdf/2204.10938v3.pdf","comment":"Accepted at ICDM 2022 FOMO-VL workshop"},{"id":"http://arxiv.org/abs/2302.13971v1","updated":"2023-02-27T17:11:15Z","published":"2023-02-27T17:11:15Z","title":"LLaMA: Open and Efficient Foundation Language Models","summary":"  We introduce LLaMA, a collection of foundation language models ranging from\n7B to 65B parameters. We train our models on trillions of tokens, and show that\nit is possible to train state-of-the-art models using publicly available\ndatasets exclusively, without resorting to proprietary and inaccessible\ndatasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks,\nand LLaMA-65B is competitive with the best models, Chinchilla-70B and\nPaLM-540B. We release all our models to the research community.\n","authors":["Hugo Touvron","Thibaut Lavril","Gautier Izacard","Xavier Martinet","Marie-Anne Lachaux","Timothée Lacroix","Baptiste Rozière","Naman Goyal","Eric Hambro","Faisal Azhar","Aurelien Rodriguez","Armand Joulin","Edouard Grave","Guillaume Lample"],"pdf_url":"https://arxiv.org/pdf/2302.13971v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13382v4","updated":"2023-02-27T17:09:15Z","published":"2022-10-24T16:29:55Z","title":"Emergent World Representations: Exploring a Sequence Model Trained on a\n  Synthetic Task","summary":"  Language models show a surprising range of capabilities, but the source of\ntheir apparent competence is unclear. Do these networks just memorize a\ncollection of surface statistics, or do they rely on internal representations\nof the process that generates the sequences they see? We investigate this\nquestion by applying a variant of the GPT model to the task of predicting legal\nmoves in a simple board game, Othello. Although the network has no a priori\nknowledge of the game or its rules, we uncover evidence of an emergent\nnonlinear internal representation of the board state. Interventional\nexperiments indicate this representation can be used to control the output of\nthe network and create \"latent saliency maps\" that can help explain predictions\nin human terms.\n","authors":["Kenneth Li","Aspen K. Hopkins","David Bau","Fernanda Viégas","Hanspeter Pfister","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2210.13382v4.pdf","comment":"ICLR 2023 oral (notable-top-5%):\n  https://openreview.net/forum?id=DeG07_TcZvT ; code:\n  https://github.com/likenneth/othello_world"},{"id":"http://arxiv.org/abs/2302.13959v1","updated":"2023-02-27T17:00:06Z","published":"2023-02-27T17:00:06Z","title":"Make Every Example Count: On Stability and Utility of Self-Influence for\n  Learning from Noisy NLP Datasets","summary":"  Increasingly larger datasets have become a standard ingredient to advancing\nthe state of the art in NLP. However, data quality might have already become\nthe bottleneck to unlock further gains. Given the diversity and the sizes of\nmodern datasets, standard data filtering is not straight-forward to apply,\nbecause of the multifacetedness of the harmful data and elusiveness of\nfiltering rules that would generalize across multiple tasks. We study the\nfitness of task-agnostic self-influence scores of training examples for data\ncleaning, analyze their efficacy in capturing naturally occurring outliers, and\ninvestigate to what extent self-influence based data cleaning can improve\ndownstream performance in machine translation, question answering and text\nclassification, building up on recent approaches to self-influence calculation\nand automated curriculum learning.\n","authors":["Irina Bejan","Artem Sokolov","Katja Filippova"],"pdf_url":"https://arxiv.org/pdf/2302.13959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13942v1","updated":"2023-02-27T16:45:50Z","published":"2023-02-27T16:45:50Z","title":"Inseq: An Interpretability Toolkit for Sequence Generation Models","summary":"  Past work in natural language processing interpretability focused mainly on\npopular classification tasks while largely overlooking generation settings,\npartly due to a lack of dedicated tools. In this work, we introduce Inseq, a\nPython library to democratize access to interpretability analyses of sequence\ngeneration models. Inseq enables intuitive and optimized extraction of models'\ninternal information and feature importance scores for popular decoder-only and\nencoder-decoder Transformers architectures. We showcase its potential by\nadopting it to highlight gender biases in machine translation models and locate\nfactual knowledge inside GPT-2. Thanks to its extensible interface supporting\ncutting-edge techniques such as contrastive feature attribution, Inseq can\ndrive future advances in explainable natural language generation, centralizing\ngood practices and enabling fair and reproducible model evaluations.\n","authors":["Gabriele Sarti","Nils Feldhus","Ludwig Sickert","Oskar van der Wal"],"pdf_url":"https://arxiv.org/pdf/2302.13942v1.pdf","comment":"Library: https://github.com/inseq-team/inseq, Documentation:\n  https://inseq.readthedocs.io, v0.4"},{"id":"http://arxiv.org/abs/2302.13939v1","updated":"2023-02-27T16:43:04Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking neural networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, we successfully implement `SpikeGPT', a generative\nlanguage model with pure binary, event-driven spiking activation units. We\ntrain the proposed model on three model variants: 45M, 125M and 260M\nparameters. To the best of our knowledge, this is 4x larger than any functional\nbackprop-trained SNN to date. We achieve this by modifying the transformer\nblock to replace multi-head self attention to reduce quadratic computational\ncomplexity to linear with increasing sequence length. Input tokens are instead\nstreamed in sequentially to our attention mechanism (as with typical SNNs). Our\npreliminary experiments show that SpikeGPT remains competitive with non-spiking\nmodels on tested benchmarks, while maintaining 5x less energy consumption when\nprocessed on neuromorphic hardware that can leverage sparse, event-driven\nactivations. Our code implementation is available at\nhttps://github.com/ridgerchu/SpikeGPT.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13925v1","updated":"2023-02-27T16:23:11Z","published":"2023-02-27T16:23:11Z","title":"Epicurus at SemEval-2023 Task 4: Improving Prediction of Human Values\n  behind Arguments by Leveraging Their Definitions","summary":"  We describe our experiments for SemEval-2023 Task 4 on the identification of\nhuman values behind arguments (ValueEval). Because human values are subjective\nconcepts which require precise definitions, we hypothesize that incorporating\nthe definitions of human values (in the form of annotation instructions and\nvalidated survey items) during model training can yield better prediction\nperformance. We explore this idea and show that our proposed models perform\nbetter than the challenge organizers' baselines, with improvements in macro F1\nscores of up to 18%.\n","authors":["Christian Fang","Qixiang Fang","Dong Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.13925v1.pdf","comment":"Under review of SemEval23"},{"id":"http://arxiv.org/abs/2302.02676v4","updated":"2023-02-27T16:00:50Z","published":"2023-02-06T10:28:16Z","title":"Chain of Hindsight Aligns Language Models with Feedback","summary":"  Learning from human preferences is important for language models to be\nhelpful and useful for humans, and to align with human and social values. Prior\nwork have achieved remarkable successes by learning from human feedback to\nunderstand and follow instructions. Nonetheless, these methods are either\nfounded on hand-picked model generations that are favored by human annotators,\nrendering them ineffective in terms of data utilization and challenging to\napply in general, or they depend on reward functions and reinforcement\nlearning, which are prone to imperfect reward function and extremely\nchallenging to optimize. In this work, we propose a novel technique, Chain of\nHindsight, that is easy to optimize and can learn from any form of feedback,\nregardless of its polarity. Our idea is inspired by how humans learn from\nextensive feedback presented in the form of languages. We convert all types of\nfeedback into sentences, which are then used to fine-tune the model, allowing\nus to take advantage of the language comprehension capabilities of language\nmodels. We condition the model on a sequence of model generations paired with\nfeedback. By doing so, models are trained to generate outputs based on\nfeedback, and models can learn to identify and correct negative attributes or\nerrors. Applying our method to large language models, we observed that Chain of\nHindsight significantly surpasses previous methods in aligning language models\nwith human preferences. We observed significant improvements on summarization\nand dialogue tasks and our approach is markedly preferred in human evaluations.\n","authors":["Hao Liu","Carmelo Sferrazza","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.02676v4.pdf","comment":"Added more ablation studies and released code"},{"id":"http://arxiv.org/abs/2302.12832v1","updated":"2023-02-27T15:54:57Z","published":"2023-02-27T15:54:57Z","title":"Fluid Transformers and Creative Analogies: Exploring Large Language\n  Models' Capacity for Augmenting Cross-Domain Analogical Creativity","summary":"  Cross-domain analogical reasoning is a core creative ability that can be\nchallenging for humans. Recent work has shown some proofs-of concept of Large\nlanguage Models' (LLMs) ability to generate cross-domain analogies. However,\nthe reliability and potential usefulness of this capacity for augmenting human\ncreative work has received little systematic exploration. In this paper, we\nsystematically explore LLMs capacity to augment cross-domain analogical\nreasoning. Across three studies, we found: 1) LLM-generated cross-domain\nanalogies were frequently judged as helpful in the context of a problem\nreformulation task (median 4 out of 5 helpfulness rating), and frequently (~80%\nof cases) led to observable changes in problem formulations, and 2) there was\nan upper bound of 25% of outputs bring rated as potentially harmful, with a\nmajority due to potentially upsetting content, rather than biased or toxic\ncontent. These results demonstrate the potential utility -- and risks -- of\nLLMs for augmenting cross-domain analogical creativity.\n","authors":["Zijian Ding","Arvind Srinivasan","Stephen MacNeil","Joel Chan"],"pdf_url":"https://arxiv.org/pdf/2302.12832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13906v1","updated":"2023-02-27T15:52:31Z","published":"2023-02-27T15:52:31Z","title":"Argument Mining using BERT and Self-Attention based Embeddings","summary":"  Argument mining automatically identifies and extracts the structure of\ninference and reasoning conveyed in natural language arguments. To the best of\nour knowledge, most of the state-of-the-art works in this field have focused on\nusing tree-like structures and linguistic modeling. But, these approaches are\nnot able to model more complex structures which are often found in online\nforums and real world argumentation structures. In this paper, a novel\nmethodology for argument mining is proposed which employs attention-based\nembeddings for link prediction to model the causational hierarchies in typical\nargument structures prevalent in online discourse.\n","authors":["Pranjal Srivastava","Pranav Bhatnagar","Anurag Goel"],"pdf_url":"https://arxiv.org/pdf/2302.13906v1.pdf","comment":"2022 4th International Conference on Advances in Computing,\n  Communication Control and Networking (ICAC3N)"},{"id":"http://arxiv.org/abs/2301.04098v2","updated":"2023-02-27T15:49:16Z","published":"2023-01-10T17:43:03Z","title":"Investigating Conversational Search Behavior For Domain Exploration","summary":"  Conversational search has evolved as a new information retrieval paradigm,\nmarking a shift from traditional search systems towards interactive dialogues\nwith intelligent search agents. This change especially affects exploratory\ninformation-seeking contexts, where conversational search systems can guide the\ndiscovery of unfamiliar domains. In these scenarios, users find it often\ndifficult to express their information goals due to insufficient background\nknowledge. Conversational interfaces can provide assistance by eliciting\ninformation needs and narrowing down the search space. However, due to the\ncomplexity of information-seeking behavior, the design of conversational\ninterfaces for retrieving information remains a great challenge. Although prior\nwork has employed user studies to empirically ground the system design, most\nexisting studies are limited to well-defined search tasks or known domains,\nthus being less exploratory in nature. Therefore, we conducted a laboratory\nstudy to investigate open-ended search behavior for navigation through unknown\ninformation landscapes. The study comprised of 26 participants who were\nrestricted in their search to a text chat interface. Based on the collected\ndialogue transcripts, we applied statistical analyses and process mining\ntechniques to uncover general information-seeking patterns across five\ndifferent domains. We not only identify core dialogue acts and their\ninterrelations that enable users to discover domain knowledge, but also derive\ndesign suggestions for conversational search systems.\n","authors":["Phillip Schneider","Anum Afzal","Juraj Vladika","Daniel Braun","Florian Matthes"],"pdf_url":"https://arxiv.org/pdf/2301.04098v2.pdf","comment":"Accepted to ECIR 2023"},{"id":"http://arxiv.org/abs/2302.13817v1","updated":"2023-02-27T14:26:29Z","published":"2023-02-27T14:26:29Z","title":"Let's have a chat! A Conversation with ChatGPT: Technology,\n  Applications, and Limitations","summary":"  The emergence of an AI-powered chatbot that can generate human-like sentences\nand write coherent essays has caught the world's attention. This paper\ndiscusses the historical overview of chatbots and the technology behind Chat\nGenerative Pre-trained Transformer, better known as ChatGPT. Moreover,\npotential applications of ChatGPT in various domains, including healthcare,\neducation, and research, are highlighted. Despite promising results, there are\nseveral privacy and ethical concerns surrounding ChatGPT. In addition, we\nhighlight some of the important limitations of the current version of ChatGPT.\nWe also ask ChatGPT to provide its point of view and present its responses to\nseveral questions we attempt to answer.\n","authors":["Sakib Shahriar","Kadhim Hayawi"],"pdf_url":"https://arxiv.org/pdf/2302.13817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13750v1","updated":"2023-02-27T13:26:17Z","published":"2023-02-27T13:26:17Z","title":"MoLE : Mixture of Language Experts for Multi-Lingual Automatic Speech\n  Recognition","summary":"  Multi-lingual speech recognition aims to distinguish linguistic expressions\nin different languages and integrate acoustic processing simultaneously. In\ncontrast, current multi-lingual speech recognition research follows a\nlanguage-aware paradigm, mainly targeted to improve recognition performance\nrather than discriminate language characteristics. In this paper, we present a\nmulti-lingual speech recognition network named\nMixture-of-Language-Expert(MoLE), which digests speech in a variety of\nlanguages. Specifically, MoLE analyzes linguistic expression from input speech\nin arbitrary languages, activating a language-specific expert with a\nlightweight language tokenizer. The tokenizer not only activates experts, but\nalso estimates the reliability of the activation. Based on the reliability, the\nactivated expert and the language-agnostic expert are aggregated to represent\nlanguage-conditioned embedding for efficient speech recognition. Our proposed\nmodel is evaluated in 5 languages scenario, and the experimental results show\nthat our structure is advantageous on multi-lingual recognition, especially for\nspeech in low-resource language.\n","authors":["Yoohwan Kwon","Soo-Whan Chung"],"pdf_url":"https://arxiv.org/pdf/2302.13750v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.13741v1","updated":"2023-02-27T13:06:58Z","published":"2023-02-27T13:06:58Z","title":"Hulk: Graph Neural Networks for Optimizing Regionally Distributed\n  Computing Systems","summary":"  Large deep learning models have shown great potential for delivering\nexceptional results in various applications. However, the training process can\nbe incredibly challenging due to the models' vast parameter sizes, often\nconsisting of hundreds of billions of parameters. Common distributed training\nmethods, such as data parallelism, tensor parallelism, and pipeline\nparallelism, demand significant data communication throughout the process,\nleading to prolonged wait times for some machines in physically distant\ndistributed systems. To address this issue, we propose a novel solution called\nHulk, which utilizes a modified graph neural network to optimize distributed\ncomputing systems. Hulk not only optimizes data communication efficiency\nbetween different countries or even different regions within the same city, but\nalso provides optimal distributed deployment of models in parallel. For\nexample, it can place certain layers on a machine in a specific region or pass\nspecific parameters of a model to a machine in a particular location. By using\nHulk in experiments, we were able to improve the time efficiency of training\nlarge deep learning models on distributed systems by more than 20\\%. Our open\nsource collection of unlabeled data:https://github.com/DLYuanGod/Hulk.\n","authors":["Zhengqing Yuan","Huiwen Xue","Chao Zhang","Yongming Liu"],"pdf_url":"https://arxiv.org/pdf/2302.13741v1.pdf","comment":"16 pages,10 figures"},{"id":"http://arxiv.org/abs/2301.00591v2","updated":"2023-02-27T11:18:02Z","published":"2023-01-02T10:36:40Z","title":"Analysing Discrete Self Supervised Speech Representation for Spoken\n  Language Modeling","summary":"  This work profoundly analyzes discrete self-supervised speech representations\nthrough the eyes of Generative Spoken Language Modeling (GSLM). Following the\nfindings of such an analysis, we propose practical improvements to the discrete\nunit for the GSLM. First, we start comprehending these units by analyzing them\nin three axes: interpretation, visualization, and resynthesis. Our analysis\nfinds a high correlation between the speech units to phonemes and phoneme\nfamilies, while their correlation with speaker or gender is weaker.\nAdditionally, we found redundancies in the extracted units and claim that one\nreason may be the units' context. Following this analysis, we propose a new,\nunsupervised metric to measure unit redundancies. Finally, we use this metric\nto develop new methods that improve the robustness of units clustering and show\nsignificant improvement considering zero-resource speech metrics such as ABX.\nCode and analysis tools are available under the following link.\n","authors":["Amitay Sicherman","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2301.00591v2.pdf","comment":"Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.13661v1","updated":"2023-02-27T10:59:08Z","published":"2023-02-27T10:59:08Z","title":"Using Auxiliary Tasks In Multimodal Fusion Of Wav2vec 2.0 And BERT For\n  Multimodal Emotion Recognition","summary":"  The lack of data and the difficulty of multimodal fusion have always been\nchallenges for multimodal emotion recognition (MER). In this paper, we propose\nto use pretrained models as upstream network, wav2vec 2.0 for audio modality\nand BERT for text modality, and finetune them in downstream task of MER to cope\nwith the lack of data. For the difficulty of multimodal fusion, we use a\nK-layer multi-head attention mechanism as a downstream fusion module. Starting\nfrom the MER task itself, we design two auxiliary tasks to alleviate the\ninsufficient fusion between modalities and guide the network to capture and\nalign emotion-related features. Compared to the previous state-of-the-art\nmodels, we achieve a better performance by 78.42% Weighted Accuracy (WA) and\n79.71% Unweighted Accuracy (UA) on the IEMOCAP dataset.\n","authors":["Dekai Sun","Yancheng He","Jiqing Han"],"pdf_url":"https://arxiv.org/pdf/2302.13661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12695v2","updated":"2023-02-27T10:58:12Z","published":"2023-02-24T15:48:23Z","title":"Cross-Lingual Transfer of Cognitive Processing Complexity","summary":"  When humans read a text, their eye movements are influenced by the structural\ncomplexity of the input sentences. This cognitive phenomenon holds across\nlanguages and recent studies indicate that multilingual language models utilize\nstructural similarities between languages to facilitate cross-lingual transfer.\nWe use sentence-level eye-tracking patterns as a cognitive indicator for\nstructural complexity and show that the multilingual model XLM-RoBERTa can\nsuccessfully predict varied patterns for 13 typologically diverse languages,\ndespite being fine-tuned only on English data. We quantify the sensitivity of\nthe model to structural complexity and distinguish a range of complexity\ncharacteristics. Our results indicate that the model develops a meaningful bias\ntowards sentence length but also integrates cross-lingual differences. We\nconduct a control experiment with randomized word order and find that the model\nseems to additionally capture more complex structural information.\n","authors":["Charlotte Pouw","Nora Hollenstein","Lisa Beinborn"],"pdf_url":"https://arxiv.org/pdf/2302.12695v2.pdf","comment":"Accepted at Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2302.13652v1","updated":"2023-02-27T10:40:41Z","published":"2023-02-27T10:40:41Z","title":"Duration-aware pause insertion using pre-trained language model for\n  multi-speaker text-to-speech","summary":"  Pause insertion, also known as phrase break prediction and phrasing, is an\nessential part of TTS systems because proper pauses with natural duration\nsignificantly enhance the rhythm and intelligibility of synthetic speech.\nHowever, conventional phrasing models ignore various speakers' different styles\nof inserting silent pauses, which can degrade the performance of the model\ntrained on a multi-speaker speech corpus. To this end, we propose more powerful\npause insertion frameworks based on a pre-trained language model. Our approach\nuses bidirectional encoder representations from transformers (BERT) pre-trained\non a large-scale text corpus, injecting speaker embedding to capture various\nspeaker characteristics. We also leverage duration-aware pause insertion for\nmore natural multi-speaker TTS. We develop and evaluate two types of models.\nThe first improves conventional phrasing models on the position prediction of\nrespiratory pauses (RPs), i.e., silent pauses at word transitions without\npunctuation. It performs speaker-conditioned RP prediction considering\ncontextual information and is used to demonstrate the effect of speaker\ninformation on the prediction. The second model is further designed for\nphoneme-based TTS models and performs duration-aware pause insertion,\npredicting both RPs and punctuation-indicated pauses (PIPs) that are\ncategorized by duration. The evaluation results show that our models improve\nthe precision and recall of pause insertion and the rhythm of synthetic speech.\n","authors":["Dong Yang","Tomoki Koriyama","Yuki Saito","Takaaki Saeki","Detai Xin","Hiroshi Saruwatari"],"pdf_url":"https://arxiv.org/pdf/2302.13652v1.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2212.05767v6","updated":"2023-02-27T10:19:44Z","published":"2022-12-12T08:40:04Z","title":"A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic,\n  and Multimodal","summary":"  Knowledge graph reasoning (KGR), aiming to deduce new facts from existing\nfacts based on mined logic rules underlying knowledge graphs (KGs), has become\na fast-growing research direction. It has been proven to significantly benefit\nthe usage of KGs in many AI applications, such as question answering and\nrecommendation systems, etc. According to the graph types, the existing KGR\nmodels can be roughly divided into three categories, i.e., static models,\ntemporal models, and multi-modal models. The early works in this domain mainly\nfocus on static KGR and tend to directly apply general knowledge graph\nembedding models to the reasoning task. However, these models are not suitable\nfor more complex but practical tasks, such as inductive static KGR, temporal\nKGR, and multi-modal KGR. To this end, multiple works have been developed\nrecently, but no survey papers and open-source repositories comprehensively\nsummarize and discuss models in this important direction. To fill the gap, we\nconduct a survey for knowledge graph reasoning tracing from static to temporal\nand then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR\nmodels, and typical datasets are introduced and discussed consequently.\nMoreover, we discuss the challenges and potential opportunities. The\ncorresponding open-source repository is shared on GitHub:\nhttps://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.\n","authors":["Ke Liang","Lingyuan Meng","Meng Liu","Yue Liu","Wenxuan Tu","Siwei Wang","Sihang Zhou","Xinwang Liu","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.05767v6.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2211.02000v2","updated":"2023-02-27T10:07:42Z","published":"2022-11-03T17:13:28Z","title":"Dynamic Kernels and Channel Attention for Low Resource Speaker\n  Verification","summary":"  State-of-the-art speaker verification frameworks have typically focused on\ndeveloping models with increasingly deeper (more layers) and wider (number of\nchannels) models to improve their verification performance. Instead, this paper\nproposes an approach to increase the model resolution capability using\nattention-based dynamic kernels in a convolutional neural network to adapt the\nmodel parameters to be feature-conditioned. The attention weights on the\nkernels are further distilled by channel attention and multi-layer feature\naggregation to learn global features from speech. This approach provides an\nefficient solution to improving representation capacity with lower data\nresources. This is due to the self-adaptation to inputs of the structures of\nthe model parameters. The proposed dynamic convolutional model achieved 1.62\\%\nEER and 0.18 miniDCF on the VoxCeleb1 test set and has a 17\\% relative\nimprovement compared to the ECAPA-TDNN using the same training resources.\n","authors":["Anna Ollerenshaw","Md Asif Jalal","Thomas Hain"],"pdf_url":"https://arxiv.org/pdf/2211.02000v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.08922v3","updated":"2023-02-27T10:06:06Z","published":"2022-04-01T10:10:27Z","title":"Feature Structure Distillation with Centered Kernel Alignment in BERT\n  Transferring","summary":"  Knowledge distillation is an approach to transfer information on\nrepresentations from a teacher to a student by reducing their difference. A\nchallenge of this approach is to reduce the flexibility of the student's\nrepresentations inducing inaccurate learning of the teacher's knowledge. To\nresolve it in transferring, we investigate distillation of structures of\nrepresentations specified to three types: intra-feature, local inter-feature,\nglobal inter-feature structures. To transfer them, we introduce feature\nstructure distillation methods based on the Centered Kernel Alignment, which\nassigns a consistent value to similar features structures and reveals more\ninformative relations. In particular, a memory-augmented transfer method with\nclustering is implemented for the global structures. The methods are\nempirically analyzed on the nine tasks for language understanding of the GLUE\ndataset with Bidirectional Encoder Representations from Transformers (BERT),\nwhich is a representative neural language model. In the results, the proposed\nmethods effectively transfer the three types of structures and improve\nperformance compared to state-of-the-art distillation methods. Indeed, the code\nfor the methods is available in https://github.com/maroo-sky/FSD.\n","authors":["Hee-Jun Jung","Doyeon Kim","Seung-Hoon Na","Kangil Kim"],"pdf_url":"https://arxiv.org/pdf/2204.08922v3.pdf","comment":"This work has been submitted to the ELSEVIER for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2302.13625v1","updated":"2023-02-27T09:47:55Z","published":"2023-02-27T09:47:55Z","title":"Evaluation of Automatically Constructed Word Meaning Explanations","summary":"  Preparing exact and comprehensive word meaning explanations is one of the key\nsteps in the process of monolingual dictionary writing. In standard\nmethodology, the explanations need an expert lexicographer who spends a\nsubstantial amount of time checking the consistency between the descriptive\ntext and corpus evidence. In the following text, we present a new tool that\nderives explanations automatically based on collective information from very\nlarge corpora, particularly on word sketches. We also propose a quantitative\nevaluation of the constructed explanations, concentrating on explanations of\nnouns. The methodology is to a certain extent language independent; however,\nthe presented verification is limited to Czech and English. We show that the\npresented approach allows to create explanations that contain data useful for\nunderstanding the word meaning in approximately 90% of cases. However, in many\ncases, the result requires post-editing to remove redundant information.\n","authors":["Marie Stará","Pavel Rychlý","Aleš Horák"],"pdf_url":"https://arxiv.org/pdf/2302.13625v1.pdf","comment":"preprint of a chapter published by College Publications at\n  https://www.collegepublications.co.uk/tributes/?00049"},{"id":"http://arxiv.org/abs/2302.13619v1","updated":"2023-02-27T09:40:41Z","published":"2023-02-27T09:40:41Z","title":"Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading\n  Comprehension","summary":"  The conversational machine reading comprehension (CMRC) task aims to answer\nquestions in conversations, which has been a hot research topic in recent years\nbecause of its wide applications. However, existing CMRC benchmarks in which\neach conversation is assigned a static passage are inconsistent with real\nscenarios. Thus, model's comprehension ability towards real scenarios are hard\nto evaluate reasonably. To this end, we propose the first Chinese CMRC\nbenchmark Orca and further provide zero-shot/few-shot settings to evaluate\nmodel's generalization ability towards diverse domains. We collect 831\nhot-topic driven conversations with 4,742 turns in total. Each turn of a\nconversation is assigned with a response-related passage, aiming to evaluate\nmodel's comprehension ability more reasonably. The topics of conversations are\ncollected from social media platform and cover 33 domains, trying to be\nconsistent with real scenarios. Importantly, answers in Orca are all\nwell-annotated natural responses rather than the specific spans or short phrase\nin previous datasets. Besides, we implement three strong baselines to tackle\nthe challenge in Orca. The results indicate the great challenge of our CMRC\nbenchmark. Our datatset and checkpoints are available at\nhttps://github.com/nuochenpku/Orca.\n","authors":["Nuo Chen","Hongguang Li","Yinan Bao","Junqing He","Xinshi Lin","Qi Yang","Jianfeng Liu","Ruyi Gan","Jiaxing Zhang","Baoyuan Wang","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2302.13619v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2302.13610v1","updated":"2023-02-27T09:20:00Z","published":"2023-02-27T09:20:00Z","title":"A Prototypical Semantic Decoupling Method via Joint Contrastive Learning\n  for Few-Shot Name Entity Recognition","summary":"  Few-shot named entity recognition (NER) aims at identifying named entities\nbased on only few labeled instances. Most existing prototype-based sequence\nlabeling models tend to memorize entity mentions which would be easily confused\nby close prototypes. In this paper, we proposed a Prototypical Semantic\nDecoupling method via joint Contrastive learning (PSDC) for few-shot NER.\nSpecifically, we decouple class-specific prototypes and contextual semantic\nprototypes by two masking strategies to lead the model to focus on two\ndifferent semantic information for inference. Besides, we further introduce\njoint contrastive learning objectives to better integrate two kinds of\ndecoupling information and prevent semantic collapse. Experimental results on\ntwo few-shot NER benchmarks demonstrate that PSDC consistently outperforms the\nprevious SOTA methods in terms of overall performance. Extensive analysis\nfurther validates the effectiveness and generalization of PSDC.\n","authors":["Guanting Dong","Zechen Wang","Liwen Wang","Daichi Guo","Dayuan Fu","Yuxiang Wu","Chen Zeng","Xuefeng Li","Tingfeng Hui","Keqing He","Xinyue Cui","Qixiang Gao","Weiran Xu"],"pdf_url":"https://arxiv.org/pdf/2302.13610v1.pdf","comment":"5 pages, 2 figures, published to ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.13584v1","updated":"2023-02-27T08:42:30Z","published":"2023-02-27T08:42:30Z","title":"Revisit Out-Of-Vocabulary Problem for Slot Filling: A Unified\n  Contrastive Frameword with Multi-level Data Augmentations","summary":"  In real dialogue scenarios, the existing slot filling model, which tends to\nmemorize entity patterns, has a significantly reduced generalization facing\nOut-of-Vocabulary (OOV) problems. To address this issue, we propose an OOV\nrobust slot filling model based on multi-level data augmentations to solve the\nOOV problem from both word and slot perspectives. We present a unified\ncontrastive learning framework, which pull representations of the origin sample\nand augmentation samples together, to make the model resistant to OOV problems.\nWe evaluate the performance of the model from some specific slots and carefully\ndesign test data with OOV word perturbation to further demonstrate the\neffectiveness of OOV words. Experiments on two datasets show that our approach\noutperforms the previous sota methods in terms of both OOV slots and words.\n","authors":["Daichi Guo","Guanting Dong","Dayuan Fu","Yuxiang Wu","Chen Zeng","Tingfeng Hui","Liwen Wang","Xuefeng Li","Zechen Wang","Keqing He","Xinyue Cui","Weiran Xu"],"pdf_url":"https://arxiv.org/pdf/2302.13584v1.pdf","comment":"5 pages, 3 figures, published to ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.12313v2","updated":"2023-02-27T08:24:05Z","published":"2023-02-23T20:18:52Z","title":"Testing AI performance on less frequent aspects of language reveals\n  insensitivity to underlying meaning","summary":"  Advances in computational methods and big data availability have recently\ntranslated into breakthroughs in AI applications. With successes in bottom-up\nchallenges partially overshadowing shortcomings, the 'human-like' performance\nof Large Language Models has raised the question of how linguistic performance\nis achieved by algorithms. Given systematic shortcomings in generalization\nacross many AI systems, in this work we ask whether linguistic performance is\nindeed guided by language knowledge in Large Language Models. To this end, we\nprompt GPT-3 with a grammaticality judgement task and comprehension questions\non less frequent constructions that are thus unlikely to form part of Large\nLanguage Models' training data. These included grammatical 'illusions',\nsemantic anomalies, complex nested hierarchies and self-embeddings. GPT-3\nfailed for every prompt but one, often offering answers that show a critical\nlack of understanding even of high-frequency words used in these less frequent\ngrammatical constructions. The present work sheds light on the boundaries of\nthe alleged AI human-like linguistic competence and argues that, far from\nhuman-like, the next-word prediction abilities of LLMs may face issues of\nrobustness, when pushed beyond training data.\n","authors":["Vittoria Dentella","Elliot Murphy","Gary Marcus","Evelina Leivada"],"pdf_url":"https://arxiv.org/pdf/2302.12313v2.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2302.13574v1","updated":"2023-02-27T08:21:14Z","published":"2023-02-27T08:21:14Z","title":"kNN-BOX: A Unified Framework for Nearest Neighbor Generation","summary":"  Augmenting the base neural model with a token-level symbolic datastore is a\nnovel generation paradigm and has achieved promising results in machine\ntranslation (MT). In this paper, we introduce a unified framework kNN-BOX,\nwhich enables quick development and interactive analysis for this novel\nparadigm. kNN-BOX decomposes the datastore-augmentation approach into three\nmodules: datastore, retriever and combiner, thus putting diverse kNN generation\nmethods into a unified way. Currently, kNN-BOX has provided implementation of\nseven popular kNN-MT variants, covering research from performance enhancement\nto efficiency optimization. It is easy for users to reproduce these existing\nworks or customize their own models. Besides, users can interact with their kNN\ngeneration systems with kNN-BOX to better understand the underlying inference\nprocess in a visualized way. In the experiment section, we apply kNN-BOX for\nmachine translation and three other seq2seq generation tasks, namely, text\nsimplification, paraphrase generation and question generation. Experiment\nresults show that augmenting the base neural model with kNN-BOX leads to a\nlarge performance improvement in all these tasks. The code and document of\nkNN-BOX is available at https://github.com/NJUNLP/knn-box.\n","authors":["Wenhao Zhu","Qianfeng Zhao","Yunzhe Lv","Shujian Huang","Siheng Zhao","Sizhe Liu","Jiajun Chen"],"pdf_url":"https://arxiv.org/pdf/2302.13574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13539v1","updated":"2023-02-27T06:32:45Z","published":"2023-02-27T06:32:45Z","title":"Finding Supporting Examples for In-Context Learning","summary":"  In-context learning is a new learning paradigm where a language model\nobserves a few examples and then straightly outputs the test input's\nprediction. Previous works have shown that in-context learning is sensitive to\nthe provided examples and randomly sampled examples show significantly unstable\nperformance. In this paper, we propose to find ``supporting examples'' for\nin-context learning: Given the training dataset, we need to select one\npermutation of a few examples, which are informative for the task's in-context\nlearning and lead to superior performance. Although in traditional\ngradient-based learning, e.g., fine-tuning, there are numerous methods to find\na ``coreset'' from the entire dataset, they are sub-optimal and not suitable\nfor this problem since in-context learning occurs in the language model's\ninference without gradients or parameter updates. Additionally, the strong\ndependence among in-context examples makes this problem an NP-hard\ncombinatorial optimization problem and enumerating all possible permutations is\ninfeasible. Hence we propose a two-stage method to tackle this challenge. First\nwe propose a novel metric to select informative examples based on the language\nmodel's feedback, with a progressive filtering strategy. And then we propose a\ndiversity-guided beam search method to refine and evaluate the selected\nexamples, iteratively. The experimental results show our method significantly\noutperforms a wide range of baselines, and further analyses show the\neffectiveness of our method and shed light on the properties of supporting\nexamples and in-context learning.\n","authors":["Xiaonan Li","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.13539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01083v2","updated":"2023-02-27T04:30:11Z","published":"2022-12-02T10:45:33Z","title":"Cross-Modal Mutual Learning for Cued Speech Recognition","summary":"  Automatic Cued Speech Recognition (ACSR) provides an intelligent\nhuman-machine interface for visual communications, where the Cued Speech (CS)\nsystem utilizes lip movements and hand gestures to code spoken language for\nhearing-impaired people. Previous ACSR approaches often utilize direct feature\nconcatenation as the main fusion paradigm. However, the asynchronous modalities\ni.e., lip, hand shape and hand position) in CS may cause interference for\nfeature concatenation. To address this challenge, we propose a transformer\nbased cross-modal mutual learning framework to prompt multi-modal interaction.\nCompared with the vanilla self-attention, our model forces modality-specific\ninformation of different modalities to pass through a modality-invariant\ncodebook, collating linguistic representations for tokens of each modality.\nThen the shared linguistic knowledge is used to re-synchronize multi-modal\nsequences. Moreover, we establish a novel large-scale multi-speaker CS dataset\nfor Mandarin Chinese. To our knowledge, this is the first work on ACSR for\nMandarin Chinese. Extensive experiments are conducted for different languages\ni.e., Chinese, French, and British English). Results demonstrate that our model\nexhibits superior recognition performance to the state-of-the-art by a large\nmargin.\n","authors":["Lei Liu","Li Liu"],"pdf_url":"https://arxiv.org/pdf/2212.01083v2.pdf","comment":"Accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2302.13512v1","updated":"2023-02-27T04:24:13Z","published":"2023-02-27T04:24:13Z","title":"Changes in Commuter Behavior from COVID-19 Lockdowns in the Atlanta\n  Metropolitan Area","summary":"  This paper analyzes the impact of COVID-19 related lockdowns in the Atlanta,\nGeorgia metropolitan area by examining commuter patterns in three periods:\nprior to, during, and after the pandemic lockdown. A cellular phone location\ndataset is utilized in a novel pipeline to infer the home and work locations of\nthousands of users from the Density-based Spatial Clustering of Applications\nwith Noise (DBSCAN) algorithm. The coordinates derived from the clustering are\nput through a reverse geocoding process from which word embeddings are\nextracted in order to categorize the industry of each work place based on the\nworkplace name and Point of Interest (POI) mapping. Frequencies of commute from\nhome locations to work locations are analyzed in and across all three time\nperiods. Public health and economic factors are discussed to explain potential\nreasons for the observed changes in commuter patterns.\n","authors":["Tejas Santanam","Anthony Trasatti","Hanyu Zhang","Connor Riley","Pascal Van Hentenryck","Ramayya Krishnan"],"pdf_url":"https://arxiv.org/pdf/2302.13512v1.pdf","comment":"7 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2302.13505v1","updated":"2023-02-27T04:01:28Z","published":"2023-02-27T04:01:28Z","title":"Multi-Action Dialog Policy Learning from Logged User Feedback","summary":"  Multi-action dialog policy, which generates multiple atomic dialog actions\nper turn, has been widely applied in task-oriented dialog systems to provide\nexpressive and efficient system responses. Existing policy models usually\nimitate action combinations from the labeled multi-action dialog examples. Due\nto data limitations, they generalize poorly toward unseen dialog flows. While\nreinforcement learning-based methods are proposed to incorporate the service\nratings from real users and user simulators as external supervision signals,\nthey suffer from sparse and less credible dialog-level rewards. To cope with\nthis problem, we explore to improve multi-action dialog policy learning with\nexplicit and implicit turn-level user feedback received for historical\npredictions (i.e., logged user feedback) that are cost-efficient to collect and\nfaithful to real-world scenarios. The task is challenging since the logged user\nfeedback provides only partial label feedback limited to the particular\nhistorical dialog actions predicted by the agent. To fully exploit such\nfeedback information, we propose BanditMatch, which addresses the task from a\nfeedback-enhanced semi-supervised learning perspective with a hybrid objective\nof semi-supervised learning and bandit learning. BanditMatch integrates\npseudo-labeling methods to better explore the action space through constructing\nfull label feedback. Extensive experiments show that our BanditMatch\noutperforms the state-of-the-art methods by generating more concise and\ninformative responses. The source code and the appendix of this paper can be\nobtained from https://github.com/ShuoZhangXJTU/BanditMatch.\n","authors":["Shuo Zhang","Junzhou Zhao","Pinghui Wang","Tianxiang Wang","Zi Liang","Jing Tao","Yi Huang","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2302.13505v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2112.08802v3","updated":"2023-02-27T03:46:44Z","published":"2021-12-16T11:39:21Z","title":"UNIREX: A Unified Learning Framework for Language Model Rationale\n  Extraction","summary":"  An extractive rationale explains a language model's (LM's) prediction on a\ngiven task instance by highlighting the text inputs that most influenced the\nprediction. Ideally, rationale extraction should be faithful (reflective of\nLM's actual behavior) and plausible (convincing to humans), without\ncompromising the LM's (i.e., task model's) task performance. Although\nattribution algorithms and select-predict pipelines are commonly used in\nrationale extraction, they both rely on certain heuristics that hinder them\nfrom satisfying all three desiderata. In light of this, we propose UNIREX, a\nflexible learning framework that generalizes rationale extractor optimization\nas follows: (1) specify architecture for a learned rationale extractor; (2)\nselect explainability objectives (i.e., faithfulness and plausibility\ncriteria); and (3) jointly the train task model and rationale extractor on the\ntask using the selected objectives. UNIREX enables replacing prior works'\nheuristic design choices with a generic learned rationale extractor in (1) and\noptimizing it for all three desiderata in (2)-(3). To facilitate comparison\nbetween methods with respect to multiple desiderata, we introduce the\nNormalized Relative Gain (NRG) metric. Across five text classification\ndatasets, our best UNIREX configuration outperforms baselines by an average of\n32.9% NRG. Plus, we find that UNIREX-trained rationale extractors can even\ngeneralize to unseen datasets and tasks.\n","authors":["Aaron Chan","Maziar Sanjabi","Lambert Mathias","Liang Tan","Shaoliang Nie","Xiaochang Peng","Xiang Ren","Hamed Firooz"],"pdf_url":"https://arxiv.org/pdf/2112.08802v3.pdf","comment":"ICML 2022"},{"id":"http://arxiv.org/abs/2302.13496v1","updated":"2023-02-27T03:43:25Z","published":"2023-02-27T03:43:25Z","title":"Strategize Before Teaching: A Conversational Tutoring System with\n  Pedagogy Self-Distillation","summary":"  Conversational tutoring systems (CTSs) aim to help students master\neducational material with natural language interaction in the form of a dialog.\nCTSs have become a key pillar in educational data mining research. A key\nchallenge in CTSs is to engage the student in the conversation while exposing\nthem to a diverse set of teaching strategies, akin to a human teacher, thereby,\nhelping them learn in the process. Different from previous work that generates\nresponses given the strategies as input, we propose to jointly predict teaching\nstrategies and generate tutor responses accordingly, which fits a more\nrealistic application scenario. We benchmark several competitive models on\nthree dialog tutoring datasets and propose a unified framework that combines\nteaching response generation and pedagogical strategy prediction, where a\nself-distillation mechanism is adopted to guide the teaching strategy learning\nand facilitate tutor response generation. Our experiments and analyses shed\nlight on how teaching strategies affect dialog tutoring.\n","authors":["Lingzhi Wang","Mrinmaya Sachan","Xingshan Zeng","Kam-Fai Wong"],"pdf_url":"https://arxiv.org/pdf/2302.13496v1.pdf","comment":"Accepted by EACL 2023 Findings"},{"id":"http://arxiv.org/abs/2211.05405v3","updated":"2023-02-27T03:35:55Z","published":"2022-11-10T08:19:44Z","title":"VieCap4H-VLSP 2021: ObjectAoA -- Enhancing performance of Object\n  Relation Transformer with Attention on Attention for Vietnamese image\n  captioning","summary":"  Image captioning is currently a challenging task that requires the ability to\nboth understand visual information and use human language to describe this\nvisual information in the image. In this paper, we propose an efficient way to\nimprove the image understanding ability of transformer-based method by\nextending Object Relation Transformer architecture with Attention on Attention\nmechanism. Experiments on the VieCap4H dataset show that our proposed method\nsignificantly outperforms its original structure on both the public test and\nprivate test of the Image Captioning shared task held by VLSP.\n","authors":["Nghia Hieu Nguyen","Duong T. D. Vo","Minh-Quan Ha"],"pdf_url":"https://arxiv.org/pdf/2211.05405v3.pdf","comment":"Accepted for publishing at the VNU Journal of Science: Computer\n  Science and Communication Engineering"},{"id":"http://arxiv.org/abs/2210.03221v5","updated":"2023-02-27T03:29:28Z","published":"2022-10-06T21:29:17Z","title":"PQLM -- Multilingual Decentralized Portable Quantum Language Model for\n  Privacy Protection","summary":"  With careful manipulation, malicious agents can reverse engineer private\ninformation encoded in pre-trained language models. Security concerns motivate\nthe development of quantum pre-training. In this work, we propose a highly\nPortable Quantum Language Model (PQLM) that can easily transmit information to\ndownstream tasks on classical machines. The framework consists of a cloud PQLM\nbuilt with random Variational Quantum Classifiers (VQC) and local models for\ndownstream applications. We demonstrate the ad hoc portability of the quantum\nmodel by extracting only the word embeddings and effectively applying them to\ndownstream tasks on classical machines. Our PQLM exhibits comparable\nperformance to its classical counterpart on both intrinsic evaluation (loss,\nperplexity) and extrinsic evaluation (multilingual sentiment analysis accuracy)\nmetrics. We also perform ablation studies on the factors affecting PQLM\nperformance to analyze model stability. Our work establishes a theoretical\nfoundation for a portable quantum pre-trained language model that could be\ntrained on private data and made available for public use with privacy\nprotection guarantees.\n","authors":["Shuyue Stella Li","Xiangyu Zhang","Shu Zhou","Hongchao Shu","Ruixing Liang","Hexin Liu","Leibny Paola Garcia"],"pdf_url":"https://arxiv.org/pdf/2210.03221v5.pdf","comment":"5 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2110.08419v2","updated":"2023-02-27T03:14:07Z","published":"2021-10-16T00:20:04Z","title":"Robustness Challenges in Model Distillation and Pruning for Natural\n  Language Understanding","summary":"  Recent work has focused on compressing pre-trained language models (PLMs)\nlike BERT where the major focus has been to improve the in-distribution\nperformance for downstream tasks. However, very few of these studies have\nanalyzed the impact of compression on the generalizability and robustness of\ncompressed models for out-of-distribution (OOD) data. Towards this end, we\nstudy two popular model compression techniques including knowledge distillation\nand pruning and show that the compressed models are significantly less robust\nthan their PLM counterparts on OOD test sets although they obtain similar\nperformance on in-distribution development sets for a task. Further analysis\nindicates that the compressed models overfit on the shortcut samples and\ngeneralize poorly on the hard ones. We further leverage this observation to\ndevelop a regularization strategy for robust model compression based on sample\nuncertainty. Experimental results on several natural language understanding\ntasks demonstrate that our bias mitigation framework improves the OOD\ngeneralization of the compressed models, while not sacrificing the\nin-distribution task performance.\n","authors":["Mengnan Du","Subhabrata Mukherjee","Yu Cheng","Milad Shokouhi","Xia Hu","Ahmed Hassan Awadallah"],"pdf_url":"https://arxiv.org/pdf/2110.08419v2.pdf","comment":"Accepted by EACL 2023"},{"id":"http://arxiv.org/abs/2302.12692v2","updated":"2023-02-27T02:55:39Z","published":"2023-02-24T15:35:36Z","title":"Language Models are Few-shot Learners for Prognostic Prediction","summary":"  Clinical prediction is an essential task in the healthcare industry. However,\nthe recent success of transformers, on which large language models are built,\nhas not been extended to this domain. In this research, we explore the use of\ntransformers and language models in prognostic prediction for immunotherapy\nusing real-world patients' clinical data and molecular profiles. This paper\ninvestigates the potential of transformers to improve clinical prediction\ncompared to conventional machine learning approaches and addresses the\nchallenge of few-shot learning in predicting rare disease areas. The study\nbenchmarks the efficacy of baselines and language models on prognostic\nprediction across multiple cancer types and investigates the impact of\ndifferent pretrained language models under few-shot regimes. The results\ndemonstrate significant improvements in accuracy and highlight the potential of\nNLP in clinical research to improve early detection and intervention for\ndifferent diseases. Anonymous codes are available at\n\\url{https://anonymous.4open.science/r/table2text-88ED}.\n","authors":["Zekai Chen","Mariann Micsinai Balan","Kevin Brown"],"pdf_url":"https://arxiv.org/pdf/2302.12692v2.pdf","comment":"7 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2302.13475v1","updated":"2023-02-27T02:15:56Z","published":"2023-02-27T02:15:56Z","title":"Elementwise Language Representation","summary":"  We propose a new technique for computational language representation called\nelementwise embedding, in which a material (semantic unit) is abstracted into a\nhorizontal concatenation of lower-dimensional element (character) embeddings.\nWhile elements are always characters, materials are arbitrary levels of\nsemantic units so it generalizes to any type of tokenization. To focus only on\nthe important letters, the $n^{th}$ spellings of each semantic unit are aligned\nin $n^{th}$ attention heads, then concatenated back into original forms\ncreating unique embedding representations; they are jointly projected thereby\ndetermining own contextual importance. Technically, this framework is achieved\nby passing a sequence of materials, each consists of $v$ elements, to a\ntransformer having $h=v$ attention heads. As a pure embedding technique,\nelementwise embedding replaces the $w$-dimensional embedding table of a\ntransformer model with $256$ $c$-dimensional elements (each corresponding to\none of UTF-8 bytes) where $c=w/v$. Using this novel approach, we show that the\nstandard transformer architecture can be reused for all levels of language\nrepresentations and be able to process much longer sequences at the same\ntime-complexity without \"any\" architectural modification and additional\noverhead. BERT trained with elementwise embedding outperforms its subword\nequivalence (original implementation) in multilabel patent document\nclassification exhibiting superior robustness to domain-specificity and data\nimbalance, despite using $0.005\\%$ of embedding parameters. Experiments\ndemonstrate the generalizability of the proposed method by successfully\ntransferring these enhancements to differently architected transformers CANINE\nand ALBERT.\n","authors":["Dunam Kim","Jeeeun Kim"],"pdf_url":"https://arxiv.org/pdf/2302.13475v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2302.12095v2","updated":"2023-02-27T02:13:38Z","published":"2023-02-22T11:01:20Z","title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution\n  Perspective","summary":"  ChatGPT is a recent chatbot service released by OpenAI and is receiving\nincreasing attention over the past few months. While evaluations of various\naspects of ChatGPT have been done, its robustness, i.e., the performance to\nunexpected inputs, is still unclear to the public. Robustness is of particular\nconcern in responsible AI, especially for safety-critical applications. In this\npaper, we conduct a thorough evaluation of the robustness of ChatGPT from the\nadversarial and out-of-distribution (OOD) perspective. To do so, we employ the\nAdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart\nreview and DDXPlus medical diagnosis datasets for OOD evaluation. We select\nseveral popular foundation models as baselines. Results show that ChatGPT shows\nconsistent advantages on most adversarial and OOD classification and\ntranslation tasks. However, the absolute performance is far from perfection,\nwhich suggests that adversarial and OOD robustness remains a significant threat\nto foundation models. Moreover, ChatGPT shows astounding performance in\nunderstanding dialogue-related texts and we find that it tends to provide\ninformal suggestions for medical tasks instead of definitive answers. Finally,\nwe present in-depth discussions of possible research directions.\n","authors":["Jindong Wang","Xixu Hu","Wenxin Hou","Hao Chen","Runkai Zheng","Yidong Wang","Linyi Yang","Haojun Huang","Wei Ye","Xiubo Geng","Binxin Jiao","Yue Zhang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2302.12095v2.pdf","comment":"Ongoing work; code is at: https://github.com/microsoft/robustlearn"},{"id":"http://arxiv.org/abs/2302.13451v1","updated":"2023-02-27T00:44:22Z","published":"2023-02-27T00:44:22Z","title":"Low latency transformers for speech processing","summary":"  The transformer is a widely-used building block in modern neural networks.\nHowever, when applied to audio data, the transformer's acausal behaviour, which\nwe term Acausal Attention (AA), has generally limited its application to\noffline tasks. In this paper we introduce Streaming Attention (SA), which\noperates causally with fixed latency, and requires lower compute and memory\nresources than AA to train. Next, we introduce Low Latency Streaming Attention\n(LLSA), a method which combines multiple SA layers without latency build-up\nproportional to the layer count. Comparative analysis between AA, SA and LLSA\non Automatic Speech Recognition (ASR) and Speech Emotion Recognition (SER)\ntasks are presented. The results show that causal SA-based networks with fixed\nlatencies of a few seconds (e.g. 1.8 seconds) and LLSA networks with latencies\nas short as 300 ms can perform comparably with acausal (AA) networks. We\nconclude that SA and LLSA methods retain many of the benefits of conventional\nacausal transformers, but with latency characteristics that make them practical\nto run in real-time streaming applications.\n","authors":["Jianbo Ma","Siqi Pan","Deepak Chandran","Andrea Fanelli","Richard Cartwright"],"pdf_url":"https://arxiv.org/pdf/2302.13451v1.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.14169v1","updated":"2023-02-27T22:05:46Z","published":"2023-02-27T22:05:46Z","title":"TabGenie: A Toolkit for Table-to-Text Generation","summary":"  Heterogenity of data-to-text generation datasets limits the research on\ndata-to-text generation systems. We present TabGenie - a toolkit which enables\nresearchers to explore, preprocess, and analyze a variety of data-to-text\ngeneration datasets through the unified framework of table-to-text generation.\nIn TabGenie, all the inputs are represented as tables with associated metadata.\nThe tables can be explored through the web interface, which also provides an\ninteractive mode for debugging table-to-text generation, facilitates\nside-by-side comparison of generated system outputs, and allows easy exports\nfor manual analysis. Furthermore, TabGenie is equipped with command line\nprocessing tools and Python bindings for unified dataset loading and\nprocessing. We release TabGenie as a PyPI package and provide its open-source\ncode and a live demo at https://github.com/kasnerz/tabgenie.\n","authors":["Zdeněk Kasner","Ekaterina Garanina","Ondřej Plátek","Ondřej Dušek"],"pdf_url":"https://arxiv.org/pdf/2302.14169v1.pdf","comment":"Submitted to ACL 2023 System Demonstration Track"},{"id":"http://arxiv.org/abs/2203.13474v5","updated":"2023-02-27T21:26:48Z","published":"2022-03-25T06:55:15Z","title":"CodeGen: An Open Large Language Model for Code with Multi-Turn Program\n  Synthesis","summary":"  Program synthesis strives to generate a computer program as a solution to a\ngiven problem specification, expressed with input-output examples or natural\nlanguage descriptions. The prevalence of large language models advances the\nstate-of-the-art for program synthesis, though limited training resources and\ndata impede open access to such models. To democratize this, we train and\nrelease a family of large language models up to 16.1B parameters, called\nCODEGEN, on natural language and programming language data, and open source the\ntraining library JAXFORMER. We show the utility of the trained model by\ndemonstrating that it is competitive with the previous state-of-the-art on\nzero-shot Python code generation on HumanEval. We further investigate the\nmulti-step paradigm for program synthesis, where a single program is factorized\ninto multiple prompts specifying subproblems. To this end, we construct an open\nbenchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverse\nproblem sets that are factorized into multi-turn prompts. Our analysis on MTPB\nshows that the same intent provided to CODEGEN in multi-turn fashion\nsignificantly improves program synthesis over that provided as a single turn.\nWe make the training library JAXFORMER and model checkpoints available as open\nsource contribution: https://github.com/salesforce/CodeGen.\n","authors":["Erik Nijkamp","Bo Pang","Hiroaki Hayashi","Lifu Tu","Huan Wang","Yingbo Zhou","Silvio Savarese","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2203.13474v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.04176v2","updated":"2023-02-27T20:41:33Z","published":"2022-02-08T22:18:25Z","title":"Police Text Analysis: Topic Modeling and Spatial Relative Density\n  Estimation","summary":"  We analyze a large corpus of police incident narrative documents in\nunderstanding the spatial distribution of the topics. The motivation for doing\nthis is that police narratives in each incident report contains very\nfine-grained information that is richer than the category that is manually\nassigned by the police. Our approach is to split the corpus into topics using\ntwo different unsupervised machine learning algorithms - Latent Dirichlet\nAllocation and Non-negative Matrix Factorization. We validate the performance\nof each learned topic model using model coherence. Then, using a k-nearest\nneighbors density ratio estimation (kNN-DRE) approach that we propose, we\nestimate the spatial density ratio per topic and use this for data discovery\nand analysis of each topic, allowing for insights into the described incidents\nat scale. We provide a qualitative assessment of each topic and highlight some\nkey benefits for using our kNN-DRE model for estimating spatial trends.\n","authors":["Sarah Huestis-Mitchell","Xiuyuan Cheng","Yao Xie"],"pdf_url":"https://arxiv.org/pdf/2202.04176v2.pdf","comment":"9 pages, 12 figures"},{"id":"http://arxiv.org/abs/2302.14132v1","updated":"2023-02-27T20:39:54Z","published":"2023-02-27T20:39:54Z","title":"Structured Pruning of Self-Supervised Pre-trained Models for Speech\n  Recognition and Understanding","summary":"  Self-supervised speech representation learning (SSL) has shown to be\neffective in various downstream tasks, but SSL models are usually large and\nslow. Model compression techniques such as pruning aim to reduce the model size\nand computation without degradation in accuracy. Prior studies focus on the\npruning of Transformers; however, speech models not only utilize a stack of\nTransformer blocks, but also combine a frontend network based on multiple\nconvolutional layers for low-level feature representation learning. This\nfrontend has a small size but a heavy computational cost. In this work, we\npropose three task-specific structured pruning methods to deal with such\nheterogeneous networks. Experiments on LibriSpeech and SLURP show that the\nproposed method is more accurate than the original wav2vec2-base with 10% to\n30% less computation, and is able to reduce the computation by 40% to 50%\nwithout any degradation.\n","authors":["Yifan Peng","Kwangyoun Kim","Felix Wu","Prashant Sridhar","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2302.14132v1.pdf","comment":"Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.14115v1","updated":"2023-02-27T19:53:49Z","published":"2023-02-27T19:53:49Z","title":"Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense\n  Video Captioning","summary":"  In this work, we introduce Vid2Seq, a multi-modal single-stage dense event\ncaptioning model pretrained on narrated videos which are readily-available at\nscale. The Vid2Seq architecture augments a language model with special time\ntokens, allowing it to seamlessly predict event boundaries and textual\ndescriptions in the same output sequence. Such a unified model requires\nlarge-scale training data, which is not available in current annotated\ndatasets. We show that it is possible to leverage unlabeled narrated videos for\ndense video captioning, by reformulating sentence boundaries of transcribed\nspeech as pseudo event boundaries, and using the transcribed speech sentences\nas pseudo event captions. The resulting Vid2Seq model pretrained on the\nYT-Temporal-1B dataset improves the state of the art on a variety of dense\nvideo captioning benchmarks including YouCook2, ViTT and ActivityNet Captions.\nVid2Seq also generalizes well to the video paragraph captioning task and the\nstandard task of video clip captioning. Our code and models will be publicly\nreleased at https://antoyang.github.io/vid2seq.html.\n","authors":["Antoine Yang","Arsha Nagrani","Paul Hongsuck Seo","Antoine Miech","Jordi Pont-Tuset","Ivan Laptev","Josef Sivic","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2302.14115v1.pdf","comment":"To appear at CVPR 2023; 18 pages; 6 figures"},{"id":"http://arxiv.org/abs/2302.14638v1","updated":"2023-02-27T11:48:54Z","published":"2023-02-27T11:48:54Z","title":"SpeechFormer++: A Hierarchical Efficient Framework for Paralinguistic\n  Speech Processing","summary":"  Paralinguistic speech processing is important in addressing many issues, such\nas sentiment and neurocognitive disorder analyses. Recently, Transformer has\nachieved remarkable success in the natural language processing field and has\ndemonstrated its adaptation to speech. However, previous works on Transformer\nin the speech field have not incorporated the properties of speech, leaving the\nfull potential of Transformer unexplored. In this paper, we consider the\ncharacteristics of speech and propose a general structure-based framework,\ncalled SpeechFormer++, for paralinguistic speech processing. More concretely,\nfollowing the component relationship in the speech signal, we design a unit\nencoder to model the intra- and inter-unit information (i.e., frames, phones,\nand words) efficiently. According to the hierarchical relationship, we utilize\nmerging blocks to generate features at different granularities, which is\nconsistent with the structural pattern in the speech signal. Moreover, a word\nencoder is introduced to integrate word-grained features into each unit\nencoder, which effectively balances fine-grained and coarse-grained\ninformation. SpeechFormer++ is evaluated on the speech emotion recognition\n(IEMOCAP & MELD), depression classification (DAIC-WOZ) and Alzheimer's disease\ndetection (Pitt) tasks. The results show that SpeechFormer++ outperforms the\nstandard Transformer while greatly reducing the computational cost.\nFurthermore, it delivers superior results compared to the state-of-the-art\napproaches.\n","authors":["Weidong Chen","Xiaofen Xing","Xiangmin Xu","Jianxin Pang","Lan Du"],"pdf_url":"https://arxiv.org/pdf/2302.14638v1.pdf","comment":"14 pages, 7 figures, 14 tables, TASLP 2023 paper"},{"id":"http://arxiv.org/abs/2302.14062v1","updated":"2023-02-27T11:09:19Z","published":"2023-02-27T11:09:19Z","title":"Explanations for Automatic Speech Recognition","summary":"  We address quality assessment for neural network based ASR by providing\nexplanations that help increase our understanding of the system and ultimately\nhelp build trust in the system. Compared to simple classification labels,\nexplaining transcriptions is more challenging as judging their correctness is\nnot straightforward and transcriptions as a variable-length sequence is not\nhandled by existing interpretable machine learning models. We provide an\nexplanation for an ASR transcription as a subset of audio frames that is both a\nminimal and sufficient cause of the transcription. To do this, we adapt\nexisting explainable AI (XAI) techniques from image classification-Statistical\nFault Localisation(SFL) and Causal. Additionally, we use an adapted version of\nLocal Interpretable Model-Agnostic Explanations (LIME) for ASR as a baseline in\nour experiments. We evaluate the quality of the explanations generated by the\nproposed techniques over three different ASR ,Google API, the baseline model of\nSphinx, Deepspeech and 100 audio samples from the Commonvoice dataset.\n","authors":["Xiaoliang Wu","Peter Bell","Ajitha Rajan"],"pdf_url":"https://arxiv.org/pdf/2302.14062v1.pdf","comment":"Accepted by Speech Track, ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00001v1","updated":"2023-02-27T22:09:35Z","published":"2023-02-27T22:09:35Z","title":"Reward Design with Language Models","summary":"  Reward design in reinforcement learning (RL) is challenging since specifying\nhuman notions of desired behavior may be difficult via reward functions or\nrequire many expert demonstrations. Can we instead cheaply design rewards using\na natural language interface? This paper explores how to simplify reward design\nby prompting a large language model (LLM) such as GPT-3 as a proxy reward\nfunction, where the user provides a textual prompt containing a few examples\n(few-shot) or a description (zero-shot) of the desired behavior. Our approach\nleverages this proxy reward function in an RL framework. Specifically, users\nspecify a prompt once at the beginning of training. During training, the LLM\nevaluates an RL agent's behavior against the desired behavior described by the\nprompt and outputs a corresponding reward signal. The RL agent then uses this\nreward to update its behavior. We evaluate whether our approach can train\nagents aligned with user objectives in the Ultimatum Game, matrix games, and\nthe DealOrNoDeal negotiation task. In all three tasks, we show that RL agents\ntrained with our framework are well-aligned with the user's objectives and\noutperform RL agents trained with reward functions learned via supervised\nlearning\n","authors":["Minae Kwon","Sang Michael Xie","Kalesha Bullard","Dorsa Sadigh"],"pdf_url":"https://arxiv.org/pdf/2303.00001v1.pdf","comment":"International Conference on Learning Representations (ICLR) 2023"},{"id":"http://arxiv.org/abs/2303.00091v1","updated":"2023-02-27T08:06:04Z","published":"2023-02-27T08:06:04Z","title":"Improving Medical Speech-to-Text Accuracy with Vision-Language\n  Pre-training Model","summary":"  Automatic Speech Recognition (ASR) is a technology that converts spoken words\ninto text, facilitating interaction between humans and machines. One of the\nmost common applications of ASR is Speech-To-Text (STT) technology, which\nsimplifies user workflows by transcribing spoken words into text. In the\nmedical field, STT has the potential to significantly reduce the workload of\nclinicians who rely on typists to transcribe their voice recordings. However,\ndeveloping an STT model for the medical domain is challenging due to the lack\nof sufficient speech and text datasets. To address this issue, we propose a\nmedical-domain text correction method that modifies the output text of a\ngeneral STT system using the Vision Language Pre-training (VLP) method. VLP\ncombines textual and visual information to correct text based on image\nknowledge. Our extensive experiments demonstrate that the proposed method\noffers quantitatively and clinically significant improvements in STT\nperformance in the medical field. We further show that multi-modal\nunderstanding of image and text information outperforms single-modal\nunderstanding using only text information.\n","authors":["Jaeyoung Huh","Sangjoon Park","Jeong Eun Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2303.00091v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.14052v1","updated":"2023-02-27T18:59:58Z","published":"2023-02-27T18:59:58Z","title":"LODE: Locally Conditioned Eikonal Implicit Scene Completion from Sparse\n  LiDAR","summary":"  Scene completion refers to obtaining dense scene representation from an\nincomplete perception of complex 3D scenes. This helps robots detect\nmulti-scale obstacles and analyse object occlusions in scenarios such as\nautonomous driving. Recent advances show that implicit representation learning\ncan be leveraged for continuous scene completion and achieved through physical\nconstraints like Eikonal equations. However, former Eikonal completion methods\nonly demonstrate results on watertight meshes at a scale of tens of meshes.\nNone of them are successfully done for non-watertight LiDAR point clouds of\nopen large scenes at a scale of thousands of scenes. In this paper, we propose\na novel Eikonal formulation that conditions the implicit representation on\nlocalized shape priors which function as dense boundary value constraints, and\ndemonstrate it works on SemanticKITTI and SemanticPOSS. It can also be extended\nto semantic Eikonal scene completion with only small modifications to the\nnetwork architecture. With extensive quantitative and qualitative results, we\ndemonstrate the benefits and drawbacks of existing Eikonal methods, which\nnaturally leads to the new locally conditioned formulation. Notably, we improve\nIoU from 31.7% to 51.2% on SemanticKITTI and from 40.5% to 48.7% on\nSemanticPOSS. We extensively ablate our methods and demonstrate that the\nproposed formulation is robust to a wide spectrum of implementation\nhyper-parameters. Codes and models are publicly available at\nhttps://github.com/AIR-DISCOVER/LODE.\n","authors":["Pengfei Li","Ruowen Zhao","Yongliang Shi","Hao Zhao","Jirui Yuan","Guyue Zhou","Ya-Qin Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14052v1.pdf","comment":"Accepted by ICRA 2023. Code: https://github.com/AIR-DISCOVER/LODE.\n  arXiv admin note: substantial text overlap with arXiv:2111.14798"},{"id":"http://arxiv.org/abs/2302.14051v1","updated":"2023-02-27T18:59:55Z","published":"2023-02-27T18:59:55Z","title":"Internet Explorer: Targeted Representation Learning on the Open Web","summary":"  Modern vision models typically rely on fine-tuning general-purpose models\npre-trained on large, static datasets. These general-purpose models only\ncapture the knowledge within their pre-training datasets, which are tiny,\nout-of-date snapshots of the Internet -- where billions of images are uploaded\neach day. We suggest an alternate approach: rather than hoping our static\ndatasets transfer to our desired tasks after large-scale pre-training, we\npropose dynamically utilizing the Internet to quickly train a small-scale model\nthat does extremely well on the task at hand. Our approach, called Internet\nExplorer, explores the web in a self-supervised manner to progressively find\nrelevant examples that improve performance on a desired target dataset. It\ncycles between searching for images on the Internet with text queries,\nself-supervised training on downloaded images, determining which images were\nuseful, and prioritizing what to search for next. We evaluate Internet Explorer\nacross several datasets and show that it outperforms or matches CLIP oracle\nperformance by using just a single GPU desktop to actively query the Internet\nfor 30--40 hours. Results, visualizations, and videos at\nhttps://internet-explorer-ssl.github.io/\n","authors":["Alexander C. Li","Ellis Brown","Alexei A. Efros","Deepak Pathak"],"pdf_url":"https://arxiv.org/pdf/2302.14051v1.pdf","comment":"Website at https://internet-explorer-ssl.github.io/"},{"id":"http://arxiv.org/abs/2302.14045v1","updated":"2023-02-27T18:55:27Z","published":"2023-02-27T18:55:27Z","title":"Language Is Not All You Need: Aligning Perception with Language Models","summary":"  A big convergence of language, multimodal perception, action, and world\nmodeling is a key step toward artificial general intelligence. In this work, we\nintroduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive\ngeneral modalities, learn in context (i.e., few-shot), and follow instructions\n(i.e., zero-shot). Specifically, we train Kosmos-1 from scratch on web-scale\nmultimodal corpora, including arbitrarily interleaved text and images,\nimage-caption pairs, and text data. We evaluate various settings, including\nzero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range\nof tasks without any gradient updates or finetuning. Experimental results show\nthat Kosmos-1 achieves impressive performance on (i) language understanding,\ngeneration, and even OCR-free NLP (directly fed with document images), (ii)\nperception-language tasks, including multimodal dialogue, image captioning,\nvisual question answering, and (iii) vision tasks, such as image recognition\nwith descriptions (specifying classification via text instructions). We also\nshow that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge\nfrom language to multimodal, and from multimodal to language. In addition, we\nintroduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning\ncapability of MLLMs.\n","authors":["Shaohan Huang","Li Dong","Wenhui Wang","Yaru Hao","Saksham Singhal","Shuming Ma","Tengchao Lv","Lei Cui","Owais Khan Mohammed","Qiang Liu","Kriti Aggarwal","Zewen Chi","Johan Bjorck","Vishrav Chaudhary","Subhojit Som","Xia Song","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2302.14045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14042v1","updated":"2023-02-27T18:53:10Z","published":"2023-02-27T18:53:10Z","title":"Knowledge-enhanced Pre-training for Auto-diagnosis of Chest Radiology\n  Images","summary":"  Despite of the success of multi-modal foundation models pre-trained on\nlarge-scale data in natural language understanding and vision recognition, its\ncounterpart in medical and clinical domains remains preliminary, due to the\nfine-grained recognition nature of the medical tasks with high demands on\ndomain knowledge. Here, we propose a knowledge-enhanced vision-language\npre-training approach for auto-diagnosis on chest X-ray images. The algorithm,\nnamed Knowledge-enhanced Auto Diagnosis~(KAD), first trains a knowledge encoder\nbased on an existing medical knowledge graph, i.e., learning neural embeddings\nof the definitions and relationships between medical concepts and then\nleverages the pre-trained knowledge encoder to guide the visual representation\nlearning with paired chest X-rays and radiology reports. We experimentally\nvalidate KAD's effectiveness on three external X-ray datasets. The zero-shot\nperformance of KAD is not only comparable to that of the fully-supervised\nmodels but also, for the first time, superior to the average of three expert\nradiologists for three (out of five) pathologies with statistical significance.\nWhen the few-shot annotation is available, KAD also surpasses all existing\napproaches in finetuning settings, demonstrating the potential for application\nin different clinical scenarios.\n","authors":["Xiaoman Zhang","Chaoyi Wu","Ya Zhang","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2302.14042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14039v1","updated":"2023-02-27T18:51:29Z","published":"2023-02-27T18:51:29Z","title":"Image-based Pose Estimation and Shape Reconstruction for Robot\n  Manipulators and Soft, Continuum Robots via Differentiable Rendering","summary":"  State estimation from measured data is crucial for robotic applications as\nautonomous systems rely on sensors to capture the motion and localize in the 3D\nworld. Among sensors that are designed for measuring a robot's pose, or for\nsoft robots, their shape, vision sensors are favorable because they are\ninformation-rich, easy to set up, and cost-effective. With recent advancements\nin computer vision, deep learning-based methods no longer require markers for\nidentifying feature points on the robot. However, learning-based methods are\ndata-hungry and hence not suitable for soft and prototyping robots, as building\nsuch bench-marking datasets is usually infeasible. In this work, we achieve\nimage-based robot pose estimation and shape reconstruction from camera images.\nOur method requires no precise robot meshes, but rather utilizes a\ndifferentiable renderer and primitive shapes. It hence can be applied to robots\nfor which CAD models might not be available or are crude. Our parameter\nestimation pipeline is fully differentiable. The robot shape and pose are\nestimated iteratively by back-propagating the image loss to update the\nparameters. We demonstrate that our method of using geometrical shape\nprimitives can achieve high accuracy in shape reconstruction for a soft\ncontinuum robot and pose estimation for a robot manipulator.\n","authors":["Jingpei Lu","Fei Liu","Cedric Girerd","Michael C. Yip"],"pdf_url":"https://arxiv.org/pdf/2302.14039v1.pdf","comment":"7 pages, 7 figures, accepted to ICRA 2023"},{"id":"http://arxiv.org/abs/2205.01490v2","updated":"2023-02-27T18:44:42Z","published":"2022-05-03T13:43:47Z","title":"Subspace Diffusion Generative Models","summary":"  Score-based models generate samples by mapping noise to data (and vice versa)\nvia a high-dimensional diffusion process. We question whether it is necessary\nto run this entire process at high dimensionality and incur all the\ninconveniences thereof. Instead, we restrict the diffusion via projections onto\nsubspaces as the data distribution evolves toward noise. When applied to\nstate-of-the-art models, our framework simultaneously improves sample quality\n-- reaching an FID of 2.17 on unconditional CIFAR-10 -- and reduces the\ncomputational cost of inference for the same number of denoising steps. Our\nframework is fully compatible with continuous-time diffusion and retains its\nflexible capabilities, including exact log-likelihoods and controllable\ngeneration. Code is available at\nhttps://github.com/bjing2016/subspace-diffusion.\n","authors":["Bowen Jing","Gabriele Corso","Renato Berlinghieri","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2205.01490v2.pdf","comment":"ECCV 2022"},{"id":"http://arxiv.org/abs/2207.04551v2","updated":"2023-02-27T18:05:32Z","published":"2022-07-10T22:12:00Z","title":"Depth Perspective-aware Multiple Object Tracking","summary":"  This paper aims to tackle Multiple Object Tracking (MOT), an important\nproblem in computer vision but remains challenging due to many practical\nissues, especially occlusions. Indeed, we propose a new real-time Depth\nPerspective-aware Multiple Object Tracking (DP-MOT) approach to tackle the\nocclusion problem in MOT. A simple yet efficient Subject-Ordered Depth\nEstimation (SODE) is first proposed to automatically order the depth positions\nof detected subjects in a 2D scene in an unsupervised manner. Using the output\nfrom SODE, a new Active pseudo-3D Kalman filter, a simple but effective\nextension of Kalman filter with dynamic control variables, is then proposed to\ndynamically update the movement of objects. In addition, a new high-order\nassociation approach is presented in the data association step to incorporate\nfirst-order and second-order relationships between the detected objects. The\nproposed approach consistently achieves state-of-the-art performance compared\nto recent MOT methods on standard MOT benchmarks.\n","authors":["Kha Gia Quach","Huu Le","Pha Nguyen","Chi Nhan Duong","Tien Dai Bui","Khoa Luu"],"pdf_url":"https://arxiv.org/pdf/2207.04551v2.pdf","comment":"In review PR journal"},{"id":"http://arxiv.org/abs/2207.01971v4","updated":"2023-02-27T17:58:11Z","published":"2022-07-05T11:30:37Z","title":"DualAfford: Learning Collaborative Visual Affordance for Dual-gripper\n  Object Manipulation","summary":"  It is essential yet challenging for future home-assistant robots to\nunderstand and manipulate diverse 3D objects in daily human environments.\nTowards building scalable systems that can perform diverse manipulation tasks\nover various 3D shapes, recent works have advocated and demonstrated promising\nresults learning visual actionable affordance, which labels every point over\nthe input 3D geometry with an action likelihood of accomplishing the downstream\ntask (e.g., pushing or picking-up). However, these works only studied\nsingle-gripper manipulation tasks, yet many real-world tasks require two hands\nto achieve collaboratively. In this work, we propose a novel learning\nframework, DualAfford, to learn collaborative affordance for dual-gripper\nmanipulation tasks. The core design of the approach is to reduce the quadratic\nproblem for two grippers into two disentangled yet interconnected subtasks for\nefficient learning. Using the large-scale PartNet-Mobility and ShapeNet\ndatasets, we set up four benchmark tasks for dual-gripper manipulation.\nExperiments prove the effectiveness and superiority of our method over three\nbaselines.\n","authors":["Yan Zhao","Ruihai Wu","Zhehuan Chen","Yourong Zhang","Qingnan Fan","Kaichun Mo","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2207.01971v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14007v1","updated":"2023-02-27T17:56:18Z","published":"2023-02-27T17:56:18Z","title":"Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud\n  Pre-training","summary":"  Masked Autoencoders (MAE) have shown promising performance in self-supervised\nlearning for both 2D and 3D computer vision. However, existing MAE-style\nmethods can only learn from the data of a single modality, i.e., either images\nor point clouds, which neglect the implicit semantic and geometric correlation\nbetween 2D and 3D. In this paper, we explore how the 2D modality can benefit 3D\nmasked autoencoding, and propose Joint-MAE, a 2D-3D joint MAE framework for\nself-supervised 3D point cloud pre-training. Joint-MAE randomly masks an input\n3D point cloud and its projected 2D images, and then reconstructs the masked\ninformation of the two modalities. For better cross-modal interaction, we\nconstruct our JointMAE by two hierarchical 2D-3D embedding modules, a joint\nencoder, and a joint decoder with modal-shared and model-specific decoders. On\ntop of this, we further introduce two cross-modal strategies to boost the 3D\nrepresentation learning, which are local-aligned attention mechanisms for 2D-3D\nsemantic cues, and a cross-reconstruction loss for 2D-3D geometric constraints.\nBy our pre-training paradigm, Joint-MAE achieves superior performance on\nmultiple downstream tasks, e.g., 92.4% accuracy for linear SVM on ModelNet40\nand 86.07% accuracy on the hardest split of ScanObjectNN.\n","authors":["Ziyu Guo","Xianzhi Li","Pheng Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2302.14007v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.13996v1","updated":"2023-02-27T17:39:21Z","published":"2023-02-27T17:39:21Z","title":"Aligning Bag of Regions for Open-Vocabulary Object Detection","summary":"  Pre-trained vision-language models (VLMs) learn to align vision and language\nrepresentations on large-scale datasets, where each image-text pair usually\ncontains a bag of semantic concepts. However, existing open-vocabulary object\ndetectors only align region embeddings individually with the corresponding\nfeatures extracted from the VLMs. Such a design leaves the compositional\nstructure of semantic concepts in a scene under-exploited, although the\nstructure may be implicitly learned by the VLMs. In this work, we propose to\nalign the embedding of bag of regions beyond individual regions. The proposed\nmethod groups contextually interrelated regions as a bag. The embeddings of\nregions in a bag are treated as embeddings of words in a sentence, and they are\nsent to the text encoder of a VLM to obtain the bag-of-regions embedding, which\nis learned to be aligned to the corresponding features extracted by a frozen\nVLM. Applied to the commonly used Faster R-CNN, our approach surpasses the\nprevious best results by 4.6 box AP50 and 2.8 mask AP on novel categories of\nopen-vocabulary COCO and LVIS benchmarks, respectively. Code and models are\navailable at https://github.com/wusize/ovdet.\n","authors":["Size Wu","Wenwei Zhang","Sheng Jin","Wentao Liu","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2302.13996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13991v1","updated":"2023-02-27T17:30:00Z","published":"2023-02-27T17:30:00Z","title":"Learning to Generalize towards Unseen Domains via a Content-Aware Style\n  Invariant Framework for Disease Detection from Chest X-rays","summary":"  Performance degradation due to source domain mismatch is a longstanding\nchallenge in deep learning-based medical image analysis, particularly for chest\nX-rays. Several methods have been proposed to address this domain shift, such\nas utilizing adversarial learning or multi-domain mixups to extract\ndomain-invariant high-level features. However, these methods do not explicitly\naccount for or regularize the content and style attributes of the extracted\ndomain-invariant features. Recent studies have demonstrated that CNN models\nexhibit a strong bias toward styles (i.e., textures) rather than content, in\nstark contrast to the human-vision system. Explainable representations are\nparamount for a robust and generalizable understanding of medical images. Thus,\nthe learned high-level semantic features need to be both content-specific,\ni.e., pathology-specific and domain-agnostic, as well as style invariant.\nInspired by this, we propose a novel framework that improves cross-domain\nperformances by focusing more on content while reducing style bias. We employ a\nstyle randomization module at both image and feature levels to create stylized\nperturbation features while preserving the content using an end-to-end\nframework. We extract the global features from the backbone model for the same\nchest X-ray with and without style randomized. We apply content consistency\nregularization between them to tweak the framework's sensitivity toward content\nmarkers for accurate predictions. Extensive experiments on unseen domain test\ndatasets demonstrate that our proposed pipeline is more robust in the presence\nof domain shifts and achieves state-of-the-art performance. Our code is\navailable via\nhttps://github.com/rafizunaed/domain_agnostic_content_aware_style_invariant.\n","authors":["Mohammad Zunaed","Md. Aynal Haque","Taufiq Hasan"],"pdf_url":"https://arxiv.org/pdf/2302.13991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13987v1","updated":"2023-02-27T17:27:45Z","published":"2023-02-27T17:27:45Z","title":"UMIFormer: Mining the Correlations between Similar Tokens for Multi-View\n  3D Reconstruction","summary":"  In recent years, many video tasks have achieved breakthroughs by utilizing\nthe vision transformer and establishing spatial-temporal decoupling for feature\nextraction. Although multi-view 3D reconstruction also faces multiple images as\ninput, it cannot immediately inherit their success due to completely ambiguous\nassociations between unordered views. There is not usable prior relationship,\nwhich is similar to the temporally-coherence property in a video. To solve this\nproblem, we propose a novel transformer network for Unordered Multiple Images\n(UMIFormer). It exploits transformer blocks for decoupled intra-view encoding\nand designed blocks for token rectification that mine the correlation between\nsimilar tokens from different views to achieve decoupled inter-view encoding.\nAfterward, all tokens acquired from various branches are compressed into a\nfixed-size compact representation while preserving rich information for\nreconstruction by leveraging the similarities between tokens. We empirically\ndemonstrate on ShapeNet and confirm that our decoupled learning method is\nadaptable for unordered multiple images. Meanwhile, the experiments also verify\nour model outperforms existing SOTA methods by a large margin.\n","authors":["Zhenwei Zhu","Liying Yang","Ning Li","Chaohao Jiang","Yanyan Liang"],"pdf_url":"https://arxiv.org/pdf/2302.13987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05188v2","updated":"2023-02-27T17:24:45Z","published":"2022-05-10T21:55:26Z","title":"On Scale Space Radon Transform, Properties and Image Reconstruction","summary":"  When developing a Filtered Backprojection (FBP) algorithm, considering the\nRadon transform (RT) as a line integral necessitates assuming that all elements\nof the Computed Tomography (CT) system, such as the detector cell, are\ndimensionless. It is generally the result of such inadequate CT modeling that\nanalytical methods are sensitive to artifacts and noise. Then, to address this\nproblem, several algebraic reconstruction techniques utilizing iterative models\nare suggested. The high computational cost of these methods restricts their\napplication. In this paper, we propose the utilization of the Scale Space Radon\nTransform (SSRT), recognized for its good behavior in the scale space where,\nthe detector width is already considered into the SSRT design and is controlled\nby the Gaussian kernel standard deviation. After depicting the basic properties\nand the inversion of SSRT, the FBP algorithm is used in two different ways to\nreconstruct the image from the SSRT sinogram: (1) Deconv-Rad-FBP: Deconvolve\nSSRT to estimate RT and apply FBP or (2) SSRT-FBP: Modify FBP such that RT\nspectrum used in FBP is replaced by SSRT, expressed in the frequency domain.\nComparison of image reconstruction using SSRT and RT are performed on\nShepp-Logan head and anthropomorphic abdominal phantoms by using, as quality\nmeasures, PSNR and SSIM. The first findings show that the SSRT-based image\nreconstruction quality is better than the one based on RT where, the SSRT-FBP\nmethod reveals to be the most accurate, especially, when the number of\nprojections is reduced, making it more appropriate for applications requiring\nlow-dose radiation such as medical X-ray CT. While SSRT-FBP and RT-FBP\nalgorithm have utmost the same execution time, the former is much faster than\nDeconv-Rad-FBP. Furthermore, the experiments show that the SSRT-FBP method is\nmore robust to CT data Poisson-Gaussian noise.\n","authors":["Nafaa Nacereddine","Djemel Ziou","Aicha Baya Goumeidane"],"pdf_url":"https://arxiv.org/pdf/2205.05188v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.10938v3","updated":"2023-02-27T17:22:15Z","published":"2022-04-22T21:46:52Z","title":"A Multi-level Alignment Training Scheme for Video-and-Language Grounding","summary":"  To solve video-and-language grounding tasks, the key is for the network to\nunderstand the connection between the two modalities. For a pair of video and\nlanguage description, their semantic relation is reflected by their encodings'\nsimilarity. A good multi-modality encoder should be able to well capture both\ninputs' semantics and encode them in the shared feature space where embedding\ndistance gets properly translated into their semantic similarity. In this work,\nwe focused on this semantic connection between video and language, and\ndeveloped a multi-level alignment training scheme to directly shape the\nencoding process. Global and segment levels of video-language alignment pairs\nwere designed, based on the information similarity ranging from high-level\ncontext to fine-grained semantics. The contrastive loss was used to contrast\nthe encodings' similarities between the positive and negative alignment pairs,\nand to ensure the network is trained in such a way that similar information is\nencoded closely in the shared feature space while information of different\nsemantics is kept apart. Our multi-level alignment training can be applied to\nvarious video-and-language grounding tasks. Together with the task-specific\ntraining loss, our framework achieved comparable performance to previous\nstate-of-the-arts on multiple video QA and retrieval datasets.\n","authors":["Yubo Zhang","Feiyang Niu","Qing Ping","Govind Thattai"],"pdf_url":"https://arxiv.org/pdf/2204.10938v3.pdf","comment":"Accepted at ICDM 2022 FOMO-VL workshop"},{"id":"http://arxiv.org/abs/2301.01914v2","updated":"2023-02-27T17:12:49Z","published":"2023-01-05T05:17:45Z","title":"Accuracy and Fidelity Comparison of Luna and DALL-E 2 Diffusion-Based\n  Image Generation Systems","summary":"  We qualitatively examine the accuracy and fidelity between two\ndiffusion-based image generation systems, namely DALL-E 2 and Luna, which have\nmassive differences in training datasets, algorithmic approaches, prompt\nresolvement, and output upscaling. The methodology used is a qualitative\nbenchmark created by Saharia et al. and in our research we conclude that DALL-E\n2 significantly edges Luna in both alignment and fidelity comparisons.\n","authors":["Michael Cahyadi","Muhammad Rafi","William Shan","Jurike Moniaga","Henry Lucky"],"pdf_url":"https://arxiv.org/pdf/2301.01914v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07237v3","updated":"2023-02-27T17:08:39Z","published":"2022-09-15T12:07:09Z","title":"Robust Implementation of Foreground Extraction and Vessel Segmentation\n  for X-ray Coronary Angiography Image Sequence","summary":"  The extraction of contrast-filled vessels from X-ray coronary angiography\n(XCA) image sequence has important clinical significance for intuitively\ndiagnosis and therapy. In this study, the XCA image sequence is regarded as a\n3D tensor input, the vessel layer is regarded as a sparse tensor, and the\nbackground layer is regarded as a low-rank tensor. Using tensor nuclear norm\n(TNN) minimization, a novel method for vessel layer extraction based on tensor\nrobust principal component analysis (TRPCA) is proposed. Furthermore,\nconsidering the irregular movement of vessels and the low-frequency dynamic\ndisturbance of surrounding irrelevant tissues, the total variation (TV)\nregularized spatial-temporal constraint is introduced to smooth the foreground\nlayer. Subsequently, for vessel layer images with uneven contrast distribution,\na two-stage region growing (TSRG) method is utilized for vessel enhancement and\nsegmentation. A global threshold method is used as the preprocessing to obtain\nmain branches, and the Radon-Like features (RLF) filter is used to enhance and\nconnect broken minor segments, the final binary vessel mask is constructed by\ncombining the two intermediate results. The visibility of TV-TRPCA algorithm\nfor foreground extraction is evaluated on clinical XCA image sequences and\nthird-party dataset, which can effectively improve the performance of commonly\nused vessel segmentation algorithms. Based on TV-TRPCA, the accuracy of TSRG\nalgorithm for vessel segmentation is further evaluated. Both qualitative and\nquantitative results validate the superiority of the proposed method over\nexisting state-of-the-art approaches.\n","authors":["Zeyu Fu","Zhuang Fu","Chenzhuo Lu","Jun Yan","Jian Fei","Hui Han"],"pdf_url":"https://arxiv.org/pdf/2209.07237v3.pdf","comment":"34pages, 14figures, 5tables"},{"id":"http://arxiv.org/abs/2302.13961v1","updated":"2023-02-27T17:02:30Z","published":"2023-02-27T17:02:30Z","title":"Soft labelling for semantic segmentation: Bringing coherence to label\n  down-sampling","summary":"  In semantic segmentation, training data down-sampling is commonly performed\nbecause of limited resources, adapting image size to the model input, or\nimproving data augmentation. This down-sampling typically employs different\nstrategies for the image data and the annotated labels. Such discrepancy leads\nto mismatches between the down-sampled pixels and labels. Hence, training\nperformance significantly decreases as the down-sampling factor increases. In\nthis paper, we bring together the downsampling strategies for the image data\nand annotated labels. To that aim, we propose a soft-labeling method for label\ndown-sampling that takes advantage of structural content prior to\ndown-sampling. Thereby, fully aligning softlabels with image data to keep the\ndistribution of the sampled pixels. This proposal also produces richer\nannotations for under-represented semantic classes. Altogether, it permits\ntraining competitive models at lower resolutions. Experiments show that the\nproposal outperforms other downsampling strategies. Moreover, state of the art\nperformance is achieved for reference benchmarks, but employing significantly\nless computational resources than other approaches. This proposal enables\ncompetitive research for semantic segmentation under resource constraints.\n","authors":["Roberto Alcover-Couso","Marcos Escudero-Vinolo","Juan C. SanMiguel"],"pdf_url":"https://arxiv.org/pdf/2302.13961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13933v1","updated":"2023-02-27T16:34:16Z","published":"2023-02-27T16:34:16Z","title":"LAformer: Trajectory Prediction for Autonomous Driving with Lane-Aware\n  Scene Constraints","summary":"  Trajectory prediction for autonomous driving must continuously reason the\nmotion stochasticity of road agents and comply with scene constraints. Existing\nmethods typically rely on one-stage trajectory prediction models, which\ncondition future trajectories on observed trajectories combined with fused\nscene information. However, they often struggle with complex scene constraints,\nsuch as those encountered at intersections. To this end, we present a novel\nmethod, called LAformer. It uses a temporally dense lane-aware estimation\nmodule to select only the top highly potential lane segments in an HD map,\nwhich effectively and continuously aligns motion dynamics with scene\ninformation, reducing the representation requirements for the subsequent\nattention-based decoder by filtering out irrelevant lane segments.\nAdditionally, unlike one-stage prediction models, LAformer utilizes predictions\nfrom the first stage as anchor trajectories and adds a second-stage motion\nrefinement module to further explore temporal consistency across the complete\ntime horizon. Extensive experiments on Argoverse 1 and nuScenes demonstrate\nthat LAformer achieves excellent performance for multimodal trajectory\nprediction.\n","authors":["Mengmeng Liu","Hao Cheng","Lin Chen","Hellward Broszio","Jiangtao Li","Runjiang Zhao","Monika Sester","Michael Ying Yang"],"pdf_url":"https://arxiv.org/pdf/2302.13933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04423v2","updated":"2023-02-27T16:25:17Z","published":"2023-01-11T12:02:10Z","title":"Multi-Scanner Canine Cutaneous Squamous Cell Carcinoma Histopathology\n  Dataset","summary":"  In histopathology, scanner-induced domain shifts are known to impede the\nperformance of trained neural networks when tested on unseen data. Multi-domain\npre-training or dedicated domain-generalization techniques can help to develop\ndomain-agnostic algorithms. For this, multi-scanner datasets with a high\nvariety of slide scanning systems are highly desirable. We present a publicly\navailable multi-scanner dataset of canine cutaneous squamous cell carcinoma\nhistopathology images, composed of 44 samples digitized with five slide\nscanners. This dataset provides local correspondences between images and\nthereby isolates the scanner-induced domain shift from other inherent, e.g.\nmorphology-induced domain shifts. To highlight scanner differences, we present\na detailed evaluation of color distributions, sharpness, and contrast of the\nindividual scanner subsets. Additionally, to quantify the inherent\nscanner-induced domain shift, we train a tumor segmentation network on each\nscanner subset and evaluate the performance both in- and cross-domain. We\nachieve a class-averaged in-domain intersection over union coefficient of up to\n0.86 and observe a cross-domain performance decrease of up to 0.38, which\nconfirms the inherent domain shift of the presented dataset and its negative\nimpact on the performance of deep neural networks.\n","authors":["Frauke Wilm","Marco Fragoso","Christof A. Bertram","Nikolas Stathonikos","Mathias Öttl","Jingna Qiu","Robert Klopfleisch","Andreas Maier","Katharina Breininger","Marc Aubreville"],"pdf_url":"https://arxiv.org/pdf/2301.04423v2.pdf","comment":"6 pages, 3 figures, 1 table, accepted at BVM workshop 2023"},{"id":"http://arxiv.org/abs/2302.13926v1","updated":"2023-02-27T16:23:19Z","published":"2023-02-27T16:23:19Z","title":"Image to Sphere: Learning Equivariant Features for Efficient Pose\n  Prediction","summary":"  Predicting the pose of objects from a single image is an important but\ndifficult computer vision problem. Methods that predict a single point estimate\ndo not predict the pose of objects with symmetries well and cannot represent\nuncertainty. Alternatively, some works predict a distribution over orientations\nin $\\mathrm{SO}(3)$. However, training such models can be computation- and\nsample-inefficient. Instead, we propose a novel mapping of features from the\nimage domain to the 3D rotation manifold. Our method then leverages\n$\\mathrm{SO}(3)$ equivariant layers, which are more sample efficient, and\noutputs a distribution over rotations that can be sampled at arbitrary\nresolution. We demonstrate the effectiveness of our method at object\norientation prediction, and achieve state-of-the-art performance on the popular\nPASCAL3D+ dataset. Moreover, we show that our method can model complex object\nsymmetries, without any modifications to the parameters or loss function. Code\nis available at https://dmklee.github.io/image2sphere.\n","authors":["David M. Klee","Ondrej Biza","Robert Platt","Robin Walters"],"pdf_url":"https://arxiv.org/pdf/2302.13926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04797v3","updated":"2023-02-27T16:07:28Z","published":"2022-06-06T21:56:11Z","title":"Memory-efficient model-based deep learning with convergence and\n  robustness guarantees","summary":"  Computational imaging has been revolutionized by compressed sensing\nalgorithms, which offer guaranteed uniqueness, convergence, and stability\nproperties. Model-based deep learning methods that combine imaging physics with\nlearned regularization priors have emerged as more powerful alternatives for\nimage recovery. The main focus of this paper is to introduce a memory efficient\nmodel-based algorithm with similar theoretical guarantees as CS methods. The\nproposed iterative algorithm alternates between a gradient descent involving\nthe score function and a conjugate gradient algorithm to encourage data\nconsistency. The score function is modeled as a monotone convolutional neural\nnetwork. Our analysis shows that the monotone constraint is necessary and\nsufficient to enforce the uniqueness of the fixed point in arbitrary inverse\nproblems. In addition, it also guarantees the convergence to a fixed point,\nwhich is robust to input perturbations. We introduce two implementations of the\nproposed MOL framework, which differ in the way the monotone property is\nimposed. The first approach enforces a strict monotone constraint, while the\nsecond one relies on an approximation. The guarantees are not valid for the\nsecond approach in the strict sense. However, our empirical studies show that\nthe convergence and robustness of both approaches are comparable, while the\nless constrained approximate implementation offers better performance. The\nproposed deep equilibrium formulation is significantly more memory efficient\nthan unrolled methods, which allows us to apply it to 3D or 2D+time problems\nthat current unrolled algorithms cannot handle.\n","authors":["Aniket Pramanik","Mathews Jacob"],"pdf_url":"https://arxiv.org/pdf/2206.04797v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13902v1","updated":"2023-02-27T15:44:24Z","published":"2023-02-27T15:44:24Z","title":"Language identification as improvement for lip-based biometric visual\n  systems","summary":"  Language has always been one of humanity's defining characteristics. Visual\nLanguage Identification (VLI) is a relatively new field of research that is\ncomplex and largely understudied. In this paper, we present a preliminary study\nin which we use linguistic information as a soft biometric trait to enhance the\nperformance of a visual (auditory-free) identification system based on lip\nmovement. We report a significant improvement in the identification performance\nof the proposed visual system as a result of the integration of these data\nusing a score-based fusion strategy. Methods of Deep and Machine Learning are\nconsidered and evaluated. To the experimentation purposes, the dataset called\nlaBial Articulation for the proBlem of the spokEn Language rEcognition\n(BABELE), consisting of eight different languages, has been created. It\nincludes a collection of different features of which the spoken language\nrepresents the most relevant, while each sample is also manually labelled with\ngender and age of the subjects.\n","authors":["Lucia Cascone","Michele Nappi","Fabio Narducci"],"pdf_url":"https://arxiv.org/pdf/2302.13902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13891v1","updated":"2023-02-27T15:36:14Z","published":"2023-02-27T15:36:14Z","title":"Supervised Virtual-to-Real Domain Adaptation for Object Detection Task\n  using YOLO","summary":"  Deep neural network shows excellent use in a lot of real-world tasks. One of\nthe deep learning tasks is object detection. Well-annotated datasets will\naffect deep neural network accuracy. More data learned by deep neural networks\nwill make the model more accurate. However, a well-annotated dataset is hard to\nfind, especially in a specific domain. To overcome this, computer-generated\ndata or virtual datasets are used. Researchers could generate many images with\nspecific use cases also with its annotation. Research studies showed that\nvirtual datasets could be used for object detection tasks. Nevertheless, with\nthe usage of the virtual dataset, the model must adapt to real datasets, or the\nmodel must have domain adaptability features. We explored the domain adaptation\ninside the object detection model using a virtual dataset to overcome a few\nwell-annotated datasets. We use VW-PPE dataset, using 5000 and 10000 virtual\ndata and 220 real data. For model architecture, we used YOLOv4 using\nCSPDarknet53 as the backbone and PAN as the neck. The domain adaptation\ntechnique with fine-tuning only on backbone weight achieved a mean average\nprecision of 74.457%.\n","authors":["Akbar Satya Nugraha","Yudistira Novanto","Bayu Rahayudi"],"pdf_url":"https://arxiv.org/pdf/2302.13891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13869v1","updated":"2023-02-27T15:17:01Z","published":"2023-02-27T15:17:01Z","title":"EDMAE: An Efficient Decoupled Masked Autoencoder for Standard View\n  Identification in Pediatric Echocardiography","summary":"  We propose an efficient decoupled mask autoencoder (EDMAE) for standard view\nrecognition in Pediatric Echocardiography, which is an unsupervised (or\nself-supervised) method. By building a novel proxy task, EDMAE is pretrained on\na large-scale unlabeled pediatric cardiac ultrasound dataset to achieve\nexcellent performance in downstream tasks of standard plane recognition. EDMAE\nimproves training efficiency by using pure convolutional operations, and forces\nthe encoder to extract more and higher quality semantic information by\ndecoupling the encoder and decoder. Extensive experiments have demonstrated the\neffectiveness of the proposed method.\n","authors":["Yiman Liu","Xiaoxiang Han","Tongtong Liang","Qiaohong Liu","Qingli Li","Yuqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13869v1.pdf","comment":"12 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.03023v2","updated":"2023-02-27T15:03:28Z","published":"2023-02-06T18:58:38Z","title":"V1T: large-scale mouse V1 response prediction using a Vision Transformer","summary":"  Accurate predictive models of the visual cortex neural response to natural\nvisual stimuli remain a challenge in computational neuroscience. In this work,\nwe introduce V1T, a novel Vision Transformer based architecture that learns a\nshared visual and behavioral representation across animals. We evaluate our\nmodel on two large datasets recorded from mouse primary visual cortex and\noutperform previous convolution-based models by more than 12.7% in prediction\nperformance. Moreover, we show that the attention weights learned by the\nTransformer correlate with the population receptive fields. Our model thus sets\na new benchmark for neural response prediction and captures characteristic\nfeatures of the visual cortex.\n","authors":["Bryan M. Li","Isabel M. Cornacchia","Nathalie L. Rochefort","Arno Onken"],"pdf_url":"https://arxiv.org/pdf/2302.03023v2.pdf","comment":"updated references and added link to code repository"},{"id":"http://arxiv.org/abs/2302.13861v1","updated":"2023-02-27T15:02:04Z","published":"2023-02-27T15:02:04Z","title":"Differentially Private Diffusion Models Generate Useful Synthetic Images","summary":"  The ability to generate privacy-preserving synthetic versions of sensitive\nimage datasets could unlock numerous ML applications currently constrained by\ndata availability. Due to their astonishing image generation quality, diffusion\nmodels are a prime candidate for generating high-quality synthetic data.\nHowever, recent studies have found that, by default, the outputs of some\ndiffusion models do not preserve training data privacy. By privately\nfine-tuning ImageNet pre-trained diffusion models with more than 80M\nparameters, we obtain SOTA results on CIFAR-10 and Camelyon17 in terms of both\nFID and the accuracy of downstream classifiers trained on synthetic data. We\ndecrease the SOTA FID on CIFAR-10 from 26.2 to 9.8, and increase the accuracy\nfrom 51.0% to 88.0%. On synthetic data from Camelyon17, we achieve a downstream\naccuracy of 91.1% which is close to the SOTA of 96.5% when training on the real\ndata. We leverage the ability of generative models to create infinite amounts\nof data to maximise the downstream prediction performance, and further show how\nto use synthetic data for hyperparameter tuning. Our results demonstrate that\ndiffusion models fine-tuned with differential privacy can produce useful and\nprovably private synthetic data, even in applications with significant\ndistribution shift between the pre-training and fine-tuning distributions.\n","authors":["Sahra Ghalebikesabi","Leonard Berrada","Sven Gowal","Ira Ktena","Robert Stanforth","Jamie Hayes","Soham De","Samuel L. Smith","Olivia Wiles","Borja Balle"],"pdf_url":"https://arxiv.org/pdf/2302.13861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13848v1","updated":"2023-02-27T14:49:53Z","published":"2023-02-27T14:49:53Z","title":"ELITE: Encoding Visual Concepts into Textual Embeddings for Customized\n  Text-to-Image Generation","summary":"  Despite unprecedented ability in imaginary creation, large text-to-image\nmodels are further expected to express customized concepts. Existing works\ngenerally learn such concepts in an optimization-based manner, yet bringing\nexcessive computation or memory burden. In this paper, we instead propose a\nlearning-based encoder for fast and accurate concept customization, which\nconsists of global and local mapping networks. In specific, the global mapping\nnetwork separately projects the hierarchical features of a given image into\nmultiple ``new'' words in the textual word embedding space, i.e., one primary\nword for well-editable concept and other auxiliary words to exclude irrelevant\ndisturbances (e.g., background). In the meantime, a local mapping network\ninjects the encoded patch features into cross attention layers to provide\nomitted details, without sacrificing the editability of primary concepts. We\ncompare our method with prior optimization-based approaches on a variety of\nuser-defined concepts, and demonstrate that our method enables more\nhigh-fidelity inversion and robust editability with a significantly faster\nencoding process. Our code will be publicly available at\nhttps://github.com/csyxwei/ELITE.\n","authors":["Yuxiang Wei","Yabo Zhang","Zhilong Ji","Jinfeng Bai","Lei Zhang","Wangmeng Zuo"],"pdf_url":"https://arxiv.org/pdf/2302.13848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13840v1","updated":"2023-02-27T14:40:58Z","published":"2023-02-27T14:40:58Z","title":"Target-Aware Tracking with Long-term Context Attention","summary":"  Most deep trackers still follow the guidance of the siamese paradigms and use\na template that contains only the target without any contextual information,\nwhich makes it difficult for the tracker to cope with large appearance changes,\nrapid target movement, and attraction from similar objects. To alleviate the\nabove problem, we propose a long-term context attention (LCA) module that can\nperform extensive information fusion on the target and its context from\nlong-term frames, and calculate the target correlation while enhancing target\nfeatures. The complete contextual information contains the location of the\ntarget as well as the state around the target. LCA uses the target state from\nthe previous frame to exclude the interference of similar objects and complex\nbackgrounds, thus accurately locating the target and enabling the tracker to\nobtain higher robustness and regression accuracy. By embedding the LCA module\nin Transformer, we build a powerful online tracker with a target-aware\nbackbone, termed as TATrack. In addition, we propose a dynamic online update\nalgorithm based on the classification confidence of historical information\nwithout additional calculation burden. Our tracker achieves state-of-the-art\nperformance on multiple benchmarks, with 71.1\\% AUC, 89.3\\% NP, and 73.0\\% AO\non LaSOT, TrackingNet, and GOT-10k. The code and trained models are available\non https://github.com/hekaijie123/TATrack.\n","authors":["Kaijie He","Canlong Zhang","Sheng Xie","Zhixin Li","Zhiwen Wang"],"pdf_url":"https://arxiv.org/pdf/2302.13840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13838v1","updated":"2023-02-27T14:39:50Z","published":"2023-02-27T14:39:50Z","title":"Cross-modal Face- and Voice-style Transfer","summary":"  Image-to-image translation and voice conversion enable the generation of a\nnew facial image and voice while maintaining some of the semantics such as a\npose in an image and linguistic content in audio, respectively. They can aid in\nthe content-creation process in many applications. However, as they are limited\nto the conversion within each modality, matching the impression of the\ngenerated face and voice remains an open question. We propose a cross-modal\nstyle transfer framework called XFaVoT that jointly learns four tasks: image\ntranslation and voice conversion tasks with audio or image guidance, which\nenables the generation of ``face that matches given voice\" and ``voice that\nmatches given face\", and intra-modality translation tasks with a single\nframework. Experimental results on multiple datasets show that XFaVoT achieves\ncross-modal style translation of image and voice, outperforming baselines in\nterms of quality, diversity, and face-voice correspondence.\n","authors":["Naoya Takahashi","Mayank K. Singh","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2302.13838v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1912.01865 by other authors"},{"id":"http://arxiv.org/abs/2302.13824v1","updated":"2023-02-27T14:33:29Z","published":"2023-02-27T14:33:29Z","title":"Dirichlet-based Uncertainty Calibration for Active Domain Adaptation","summary":"  Active domain adaptation (DA) aims to maximally boost the model adaptation on\na new target domain by actively selecting limited target data to annotate,\nwhereas traditional active learning methods may be less effective since they do\nnot consider the domain shift issue. Despite active DA methods address this by\nfurther proposing targetness to measure the representativeness of target domain\ncharacteristics, their predictive uncertainty is usually based on the\nprediction of deterministic models, which can easily be miscalibrated on data\nwith distribution shift. Considering this, we propose a \\textit{Dirichlet-based\nUncertainty Calibration} (DUC) approach for active DA, which simultaneously\nachieves the mitigation of miscalibration and the selection of informative\ntarget samples. Specifically, we place a Dirichlet prior on the prediction and\ninterpret the prediction as a distribution on the probability simplex, rather\nthan a point estimate like deterministic models. This manner enables us to\nconsider all possible predictions, mitigating the miscalibration of unilateral\nprediction. Then a two-round selection strategy based on different uncertainty\norigins is designed to select target samples that are both representative of\ntarget domain and conducive to discriminability. Extensive experiments on\ncross-domain image classification and semantic segmentation validate the\nsuperiority of DUC.\n","authors":["Mixue Xie","Shuang Li","Rui Zhang","Chi Harold Liu"],"pdf_url":"https://arxiv.org/pdf/2302.13824v1.pdf","comment":"Accepted at ICLR 2023 as Spotlight"},{"id":"http://arxiv.org/abs/2210.09461v2","updated":"2023-02-27T14:25:08Z","published":"2022-10-17T22:23:40Z","title":"Token Merging: Your ViT But Faster","summary":"  We introduce Token Merging (ToMe), a simple method to increase the throughput\nof existing ViT models without needing to train. ToMe gradually combines\nsimilar tokens in a transformer using a general and light-weight matching\nalgorithm that is as fast as pruning while being more accurate. Off-the-shelf,\nToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518\nmodels on images and 2.2x the throughput of ViT-L on video with only a 0.2-0.3%\naccuracy drop in each case. ToMe can also easily be applied during training,\nimproving in practice training speed up to 2x for MAE fine-tuning on video.\nTraining with ToMe further minimizes accuracy drop, leading to 2x the\nthroughput of ViT-B on audio for only a 0.4% mAP drop. Qualitatively, we find\nthat ToMe merges object parts into one token, even over multiple frames of\nvideo. Overall, ToMe's accuracy and speed are competitive with state-of-the-art\non images, video, and audio.\n","authors":["Daniel Bolya","Cheng-Yang Fu","Xiaoliang Dai","Peizhao Zhang","Christoph Feichtenhofer","Judy Hoffman"],"pdf_url":"https://arxiv.org/pdf/2210.09461v2.pdf","comment":"Accepted ICLR 2023 Oral (top 5%). This version includes stable\n  diffusion experiments. See code at https://github.com/facebookresearch/ToMe"},{"id":"http://arxiv.org/abs/2302.13800v1","updated":"2023-02-27T14:19:31Z","published":"2023-02-27T14:19:31Z","title":"Spatially-Adaptive Feature Modulation for Efficient Image\n  Super-Resolution","summary":"  Although numerous solutions have been proposed for image super-resolution,\nthey are usually incompatible with low-power devices with many computational\nand memory constraints. In this paper, we address this problem by proposing a\nsimple yet effective deep network to solve image super-resolution efficiently.\nIn detail, we develop a spatially-adaptive feature modulation (SAFM) mechanism\nupon a vision transformer (ViT)-like block. Within it, we first apply the SAFM\nblock over input features to dynamically select representative feature\nrepresentations. As the SAFM block processes the input features from a\nlong-range perspective, we further introduce a convolutional channel mixer\n(CCM) to simultaneously extract local contextual information and perform\nchannel mixing. Extensive experimental results show that the proposed method is\n$3\\times$ smaller than state-of-the-art efficient SR methods, e.g., IMDN, in\nterms of the network parameters and requires less computational cost while\nachieving comparable performance. The code is available at\nhttps://github.com/sunny2109/SAFMN.\n","authors":["Long Sun","Jiangxin Dong","Jinhui Tang","Jinshan Pan"],"pdf_url":"https://arxiv.org/pdf/2302.13800v1.pdf","comment":"The code is available at https://github.com/sunny2109/SAFMN"},{"id":"http://arxiv.org/abs/2302.13796v1","updated":"2023-02-27T14:14:52Z","published":"2023-02-27T14:14:52Z","title":"Fast Trajectory End-Point Prediction with Event Cameras for Reactive\n  Robot Control","summary":"  Prediction skills can be crucial for the success of tasks where robots have\nlimited time to act or joints actuation power. In such a scenario, a vision\nsystem with a fixed, possibly too low, sampling rate could lead to the loss of\ninformative points, slowing down prediction convergence and reducing the\naccuracy. In this paper, we propose to exploit the low latency, motion-driven\nsampling, and data compression properties of event cameras to overcome these\nissues. As a use-case, we use a Panda robotic arm to intercept a ball bouncing\non a table. To predict the interception point, we adopt a Stateful LSTM\nnetwork, a specific LSTM variant without fixed input length, which perfectly\nsuits the event-driven paradigm and the problem at hand, where the length of\nthe trajectory is not defined. We train the network in simulation to speed up\nthe dataset acquisition and then fine-tune the models on real trajectories.\nExperimental results demonstrate how using a dense spatial sampling (i.e. event\ncameras) significantly increases the number of intercepted trajectories as\ncompared to a fixed temporal sampling (i.e. frame-based cameras).\n","authors":["Marco Monforte","Luna Gava","Massimiliano Iacono","Arren Glover","Chiara Bartolozzi"],"pdf_url":"https://arxiv.org/pdf/2302.13796v1.pdf","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2210.14571v2","updated":"2023-02-27T14:11:56Z","published":"2022-10-26T09:01:19Z","title":"Towards the Detection of Diffusion Model Deepfakes","summary":"  Diffusion models (DMs) have recently emerged as a promising method in image\nsynthesis. However, to date, only little attention has been paid to the\ndetection of DM-generated images, which is critical to prevent adverse impacts\non our society. In this work, we address this pressing challenge from two\ndifferent angles: First, we evaluate the performance of state-of-the-art\ndetectors, which are very effective against images generated by generative\nadversarial networks (GANs), on a variety of DMs. Second, we analyze\nDM-generated images in the frequency domain and study different factors that\ninfluence the spectral properties of these images. Most importantly, we\ndemonstrate that GANs and DMs produce images with different characteristics,\nwhich requires adaptation of existing classifiers to ensure reliable detection.\nWe believe this work provides the foundation and starting point for further\nresearch to detect DM deepfakes effectively.\n","authors":["Jonas Ricker","Simon Damm","Thorsten Holz","Asja Fischer"],"pdf_url":"https://arxiv.org/pdf/2210.14571v2.pdf","comment":"29 pages, 24 figures"},{"id":"http://arxiv.org/abs/2009.02653v3","updated":"2023-02-27T13:52:42Z","published":"2020-09-06T06:13:09Z","title":"A Survey on Machine Learning from Few Samples","summary":"  Few sample learning (FSL) is significant and challenging in the field of\nmachine learning. The capability of learning and generalizing from very few\nsamples successfully is a noticeable demarcation separating artificial\nintelligence and human intelligence since humans can readily establish their\ncognition to novelty from just a single or a handful of examples whereas\nmachine learning algorithms typically entail hundreds or thousands of\nsupervised samples to guarantee generalization ability. Despite the long\nhistory dated back to the early 2000s and the widespread attention in recent\nyears with booming deep learning technologies, little surveys or reviews for\nFSL are available until now. In this context, we extensively review 300+ papers\nof FSL spanning from the 2000s to 2019 and provide a timely and comprehensive\nsurvey for FSL. In this survey, we review the evolution history as well as the\ncurrent progress on FSL, categorize FSL approaches into the generative model\nbased and discriminative model based kinds in principle, and emphasize\nparticularly on the meta learning based FSL approaches. We also summarize\nseveral recently emerging extensional topics of FSL and review the latest\nadvances on these topics. Furthermore, we highlight the important FSL\napplications covering many research hotspots in computer vision, natural\nlanguage processing, audio and speech, reinforcement learning and robotic, data\nanalysis, etc. Finally, we conclude the survey with a discussion on promising\ntrends in the hope of providing guidance and insights to follow-up researches.\n","authors":["Jiang Lu","Pinghua Gong","Jieping Ye","Jianwei Zhang","Changshui Zhang"],"pdf_url":"https://arxiv.org/pdf/2009.02653v3.pdf","comment":"30 pages, Accepted by Pattern Recognition, 2023"},{"id":"http://arxiv.org/abs/2302.13770v1","updated":"2023-02-27T13:52:38Z","published":"2023-02-27T13:52:38Z","title":"Mask Reference Image Quality Assessment","summary":"  Understanding semantic information is an essential step in knowing what is\nbeing learned in both full-reference (FR) and no-reference (NR) image quality\nassessment (IQA) methods. However, especially for many severely distorted\nimages, even if there is an undistorted image as a reference (FR-IQA), it is\ndifficult to perceive the lost semantic and texture information of distorted\nimages directly. In this paper, we propose a Mask Reference IQA (MR-IQA) method\nthat masks specific patches of a distorted image and supplements missing\npatches with the reference image patches. In this way, our model only needs to\ninput the reconstructed image for quality assessment. First, we design a mask\ngenerator to select the best candidate patches from reference images and\nsupplement the lost semantic information in distorted images, thus providing\nmore reference for quality assessment; in addition, the different masked\npatches imply different data augmentations, which favors model training and\nreduces overfitting. Second, we provide a Mask Reference Network (MRNet): the\ndedicated modules can prevent disturbances due to masked patches and help\neliminate the patch discontinuity in the reconstructed image. Our method\nachieves state-of-the-art performances on the benchmark KADID-10k, LIVE and\nCSIQ datasets and has better generalization performance across datasets. The\ncode and results are available in the supplementary material.\n","authors":["Pengxiang Xiao","Shuai He","Limin Liu","Anlong Ming"],"pdf_url":"https://arxiv.org/pdf/2302.13770v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.13766v1","updated":"2023-02-27T13:46:42Z","published":"2023-02-27T13:46:42Z","title":"Learning to Super-Resolve Blurry Images with Events","summary":"  Super-Resolution from a single motion Blurred image (SRB) is a severely\nill-posed problem due to the joint degradation of motion blurs and low spatial\nresolution. In this paper, we employ events to alleviate the burden of SRB and\npropose an Event-enhanced SRB (E-SRB) algorithm, which can generate a sequence\nof sharp and clear images with High Resolution (HR) from a single blurry image\nwith Low Resolution (LR). To achieve this end, we formulate an event-enhanced\ndegeneration model to consider the low spatial resolution, motion blurs, and\nevent noises simultaneously. We then build an event-enhanced Sparse Learning\nNetwork (eSL-Net++) upon a dual sparse learning scheme where both events and\nintensity frames are modeled with sparse representations. Furthermore, we\npropose an event shuffle-and-merge scheme to extend the single-frame SRB to the\nsequence-frame SRB without any additional training process. Experimental\nresults on synthetic and real-world datasets show that the proposed eSL-Net++\noutperforms state-of-the-art methods by a large margin. Datasets, codes, and\nmore results are available at https://github.com/ShinyWang33/eSL-Net-Plusplus.\n","authors":["Lei Yu","Bishan Wang","Xiang Zhang","Haijian Zhang","Wen Yang","Jianzhuang Liu","Gui-Song Xia"],"pdf_url":"https://arxiv.org/pdf/2302.13766v1.pdf","comment":"Accepted by IEEE TPAMI"},{"id":"http://arxiv.org/abs/2302.13765v1","updated":"2023-02-27T13:46:40Z","published":"2023-02-27T13:46:40Z","title":"Self Correspondence Distillation for End-to-End Weakly-Supervised\n  Semantic Segmentation","summary":"  Efficiently training accurate deep models for weakly supervised semantic\nsegmentation (WSSS) with image-level labels is challenging and important.\nRecently, end-to-end WSSS methods have become the focus of research due to\ntheir high training efficiency. However, current methods suffer from\ninsufficient extraction of comprehensive semantic information, resulting in\nlow-quality pseudo-labels and sub-optimal solutions for end-to-end WSSS. To\nthis end, we propose a simple and novel Self Correspondence Distillation (SCD)\nmethod to refine pseudo-labels without introducing external supervision. Our\nSCD enables the network to utilize feature correspondence derived from itself\nas a distillation target, which can enhance the network's feature learning\nprocess by complementing semantic information. In addition, to further improve\nthe segmentation accuracy, we design a Variation-aware Refine Module to enhance\nthe local consistency of pseudo-labels by computing pixel-level variation.\nFinally, we present an efficient end-to-end Transformer-based framework (TSCD)\nvia SCD and Variation-aware Refine Module for the accurate WSSS task. Extensive\nexperiments on the PASCAL VOC 2012 and MS COCO 2014 datasets demonstrate that\nour method significantly outperforms other state-of-the-art methods.\n  Our code is available at\n{https://github.com/Rongtao-Xu/RepresentationLearning/tree/main/SCD-AAAI2023}.\n","authors":["Rongtao Xu","Changwei Wang","Jiaxi Sun","Shibiao Xu","Weiliang Meng","Xiaopeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13748v1","updated":"2023-02-27T13:24:08Z","published":"2023-02-27T13:24:08Z","title":"Unsupervised Video Anomaly Detection for Stereotypical Behaviours in\n  Autism","summary":"  Monitoring and analyzing stereotypical behaviours is important for early\nintervention and care taking in Autism Spectrum Disorder (ASD). This paper\nfocuses on automatically detecting stereotypical behaviours with computer\nvision techniques. Off-the-shelf methods tackle this task by supervised\nclassification and activity recognition techniques. However, the unbounded\ntypes of stereotypical behaviours and the difficulty in collecting video\nrecordings of ASD patients largely limit the feasibility of the existing\nsupervised detection methods. As a result, we tackle these challenges from a\nnew perspective, i.e. unsupervised video anomaly detection for stereotypical\nbehaviours detection. The models can be trained among unlabeled videos\ncontaining only normal behaviours and unknown types of abnormal behaviours can\nbe detected during inference. Correspondingly, we propose a Dual Stream deep\nmodel for Stereotypical Behaviours Detection, DS-SBD, based on the temporal\ntrajectory of human poses and the repetition patterns of human actions.\nExtensive experiments are conducted to verify the effectiveness of our proposed\nmethod and suggest that it serves as a potential benchmark for future research.\n","authors":["Jiaqi Gao","Xinyang Jiang","Yuqing Yang","Dongsheng Li","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.13748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.04042v3","updated":"2023-02-27T13:23:37Z","published":"2022-05-09T05:08:08Z","title":"Incremental-DETR: Incremental Few-Shot Object Detection via\n  Self-Supervised Learning","summary":"  Incremental few-shot object detection aims at detecting novel classes without\nforgetting knowledge of the base classes with only a few labeled training data\nfrom the novel classes. Most related prior works are on incremental object\ndetection that rely on the availability of abundant training samples per novel\nclass that substantially limits the scalability to real-world setting where\nnovel data can be scarce. In this paper, we propose the Incremental-DETR that\ndoes incremental few-shot object detection via fine-tuning and self-supervised\nlearning on the DETR object detector. To alleviate severe over-fitting with few\nnovel class data, we first fine-tune the class-specific components of DETR with\nself-supervision from additional object proposals generated using Selective\nSearch as pseudo labels. We further introduce an incremental few-shot\nfine-tuning strategy with knowledge distillation on the class-specific\ncomponents of DETR to encourage the network in detecting novel classes without\nforgetting the base classes. Extensive experiments conducted on standard\nincremental object detection and incremental few-shot object detection settings\nshow that our approach significantly outperforms state-of-the-art methods by a\nlarge margin.\n","authors":["Na Dong","Yongqiang Zhang","Mingli Ding","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2205.04042v3.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2205.02938v2","updated":"2023-02-27T12:40:17Z","published":"2022-05-04T12:41:36Z","title":"Immiscible Color Flows in Optimal Transport Networks for Image\n  Classification","summary":"  In classification tasks, it is crucial to meaningfully exploit the\ninformation contained in data. While much of the work in addressing these tasks\nis devoted to building complex algorithmic infrastructures to process inputs in\na black-box fashion, less is known about how to exploit the various facets of\nthe data, before inputting this into an algorithm. Here, we focus on this\nlatter perspective, by proposing a physics-inspired dynamical system that\nadapts Optimal Transport principles to effectively leverage color distributions\nof images. Our dynamics regulates immiscible fluxes of colors traveling on a\nnetwork built from images. Instead of aggregating colors together, it treats\nthem as different commodities that interact with a shared capacity on edges.\nThe resulting optimal flows can then be fed into standard classifiers to\ndistinguish images in different classes. We show how our method can outperform\ncompeting approaches on image classification tasks in datasets where color\ninformation matters.\n","authors":["Alessandro Lonardi","Diego Baptista","Caterina De Bacco"],"pdf_url":"https://arxiv.org/pdf/2205.02938v2.pdf","comment":"23 pages, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2302.13721v1","updated":"2023-02-27T12:33:53Z","published":"2023-02-27T12:33:53Z","title":"Wireless End-to-End Image Transmission System using Semantic\n  Communications","summary":"  Semantic communication is considered the future of mobile communication,\nwhich aims to transmit data beyond Shannon's theorem of communications by\ntransmitting the semantic meaning of the data rather than the bit-by-bit\nreconstruction of the data at the receiver's end. The semantic communication\nparadigm aims to bridge the gap of limited bandwidth problems in modern\nhigh-volume multimedia application content transmission. Integrating AI\ntechnologies with the 6G communications networks paved the way to develop\nsemantic communication-based end-to-end communication systems. In this study,\nwe have implemented a semantic communication-based end-to-end image\ntransmission system, and we discuss potential design considerations in\ndeveloping semantic communication systems in conjunction with physical channel\ncharacteristics. A Pre-trained GAN network is used at the receiver as the\ntransmission task to reconstruct the realistic image based on the Semantic\nsegmented image at the receiver input. The semantic segmentation task at the\ntransmitter (encoder) and the GAN network at the receiver (decoder) is trained\non a common knowledge base, the COCO-Stuff dataset. The research shows that the\nresource gain in the form of bandwidth saving is immense when transmitting the\nsemantic segmentation map through the physical channel instead of the ground\ntruth image in contrast to conventional communication systems. Furthermore, the\nresearch studies the effect of physical channel distortions and quantization\nnoise on semantic communication-based multimedia content transmission.\n","authors":["Maheshi Lokumarambage","Vishnu Gowrisetty","Hossein Rezaei","Thushan Sivalingam","Nandana Rajatheva","Anil Fernando"],"pdf_url":"https://arxiv.org/pdf/2302.13721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13700v1","updated":"2023-02-27T11:59:28Z","published":"2023-02-27T11:59:28Z","title":"Imaginary Voice: Face-styled Diffusion Model for Text-to-Speech","summary":"  The goal of this work is zero-shot text-to-speech synthesis, with speaking\nstyles and voices learnt from facial characteristics. Inspired by the natural\nfact that people can imagine the voice of someone when they look at his or her\nface, we introduce a face-styled diffusion text-to-speech (TTS) model within a\nunified framework learnt from visible attributes, called Face-TTS. This is the\nfirst time that face images are used as a condition to train a TTS model.\n  We jointly train cross-model biometrics and TTS models to preserve speaker\nidentity between face images and generated speech segments. We also propose a\nspeaker feature binding loss to enforce the similarity of the generated and the\nground truth speech segments in speaker embedding space. Since the biometric\ninformation is extracted directly from the face image, our method does not\nrequire extra fine-tuning steps to generate speech from unseen and unheard\nspeakers. We train and evaluate the model on the LRS3 dataset, an in-the-wild\naudio-visual corpus containing background noise and diverse speaking styles.\nThe project page is https://facetts.github.io.\n","authors":["Jiyoung Lee","Joon Son Chung","Soo-Whan Chung"],"pdf_url":"https://arxiv.org/pdf/2302.13700v1.pdf","comment":"ICASSP 2023. Project page: https://facetts.github.io"},{"id":"http://arxiv.org/abs/2302.13699v1","updated":"2023-02-27T11:57:06Z","published":"2023-02-27T11:57:06Z","title":"MPS-AMS: Masked Patches Selection and Adaptive Masking Strategy Based\n  Self-Supervised Medical Image Segmentation","summary":"  Existing self-supervised learning methods based on contrastive learning and\nmasked image modeling have demonstrated impressive performances. However,\ncurrent masked image modeling methods are mainly utilized in natural images,\nand their applications in medical images are relatively lacking. Besides, their\nfixed high masking strategy limits the upper bound of conditional mutual\ninformation, and the gradient noise is considerable, making less the learned\nrepresentation information. Motivated by these limitations, in this paper, we\npropose masked patches selection and adaptive masking strategy based\nself-supervised medical image segmentation method, named MPS-AMS. We leverage\nthe masked patches selection strategy to choose masked patches with lesions to\nobtain more lesion representation information, and the adaptive masking\nstrategy is utilized to help learn more mutual information and improve\nperformance further. Extensive experiments on three public medical image\nsegmentation datasets (BUSI, Hecktor, and Brats2018) show that our proposed\nmethod greatly outperforms the state-of-the-art self-supervised baselines.\n","authors":["Xiangtao Wang","Ruizhi Wang","Biao Tian","Jiaojiao Zhang","Shuo Zhang","Junyang Chen","Thomas Lukasiewicz","Zhenghua Xu"],"pdf_url":"https://arxiv.org/pdf/2302.13699v1.pdf","comment":"6 pages, 3 figures,Received by the ICASSP2023"},{"id":"http://arxiv.org/abs/2302.13694v1","updated":"2023-02-27T11:54:04Z","published":"2023-02-27T11:54:04Z","title":"DLOFTBs -- Fast Tracking of Deformable Linear Objects with B-splines","summary":"  While the manipulation of rigid objects is an extensively explored research\ntopic, deformable linear object (DLO) manipulation seems significantly\nunderdeveloped. A potential reason for this is the inherent difficulty in\ndescribing and observing the state of the DLO as its geometry changes during\nmanipulation. This paper proposes an algorithm for fast-tracking the shape of a\nDLO based on the masked image. Having no prior knowledge about the tracked\nobject, the proposed method finds a reliable representation of the shape of the\ntracked object within tens of milliseconds. This algorithm's main idea is to\nfirst skeletonize the DLO mask image, walk through the parts of the DLO\nskeleton, arrange the segments into an ordered path, and finally fit a B-spline\ninto it. Experiments show that our solution outperforms the State-of-the-Art\napproaches in DLO's shape reconstruction accuracy and algorithm running time\nand can handle challenging scenarios such as severe occlusions,\nself-intersections, and multiple DLOs in a single image.\n","authors":["Piotr Kicki","Amadeusz Szymko","Krzysztof Walas"],"pdf_url":"https://arxiv.org/pdf/2302.13694v1.pdf","comment":"Accepted at International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2302.13668v1","updated":"2023-02-27T11:09:13Z","published":"2023-02-27T11:09:13Z","title":"Contrastive Video Question Answering via Video Graph Transformer","summary":"  We propose to perform video question answering (VideoQA) in a Contrastive\nmanner via a Video Graph Transformer model (CoVGT). CoVGT's uniqueness and\nsuperiority are three-fold: 1) It proposes a dynamic graph transformer module\nwhich encodes video by explicitly capturing the visual objects, their relations\nand dynamics, for complex spatio-temporal reasoning. 2) It designs separate\nvideo and text transformers for contrastive learning between the video and text\nto perform QA, instead of multi-modal transformer for answer classification.\nFine-grained video-text communication is done by additional cross-modal\ninteraction modules. 3) It is optimized by the joint fully- and self-supervised\ncontrastive objectives between the correct and incorrect answers, as well as\nthe relevant and irrelevant questions respectively. With superior video\nencoding and QA solution, we show that CoVGT can achieve much better\nperformances than previous arts on video reasoning tasks. Its performances even\nsurpass those models that are pretrained with millions of external data. We\nfurther show that CoVGT can also benefit from cross-modal pretraining, yet with\norders of magnitude smaller data. The results demonstrate the effectiveness and\nsuperiority of CoVGT, and additionally reveal its potential for more\ndata-efficient pretraining. We hope our success can advance VideoQA beyond\ncoarse recognition/description towards fine-grained relation reasoning of video\ncontents. Our code will be available at https://github.com/doc-doc/CoVGT.\n","authors":["Junbin Xiao","Pan Zhou","Angela Yao","Yicong Li","Richang Hong","Shuicheng Yan","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2302.13668v1.pdf","comment":"Manuscript was submitted for reviewing at IEEE T-PAMI on 11 Oct.\n  2022. This version is with small modification"},{"id":"http://arxiv.org/abs/2205.02573v2","updated":"2023-02-27T09:59:20Z","published":"2022-05-05T11:12:59Z","title":"Intra and Cross-spectrum Iris Presentation Attack Detection in the NIR\n  and Visible Domains","summary":"  Iris Presentation Attack Detection (PAD) is essential to secure iris\nrecognition systems. Recent iris PAD solutions achieved good performance by\nleveraging deep learning techniques. However, most results were reported under\nintra-database scenarios and it is unclear if such solutions can generalize\nwell across databases and capture spectra. These PAD methods run the risk of\noverfitting because of the binary label supervision during the network\ntraining, which serves global information learning but weakens the capture of\nlocal discriminative features. This chapter presents a novel attention-based\ndeep pixel-wise binary supervision (A-PBS) method. A-PBS utilizes pixel-wise\nsupervision to capture the fine-grained pixel/patch-level cues and attention\nmechanism to guide the network to automatically find regions where most\ncontribute to an accurate PAD decision. Extensive experiments are performed on\nsix NIR and one visible-light iris databases to show the effectiveness and\nrobustness of proposed A-PBS methods. We additionally conduct extensive\nexperiments under intra-/cross-database and intra-/cross-spectrum for detailed\nanalysis. The results of our experiments indicates the generalizability of the\nA-PBS iris PAD approach.\n","authors":["Meiling Fang","Fadi Boutros","Naser Damer"],"pdf_url":"https://arxiv.org/pdf/2205.02573v2.pdf","comment":"Chapter of the Handbook of Biometric Anti-Spoofing (Third Edition).\n  arXiv admin note: substantial text overlap with arXiv:2106.14845"},{"id":"http://arxiv.org/abs/2302.13631v1","updated":"2023-02-27T09:58:09Z","published":"2023-02-27T09:58:09Z","title":"Curriculum Based Multi-Task Learning for Parkinson's Disease Detection","summary":"  There is great interest in developing radiological classifiers for diagnosis,\nstaging, and predictive modeling in progressive diseases such as Parkinson's\ndisease (PD), a neurodegenerative disease that is difficult to detect in its\nearly stages. Here we leverage severity-based meta-data on the stages of\ndisease to define a curriculum for training a deep convolutional neural network\n(CNN). Typically, deep learning networks are trained by randomly selecting\nsamples in each mini-batch. By contrast, curriculum learning is a training\nstrategy that aims to boost classifier performance by starting with examples\nthat are easier to classify. Here we define a curriculum to progressively\nincrease the difficulty of the training data corresponding to the Hoehn and\nYahr (H&Y) staging system for PD (total N=1,012; 653 PD patients, 359 controls;\nage range: 20.0-84.9 years). Even with our multi-task setting using pre-trained\nCNNs and transfer learning, PD classification based on T1-weighted (T1-w) MRI\nwas challenging (ROC AUC: 0.59-0.65), but curriculum training boosted\nperformance (by 3.9%) compared to our baseline model. Future work with\nmultimodal imaging may further boost performance.\n","authors":["Nikhil J. Dhinagar","Conor Owens-Walton","Emily Laltoo","Christina P. Boyle","Yao-Liang Chen","Philip Cook","Corey McMillan","Chih-Chien Tsai","J-J Wang","Yih-Ru Wu","Ysbrand van der Werf","Paul M. Thompson"],"pdf_url":"https://arxiv.org/pdf/2302.13631v1.pdf","comment":"Accepted for publication at the 20th IEEE International Symposium on\n  Biomedical Imaging, ISBI 2023"},{"id":"http://arxiv.org/abs/2302.13602v1","updated":"2023-02-27T09:10:08Z","published":"2023-02-27T09:10:08Z","title":"The Role of Pre-training Data in Transfer Learning","summary":"  The transfer learning paradigm of model pre-training and subsequent\nfine-tuning produces high-accuracy models. While most studies recommend scaling\nthe pre-training size to benefit most from transfer learning, a question\nremains: what data and method should be used for pre-training? We investigate\nthe impact of pre-training data distribution on the few-shot and full\nfine-tuning performance using 3 pre-training methods (supervised, contrastive\nlanguage-image and image-image), 7 pre-training datasets, and 9 downstream\ndatasets. Through extensive controlled experiments, we find that the choice of\nthe pre-training data source is essential for the few-shot transfer, but its\nrole decreases as more data is made available for fine-tuning. Additionally, we\nexplore the role of data curation and examine the trade-offs between label\nnoise and the size of the pre-training dataset. We find that using 2000X more\npre-training data from LAION can match the performance of supervised ImageNet\npre-training. Furthermore, we investigate the effect of pre-training methods,\ncomparing language-image contrastive vs. image-image contrastive, and find that\nthe latter leads to better downstream accuracy\n","authors":["Rahim Entezari","Mitchell Wortsman","Olga Saukh","M. Moein Shariatnia","Hanie Sedghi","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2302.13602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13598v1","updated":"2023-02-27T09:07:15Z","published":"2023-02-27T09:07:15Z","title":"Spatial-Frequency Attention for Image Denoising","summary":"  The recently developed transformer networks have achieved impressive\nperformance in image denoising by exploiting the self-attention (SA) in images.\nHowever, the existing methods mostly use a relatively small window to compute\nSA due to the quadratic complexity of it, which limits the model's ability to\nmodel long-term image information. In this paper, we propose the\nspatial-frequency attention network (SFANet) to enhance the network's ability\nin exploiting long-range dependency. For spatial attention module (SAM), we\nadopt dilated SA to model long-range dependency. In the frequency attention\nmodule (FAM), we exploit more global information by using Fast Fourier\nTransform (FFT) by designing a window-based frequency channel attention (WFCA)\nblock to effectively model deep frequency features and their dependencies. To\nmake our module applicable to images of different sizes and keep the model\nconsistency between training and inference, we apply window-based FFT with a\nset of fixed window sizes. In addition, channel attention is computed on both\nreal and imaginary parts of the Fourier spectrum, which further improves\nrestoration performance. The proposed WFCA block can effectively model image\nlong-range dependency with acceptable complexity. Experiments on multiple\ndenoising benchmarks demonstrate the leading performance of SFANet network.\n","authors":["Shi Guo","Hongwei Yong","Xindong Zhang","Jianqi Ma","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08498v2","updated":"2023-02-27T09:06:19Z","published":"2022-09-18T07:56:06Z","title":"LATITUDE: Robotic Global Localization with Truncated Dynamic Low-pass\n  Filter in City-scale NeRF","summary":"  Neural Radiance Fields (NeRFs) have made great success in representing\ncomplex 3D scenes with high-resolution details and efficient memory.\nNevertheless, current NeRF-based pose estimators have no initial pose\nprediction and are prone to local optima during optimization. In this paper, we\npresent LATITUDE: Global Localization with Truncated Dynamic Low-pass Filter,\nwhich introduces a two-stage localization mechanism in city-scale NeRF. In\nplace recognition stage, we train a regressor through images generated from\ntrained NeRFs, which provides an initial value for global localization. In pose\noptimization stage, we minimize the residual between the observed image and\nrendered image by directly optimizing the pose on tangent plane. To avoid\nconvergence to local optimum, we introduce a Truncated Dynamic Low-pass Filter\n(TDLF) for coarse-to-fine pose registration. We evaluate our method on both\nsynthetic and real-world data and show its potential applications for\nhigh-precision navigation in large-scale city scenes. Codes and data will be\npublicly available at https://github.com/jike5/LATITUDE.\n","authors":["Zhenxin Zhu","Yuantao Chen","Zirui Wu","Chao Hou","Yongliang Shi","Chuxuan Li","Pengfei Li","Hao Zhao","Guyue Zhou"],"pdf_url":"https://arxiv.org/pdf/2209.08498v2.pdf","comment":"7 pages, 6 figures, ICRA 2023"},{"id":"http://arxiv.org/abs/2302.13596v1","updated":"2023-02-27T09:02:35Z","published":"2023-02-27T09:02:35Z","title":"LSR: A Light-Weight Super-Resolution Method","summary":"  A light-weight super-resolution (LSR) method from a single image targeting\nmobile applications is proposed in this work. LSR predicts the residual image\nbetween the interpolated low-resolution (ILR) and high-resolution (HR) images\nusing a self-supervised framework. To lower the computational complexity, LSR\ndoes not adopt the end-to-end optimization deep networks. It consists of three\nmodules: 1) generation of a pool of rich and diversified representations in the\nneighborhood of a target pixel via unsupervised learning, 2) selecting a subset\nfrom the representation pool that is most relevant to the underlying\nsuper-resolution task automatically via supervised learning, 3) predicting the\nresidual of the target pixel via regression. LSR has low computational\ncomplexity and reasonable model size so that it can be implemented on\nmobile/edge platforms conveniently. Besides, it offers better visual quality\nthan classical exemplar-based methods in terms of PSNR/SSIM measures.\n","authors":["Wei Wang","Xuejing Lei","Yueru Chen","Ming-Sui Lee","C. -C. Jay Kuo"],"pdf_url":"https://arxiv.org/pdf/2302.13596v1.pdf","comment":"8 pages, 3 figures, 10 tables"},{"id":"http://arxiv.org/abs/2302.13594v1","updated":"2023-02-27T09:00:29Z","published":"2023-02-27T09:00:29Z","title":"Leveraging Video Coding Knowledge for Deep Video Enhancement","summary":"  Recent advancements in deep learning techniques have significantly improved\nthe quality of compressed videos. However, previous approaches have not fully\nexploited the motion characteristics of compressed videos, such as the drastic\nchange in motion between video contents and the hierarchical coding structure\nof the compressed video. This study proposes a novel framework that leverages\nthe low-delay configuration of video compression to enhance the existing\nstate-of-the-art method, BasicVSR++. We incorporate a context-adaptive video\nfusion method to enhance the final quality of compressed videos. The proposed\napproach has been evaluated in the NTIRE22 challenge, a benchmark for video\nrestoration and enhancement, and achieved improvements in both quantitative\nmetrics and visual quality compared to the previous method.\n","authors":["Thong Bach","Thuong Nguyen Canh","Van-Quang Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.13594v1.pdf","comment":"for NTIRE2 challenge in CVPR22"},{"id":"http://arxiv.org/abs/2302.13578v1","updated":"2023-02-27T08:30:46Z","published":"2023-02-27T08:30:46Z","title":"Online Black-Box Confidence Estimation of Deep Neural Networks","summary":"  Autonomous driving (AD) and advanced driver assistance systems (ADAS)\nincreasingly utilize deep neural networks (DNNs) for improved perception or\nplanning. Nevertheless, DNNs are quite brittle when the data distribution\nduring inference deviates from the data distribution during training. This\nrepresents a challenge when deploying in partly unknown environments like in\nthe case of ADAS. At the same time, the standard confidence of DNNs remains\nhigh even if the classification reliability decreases. This is problematic\nsince following motion control algorithms consider the apparently confident\nprediction as reliable even though it might be considerably wrong. To reduce\nthis problem real-time capable confidence estimation is required that better\naligns with the actual reliability of the DNN classification. Additionally, the\nneed exists for black-box confidence estimation to enable the homogeneous\ninclusion of externally developed components to an entire system. In this work\nwe explore this use case and introduce the neighborhood confidence (NHC) which\nestimates the confidence of an arbitrary DNN for classification. The metric can\nbe used for black-box systems since only the top-1 class output is required and\ndoes not need access to the gradients, the training dataset or a hold-out\nvalidation dataset. Evaluation on different data distributions, including small\nin-domain distribution shifts, out-of-domain data or adversarial attacks, shows\nthat the NHC performs better or on par with a comparable method for online\nwhite-box confidence estimation in low data regimes which is required for\nreal-time capable AD/ADAS.\n","authors":["Fabian Woitschek","Georg Schneider"],"pdf_url":"https://arxiv.org/pdf/2302.13578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13577v1","updated":"2023-02-27T08:30:02Z","published":"2023-02-27T08:30:02Z","title":"DuEqNet: Dual-Equivariance Network in Outdoor 3D Object Detection for\n  Autonomous Driving","summary":"  Outdoor 3D object detection has played an essential role in the environment\nperception of autonomous driving. In complicated traffic situations, precise\nobject recognition provides indispensable information for prediction and\nplanning in the dynamic system, improving self-driving safety and reliability.\nHowever, with the vehicle's veering, the constant rotation of the surrounding\nscenario makes a challenge for the perception systems. Yet most existing\nmethods have not focused on alleviating the detection accuracy impairment\nbrought by the vehicle's rotation, especially in outdoor 3D detection. In this\npaper, we propose DuEqNet, which first introduces the concept of equivariance\ninto 3D object detection network by leveraging a hierarchical embedded\nframework. The dual-equivariance of our model can extract the equivariant\nfeatures at both local and global levels, respectively. For the local feature,\nwe utilize the graph-based strategy to guarantee the equivariance of the\nfeature in point cloud pillars. In terms of the global feature, the group\nequivariant convolution layers are adopted to aggregate the local feature to\nachieve the global equivariance. In the experiment part, we evaluate our\napproach with different baselines in 3D object detection tasks and obtain\nState-Of-The-Art performance. According to the results, our model presents\nhigher accuracy on orientation and better prediction efficiency. Moreover, our\ndual-equivariance strategy exhibits the satisfied plug-and-play ability on\nvarious popular object detection frameworks to improve their performance.\n","authors":["Xihao Wang","Jiaming Lei","Hai Lan","Arafat Al-Jawari","Xian Wei"],"pdf_url":"https://arxiv.org/pdf/2302.13577v1.pdf","comment":"This work is accepted by ICRA2023"},{"id":"http://arxiv.org/abs/2302.13570v1","updated":"2023-02-27T08:10:58Z","published":"2023-02-27T08:10:58Z","title":"Physical Adversarial Attacks on Deep Neural Networks for Traffic Sign\n  Recognition: A Feasibility Study","summary":"  Deep Neural Networks (DNNs) are increasingly applied in the real world in\nsafety critical applications like advanced driver assistance systems. An\nexample for such use case is represented by traffic sign recognition systems.\nAt the same time, it is known that current DNNs can be fooled by adversarial\nattacks, which raises safety concerns if those attacks can be applied under\nrealistic conditions. In this work we apply different black-box attack methods\nto generate perturbations that are applied in the physical environment and can\nbe used to fool systems under different environmental conditions. To the best\nof our knowledge we are the first to combine a general framework for physical\nattacks with different black-box attack methods and study the impact of the\ndifferent methods on the success rate of the attack under the same setting. We\nshow that reliable physical adversarial attacks can be performed with different\nmethods and that it is also possible to reduce the perceptibility of the\nresulting perturbations. The findings highlight the need for viable defenses of\na DNN even in the black-box case, but at the same time form the basis for\nsecuring a DNN with methods like adversarial training which utilizes\nadversarial attacks to augment the original training data.\n","authors":["Fabian Woitschek","Georg Schneider"],"pdf_url":"https://arxiv.org/pdf/2302.13570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07042v4","updated":"2023-02-27T08:04:37Z","published":"2022-09-15T04:51:17Z","title":"Efficient Perception, Planning, and Control Algorithms for Vision-Based\n  Automated Vehicles","summary":"  Autonomous vehicles have limited computational resources; hence, their\ncontrol systems must be efficient. The cost and size of sensors have limited\nthe development of self-driving cars. To overcome these restrictions, this\nstudy proposes an efficient framework for the operation of vision-based\nautomatic vehicles; the framework requires only a monocular camera and a few\ninexpensive radars. The proposed algorithm comprises a multi-task UNet (MTUNet)\nnetwork for extracting image features and constrained iterative linear\nquadratic regulator (CILQR) and vision predictive control (VPC) modules for\nrapid motion planning and control. MTUNet is designed to simultaneously solve\nlane line segmentation, the ego vehicle's heading angle regression, road type\nclassification, and traffic object detection tasks at approximately 40 FPS\n(frames per second) for 228 x 228 pixel RGB input images. The CILQR controllers\nthen use the MTUNet outputs and radar data as inputs to produce driving\ncommands for lateral and longitudinal vehicle guidance within only 1 ms. In\nparticular, the VPC algorithm is included to reduce steering command latency to\nbelow actuator latency to prevent vehicle understeer during tight turns. The\nVPC algorithm uses road curvature data from MTUNet to estimate the correction\nof the current steering angle at a look-ahead point to adjust the turning\namount. Including the VPC algorithm in a VPC-CILQR controller leads to higher\nperformance than CILQR alone; this controller can minimize the influence of\ncommand lag, maintaining the ego car's speed and lateral offset at 76 km/h and\nwithin 0.52 m, respectively, on a simulated road with a curvature of 0.03 1/m.\nOur experiments demonstrate that the proposed autonomous driving system, which\ndoes not require high-definition maps, could be applied in current autonomous\nvehicles.\n","authors":["Der-Hau Lee"],"pdf_url":"https://arxiv.org/pdf/2209.07042v4.pdf","comment":"10 figures, 13 pages"},{"id":"http://arxiv.org/abs/2302.13567v1","updated":"2023-02-27T07:57:52Z","published":"2023-02-27T07:57:52Z","title":"Towards Audit Requirements for AI-based Systems in Mobility Applications","summary":"  Various mobility applications like advanced driver assistance systems\nincreasingly utilize artificial intelligence (AI) based functionalities.\nTypically, deep neural networks (DNNs) are used as these provide the best\nperformance on the challenging perception, prediction or planning tasks that\noccur in real driving environments. However, current regulations like UNECE R\n155 or ISO 26262 do not consider AI-related aspects and are only applied to\ntraditional algorithm-based systems. The non-existence of AI-specific standards\nor norms prevents the practical application and can harm the trust level of\nusers. Hence, it is important to extend existing standardization for security\nand safety to consider AI-specific challenges and requirements. To take a step\ntowards a suitable regulation we propose 50 technical requirements or best\npractices that extend existing regulations and address the concrete needs for\nDNN-based systems. We show the applicability, usefulness and meaningfulness of\nthe proposed requirements by performing an exemplary audit of a DNN-based\ntraffic sign recognition system using three of the proposed requirements.\n","authors":["Devi Padmavathi Alagarswamy","Christian Berghoff","Vasilios Danos","Fabian Langer","Thora Markert","Georg Schneider","Arndt von Twickel","Fabian Woitschek"],"pdf_url":"https://arxiv.org/pdf/2302.13567v1.pdf","comment":"To appear in Proceedings of the 9th International Conference on\n  Information Systems Security and Privacy"},{"id":"http://arxiv.org/abs/2206.00356v2","updated":"2023-02-27T06:58:28Z","published":"2022-06-01T09:43:10Z","title":"A Survey on Deep Learning for Skin Lesion Segmentation","summary":"  Skin cancer is a major public health problem that could benefit from\ncomputer-aided diagnosis to reduce the burden of this common disease. Skin\nlesion segmentation from images is an important step toward achieving this\ngoal. However, the presence of natural and artificial artifacts (e.g., hair and\nair bubbles), intrinsic factors (e.g., lesion shape and contrast), and\nvariations in image acquisition conditions make skin lesion segmentation a\nchallenging task. Recently, various researchers have explored the applicability\nof deep learning models to skin lesion segmentation. In this survey, we\ncross-examine 177 research papers that deal with deep learning-based\nsegmentation of skin lesions. We analyze these works along several dimensions,\nincluding input data (datasets, preprocessing, and synthetic data generation),\nmodel design (architecture, modules, and losses), and evaluation aspects (data\nannotation requirements and segmentation performance). We discuss these\ndimensions both from the viewpoint of select seminal works, and from a\nsystematic viewpoint, examining how those choices have influenced current\ntrends, and how their limitations should be addressed. To facilitate\ncomparisons, we summarize all examined works in a comprehensive table as well\nas an interactive table available online at\nhttps://github.com/sfu-mial/skin-lesion-segmentation-survey.\n","authors":["Zahra Mirikharaji","Kumar Abhishek","Alceu Bissoto","Catarina Barata","Sandra Avila","Eduardo Valle","M. Emre Celebi","Ghassan Hamarneh"],"pdf_url":"https://arxiv.org/pdf/2206.00356v2.pdf","comment":"55 pages, 10 figures; Mirikharaji and Abhishek: Joint first authors;\n  Celebi and Hamarneh: Joint senior authors"},{"id":"http://arxiv.org/abs/2302.13546v1","updated":"2023-02-27T06:55:00Z","published":"2023-02-27T06:55:00Z","title":"Self-Supervised Pre-Training for Deep Image Prior-Based Robust PET Image\n  Denoising","summary":"  Deep image prior (DIP) has been successfully applied to positron emission\ntomography (PET) image restoration, enabling represent implicit prior using\nonly convolutional neural network architecture without training dataset,\nwhereas the general supervised approach requires massive low- and high-quality\nPET image pairs. To answer the increased need for PET imaging with DIP, it is\nindispensable to improve the performance of the underlying DIP itself. Here, we\npropose a self-supervised pre-training model to improve the DIP-based PET image\ndenoising performance. Our proposed pre-training model acquires transferable\nand generalizable visual representations from only unlabeled PET images by\nrestoring various degraded PET images in a self-supervised approach. We\nevaluated the proposed method using clinical brain PET data with various\nradioactive tracers ($^{18}$F-florbetapir, $^{11}$C-Pittsburgh compound-B,\n$^{18}$F-fluoro-2-deoxy-D-glucose, and $^{15}$O-CO$_{2}$) acquired from\ndifferent PET scanners. The proposed method using the self-supervised\npre-training model achieved robust and state-of-the-art denoising performance\nwhile retaining spatial details and quantification accuracy compared to other\nunsupervised methods and pre-training model. These results highlight the\npotential that the proposed method is particularly effective against rare\ndiseases and probes and helps reduce the scan time or the radiotracer dose\nwithout affecting the patients.\n","authors":["Yuya Onishi","Fumio Hashimoto","Kibo Ote","Keisuke Matsubara","Masanobu Ibaraki"],"pdf_url":"https://arxiv.org/pdf/2302.13546v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.13543v1","updated":"2023-02-27T06:40:32Z","published":"2023-02-27T06:40:32Z","title":"BaLi-RF: Bandlimited Radiance Fields for Dynamic Scene Modeling","summary":"  Reasoning the 3D structure of a non-rigid dynamic scene from a single moving\ncamera is an under-constrained problem. Inspired by the remarkable progress of\nneural radiance fields (NeRFs) in photo-realistic novel view synthesis of\nstatic scenes, extensions have been proposed for dynamic settings. These\nmethods heavily rely on neural priors in order to regularize the problem. In\nthis work, we take a step back and reinvestigate how current implementations\nmay entail deleterious effects, including limited expressiveness, entanglement\nof light and density fields, and sub-optimal motion localization. As a remedy,\nwe advocate for a bridge between classic non-rigid-structure-from-motion\n(\\nrsfm) and NeRF, enabling the well-studied priors of the former to constrain\nthe latter. To this end, we propose a framework that factorizes time and space\nby formulating a scene as a composition of bandlimited, high-dimensional\nsignals. We demonstrate compelling results across complex dynamic scenes that\ninvolve changes in lighting, texture and long-range dynamics.\n","authors":["Sameera Ramasinghe","Violetta Shevchenko","Gil Avraham","Anton Van Den Hengel"],"pdf_url":"https://arxiv.org/pdf/2302.13543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13540v1","updated":"2023-02-27T06:35:03Z","published":"2023-02-27T06:35:03Z","title":"OccDepth: A Depth-Aware Method for 3D Semantic Scene Completion","summary":"  3D Semantic Scene Completion (SSC) can provide dense geometric and semantic\nscene representations, which can be applied in the field of autonomous driving\nand robotic systems. It is challenging to estimate the complete geometry and\nsemantics of a scene solely from visual images, and accurate depth information\nis crucial for restoring 3D geometry. In this paper, we propose the first\nstereo SSC method named OccDepth, which fully exploits implicit depth\ninformation from stereo images (or RGBD images) to help the recovery of 3D\ngeometric structures. The Stereo Soft Feature Assignment (Stereo-SFA) module is\nproposed to better fuse 3D depth-aware features by implicitly learning the\ncorrelation between stereo images. In particular, when the input are RGBD\nimage, a virtual stereo images can be generated through original RGB image and\ndepth map. Besides, the Occupancy Aware Depth (OAD) module is used to obtain\ngeometry-aware 3D features by knowledge distillation using pre-trained depth\nmodels. In addition, a reformed TartanAir benchmark, named SemanticTartanAir,\nis provided in this paper for further testing our OccDepth method on SSC task.\nCompared with the state-of-the-art RGB-inferred SSC method, extensive\nexperiments on SemanticKITTI show that our OccDepth method achieves superior\nperformance with improving +4.82% mIoU, of which +2.49% mIoU comes from stereo\nimages and +2.33% mIoU comes from our proposed depth-aware method. Our code and\ntrained models are available at https://github.com/megvii-research/OccDepth.\n","authors":["Ruihang Miao","Weizhou Liu","Mingrui Chen","Zheng Gong","Weixin Xu","Chen Hu","Shuchang Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.13540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08175v2","updated":"2023-02-27T06:18:41Z","published":"2023-02-16T09:44:55Z","title":"A numerical approximation method for the Fisher-Rao distance between\n  multivariate normal distributions","summary":"  We present a simple method to approximate Rao's distance between multivariate\nnormal distributions based on discretizing curves joining normal distributions\nand approximating Rao distances between successive nearby normal distributions\non the curve by Jeffreys divergence. We consider experimentally the linear\ninterpolation curves in the ordinary, natural and expectation parameterizations\nof the normal distributions, and compare these curves with a curve derived from\nthe Calvo and Oller's isometric embedding of the Fisher-Rao $d$-variate normal\nmanifold into the cone of $(d+1)\\times (d+1)$ symmetric positive-definite\nmatrices [Journal of multivariate analysis 35.2 (1990): 223-242]. We report on\nour experiments and assess the quality of our approximation technique by\ncomparing the numerical approximations with lower and upper bounds. Finally, we\npresent some information-geometric properties of the Calvo and Oller's\nisometric embedding.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2302.08175v2.pdf","comment":"15 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.13519v1","updated":"2023-02-27T05:10:27Z","published":"2023-02-27T05:10:27Z","title":"CBA: Contextual Background Attack against Optical Aerial Detection in\n  the Physical World","summary":"  Patch-based physical attacks have increasingly aroused concerns.\n  However, most existing methods focus on obscuring targets captured on the\nground, and some of these methods are simply extended to deceive aerial\ndetectors.\n  They smear the targeted objects in the physical world with the elaborated\nadversarial patches, which can only slightly sway the aerial detectors'\nprediction and with weak attack transferability.\n  To address the above issues, we propose to perform Contextual Background\nAttack (CBA), a novel physical attack framework against aerial detection, which\ncan achieve strong attack efficacy and transferability in the physical world\neven without smudging the interested objects at all.\n  Specifically, the targets of interest, i.e. the aircraft in aerial images,\nare adopted to mask adversarial patches.\n  The pixels outside the mask area are optimized to make the generated\nadversarial patches closely cover the critical contextual background area for\ndetection, which contributes to gifting adversarial patches with more robust\nand transferable attack potency in the real world.\n  To further strengthen the attack performance, the adversarial patches are\nforced to be outside targets during training, by which the detected objects of\ninterest, both on and outside patches, benefit the accumulation of attack\nefficacy.\n  Consequently, the sophisticatedly designed patches are gifted with solid\nfooling efficacy against objects both on and outside the adversarial patches\nsimultaneously.\n  Extensive proportionally scaled experiments are performed in physical\nscenarios, demonstrating the superiority and potential of the proposed\nframework for physical attacks.\n  We expect that the proposed physical attack method will serve as a benchmark\nfor assessing the adversarial robustness of diverse aerial detectors and\ndefense methods.\n","authors":["Jiawei Lian","Xiaofei Wang","Yuru Su","Mingyang Ma","Shaohui Mei"],"pdf_url":"https://arxiv.org/pdf/2302.13519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1807.05653v2","updated":"2023-02-27T05:06:01Z","published":"2018-07-16T01:58:27Z","title":"Learning and Matching Multi-View Descriptors for Registration of Point\n  Clouds","summary":"  Critical to the registration of point clouds is the establishment of a set of\naccurate correspondences between points in 3D space. The correspondence problem\nis generally addressed by the design of discriminative 3D local descriptors on\nthe one hand, and the development of robust matching strategies on the other\nhand. In this work, we first propose a multi-view local descriptor, which is\nlearned from the images of multiple views, for the description of 3D keypoints.\nThen, we develop a robust matching approach, aiming at rejecting outlier\nmatches based on the efficient inference via belief propagation on the defined\ngraphical model. We have demonstrated the boost of our approaches to\nregistration on the public scanning and multi-view stereo datasets. The\nsuperior performance has been verified by the intensive comparisons against a\nvariety of descriptors and matching methods.\n","authors":["Lei Zhou","Siyu Zhu","Zixin Luo","Tianwei Shen","Runze Zhang","Mingmin Zhen","Tian Fang","Long Quan"],"pdf_url":"https://arxiv.org/pdf/1807.05653v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10352v2","updated":"2023-02-27T04:52:14Z","published":"2022-10-19T07:40:47Z","title":"Temporal Action Segmentation: An Analysis of Modern Technique","summary":"  Temporal action segmentation from videos aims at the dense labeling of video\nframes with multiple action classes in minutes-long videos. Categorized as a\nlong-range video understanding task, researchers have proposed an extended\ncollection of methods and examined their performance using various benchmarks.\nDespite the rapid development of action segmentation techniques in recent\nyears, there has been no systematic survey in such fields. To this end, in this\nsurvey, we analyse and summarize the main contributions and trends for this\ntask. Specifically, we first examine the task definition, common benchmarks,\ntypes of supervision, and popular evaluation measures. Furthermore, we\nsystematically investigate two fundamental aspects of this topic, i.e., frame\nrepresentation and temporal modeling, which are widely and extensively studied\nin the literature. We then comprehensively review existing temporal action\nsegmentation works, each categorized by their form of supervision. Finally, we\nconclude our survey by highlighting and identifying several open topics for\nresearch. In addition, we supplement our survey with a curated list of temporal\naction segmentation resources, which is available at\nhttps://github.com/atlas-eccv22/awesome-temporal-action-segmentation.\n","authors":["Guodong Ding","Fadime Sener","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2210.10352v2.pdf","comment":"26 pages, 10 figures, 9 tables"},{"id":"http://arxiv.org/abs/2212.01083v2","updated":"2023-02-27T04:30:11Z","published":"2022-12-02T10:45:33Z","title":"Cross-Modal Mutual Learning for Cued Speech Recognition","summary":"  Automatic Cued Speech Recognition (ACSR) provides an intelligent\nhuman-machine interface for visual communications, where the Cued Speech (CS)\nsystem utilizes lip movements and hand gestures to code spoken language for\nhearing-impaired people. Previous ACSR approaches often utilize direct feature\nconcatenation as the main fusion paradigm. However, the asynchronous modalities\ni.e., lip, hand shape and hand position) in CS may cause interference for\nfeature concatenation. To address this challenge, we propose a transformer\nbased cross-modal mutual learning framework to prompt multi-modal interaction.\nCompared with the vanilla self-attention, our model forces modality-specific\ninformation of different modalities to pass through a modality-invariant\ncodebook, collating linguistic representations for tokens of each modality.\nThen the shared linguistic knowledge is used to re-synchronize multi-modal\nsequences. Moreover, we establish a novel large-scale multi-speaker CS dataset\nfor Mandarin Chinese. To our knowledge, this is the first work on ACSR for\nMandarin Chinese. Extensive experiments are conducted for different languages\ni.e., Chinese, French, and British English). Results demonstrate that our model\nexhibits superior recognition performance to the state-of-the-art by a large\nmargin.\n","authors":["Lei Liu","Li Liu"],"pdf_url":"https://arxiv.org/pdf/2212.01083v2.pdf","comment":"Accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2209.06430v3","updated":"2023-02-27T04:25:24Z","published":"2022-09-14T05:47:02Z","title":"CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language\n  Representation Alignment","summary":"  The pre-trained image-text models, like CLIP, have demonstrated the strong\npower of vision-language representation learned from a large scale of\nweb-collected image-text data. In light of the well-learned visual features,\nsome existing works transfer image representation to video domain and achieve\ngood results. However, how to utilize image-language pre-trained model (e.g.,\nCLIP) for video-language pre-training (post-pretraining) is still under\nexplored. In this paper, we investigate two questions: 1) what are the factors\nhindering post-pretraining CLIP to further improve the performance on\nvideo-language tasks? and 2) how to mitigate the impact of these factors?\nThrough a series of comparative experiments and analyses, we find that the data\nscale and domain gap between language sources have great impacts. Motivated by\nthese, we propose a Omnisource Cross-modal Learning method equipped with a\nVideo Proxy mechanism on the basis of CLIP, namely CLIP-ViP. Extensive results\nshow that our approach improves the performance of CLIP on video-text retrieval\nby a large margin. Our model also achieves SOTA results on a variety of\ndatasets, including MSR-VTT, DiDeMo, LSMDC, and ActivityNet. We will release\nour code and pre-trained CLIP-ViP models at\nhttps://github.com/microsoft/XPretrain/tree/main/CLIP-ViP.\n","authors":["Hongwei Xue","Yuchong Sun","Bei Liu","Jianlong Fu","Ruihua Song","Houqiang Li","Jiebo Luo"],"pdf_url":"https://arxiv.org/pdf/2209.06430v3.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.13495v1","updated":"2023-02-27T03:43:03Z","published":"2023-02-27T03:43:03Z","title":"LMSeg: Language-guided Multi-dataset Segmentation","summary":"  It's a meaningful and attractive topic to build a general and inclusive\nsegmentation model that can recognize more categories in various scenarios. A\nstraightforward way is to combine the existing fragmented segmentation datasets\nand train a multi-dataset network. However, there are two major issues with\nmulti-dataset segmentation: (1) the inconsistent taxonomy demands manual\nreconciliation to construct a unified taxonomy; (2) the inflexible one-hot\ncommon taxonomy causes time-consuming model retraining and defective\nsupervision of unlabeled categories. In this paper, we investigate the\nmulti-dataset segmentation and propose a scalable Language-guided Multi-dataset\nSegmentation framework, dubbed LMSeg, which supports both semantic and panoptic\nsegmentation. Specifically, we introduce a pre-trained text encoder to map the\ncategory names to a text embedding space as a unified taxonomy, instead of\nusing inflexible one-hot label. The model dynamically aligns the segment\nqueries with the category embeddings. Instead of relabeling each dataset with\nthe unified taxonomy, a category-guided decoding module is designed to\ndynamically guide predictions to each datasets taxonomy. Furthermore, we adopt\na dataset-aware augmentation strategy that assigns each dataset a specific\nimage augmentation pipeline, which can suit the properties of images from\ndifferent datasets. Extensive experiments demonstrate that our method achieves\nsignificant improvements on four semantic and three panoptic segmentation\ndatasets, and the ablation study evaluates the effectiveness of each component.\n","authors":["Qiang Zhou","Yuang Liu","Chaohui Yu","Jingliang Li","Zhibin Wang","Fan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.13495v1.pdf","comment":"12 figures, 5 figures"},{"id":"http://arxiv.org/abs/2211.05405v3","updated":"2023-02-27T03:35:55Z","published":"2022-11-10T08:19:44Z","title":"VieCap4H-VLSP 2021: ObjectAoA -- Enhancing performance of Object\n  Relation Transformer with Attention on Attention for Vietnamese image\n  captioning","summary":"  Image captioning is currently a challenging task that requires the ability to\nboth understand visual information and use human language to describe this\nvisual information in the image. In this paper, we propose an efficient way to\nimprove the image understanding ability of transformer-based method by\nextending Object Relation Transformer architecture with Attention on Attention\nmechanism. Experiments on the VieCap4H dataset show that our proposed method\nsignificantly outperforms its original structure on both the public test and\nprivate test of the Image Captioning shared task held by VLSP.\n","authors":["Nghia Hieu Nguyen","Duong T. D. Vo","Minh-Quan Ha"],"pdf_url":"https://arxiv.org/pdf/2211.05405v3.pdf","comment":"Accepted for publishing at the VNU Journal of Science: Computer\n  Science and Communication Engineering"},{"id":"http://arxiv.org/abs/2302.13487v1","updated":"2023-02-27T02:57:58Z","published":"2023-02-27T02:57:58Z","title":"Contextual adversarial attack against aerial detection in the physical\n  world","summary":"  Deep Neural Networks (DNNs) have been extensively utilized in aerial\ndetection. However, DNNs' sensitivity and vulnerability to maliciously\nelaborated adversarial examples have progressively garnered attention.\nRecently, physical attacks have gradually become a hot issue due to they are\nmore practical in the real world, which poses great threats to some\nsecurity-critical applications. In this paper, we take the first attempt to\nperform physical attacks in contextual form against aerial detection in the\nphysical world. We propose an innovative contextual attack method against\naerial detection in real scenarios, which achieves powerful attack performance\nand transfers well between various aerial object detectors without smearing or\nblocking the interested objects to hide. Based on the findings that the\ntargets' contextual information plays an important role in aerial detection by\nobserving the detectors' attention maps, we propose to make full use of the\ncontextual area of the interested targets to elaborate contextual perturbations\nfor the uncovered attacks in real scenarios. Extensive proportionally scaled\nexperiments are conducted to evaluate the effectiveness of the proposed\ncontextual attack method, which demonstrates the proposed method's superiority\nin both attack efficacy and physical practicality.\n","authors":["Jiawei Lian","Xiaofei Wang","Yuru Su","Mingyang Ma","Shaohui Mei"],"pdf_url":"https://arxiv.org/pdf/2302.13487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05615v2","updated":"2023-02-27T02:56:32Z","published":"2023-02-11T06:36:20Z","title":"Anatomical Invariance Modeling and Semantic Alignment for\n  Self-supervised Learning in 3D Medical Image Segmentation","summary":"  Self-supervised learning (SSL) has recently achieved promising performance\nfor 3D medical image segmentation tasks. Most current methods follow existing\nSSL paradigm originally designed for photographic or natural images, which\ncannot explicitly and thoroughly exploit the intrinsic similar anatomical\nstructures across varying medical images. This may in fact degrade the quality\nof learned deep representations by maximizing the similarity among features\ncontaining spatial misalignment information and different anatomical semantics.\nIn this work, we propose a new self-supervised learning framework, namely\nAlice, that explicitly fulfills Anatomical invariance modeling and semantic\nalignment via elaborately combining discriminative and generative objectives.\nAlice introduces a new contrastive learning strategy which encourages the\nsimilarity between views that are diversely mined but with consistent\nhigh-level semantics, in order to learn invariant anatomical features.\nMoreover, we design a conditional anatomical feature alignment module to\ncomplement corrupted embeddings with globally matched semantics and inter-patch\ntopology information, conditioned by the distribution of local image content,\nwhich permits to create better contrastive pairs. Our extensive quantitative\nexperiments on two public 3D medical image segmentation benchmarks of FLARE\n2022 and BTCV demonstrate and validate the performance superiority of Alice,\nsurpassing the previous best SSL counterpart methods by 2.11% and 1.77% in Dice\ncoefficients, respectively.\n","authors":["Yankai Jiang","Mingze Sun","Heng Guo","Ke Yan","Le Lu","Minfeng Xu"],"pdf_url":"https://arxiv.org/pdf/2302.05615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.07085v3","updated":"2023-02-27T02:32:56Z","published":"2022-05-14T15:24:06Z","title":"Monitoring of Pigmented Skin Lesions Using 3D Whole Body Imaging","summary":"  Advanced artificial intelligence and machine learning have great potential to\nredefine how skin lesions are detected, mapped, tracked and documented. Here,\nWe propose a 3D whole-body imaging system known as 3DSkin-mapper to enable\nautomated detection, evaluation and mapping of skin lesions. A modular camera\nrig arranged in a cylindrical configuration was designed to automatically\ncapture images of the entire skin surface of a subject synchronously from\nmultiple angles. Based on the images, we developed algorithms for 3D model\nreconstruction, data processing and skin lesion detection and tracking based on\ndeep convolutional neural networks. We also introduced a customised,\nuser-friendly, and adaptable interface that enables individuals to\ninteractively visualise, manipulate, and annotate the images. The proposed\nsystem is developed for skin lesion screening, the focus of this paper is to\nintroduce the system instead of clinical study. Using synthetic and real images\nwe demonstrate the effectiveness of the proposed system by providing multiple\nviews of a target skin lesion, enabling further 3D geometry analysis and\nlongitudinal tracking. It takes only a few seconds to capture the entire skin\nsurface, and about half an hour to process and analyse the images. Our\nexperiments show that the proposed system allow fast and easy whole body 3D\nimaging. It can be used by dermatological clinics to conduct skin screening,\ndetect and track skin lesions over time, identify suspicious lesions, and\ndocument pigmented lesions. The system can potentially save clinicians time and\neffort significantly. The 3D imaging and analysis has the potential to change\nthe paradigm of whole body photography with many applications in skin diseases,\nincluding inflammatory and pigmentary disorders.\n","authors":["David Ahmedt-Aristizabal","Chuong Nguyen","Lachlan Tychsen-Smith","Ashley Stacey","Shenghong Li","Joseph Pathikulangara","Lars Petersson","Dadong Wang"],"pdf_url":"https://arxiv.org/pdf/2205.07085v3.pdf","comment":"In Computer Methods and Programs in Biomedicine"},{"id":"http://arxiv.org/abs/2207.01405v3","updated":"2023-02-27T02:19:04Z","published":"2022-07-04T13:37:38Z","title":"I-ViT: Integer-only Quantization for Efficient Vision Transformer\n  Inference","summary":"  Vision Transformers (ViTs) have achieved state-of-the-art performance on\nvarious computer vision applications. However, these models have considerable\nstorage and computational overheads, making their deployment and efficient\ninference on edge devices challenging. Quantization is a promising approach to\nreducing model complexity, and the dyadic arithmetic pipeline can allow the\nquantized models to perform efficient integer-only inference. Unfortunately,\ndyadic arithmetic is based on the homogeneity condition in convolutional neural\nnetworks, which is not applicable to the non-linear components in ViTs, making\ninteger-only inference of ViTs an open issue. In this paper, we propose I-ViT,\nan integer-only quantization scheme for ViTs, to enable ViTs to perform the\nentire computational graph of inference with integer arithmetic and\nbit-shifting, and without any floating-point arithmetic. In I-ViT, linear\noperations (e.g., MatMul and Dense) follow the integer-only pipeline with\ndyadic arithmetic, and non-linear operations (e.g., Softmax, GELU, and\nLayerNorm) are approximated by the proposed light-weight integer-only\narithmetic methods. More specifically, I-ViT applies the proposed Shiftmax and\nShiftGELU, which are designed to use integer bit-shifting to approximate the\ncorresponding floating-point operations. We evaluate I-ViT on various benchmark\nmodels and the results show that integer-only INT8 quantization achieves\ncomparable (or even slightly higher) accuracy to the full-precision (FP)\nbaseline. Furthermore, we utilize TVM for practical hardware deployment on the\nGPU's integer arithmetic units, achieving 3.72$\\sim$4.11$\\times$ inference\nspeedup compared to the FP model.\n","authors":["Zhikai Li","Qingyi Gu"],"pdf_url":"https://arxiv.org/pdf/2207.01405v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14687v3","updated":"2023-02-27T02:17:13Z","published":"2022-09-29T11:12:27Z","title":"Diffusion Posterior Sampling for General Noisy Inverse Problems","summary":"  Diffusion models have been recently studied as powerful generative inverse\nproblem solvers, owing to their high quality reconstructions and the ease of\ncombining existing iterative solvers. However, most works focus on solving\nsimple linear inverse problems in noiseless settings, which significantly\nunder-represents the complexity of real-world problems. In this work, we extend\ndiffusion solvers to efficiently handle general noisy (non)linear inverse\nproblems via approximation of the posterior sampling. Interestingly, the\nresulting posterior sampling scheme is a blended version of diffusion sampling\nwith the manifold constrained gradient without a strict measurement consistency\nprojection step, yielding a more desirable generative path in noisy settings\ncompared to the previous studies. Our method demonstrates that diffusion models\ncan incorporate various measurement noise statistics such as Gaussian and\nPoisson, and also efficiently handle noisy nonlinear inverse problems such as\nFourier phase retrieval and non-uniform deblurring. Code available at\nhttps://github.com/DPS2022/diffusion-posterior-sampling\n","authors":["Hyungjin Chung","Jeongsol Kim","Michael T. Mccann","Marc L. Klasky","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2209.14687v3.pdf","comment":"ICLR 2023 spotlight"},{"id":"http://arxiv.org/abs/2302.12491v2","updated":"2023-02-27T01:24:52Z","published":"2023-02-24T07:17:15Z","title":"Joint Learning of Blind Super-Resolution and Crack Segmentation for\n  Realistic Degraded Images","summary":"  This paper proposes crack segmentation augmented by super resolution (SR)\nwith deep neural networks. In the proposed method, a SR network is jointly\ntrained with a binary segmentation network in an end-to-end manner. This joint\nlearning allows the SR network to be optimized for improving segmentation\nresults. For realistic scenarios, the SR network is extended from non-blind to\nblind for processing a low-resolution image degraded by unknown blurs. The\njoint network is improved by our proposed two extra paths that further\nencourage the mutual optimization between SR and segmentation. Comparative\nexperiments with SoTA segmentation methods demonstrate the superiority of our\njoint learning, and various ablation studies prove the effects of our\ncontributions.\n","authors":["Yuki Kondo","Norimichi Ukita"],"pdf_url":"https://arxiv.org/pdf/2302.12491v2.pdf","comment":"We have transferred this paper from \"Automation in Construction\" to\n  \"Advanced Engineering Informatics\". The code used in this paper will be made\n  public"},{"id":"http://arxiv.org/abs/2006.13999v3","updated":"2023-02-27T01:24:00Z","published":"2020-06-24T19:01:05Z","title":"MCAL: Minimum Cost Human-Machine Active Labeling","summary":"  Today, ground-truth generation uses data sets annotated by cloud-based\nannotation services. These services rely on human annotation, which can be\nprohibitively expensive. In this paper, we consider the problem of hybrid\nhuman-machine labeling, which trains a classifier to accurately auto-label part\nof the data set. However, training the classifier can be expensive too. We\npropose an iterative approach that minimizes total overall cost by, at each\nstep, jointly determining which samples to label using humans and which to\nlabel using the trained classifier. We validate our approach on well known\npublic data sets such as Fashion-MNIST, CIFAR-10, CIFAR-100, and ImageNet. In\nsome cases, our approach has 6x lower overall cost relative to human labeling\nthe entire data set, and is always cheaper than the cheapest competing\nstrategy.\n","authors":["Hang Qiu","Krishna Chintalapudi","Ramesh Govindan"],"pdf_url":"https://arxiv.org/pdf/2006.13999v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14197v1","updated":"2023-02-27T23:28:17Z","published":"2023-02-27T23:28:17Z","title":"Image-Based Virtual Try-on System With Clothing-Size Adjustment","summary":"  The conventional image-based virtual try-on method cannot generate fitting\nimages that correspond to the clothing size because the system cannot\naccurately reflect the body information of a person. In this study, an\nimage-based virtual try-on system that could adjust the clothing size was\nproposed. The size information of the person and clothing were used as the\ninput for the proposed method to visualize the fitting of various clothing\nsizes in a virtual space. First, the distance between the shoulder width and\nheight of the clothing in the person image is calculated based on the\ncoordinate information of the key points detected by OpenPose. Then, the system\nchanges the size of only the clothing area of the segmentation map, whose\nlayout is estimated using the size of the person measured in the person image\nbased on the ratio of the person and clothing sizes. If the size of the\nclothing area increases during the drawing, the details in the collar and\noverlapping areas are corrected to improve visual appearance.\n","authors":["Minoru Kuribayashi","Koki Nakai","Nobuo Funabiki"],"pdf_url":"https://arxiv.org/pdf/2302.14197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14193v1","updated":"2023-02-27T23:06:01Z","published":"2023-02-27T23:06:01Z","title":"PointFlowHop: Green and Interpretable Scene Flow Estimation from\n  Consecutive Point Clouds","summary":"  An efficient 3D scene flow estimation method called PointFlowHop is proposed\nin this work. PointFlowHop takes two consecutive point clouds and determines\nthe 3D flow vectors for every point in the first point cloud. PointFlowHop\ndecomposes the scene flow estimation task into a set of subtasks, including\nego-motion compensation, object association and object-wise motion estimation.\nIt follows the green learning (GL) pipeline and adopts the feedforward data\nprocessing path. As a result, its underlying mechanism is more transparent than\ndeep-learning (DL) solutions based on end-to-end optimization of network\nparameters. We conduct experiments on the stereoKITTI and the Argoverse LiDAR\npoint cloud datasets and demonstrate that PointFlowHop outperforms\ndeep-learning methods with a small model size and less training time.\nFurthermore, we compare the Floating Point Operations (FLOPs) required by\nPointFlowHop and other learning-based methods in inference, and show its big\nsavings in computational complexity.\n","authors":["Pranav Kadam","Jiahao Gu","Shan Liu","C. -C. Jay Kuo"],"pdf_url":"https://arxiv.org/pdf/2302.14193v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.07102v2","updated":"2023-02-27T22:38:04Z","published":"2022-12-14T08:48:37Z","title":"Artificial intelligence-driven digital twin of a modern house\n  demonstrated in virtual reality","summary":"  A digital twin is a powerful tool that can help monitor and optimize physical\nassets in real-time. Simply put, it is a virtual representation of a physical\nasset, enabled through data and simulators, that can be used for a variety of\npurposes such as prediction, monitoring, and decision-making. However, the\nconcept of digital twin can be vague and difficult to understand, which is why\na new concept called \"capability level\" has been introduced. This concept\ncategorizes digital twins based on their capability and defines a scale from\nzero to five, with each level indicating an increasing level of functionality.\nThese levels are standalone, descriptive, diagnostic, predictive, prescriptive,\nand autonomous. By understanding the capability level of a digital twin, we can\nbetter understand its potential and limitations. To demonstrate the concepts,\nwe use a modern house as an example. The house is equipped with a range of\nsensors that collect data about its internal state, which can then be used to\ncreate digital twins of different capability levels. These digital twins can be\nvisualized in virtual reality, allowing users to interact with and manipulate\nthe virtual environment. The current work not only presents a blueprint for\ndeveloping digital twins but also suggests future research directions to\nenhance this technology. Digital twins have the potential to transform the way\nwe monitor and optimize physical assets, and by understanding their\ncapabilities, we can unlock their full potential.\n","authors":["Elias Mohammed Elfarri","Adil Rasheed","Omer San"],"pdf_url":"https://arxiv.org/pdf/2212.07102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00714v2","updated":"2023-02-27T22:19:55Z","published":"2023-01-02T15:13:30Z","title":"Learning Road Scene-level Representations via Semantic Region Prediction","summary":"  In this work, we tackle two vital tasks in automated driving systems, i.e.,\ndriver intent prediction and risk object identification from egocentric images.\nMainly, we investigate the question: what would be good road scene-level\nrepresentations for these two tasks? We contend that a scene-level\nrepresentation must capture higher-level semantic and geometric representations\nof traffic scenes around ego-vehicle while performing actions to their\ndestinations. To this end, we introduce the representation of semantic regions,\nwhich are areas where ego-vehicles visit while taking an afforded action (e.g.,\nleft-turn at 4-way intersections). We propose to learn scene-level\nrepresentations via a novel semantic region prediction task and an automatic\nsemantic region labeling algorithm. Extensive evaluations are conducted on the\nHDD and nuScenes datasets, and the learned representations lead to\nstate-of-the-art performance for driver intention prediction and risk object\nidentification.\n","authors":["Zihao Xiao","Alan Yuille","Yi-Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2301.00714v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2302.14166v1","updated":"2023-02-27T22:01:34Z","published":"2023-02-27T22:01:34Z","title":"GLOW: Global Layout Aware Attacks for Object Detection","summary":"  Adversarial attacks aims to perturb images such that a predictor outputs\nincorrect results. Due to the limited research in structured attacks, imposing\nconsistency checks on natural multi-object scenes is a promising yet practical\ndefense against conventional adversarial attacks. More desired attacks, to this\nend, should be able to fool defenses with such consistency checks. Therefore,\nwe present the first approach GLOW that copes with various attack requests by\ngenerating global layout-aware adversarial attacks where both categorical and\ngeometric layout constraints are explicitly established. Specifically, we focus\non object detection task and given a victim image, GLOW first localizes victim\nobjects according to target labels. And then it generates multiple attack\nplans, together with their context-consistency scores. Our proposed GLOW, on\nthe one hand, is capable of handling various types of requests, including\nsingle or multiple victim objects, with or without specified victim objects. On\nthe other hand, it produces a consistency score for each attack plan,\nreflecting the overall contextual consistency that both semantic category and\nglobal scene layout are considered. In experiment, we design multiple types of\nattack requests and validate our ideas on MS COCO validation set. Extensive\nexperimental results demonstrate that we can achieve about 40$\\%$ average\nrelative improvement compared to state-of-the-art methods in conventional\nsingle object attack request; Moreover, our method outperforms SOTAs\nsignificantly on more generic attack requests by at least 30$\\%$; Finally, our\nmethod produces superior performance under challenging zero-query black-box\nsetting, or 30$\\%$ better than SOTAs. Our code, model and attack requests would\nbe made available.\n","authors":["Jun Bao","Buyu Liu","Jianping Fan","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2302.14166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14163v1","updated":"2023-02-27T21:55:48Z","published":"2023-02-27T21:55:48Z","title":"A Language-Guided Benchmark for Weakly Supervised Open Vocabulary\n  Semantic Segmentation","summary":"  Increasing attention is being diverted to data-efficient problem settings\nlike Open Vocabulary Semantic Segmentation (OVSS) which deals with segmenting\nan arbitrary object that may or may not be seen during training. The closest\nstandard problems related to OVSS are Zero-Shot and Few-Shot Segmentation (ZSS,\nFSS) and their Cross-dataset variants where zero to few annotations are needed\nto segment novel classes. The existing FSS and ZSS methods utilize fully\nsupervised pixel-labelled seen classes to segment unseen classes. Pixel-level\nlabels are hard to obtain, and using weak supervision in the form of\ninexpensive image-level labels is often more practical. To this end, we propose\na novel unified weakly supervised OVSS pipeline that can perform ZSS, FSS and\nCross-dataset segmentation on novel classes without using pixel-level labels\nfor either the base (seen) or the novel (unseen) classes in an inductive\nsetting. We propose Weakly-Supervised Language-Guided Segmentation Network\n(WLSegNet), a novel language-guided segmentation pipeline that i) learns\ngeneralizable context vectors with batch aggregates (mean) to map class prompts\nto image features using frozen CLIP (a vision-language model) and ii) decouples\nweak ZSS/FSS into weak semantic segmentation and Zero-Shot segmentation. The\nlearned context vectors avoid overfitting on seen classes during training and\ntransfer better to novel classes during testing. WLSegNet avoids fine-tuning\nand the use of external datasets during training. The proposed pipeline beats\nexisting methods for weak generalized Zero-Shot and weak Few-Shot semantic\nsegmentation by 39 and 3 mIOU points respectively on PASCAL VOC and weak\nFew-Shot semantic segmentation by 5 mIOU points on MS COCO. On a harder setting\nof 2-way 1-shot weak FSS, WLSegNet beats the baselines by 13 and 22 mIOU points\non PASCAL VOC and MS COCO, respectively.\n","authors":["Prashant Pandey","Mustafa Chasmai","Monish Natarajan","Brejesh Lall"],"pdf_url":"https://arxiv.org/pdf/2302.14163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08647v2","updated":"2023-02-27T21:42:16Z","published":"2022-10-16T22:13:59Z","title":"D2SLAM: Semantic visual SLAM based on the Depth-related influence on\n  object interactions for Dynamic environments","summary":"  Considering the scene's dynamics is the most effective solution to obtain an\naccurate perception of unknown environments for real vSLAM applications. Most\nexisting methods attempt to address the non-rigid scene assumption by combining\ngeometric and semantic approaches to determine dynamic elements that lack\ngeneralization and scene awareness. We propose a novel approach that overcomes\nthese limitations by using scene-depth information to improve the accuracy of\nthe localization from geometric and semantic modules. In addition, we use depth\ninformation to determine an area of influence of dynamic objects through an\nObject Interaction Module that estimates the state of both non-matched and\nnon-segmented key points. The obtained results on TUM-RGBD dataset clearly\ndemonstrate that the proposed method outperforms the state-of-the-art.\n","authors":["Ayman Beghdadi","Malik Mallem","Lotfi Beji"],"pdf_url":"https://arxiv.org/pdf/2210.08647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.10520v2","updated":"2023-02-27T21:36:57Z","published":"2022-01-21T22:21:31Z","title":"Automatic Attention Pruning: Improving and Automating Model Pruning\n  using Attentions","summary":"  Pruning is a promising approach to compress deep learning models in order to\ndeploy them on resource-constrained edge devices. However, many existing\npruning solutions are based on unstructured pruning, which yields models that\ncannot efficiently run on commodity hardware; and they often require users to\nmanually explore and tune the pruning process, which is time-consuming and\noften leads to sub-optimal results. To address these limitations, this paper\npresents Automatic Attention Pruning (AAP), an adaptive, attention-based,\nstructured pruning approach to automatically generate small, accurate, and\nhardware-efficient models that meet user objectives. First, it proposes\niterative structured pruning using activation-based attention maps to\neffectively identify and prune unimportant filters. Then, it proposes adaptive\npruning policies for automatically meeting the pruning objectives of\naccuracy-critical, memory-constrained, and latency-sensitive tasks. A\ncomprehensive evaluation shows that AAP substantially outperforms the\nstate-of-the-art structured pruning works for a variety of model architectures.\nOur code is at: https://github.com/kaiqi123/Automatic-Attention-Pruning.git.\n","authors":["Kaiqi Zhao","Animesh Jain","Ming Zhao"],"pdf_url":"https://arxiv.org/pdf/2201.10520v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14138v1","updated":"2023-02-27T20:52:10Z","published":"2023-02-27T20:52:10Z","title":"Layer Grafted Pre-training: Bridging Contrastive Learning And Masked\n  Image Modeling For Label-Efficient Representations","summary":"  Recently, both Contrastive Learning (CL) and Mask Image Modeling (MIM)\ndemonstrate that self-supervision is powerful to learn good representations.\nHowever, naively combining them is far from success. In this paper, we start by\nmaking the empirical observation that a naive joint optimization of CL and MIM\nlosses leads to conflicting gradient directions - more severe as the layers go\ndeeper. This motivates us to shift the paradigm from combining loss at the end,\nto choosing the proper learning method per network layer. Inspired by\nexperimental observations, we find that MIM and CL are suitable to lower and\nhigher layers, respectively. We hence propose to combine them in a surprisingly\nsimple, \"sequential cascade\" fashion: early layers are first trained under one\nMIM loss, on top of which latter layers continue to be trained under another CL\nloss. The proposed Layer Grafted Pre-training learns good visual\nrepresentations that demonstrate superior label efficiency in downstream\napplications, in particular yielding strong few-shot performance besides linear\nevaluation. For instance, on ImageNet-1k, Layer Grafted Pre-training yields\n65.5% Top-1 accuracy in terms of 1% few-shot learning with ViT-B/16, which\nimproves MIM and CL baselines by 14.4% and 2.1% with no bells and whistles. The\ncode is available at\nhttps://github.com/VITA-Group/layerGraftedPretraining_ICLR23.git.\n","authors":["Ziyu Jiang","Yinpeng Chen","Mengchen Liu","Dongdong Chen","Xiyang Dai","Lu Yuan","Zicheng Liu","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14138v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.12301v2","updated":"2023-02-27T20:50:27Z","published":"2023-02-23T19:43:20Z","title":"An Aligned Multi-Temporal Multi-Resolution Satellite Image Dataset for\n  Change Detection Research","summary":"  This paper presents an aligned multi-temporal and multi-resolution satellite\nimage dataset for research in change detection. We expect our dataset to be\nuseful to researchers who want to fuse information from multiple satellites for\ndetecting changes on the surface of the earth that may not be fully visible in\nany single satellite. The dataset we present was created by augmenting the\nSpaceNet-7 dataset with temporally parallel stacks of Landsat and Sentinel\nimages. The SpaceNet-7 dataset consists of time-sequenced Planet images\nrecorded over 101 AOIs (Areas-of-Interest). In our dataset, for each of the 60\nAOIs that are meant for training, we augment the Planet datacube with\ntemporally parallel datacubes of Landsat and Sentinel images. The temporal\nalignments between the high-res Planet images, on the one hand, and the Landsat\nand Sentinel images, on the other, are approximate since the temporal\nresolution for the Planet images is one month -- each image being a mosaic of\nthe best data collected over a month. Whenever we have a choice regarding which\nLandsat and Sentinel images to pair up with the Planet images, we have chosen\nthose that had the least cloud cover. A particularly important feature of our\ndataset is that the high-res and the low-res images are spatially aligned\ntogether with our MuRA framework presented in this paper. Foundational to the\nalignment calculation is the modeling of inter-satellite misalignment errors\nwith polynomials as in NASA's AROP algorithm. We have named our dataset MuRA-T\nfor the MuRA framework that is used for aligning the cross-satellite images and\n\"T\" for the temporal dimension in the dataset.\n","authors":["Rahul Deshmukh","Constantine J. Roros","Amith Kashyap","Avinash C. Kak"],"pdf_url":"https://arxiv.org/pdf/2302.12301v2.pdf","comment":"8 pages, 4 figures, 3 tables, satellite image dataset"},{"id":"http://arxiv.org/abs/2302.14130v1","updated":"2023-02-27T20:34:30Z","published":"2023-02-27T20:34:30Z","title":"Leveraging Angular Distributions for Improved Knowledge Distillation","summary":"  Knowledge distillation as a broad class of methods has led to the development\nof lightweight and memory efficient models, using a pre-trained model with a\nlarge capacity (teacher network) to train a smaller model (student network).\nRecently, additional variations for knowledge distillation, utilizing\nactivation maps of intermediate layers as the source of knowledge, have been\nstudied. Generally, in computer vision applications, it is seen that the\nfeature activation learned by a higher capacity model contains richer\nknowledge, highlighting complete objects while focusing less on the background.\nBased on this observation, we leverage the dual ability of the teacher to\naccurately distinguish between positive (relevant to the target object) and\nnegative (irrelevant) areas. We propose a new loss function for distillation,\ncalled angular margin-based distillation (AMD) loss. AMD loss uses the angular\ndistance between positive and negative features by projecting them onto a\nhypersphere, motivated by the near angular distributions seen in many feature\nextractors. Then, we create a more attentive feature that is angularly\ndistributed on the hypersphere by introducing an angular margin to the positive\nfeature. Transferring such knowledge from the teacher network enables the\nstudent model to harness the higher discrimination of positive and negative\nfeatures for the teacher, thus distilling superior student models. The proposed\nmethod is evaluated for various student-teacher network pairs on four public\ndatasets. Furthermore, we show that the proposed method has advantages in\ncompatibility with other learning techniques, such as using fine-grained\nfeatures, augmentation, and other distillation methods.\n","authors":["Eun Som Jeon","Hongjun Choi","Ankita Shukla","Pavan Turaga"],"pdf_url":"https://arxiv.org/pdf/2302.14130v1.pdf","comment":"Neurocomputing, Volume 518, 21 January 2023, Pages 466-481"},{"id":"http://arxiv.org/abs/2302.14124v1","updated":"2023-02-27T20:12:28Z","published":"2023-02-27T20:12:28Z","title":"Multimodal Deep Learning to Differentiate Tumor Recurrence from\n  Treatment Effect in Human Glioblastoma","summary":"  Differentiating tumor progression (TP) from treatment-related necrosis (TN)\nis critical for clinical management decisions in glioblastoma (GBM). Dynamic\nFDG PET (dPET), an advance from traditional static FDG PET, may prove\nadvantageous in clinical staging. dPET includes novel methods of a\nmodel-corrected blood input function that accounts for partial volume averaging\nto compute parametric maps that reveal kinetic information. In a preliminary\nstudy, a convolution neural network (CNN) was trained to predict classification\naccuracy between TP and TN for $35$ brain tumors from $26$ subjects in the\nPET-MR image space. 3D parametric PET Ki (from dPET), traditional static PET\nstandardized uptake values (SUV), and also the brain tumor MR voxels formed the\ninput for the CNN. The average test accuracy across all leave-one-out\ncross-validation iterations adjusting for class weights was $0.56$ using only\nthe MR, $0.65$ using only the SUV, and $0.71$ using only the Ki voxels.\nCombining SUV and MR voxels increased the test accuracy to $0.62$. On the other\nhand, MR and Ki voxels increased the test accuracy to $0.74$. Thus, dPET\nfeatures alone or with MR features in deep learning models would enhance\nprediction accuracy in differentiating TP vs TN in GBM.\n","authors":["Tonmoy Hossain","Zoraiz Qureshi","Nivetha Jayakumar","Thomas Eluvathingal Muttikkal","Sohil Patel","David Schiff","Miaomiao Zhang","Bijoy Kundu"],"pdf_url":"https://arxiv.org/pdf/2302.14124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14115v1","updated":"2023-02-27T19:53:49Z","published":"2023-02-27T19:53:49Z","title":"Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense\n  Video Captioning","summary":"  In this work, we introduce Vid2Seq, a multi-modal single-stage dense event\ncaptioning model pretrained on narrated videos which are readily-available at\nscale. The Vid2Seq architecture augments a language model with special time\ntokens, allowing it to seamlessly predict event boundaries and textual\ndescriptions in the same output sequence. Such a unified model requires\nlarge-scale training data, which is not available in current annotated\ndatasets. We show that it is possible to leverage unlabeled narrated videos for\ndense video captioning, by reformulating sentence boundaries of transcribed\nspeech as pseudo event boundaries, and using the transcribed speech sentences\nas pseudo event captions. The resulting Vid2Seq model pretrained on the\nYT-Temporal-1B dataset improves the state of the art on a variety of dense\nvideo captioning benchmarks including YouCook2, ViTT and ActivityNet Captions.\nVid2Seq also generalizes well to the video paragraph captioning task and the\nstandard task of video clip captioning. Our code and models will be publicly\nreleased at https://antoyang.github.io/vid2seq.html.\n","authors":["Antoine Yang","Arsha Nagrani","Paul Hongsuck Seo","Antoine Miech","Jordi Pont-Tuset","Ivan Laptev","Josef Sivic","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2302.14115v1.pdf","comment":"To appear at CVPR 2023; 18 pages; 6 figures"},{"id":"http://arxiv.org/abs/2302.14098v1","updated":"2023-02-27T19:16:42Z","published":"2023-02-27T19:16:42Z","title":"An Embedded and Real-Time Pupil Detection Pipeline","summary":"  Wearable pupil detection systems often separate the analysis of the captured\nwearer's eye images for wirelessly-tethered back-end systems. We argue in this\npaper that investigating hardware-software co-designs would bring along\nopportunities to make such systems smaller and more efficient. We introduce an\nopen-source embedded system for wearable, non-invasive pupil detection in\nreal-time, on the wearable, embedded platform itself. Our system consists of a\nhead-mounted eye tracker prototype, which combines two miniature camera systems\nwith Raspberry Pi-based embedded system. Apart from the hardware design, we\nalso contribute a pupil detection pipeline that operates using edge analysis,\nnatively on the embedded system at 30fps and run-time of 54ms at 480x640 and\n23ms at 240x320. Average cumulative error of 5.3368px is found on the LPW\ndataset for a detection rate of 51.9\\% with our detection pipeline. For\nevaluation on our hardware-specific camera frames, we also contribute a dataset\nof 35000 images, from 20 participants.\n","authors":["Ankur Raj","Diwas Bhattarai","Kristof Van Laerhoven"],"pdf_url":"https://arxiv.org/pdf/2302.14098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06710v2","updated":"2023-02-27T19:13:37Z","published":"2022-12-13T16:29:13Z","title":"TIER: Text-Image Entropy Regularization for CLIP-style models","summary":"  In this paper, we introduce a novel regularization scheme on contrastive\nlanguage-image pre-trained (CLIP) medical vision models. Our approach is based\non the observation that on many medical imaging tasks text tokens should only\ndescribe a small number of image regions and, likewise, each image region\nshould correspond to only a few text tokens. In CLIP-style models, this implies\nthat text-token embeddings should have high similarity to only a small number\nof image-patch embeddings for a given image-text pair. We formalize this\nobservation using a novel regularization scheme that penalizes the entropy of\nthe text-token to image-patch similarity scores. We qualitatively and\nquantitatively demonstrate that the proposed regularization scheme shrinks most\nof the pairwise text-token and image-patch similarity scores towards zero, thus\nachieving the desired effect. We demonstrate the promise of our approach in an\nimportant medical context, chest x-rays, where this underlying sparsity\nhypothesis naturally arises. Using our proposed approach, we achieve state of\nthe art (SOTA) average zero-shot performance on the CheXpert and Padchest chest\nx-ray datasets, outperforming an unregularized version of the model and several\nrecently published self-supervised models.\n","authors":["Anil Palepu","Andrew L. Beam"],"pdf_url":"https://arxiv.org/pdf/2212.06710v2.pdf","comment":"Submitted to CHIL 2023 conference"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.14027v1","updated":"2023-02-27T18:38:10Z","published":"2023-02-27T18:38:10Z","title":"Diversity matters: Robustness of bias measurements in Wikidata","summary":"  With the widespread use of knowledge graphs (KG) in various automated AI\nsystems and applications, it is very important to ensure that information\nretrieval algorithms leveraging them are free from societal biases. Previous\nworks have depicted biases that persist in KGs, as well as employed several\nmetrics for measuring the biases. However, such studies lack the systematic\nexploration of the sensitivity of the bias measurements, through varying\nsources of data, or the embedding algorithms used. To address this research\ngap, in this work, we present a holistic analysis of bias measurement on the\nknowledge graph. First, we attempt to reveal data biases that surface in\nWikidata for thirteen different demographics selected from seven continents.\nNext, we attempt to unfold the variance in the detection of biases by two\ndifferent knowledge graph embedding algorithms - TransE and ComplEx. We conduct\nour extensive experiments on a large number of occupations sampled from the\nthirteen demographics with respect to the sensitive attribute, i.e., gender.\nOur results show that the inherent data bias that persists in KG can be altered\nby specific algorithm bias as incorporated by KG embedding learning algorithms.\nFurther, we show that the choice of the state-of-the-art KG embedding algorithm\nhas a strong impact on the ranking of biased occupations irrespective of\ngender. We observe that the similarity of the biased occupations across\ndemographics is minimal which reflects the socio-cultural differences around\nthe globe. We believe that this full-scale audit of the bias measurement\npipeline will raise awareness among the community while deriving insights\nrelated to design choices of data and algorithms both and refrain from the\npopular dogma of ``one-size-fits-all''.\n","authors":["Paramita Das","Sai Keerthana Karnam","Anirban Panda","Bhanu Prakash Reddy Guda","Soumya Sarkar","Animesh Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2302.14027v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2302.14021v1","updated":"2023-02-27T18:25:19Z","published":"2023-02-27T18:25:19Z","title":"Quantifying Valence and Arousal in Text with Multilingual Pre-trained\n  Transformers","summary":"  The analysis of emotions expressed in text has numerous applications. In\ncontrast to categorical analysis, focused on classifying emotions according to\na pre-defined set of common classes, dimensional approaches can offer a more\nnuanced way to distinguish between different emotions. Still, dimensional\nmethods have been less studied in the literature. Considering a valence-arousal\ndimensional space, this work assesses the use of pre-trained Transformers to\npredict these two dimensions on a continuous scale, with input texts from\nmultiple languages and domains. We specifically combined multiple annotated\ndatasets from previous studies, corresponding to either emotional lexica or\nshort text documents, and evaluated models of multiple sizes and trained under\ndifferent settings. Our results show that model size can have a significant\nimpact on the quality of predictions, and that by fine-tuning a large model we\ncan confidently predict valence and arousal in multiple languages. We make\navailable the code, models, and supporting data.\n","authors":["Gonçalo Azevedo Mendes","Bruno Martins"],"pdf_url":"https://arxiv.org/pdf/2302.14021v1.pdf","comment":"Accepted at the 45th European Conference on Information Retrieval\n  (ECIR'23), full paper track"},{"id":"http://arxiv.org/abs/2209.06128v2","updated":"2023-02-27T17:02:51Z","published":"2022-09-06T14:59:00Z","title":"A Scalable Recommendation Engine for New Users and Items","summary":"  In many digital contexts such as online news and e-tailing with many new\nusers and items, recommendation systems face several challenges: i) how to make\ninitial recommendations to users with little or no response history (i.e.,\ncold-start problem), ii) how to learn user preferences on items (test and\nlearn), and iii) how to scale across many users and items with myriad\ndemographics and attributes. While many recommendation systems accommodate\naspects of these challenges, few if any address all. This paper introduces a\nCollaborative Filtering (CF) Multi-armed Bandit (B) with Attributes (A)\nrecommendation system (CFB-A) to jointly accommodate all of these\nconsiderations. Empirical applications including an offline test on MovieLens\ndata, synthetic data simulations, and an online grocery experiment indicate the\nCFB-A leads to substantial improvement on cumulative average rewards (e.g.,\ntotal money or time spent, clicks, purchased quantities, average ratings, etc.)\nrelative to the most powerful extant baseline methods.\n","authors":["Boya Xu","Yiting Deng","Carl Mela"],"pdf_url":"https://arxiv.org/pdf/2209.06128v2.pdf","comment":"59 pages, 13 figures"},{"id":"http://arxiv.org/abs/2302.13915v1","updated":"2023-02-27T16:02:28Z","published":"2023-02-27T16:02:28Z","title":"TwERC: High Performance Ensembled Candidate Generation for Ads\n  Recommendation at Twitter","summary":"  Recommendation systems are a core feature of social media companies with\ntheir uses including recommending organic and promoted contents. Many modern\nrecommendation systems are split into multiple stages - candidate generation\nand heavy ranking - to balance computational cost against recommendation\nquality. We focus on the candidate generation phase of a large-scale ads\nrecommendation problem in this paper, and present a machine learning first\nheterogeneous re-architecture of this stage which we term TwERC. We show that a\nsystem that combines a real-time light ranker with sourcing strategies capable\nof capturing additional information provides validated gains. We present two\nstrategies. The first strategy uses a notion of similarity in the interaction\ngraph, while the second strategy caches previous scores from the ranking stage.\nThe graph based strategy achieves a 4.08% revenue gain and the rankscore based\nstrategy achieves a 1.38% gain. These two strategies have biases that\ncomplement both the light ranker and one another. Finally, we describe a set of\nmetrics that we believe are valuable as a means of understanding the complex\nproduct trade offs inherent in industrial candidate generation systems.\n","authors":["Vanessa Cai","Pradeep Prabakar","Manuel Serrano Rebuelta","Lucas Rosen","Federico Monti","Katarzyna Janocha","Tomo Lazovich","Jeetu Raj","Yedendra Shrinivasan","Hao Li","Thomas Markovich"],"pdf_url":"https://arxiv.org/pdf/2302.13915v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.13756v1","updated":"2023-02-27T13:34:38Z","published":"2023-02-27T13:34:38Z","title":"Multi-Feature Integration for Perception-Dependent Examination-Bias\n  Estimation","summary":"  Eliminating examination bias accurately is pivotal to apply click-through\ndata to train an unbiased ranking model. However, most examination-bias\nestimators are limited to the hypothesis of Position-Based Model (PBM), which\nsupposes that the calculation of examination bias only depends on the rank of\nthe document. Recently, although some works introduce information such as\nclicks in the same query list and contextual information when calculating the\nexamination bias, they still do not model the impact of document representation\non search engine result pages (SERPs) that seriously affects one's perception\nof document relevance to a query when examining. Therefore, we propose a\nMulti-Feature Integration Model (MFIM) where the examination bias depends on\nthe representation of document except the rank of it. Furthermore, we mine a\nkey factor slipoff counts that can indirectly reflects the influence of all\nperception-bias factors. Real world experiments on Baidu-ULTR dataset\ndemonstrate the superior effectiveness and robustness of the new approach. The\nsource code is available at\n\\href{https://github.com/lixsh6/Tencent_wsdm_cup2023/tree/main/pytorch_unbias}{https://github.com/lixsh6/Tencent\\_wsdm\\_cup2023}\n","authors":["Xiaoshu Chen","Xiangsheng Li","Kunliang Wei","Bin Hu","Lei Jiang","Zeqian Huang","Zhanhui Kang"],"pdf_url":"https://arxiv.org/pdf/2302.13756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03266v3","updated":"2023-02-27T12:08:24Z","published":"2023-01-09T11:02:49Z","title":"Doc2Query--: When Less is More","summary":"  Doc2Query -- the process of expanding the content of a document before\nindexing using a sequence-to-sequence model -- has emerged as a prominent\ntechnique for improving the first-stage retrieval effectiveness of search\nengines. However, sequence-to-sequence models are known to be prone to\n\"hallucinating\" content that is not present in the source text. We argue that\nDoc2Query is indeed prone to hallucination, which ultimately harms retrieval\neffectiveness and inflates the index size. In this work, we explore techniques\nfor filtering out these harmful queries prior to indexing. We find that using a\nrelevance model to remove poor-quality queries can improve the retrieval\neffectiveness of Doc2Query by up to 16%, while simultaneously reducing mean\nquery execution time by 23% and cutting the index size by 33%. We release the\ncode, data, and a live demonstration to facilitate reproduction and further\nexploration at https://github.com/terrierteam/pyterrier_doc2query.\n","authors":["Mitko Gospodinov","Sean MacAvaney","Craig Macdonald"],"pdf_url":"https://arxiv.org/pdf/2301.03266v3.pdf","comment":"ECIR 2023"},{"id":"http://arxiv.org/abs/2212.05767v6","updated":"2023-02-27T10:19:44Z","published":"2022-12-12T08:40:04Z","title":"A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic,\n  and Multimodal","summary":"  Knowledge graph reasoning (KGR), aiming to deduce new facts from existing\nfacts based on mined logic rules underlying knowledge graphs (KGs), has become\na fast-growing research direction. It has been proven to significantly benefit\nthe usage of KGs in many AI applications, such as question answering and\nrecommendation systems, etc. According to the graph types, the existing KGR\nmodels can be roughly divided into three categories, i.e., static models,\ntemporal models, and multi-modal models. The early works in this domain mainly\nfocus on static KGR and tend to directly apply general knowledge graph\nembedding models to the reasoning task. However, these models are not suitable\nfor more complex but practical tasks, such as inductive static KGR, temporal\nKGR, and multi-modal KGR. To this end, multiple works have been developed\nrecently, but no survey papers and open-source repositories comprehensively\nsummarize and discuss models in this important direction. To fill the gap, we\nconduct a survey for knowledge graph reasoning tracing from static to temporal\nand then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR\nmodels, and typical datasets are introduced and discussed consequently.\nMoreover, we discuss the challenges and potential opportunities. The\ncorresponding open-source repository is shared on GitHub:\nhttps://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.\n","authors":["Ke Liang","Lingyuan Meng","Meng Liu","Yue Liu","Wenxuan Tu","Siwei Wang","Sihang Zhou","Xinwang Liu","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.05767v6.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2207.05969v2","updated":"2023-02-27T08:11:52Z","published":"2022-07-13T05:25:39Z","title":"Bootstrap Latent Representations for Multi-modal Recommendation","summary":"  This paper studies the multi-modal recommendation problem, where the item\nmulti-modality information (e.g., images and textual descriptions) is exploited\nto improve the recommendation accuracy. Besides the user-item interaction\ngraph, existing state-of-the-art methods usually use auxiliary graphs (e.g.,\nuser-user or item-item relation graph) to augment the learned representations\nof users and/or items. These representations are often propagated and\naggregated on auxiliary graphs using graph convolutional networks, which can be\nprohibitively expensive in computation and memory, especially for large graphs.\nMoreover, existing multi-modal recommendation methods usually leverage randomly\nsampled negative examples in Bayesian Personalized Ranking (BPR) loss to guide\nthe learning of user/item representations, which increases the computational\ncost on large graphs and may also bring noisy supervision signals into the\ntraining process. To tackle the above issues, we propose a novel\nself-supervised multi-modal recommendation model, dubbed BM3, which requires\nneither augmentations from auxiliary graphs nor negative samples. Specifically,\nBM3 first bootstraps latent contrastive views from the representations of users\nand items with a simple dropout augmentation. It then jointly optimizes three\nmulti-modal objectives to learn the representations of users and items by\nreconstructing the user-item interaction graph and aligning modality features\nunder both inter- and intra-modality perspectives. BM3 alleviates both the need\nfor contrasting with negative examples and the complex graph augmentation from\nan additional target network for contrastive view generation. We show BM3\noutperforms prior recommendation models on three datasets with number of nodes\nranging from 20K to 200K, while achieving a 2-9X reduction in training time.\nOur code is available at https://github.com/enoche/BM3.\n","authors":["Xin Zhou","Hongyu Zhou","Yong Liu","Zhiwei Zeng","Chunyan Miao","Pengwei Wang","Yuan You","Feijun Jiang"],"pdf_url":"https://arxiv.org/pdf/2207.05969v2.pdf","comment":"Accepted by Proceedings of the ACM Web Conference 2023 (WWW'23)"},{"id":"http://arxiv.org/abs/2302.13522v1","updated":"2023-02-27T05:21:35Z","published":"2023-02-27T05:21:35Z","title":"IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size\n  of Public Graph Datasets for Deep Learning Research","summary":"  Graph neural networks (GNNs) have shown high potential for a variety of\nreal-world, challenging applications, but one of the major obstacles in GNN\nresearch is the lack of large-scale flexible datasets. Most existing public\ndatasets for GNNs are relatively small, which limits the ability of GNNs to\ngeneralize to unseen data. The few existing large-scale graph datasets provide\nvery limited labeled data. This makes it difficult to determine if the GNN\nmodel's low accuracy for unseen data is inherently due to insufficient training\ndata or if the model failed to generalize. Additionally, datasets used to train\nGNNs need to offer flexibility to enable a thorough study of the impact of\nvarious factors while training GNN models.\n  In this work, we introduce the Illinois Graph Benchmark (IGB), a research\ndataset tool that the developers can use to train, scrutinize and\nsystematically evaluate GNN models with high fidelity. IGB includes both\nhomogeneous and heterogeneous graphs of enormous sizes, with more than 40% of\ntheir nodes labeled. Compared to the largest graph datasets publicly available,\nthe IGB provides over 162X more labeled data for deep learning practitioners\nand developers to create and evaluate models with higher accuracy. The IGB\ndataset is designed to be flexible, enabling the study of various GNN\narchitectures, embedding generation techniques, and analyzing system\nperformance issues. IGB is open-sourced, supports DGL and PyG frameworks, and\ncomes with releases of the raw text that we believe foster emerging language\nmodels and GNN research projects. An early public version of IGB is available\nat https://github.com/IllinoisGraphBenchmark/IGB-Datasets.\n","authors":["Arpandeep Khatua","Vikram Sharma Mailthody","Bhagyashree Taleka","Tengfei Ma","Xiang Song","Wen-mei Hwu"],"pdf_url":"https://arxiv.org/pdf/2302.13522v1.pdf","comment":"Under Review in KDD'23 conference"},{"id":"http://arxiv.org/abs/2202.12524v3","updated":"2023-02-27T05:19:59Z","published":"2022-02-25T06:58:28Z","title":"MAMDR: A Model Agnostic Learning Method for Multi-Domain Recommendation","summary":"  Large-scale e-commercial platforms in the real-world usually contain various\nrecommendation scenarios (domains) to meet demands of diverse customer groups.\nMulti-Domain Recommendation (MDR), which aims to jointly improve\nrecommendations on all domains and easily scales to thousands of domains, has\nattracted increasing attention from practitioners and researchers. Existing MDR\nmethods usually employ a shared structure and several specific components to\nrespectively leverage reusable features and domain-specific information.\nHowever, data distribution differs across domains, making it challenging to\ndevelop a general model that can be applied to all circumstances. Additionally,\nduring training, shared parameters often suffer from the domain conflict while\nspecific parameters are inclined to overfitting on data sparsity domains. we\nfirst present a scalable MDR platform served in Taobao that enables to provide\nservices for thousands of domains without specialists involved. To address the\nproblems of MDR methods, we propose a novel model agnostic learning framework,\nnamely MAMDR, for the multi-domain recommendation. Specifically, we first\npropose a Domain Negotiation (DN) strategy to alleviate the conflict between\ndomains. Then, we develop a Domain Regularization (DR) to improve the\ngeneralizability of specific parameters by learning from other domains. We\nintegrate these components into a unified framework and present MAMDR, which\ncan be applied to any model structure to perform multi-domain recommendation.\nFinally, we present a large-scale implementation of MAMDR in the Taobao\napplication and construct various public MDR benchmark datasets which can be\nused for following studies. Extensive experiments on both benchmark datasets\nand industry datasets demonstrate the effectiveness and generalizability of\nMAMDR.\n","authors":["Linhao Luo","Yumeng Li","Buyu Gao","Shuai Tang","Sinan Wang","Jiancheng Li","Tanchao Zhu","Jiancai Liu","Zhao Li","Binqiang Zhao","Ziyang Zheng","Shirui Pan"],"pdf_url":"https://arxiv.org/pdf/2202.12524v3.pdf","comment":"This paper has been accepted by ICDE 2023"},{"id":"http://arxiv.org/abs/2302.13498v1","updated":"2023-02-27T03:47:07Z","published":"2023-02-27T03:47:07Z","title":"Pretraining De-Biased Language Model with Large-scale Click Logs for\n  Document Ranking","summary":"  Pre-trained language models have achieved great success in various\nlarge-scale information retrieval tasks. However, most of pretraining tasks are\nbased on counterfeit retrieval data where the query produced by the tailored\nrule is assumed as the user's issued query on the given document or passage.\nTherefore, we explore to use large-scale click logs to pretrain a language\nmodel instead of replying on the simulated queries. Specifically, we propose to\nuse user behavior features to pretrain a debiased language model for document\nranking. Extensive experiments on Baidu desensitization click logs validate the\neffectiveness of our method. Our team on WSDM Cup 2023 Pre-training for Web\nSearch won the 1st place with a Discounted Cumulative Gain @ 10 (DCG@10) score\nof 12.16525 on the final leaderboard.\n","authors":["Xiangsheng Li","Xiaoshu Chen","Kunliang Wei","Bin Hu","Lei Jiang","Zeqian Huang","Zhanhui Kang"],"pdf_url":"https://arxiv.org/pdf/2302.13498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.04176v2","updated":"2023-02-27T20:41:33Z","published":"2022-02-08T22:18:25Z","title":"Police Text Analysis: Topic Modeling and Spatial Relative Density\n  Estimation","summary":"  We analyze a large corpus of police incident narrative documents in\nunderstanding the spatial distribution of the topics. The motivation for doing\nthis is that police narratives in each incident report contains very\nfine-grained information that is richer than the category that is manually\nassigned by the police. Our approach is to split the corpus into topics using\ntwo different unsupervised machine learning algorithms - Latent Dirichlet\nAllocation and Non-negative Matrix Factorization. We validate the performance\nof each learned topic model using model coherence. Then, using a k-nearest\nneighbors density ratio estimation (kNN-DRE) approach that we propose, we\nestimate the spatial density ratio per topic and use this for data discovery\nand analysis of each topic, allowing for insights into the described incidents\nat scale. We provide a qualitative assessment of each topic and highlight some\nkey benefits for using our kNN-DRE model for estimating spatial trends.\n","authors":["Sarah Huestis-Mitchell","Xiuyuan Cheng","Yao Xie"],"pdf_url":"https://arxiv.org/pdf/2202.04176v2.pdf","comment":"9 pages, 12 figures"},{"id":"http://arxiv.org/abs/2302.14096v1","updated":"2023-02-27T19:14:37Z","published":"2023-02-27T19:14:37Z","title":"A Dataset for Learning Graph Representations to Predict Customer Returns\n  in Fashion Retail","summary":"  We present a novel dataset collected by ASOS (a major online fashion\nretailer) to address the challenge of predicting customer returns in a fashion\nretail ecosystem. With the release of this substantial dataset we hope to\nmotivate further collaboration between research communities and the fashion\nindustry. We first explore the structure of this dataset with a focus on the\napplication of Graph Representation Learning in order to exploit the natural\ndata structure and provide statistical insights into particular features within\nthe data. In addition to this, we show examples of a return prediction\nclassification task with a selection of baseline models (i.e. with no\nintermediate representation learning step) and a graph representation based\nmodel. We show that in a downstream return prediction classification task, an\nF1-score of 0.792 can be found using a Graph Neural Network (GNN), improving\nupon other models discussed in this work. Alongside this increased F1-score, we\nalso present a lower cross-entropy loss by recasting the data into a graph\nstructure, indicating more robust predictions from a GNN based solution. These\nresults provide evidence that GNNs could provide more impactful and usable\nclassifications than other baseline models on the presented dataset and with\nthis motivation, we hope to encourage further research into graph-based\napproaches using the ASOS GraphReturns dataset.\n","authors":["Jamie McGowan","Elizabeth Guest","Ziyang Yan","Cong Zheng","Neha Patel","Mason Cusack","Charlie Donaldson","Sofie de Cnudde","Gabriel Facini","Fabon Dzogang"],"pdf_url":"https://arxiv.org/pdf/2302.14096v1.pdf","comment":"The ASOS GraphReturns dataset can be found at https://osf.io/c793h/.\n  Accepted at FashionXRecSys 2022 workshop"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.14051v1","updated":"2023-02-27T18:59:55Z","published":"2023-02-27T18:59:55Z","title":"Internet Explorer: Targeted Representation Learning on the Open Web","summary":"  Modern vision models typically rely on fine-tuning general-purpose models\npre-trained on large, static datasets. These general-purpose models only\ncapture the knowledge within their pre-training datasets, which are tiny,\nout-of-date snapshots of the Internet -- where billions of images are uploaded\neach day. We suggest an alternate approach: rather than hoping our static\ndatasets transfer to our desired tasks after large-scale pre-training, we\npropose dynamically utilizing the Internet to quickly train a small-scale model\nthat does extremely well on the task at hand. Our approach, called Internet\nExplorer, explores the web in a self-supervised manner to progressively find\nrelevant examples that improve performance on a desired target dataset. It\ncycles between searching for images on the Internet with text queries,\nself-supervised training on downloaded images, determining which images were\nuseful, and prioritizing what to search for next. We evaluate Internet Explorer\nacross several datasets and show that it outperforms or matches CLIP oracle\nperformance by using just a single GPU desktop to actively query the Internet\nfor 30--40 hours. Results, visualizations, and videos at\nhttps://internet-explorer-ssl.github.io/\n","authors":["Alexander C. Li","Ellis Brown","Alexei A. Efros","Deepak Pathak"],"pdf_url":"https://arxiv.org/pdf/2302.14051v1.pdf","comment":"Website at https://internet-explorer-ssl.github.io/"},{"id":"http://arxiv.org/abs/2302.14043v1","updated":"2023-02-27T18:53:28Z","published":"2023-02-27T18:53:28Z","title":"Single-Call Stochastic Extragradient Methods for Structured Non-monotone\n  Variational Inequalities: Improved Analysis under Weaker Conditions","summary":"  Single-call stochastic extragradient methods, like stochastic past\nextragradient (SPEG) and stochastic optimistic gradient (SOG), have gained a\nlot of interest in recent years and are one of the most efficient algorithms\nfor solving large-scale min-max optimization and variational inequalities\nproblems (VIP) appearing in various machine learning tasks. However, despite\ntheir undoubted popularity, current convergence analyses of SPEG and SOG\nrequire a bounded variance assumption. In addition, several important questions\nregarding the convergence properties of these methods are still open, including\nmini-batching, efficient step-size selection, and convergence guarantees under\ndifferent sampling strategies. In this work, we address these questions and\nprovide convergence guarantees for two large classes of structured non-monotone\nVIPs: (i) quasi-strongly monotone problems (a generalization of strongly\nmonotone problems) and (ii) weak Minty variational inequalities (a\ngeneralization of monotone and Minty VIPs). We introduce the expected residual\ncondition, explain its benefits, and show how it can be used to obtain a\nstrictly weaker bound than previously used growth conditions, expected\nco-coercivity, or bounded variance assumptions. Equipped with this condition,\nwe provide theoretical guarantees for the convergence of single-call\nextragradient methods for different step-size selections, including constant,\ndecreasing, and step-size-switching rules. Furthermore, our convergence\nanalysis holds under the arbitrary sampling paradigm, which includes importance\nsampling and various mini-batching strategies as special cases.\n","authors":["Sayantan Choudhury","Eduard Gorbunov","Nicolas Loizou"],"pdf_url":"https://arxiv.org/pdf/2302.14043v1.pdf","comment":"40 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.14040v1","updated":"2023-02-27T18:52:38Z","published":"2023-02-27T18:52:38Z","title":"Permutation Equivariant Neural Functionals","summary":"  This work studies the design of neural networks that can process the weights\nor gradients of other neural networks, which we refer to as neural functional\nnetworks (NFNs). Despite a wide range of potential applications, including\nlearned optimization, processing implicit neural representations, network\nediting, and policy evaluation, there are few unifying principles for designing\neffective architectures that process the weights of other networks. We approach\nthe design of neural functionals through the lens of symmetry, in particular by\nfocusing on the permutation symmetries that arise in the weights of deep\nfeedforward networks because hidden layer neurons have no inherent order. We\nintroduce a framework for building permutation equivariant neural functionals,\nwhose architectures encode these symmetries as an inductive bias. The key\nbuilding blocks of this framework are NF-Layers (neural functional layers) that\nwe constrain to be permutation equivariant through an appropriate parameter\nsharing scheme. In our experiments, we find that permutation equivariant neural\nfunctionals are effective on a diverse set of tasks that require processing the\nweights of MLPs and CNNs, such as predicting classifier generalization,\nproducing \"winning ticket\" sparsity masks for initializations, and editing the\nweights of implicit neural representations (INRs). In addition, we provide code\nfor our models and experiments at https://github.com/AllanYangZhou/nfn.\n","authors":["Allan Zhou","Kaien Yang","Kaylee Burns","Yiding Jiang","Samuel Sokota","J. Zico Kolter","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2302.14040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14038v1","updated":"2023-02-27T18:48:33Z","published":"2023-02-27T18:48:33Z","title":"Revisiting Variable Ordering for Real Quantifier Elimination using\n  Machine Learning","summary":"  Cylindrical Algebraic Decomposition (CAD) is a key proof technique for formal\nverification of cyber-physical systems. CAD is computationally expensive, with\nworst-case doubly-exponential complexity. Selecting an optimal variable\nordering is paramount to efficient use of CAD. Prior work has demonstrated that\nmachine learning can be useful in determining efficient variable orderings.\nMuch of this work has been driven by CAD problems extracted from applications\nof the MetiTarski theorem prover. In this paper, we revisit this prior work and\nconsider issues of bias in existing training and test data. We observe that the\nclassical MetiTarski benchmarks are heavily biased towards particular variable\norderings. To address this, we apply symmetries to create a new dataset\ncontaining more than 41K MetiTarski challenges designed to remove bias.\nFurthermore, we evaluate issues of information leakage, and test the\ngeneralizability of our models on the new dataset.\n","authors":["John Hester","Briland Hitaj","Grant Passmore","Sam Owre","Natarajan Shankar","Eric Yeh"],"pdf_url":"https://arxiv.org/pdf/2302.14038v1.pdf","comment":"7 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2302.14036v1","updated":"2023-02-27T18:47:55Z","published":"2023-02-27T18:47:55Z","title":"Text-only domain adaptation for end-to-end ASR using integrated\n  text-to-mel-spectrogram generator","summary":"  We propose an end-to-end ASR system that can be trained on transcribed speech\ndata, text data, or a mixture of both. For text-only training, our extended ASR\nmodel uses an integrated auxiliary TTS block that creates mel spectrograms from\nthe text. This block contains a conventional non-autoregressive\ntext-to-mel-spectrogram generator augmented with a GAN enhancer to improve the\nspectrogram quality. The proposed system can improve the accuracy of the ASR\nmodel on a new domain by using text-only data, and allows to significantly\nsurpass conventional audio-text training by using large text corpora.\n","authors":["Vladimir Bataev","Roman Korostik","Evgeny Shabalin","Vitaly Lavrukhin","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2302.14036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05782v2","updated":"2023-02-27T18:44:56Z","published":"2022-10-11T20:52:48Z","title":"Gradient-Guided Importance Sampling for Learning Binary Energy-Based\n  Models","summary":"  Learning energy-based models (EBMs) is known to be difficult especially on\ndiscrete data where gradient-based learning strategies cannot be applied\ndirectly. Although ratio matching is a sound method to learn discrete EBMs, it\nsuffers from expensive computation and excessive memory requirements, thereby\nresulting in difficulties in learning EBMs on high-dimensional data. Motivated\nby these limitations, in this study, we propose ratio matching with\ngradient-guided importance sampling (RMwGGIS). Particularly, we use the\ngradient of the energy function w.r.t. the discrete data space to approximately\nconstruct the provably optimal proposal distribution, which is subsequently\nused by importance sampling to efficiently estimate the original ratio matching\nobjective. We perform experiments on density modeling over synthetic discrete\ndata, graph generation, and training Ising models to evaluate our proposed\nmethod. The experimental results demonstrate that our method can significantly\nalleviate the limitations of ratio matching, perform more effectively in\npractice, and scale to high-dimensional problems. Our implementation is\navailable at https://github.com/divelab/RMwGGIS.\n","authors":["Meng Liu","Haoran Liu","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2210.05782v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2205.01490v2","updated":"2023-02-27T18:44:42Z","published":"2022-05-03T13:43:47Z","title":"Subspace Diffusion Generative Models","summary":"  Score-based models generate samples by mapping noise to data (and vice versa)\nvia a high-dimensional diffusion process. We question whether it is necessary\nto run this entire process at high dimensionality and incur all the\ninconveniences thereof. Instead, we restrict the diffusion via projections onto\nsubspaces as the data distribution evolves toward noise. When applied to\nstate-of-the-art models, our framework simultaneously improves sample quality\n-- reaching an FID of 2.17 on unconditional CIFAR-10 -- and reduces the\ncomputational cost of inference for the same number of denoising steps. Our\nframework is fully compatible with continuous-time diffusion and retains its\nflexible capabilities, including exact log-likelihoods and controllable\ngeneration. Code is available at\nhttps://github.com/bjing2016/subspace-diffusion.\n","authors":["Bowen Jing","Gabriele Corso","Renato Berlinghieri","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2205.01490v2.pdf","comment":"ECCV 2022"},{"id":"http://arxiv.org/abs/2302.14031v1","updated":"2023-02-27T18:43:11Z","published":"2023-02-27T18:43:11Z","title":"Proof-of-Contribution-Based Design for Collaborative Machine Learning on\n  Blockchain","summary":"  We consider a project (model) owner that would like to train a model by\nutilizing the local private data and compute power of interested data owners,\ni.e., trainers. Our goal is to design a data marketplace for such decentralized\ncollaborative/federated learning applications that simultaneously provides i)\nproof-of-contribution based reward allocation so that the trainers are\ncompensated based on their contributions to the trained model; ii)\nprivacy-preserving decentralized model training by avoiding any data movement\nfrom data owners; iii) robustness against malicious parties (e.g., trainers\naiming to poison the model); iv) verifiability in the sense that the integrity,\ni.e., correctness, of all computations in the data market protocol including\ncontribution assessment and outlier detection are verifiable through\nzero-knowledge proofs; and v) efficient and universal design. We propose a\nblockchain-based marketplace design to achieve all five objectives mentioned\nabove. In our design, we utilize a distributed storage infrastructure and an\naggregator aside from the project owner and the trainers. The aggregator is a\nprocessing node that performs certain computations, including assessing trainer\ncontributions, removing outliers, and updating hyper-parameters. We execute the\nproposed data market through a blockchain smart contract. The deployed smart\ncontract ensures that the project owner cannot evade payment, and honest\ntrainers are rewarded based on their contributions at the end of training.\nFinally, we implement the building blocks of the proposed data market and\ndemonstrate their applicability in practical scenarios through extensive\nexperiments.\n","authors":["Baturalp Buyukates","Chaoyang He","Shanshan Han","Zhiyong Fang","Yupeng Zhang","Jieyi Long","Ali Farahanchi","Salman Avestimehr"],"pdf_url":"https://arxiv.org/pdf/2302.14031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13893v2","updated":"2023-02-27T18:39:20Z","published":"2022-08-29T21:28:35Z","title":"Data Isotopes for Data Provenance in DNNs","summary":"  Today, creators of data-hungry deep neural networks (DNNs) scour the Internet\nfor training fodder, leaving users with little control over or knowledge of\nwhen their data is appropriated for model training. To empower users to\ncounteract unwanted data use, we design, implement and evaluate a practical\nsystem that enables users to detect if their data was used to train an DNN\nmodel. We show how users can create special data points we call isotopes, which\nintroduce \"spurious features\" into DNNs during training. With only query access\nto a trained model and no knowledge of the model training process, or control\nof the data labels, a user can apply statistical hypothesis testing to detect\nif a model has learned the spurious features associated with their isotopes by\ntraining on the user's data. This effectively turns DNNs' vulnerability to\nmemorization and spurious correlations into a tool for data provenance. Our\nresults confirm efficacy in multiple settings, detecting and distinguishing\nbetween hundreds of isotopes with high accuracy. We further show that our\nsystem works on public ML-as-a-service platforms and larger models such as\nImageNet, can use physical objects instead of digital marks, and remains\ngenerally robust against several adaptive countermeasures.\n","authors":["Emily Wenger","Xiuyu Li","Ben Y. Zhao","Vitaly Shmatikov"],"pdf_url":"https://arxiv.org/pdf/2208.13893v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2302.14027v1","updated":"2023-02-27T18:38:10Z","published":"2023-02-27T18:38:10Z","title":"Diversity matters: Robustness of bias measurements in Wikidata","summary":"  With the widespread use of knowledge graphs (KG) in various automated AI\nsystems and applications, it is very important to ensure that information\nretrieval algorithms leveraging them are free from societal biases. Previous\nworks have depicted biases that persist in KGs, as well as employed several\nmetrics for measuring the biases. However, such studies lack the systematic\nexploration of the sensitivity of the bias measurements, through varying\nsources of data, or the embedding algorithms used. To address this research\ngap, in this work, we present a holistic analysis of bias measurement on the\nknowledge graph. First, we attempt to reveal data biases that surface in\nWikidata for thirteen different demographics selected from seven continents.\nNext, we attempt to unfold the variance in the detection of biases by two\ndifferent knowledge graph embedding algorithms - TransE and ComplEx. We conduct\nour extensive experiments on a large number of occupations sampled from the\nthirteen demographics with respect to the sensitive attribute, i.e., gender.\nOur results show that the inherent data bias that persists in KG can be altered\nby specific algorithm bias as incorporated by KG embedding learning algorithms.\nFurther, we show that the choice of the state-of-the-art KG embedding algorithm\nhas a strong impact on the ranking of biased occupations irrespective of\ngender. We observe that the similarity of the biased occupations across\ndemographics is minimal which reflects the socio-cultural differences around\nthe globe. We believe that this full-scale audit of the bias measurement\npipeline will raise awareness among the community while deriving insights\nrelated to design choices of data and algorithms both and refrain from the\npopular dogma of ``one-size-fits-all''.\n","authors":["Paramita Das","Sai Keerthana Karnam","Anirban Panda","Bhanu Prakash Reddy Guda","Soumya Sarkar","Animesh Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2302.14027v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2205.15935v2","updated":"2023-02-27T18:25:38Z","published":"2022-05-31T16:27:57Z","title":"Unfair geometries: exactly solvable data model with fairness\n  implications","summary":"  Machine learning (ML) may be oblivious to human bias but it is not immune to\nits perpetuation. Marginalisation and iniquitous group representation are often\ntraceable in the very data used for training, and may be reflected or even\nenhanced by the learning models. In the present work, we aim at clarifying the\nrole played by data geometry in the emergence of ML bias. We introduce an\nexactly solvable high-dimensional model of data imbalance, where parametric\ncontrol over the many bias-inducing factors allows for an extensive exploration\nof the bias inheritance mechanism. Through the tools of statistical physics, we\nanalytically characterise the typical properties of learning models trained in\nthis synthetic framework and obtain exact predictions for the observables that\nare commonly employed for fairness assessment. Despite the simplicity of the\ndata model, we retrace and unpack typical unfairness behaviour observed on\nreal-world datasets. We also obtain a detailed analytical characterisation of a\nclass of bias mitigation strategies. We first consider a basic loss-reweighing\nscheme, which allows for an implicit minimisation of different unfairness\nmetrics, and quantify the incompatibilities between some existing fairness\ncriteria. Then, we consider a novel mitigation strategy based on a matched\ninference approach, consisting in the introduction of coupled learning models.\nOur theoretical analysis of this approach shows that the coupled strategy can\nstrike superior fairness-accuracy trade-offs.\n","authors":["Stefano Sarao Mannelli","Federica Gerace","Negar Rostamzadeh","Luca Saglietti"],"pdf_url":"https://arxiv.org/pdf/2205.15935v2.pdf","comment":"8 pages, 6 figures + appendix"},{"id":"http://arxiv.org/abs/2302.14017v1","updated":"2023-02-27T18:18:13Z","published":"2023-02-27T18:18:13Z","title":"Full Stack Optimization of Transformer Inference: a Survey","summary":"  Recent advances in state-of-the-art DNN architecture design have been moving\ntoward Transformer models. These models achieve superior accuracy across a wide\nrange of applications. This trend has been consistent over the past several\nyears since Transformer models were originally introduced. However, the amount\nof compute and bandwidth required for inference of recent Transformer models is\ngrowing at a significant rate, and this has made their deployment in\nlatency-sensitive applications challenging. As such, there has been an\nincreased focus on making Transformer models more efficient, with methods that\nrange from changing the architecture design, all the way to developing\ndedicated domain-specific accelerators. In this work, we survey different\napproaches for efficient Transformer inference, including: (i) analysis and\nprofiling of the bottlenecks in existing Transformer architectures and their\nsimilarities and differences with previous convolutional models; (ii)\nimplications of Transformer architecture on hardware, including the impact of\nnon-linear operations such as Layer Normalization, Softmax, and GELU, as well\nas linear operations, on hardware design; (iii) approaches for optimizing a\nfixed Transformer architecture; (iv) challenges in finding the right mapping\nand scheduling of operations for Transformer models; and (v) approaches for\noptimizing Transformer models by adapting the architecture using neural\narchitecture search. Finally, we perform a case study by applying the surveyed\noptimizations on Gemmini, the open-source, full-stack DNN accelerator\ngenerator, and we show how each of these approaches can yield improvements,\ncompared to previous benchmark results on Gemmini. Among other things, we find\nthat a full-stack co-design approach with the aforementioned methods can result\nin up to 88.7x speedup with a minimal performance degradation for Transformer\ninference.\n","authors":["Sehoon Kim","Coleman Hooper","Thanakul Wattanawong","Minwoo Kang","Ruohan Yan","Hasan Genc","Grace Dinh","Qijing Huang","Kurt Keutzer","Michael W. Mahoney","Yakun Sophia Shao","Amir Gholami"],"pdf_url":"https://arxiv.org/pdf/2302.14017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10868v4","updated":"2023-02-27T18:16:13Z","published":"2022-05-22T17:02:51Z","title":"Memory-efficient Reinforcement Learning with Knowledge Consolidation","summary":"  Artificial neural networks are promising for general function approximation\nbut challenging to train on non-independent or non-identically distributed data\ndue to catastrophic forgetting. The experience replay buffer, a standard\ncomponent in deep reinforcement learning, is often used to reduce forgetting\nand improve sample efficiency by storing experiences in a large buffer and\nusing them for training later. However, a large replay buffer results in a\nheavy memory burden, especially for onboard and edge devices with limited\nmemory capacities. We propose memory-efficient reinforcement learning\nalgorithms based on the deep Q-network algorithm to alleviate this problem. Our\nalgorithms reduce forgetting and maintain high sample efficiency by\nconsolidating knowledge from the target Q-network to the current Q-network.\nCompared to baseline methods, our algorithms achieve comparable or better\nperformance in both feature-based and image-based tasks while easing the burden\nof large experience replay buffers.\n","authors":["Qingfeng Lan","Yangchen Pan","Jun Luo","A. Rupam Mahmood"],"pdf_url":"https://arxiv.org/pdf/2205.10868v4.pdf","comment":"update author info"},{"id":"http://arxiv.org/abs/2210.12529v2","updated":"2023-02-27T18:15:34Z","published":"2022-10-22T19:07:26Z","title":"On-Demand Sampling: Learning Optimally from Multiple Distributions","summary":"  Social and real-world considerations such as robustness, fairness, social\nwelfare and multi-agent tradeoffs have given rise to multi-distribution\nlearning paradigms, such as collaborative, group distributionally robust, and\nfair federated learning. In each of these settings, a learner seeks to minimize\nits worst-case loss over a set of $n$ predefined distributions, while using as\nfew samples as possible. In this paper, we establish the optimal sample\ncomplexity of these learning paradigms and give algorithms that meet this\nsample complexity. Importantly, our sample complexity bounds exceed that of the\nsample complexity of learning a single distribution only by an additive factor\nof $n \\log(n) / \\epsilon^2$. These improve upon the best known sample\ncomplexity of agnostic federated learning by Mohri et al. by a multiplicative\nfactor of $n$, the sample complexity of collaborative learning by Nguyen and\nZakynthinou by a multiplicative factor $\\log n / \\epsilon^3$, and give the\nfirst sample complexity bounds for the group DRO objective of Sagawa et al. To\nachieve optimal sample complexity, our algorithms learn to sample and learn\nfrom distributions on demand. Our algorithm design and analysis is enabled by\nour extensions of stochastic optimization techniques for solving stochastic\nzero-sum games. In particular, we contribute variants of Stochastic Mirror\nDescent that can trade off between players' access to cheap one-off samples or\nmore expensive reusable ones.\n","authors":["Nika Haghtalab","Michael I. Jordan","Eric Zhao"],"pdf_url":"https://arxiv.org/pdf/2210.12529v2.pdf","comment":"40 pages, 1 figure. Authors are ordered alphabetically. Outstanding\n  paper award at the Thirty-sixth Conference on Neural Information Processing\n  Systems (NeurIPS 2022). Version V2 updates a minor mistake in Lemma 3.1"},{"id":"http://arxiv.org/abs/2302.14015v1","updated":"2023-02-27T18:14:13Z","published":"2023-02-27T18:14:13Z","title":"CO-BED: Information-Theoretic Contextual Optimization via Bayesian\n  Experimental Design","summary":"  We formalize the problem of contextual optimization through the lens of\nBayesian experimental design and propose CO-BED -- a general, model-agnostic\nframework for designing contextual experiments using information-theoretic\nprinciples. After formulating a suitable information-based objective, we employ\nblack-box variational methods to simultaneously estimate it and optimize the\ndesigns in a single stochastic gradient scheme. We further introduce a\nrelaxation scheme to allow discrete actions to be accommodated. As a result,\nCO-BED provides a general and automated solution to a wide range of contextual\noptimization problems. We illustrate its effectiveness in a number of\nexperiments, where CO-BED demonstrates competitive performance even when\ncompared to bespoke, model-specific alternatives.\n","authors":["Desi R. Ivanova","Joel Jennings","Tom Rainforth","Cheng Zhang","Adam Foster"],"pdf_url":"https://arxiv.org/pdf/2302.14015v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.01293v2","updated":"2023-02-27T18:13:31Z","published":"2023-01-03T18:52:39Z","title":"Linear chain conditional random fields, hidden Markov models, and\n  related classifiers","summary":"  Practitioners use Hidden Markov Models (HMMs) in different problems for about\nsixty years. Besides, Conditional Random Fields (CRFs) are an alternative to\nHMMs and appear in the literature as different and somewhat concurrent models.\nWe propose two contributions. First, we show that basic Linear-Chain CRFs\n(LC-CRFs), considered as different from the HMMs, are in fact equivalent to\nthem in the sense that for each LC-CRF there exists a HMM - that we specify -\nwhom posterior distribution is identical to the given LC-CRF. Second, we show\nthat it is possible to reformulate the generative Bayesian classifiers Maximum\nPosterior Mode (MPM) and Maximum a Posteriori (MAP) used in HMMs, as\ndiscriminative ones. The last point is of importance in many fields, especially\nin Natural Language Processing (NLP), as it shows that in some situations\ndropping HMMs in favor of CRFs was not necessary.\n","authors":["Elie Azeraf","Emmanuel Monfrini","Wojciech Pieczynski"],"pdf_url":"https://arxiv.org/pdf/2301.01293v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2302.14013v1","updated":"2023-02-27T18:12:56Z","published":"2023-02-27T18:12:56Z","title":"Revisiting Self-Training with Regularized Pseudo-Labeling for Tabular\n  Data","summary":"  Recent progress in semi- and self-supervised learning has caused a rift in\nthe long-held belief about the need for an enormous amount of labeled data for\nmachine learning and the irrelevancy of unlabeled data. Although it has been\nsuccessful in various data, there is no dominant semi- and self-supervised\nlearning method that can be generalized for tabular data (i.e. most of the\nexisting methods require appropriate tabular datasets and architectures). In\nthis paper, we revisit self-training which can be applied to any kind of\nalgorithm including the most widely used architecture, gradient boosting\ndecision tree, and introduce curriculum pseudo-labeling (a state-of-the-art\npseudo-labeling technique in image) for a tabular domain. Furthermore, existing\npseudo-labeling techniques do not assure the cluster assumption when computing\nconfidence scores of pseudo-labels generated from unlabeled data. To overcome\nthis issue, we propose a novel pseudo-labeling approach that regularizes the\nconfidence scores based on the likelihoods of the pseudo-labels so that more\nreliable pseudo-labels which lie in high density regions can be obtained. We\nexhaustively validate the superiority of our approaches using various models\nand tabular datasets.\n","authors":["Miwook Kim","Juseong Kim","Jose Bento","Giltae Song"],"pdf_url":"https://arxiv.org/pdf/2302.14013v1.pdf","comment":"10 pages for the main part and 8 extra pages for the appendix. 2\n  figures and 3 tables for the main part"},{"id":"http://arxiv.org/abs/2302.14011v1","updated":"2023-02-27T18:07:49Z","published":"2023-02-27T18:07:49Z","title":"Causal isotonic calibration for heterogeneous treatment effects","summary":"  We propose causal isotonic calibration, a novel nonparametric method for\ncalibrating predictors of heterogeneous treatment effects. In addition, we\nintroduce a novel data-efficient variant of calibration that avoids the need\nfor hold-out calibration sets, which we refer to as cross-calibration. Causal\nisotonic cross-calibration takes cross-fitted predictors and outputs a single\ncalibrated predictor obtained using all available data. We establish under weak\nconditions that causal isotonic calibration and cross-calibration both achieve\nfast doubly-robust calibration rates so long as either the propensity score or\noutcome regression is estimated well in an appropriate sense. The proposed\ncausal isotonic calibrator can be wrapped around any black-box learning\nalgorithm to provide strong distribution-free calibration guarantees while\npreserving predictive performance.\n","authors":["Lars van der Laan","Ernesto Ulloa-Pérez","Marco Carone","Alex Luedtke"],"pdf_url":"https://arxiv.org/pdf/2302.14011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07365v4","updated":"2023-02-27T18:06:50Z","published":"2022-02-15T12:46:43Z","title":"A Statistical Learning View of Simple Kriging","summary":"  In the Big Data era, with the ubiquity of geolocation sensors in particular,\nmassive datasets exhibiting a possibly complex spatial dependence structure are\nbecoming increasingly available. In this context, the standard probabilistic\ntheory of statistical learning does not apply directly and guarantees of the\ngeneralization capacity of predictive rules learned from such data are left to\nestablish. We analyze here the simple Kriging task from a statistical learning\nperspective, i.e. by carrying out a nonparametric finite-sample predictive\nanalysis. Given $d\\geq 1$ values taken by a realization of a square integrable\nrandom field $X=\\{X_s\\}_{s\\in S}$, $S\\subset \\mathbb{R}^2$, with unknown\ncovariance structure, at sites $s_1,\\; \\ldots,\\; s_d$ in $S$, the goal is to\npredict the unknown values it takes at any other location $s\\in S$ with minimum\nquadratic risk. The prediction rule being derived from a training spatial\ndataset: a single realization $X'$ of $X$, independent from those to be\npredicted, observed at $n\\geq 1$ locations $\\sigma_1,\\; \\ldots,\\; \\sigma_n$ in\n$S$. Despite the connection of this minimization problem with kernel ridge\nregression, establishing the generalization capacity of empirical risk\nminimizers is far from straightforward, due to the non independent and\nidentically distributed nature of the training data $X'_{\\sigma_1},\\; \\ldots,\\;\nX'_{\\sigma_n}$ involved in the learning procedure. In this article,\nnon-asymptotic bounds of order $O_{\\mathbb{P}}(1/\\sqrt{n})$ are proved for the\nexcess risk of a plug-in predictive rule mimicking the true minimizer in the\ncase of isotropic stationary Gaussian processes, observed at locations forming\na regular grid in the learning stage. These theoretical results are illustrated\nby various numerical experiments, on simulated data and on real-world datasets.\n","authors":["Emilia Siviero","Emilie Chautru","Stephan Clémençon"],"pdf_url":"https://arxiv.org/pdf/2202.07365v4.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2302.14004v1","updated":"2023-02-27T17:48:08Z","published":"2023-02-27T17:48:08Z","title":"Optimistic Planning by Regularized Dynamic Programming","summary":"  We propose a new method for optimistic planning in infinite-horizon\ndiscounted Markov decision processes based on the idea of adding regularization\nto the updates of an otherwise standard approximate value iteration procedure.\nThis technique allows us to avoid contraction and monotonicity arguments that\nare typically required by existing analyses of approximate dynamic programming\nmethods, and in particular to use approximate transition functions estimated\nvia least-squares procedures in MDPs with linear function approximation. We use\nour method to provide a computationally efficient algorithm for learning\nnear-optimal policies in discounted linear kernel MDPs from a single stream of\nexperience, and show that it achieves near-optimal statistical guarantees.\n","authors":["Antoine Moulin","Gergely Neu"],"pdf_url":"https://arxiv.org/pdf/2302.14004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14003v1","updated":"2023-02-27T17:47:53Z","published":"2023-02-27T17:47:53Z","title":"Systematic Rectification of Language Models via Dead-end Analysis","summary":"  With adversarial or otherwise normal prompts, existing large language models\n(LLM) can be pushed to generate toxic discourses. One way to reduce the risk of\nLLMs generating undesired discourses is to alter the training of the LLM. This\ncan be very restrictive due to demanding computation requirements. Other\nmethods rely on rule-based or prompt-based token elimination, which are limited\nas they dismiss future tokens and the overall meaning of the complete\ndiscourse. Here, we center detoxification on the probability that the finished\ndiscourse is ultimately considered toxic. That is, at each point, we advise\nagainst token selections proportional to how likely a finished text from this\npoint will be toxic. To this end, we formally extend the dead-end theory from\nthe recent reinforcement learning (RL) literature to also cover uncertain\noutcomes. Our approach, called rectification, utilizes a separate but\nsignificantly smaller model for detoxification, which can be applied to diverse\nLLMs as long as they share the same vocabulary. Importantly, our method does\nnot require access to the internal representations of the LLM, but only the\ntoken probability distribution at each decoding step. This is crucial as many\nLLMs today are hosted in servers and only accessible through APIs. When applied\nto various LLMs, including GPT-3, our approach significantly improves the\ngenerated discourse compared to the base LLMs and other techniques in terms of\nboth the overall language and detoxification performance.\n","authors":["Meng Cao","Mehdi Fatemi","Jackie Chi Kit Cheung","Samira Shabanian"],"pdf_url":"https://arxiv.org/pdf/2302.14003v1.pdf","comment":"The Eleventh International Conference on Learning Representations,\n  ICLR'23"},{"id":"http://arxiv.org/abs/2302.13995v1","updated":"2023-02-27T17:38:47Z","published":"2023-02-27T17:38:47Z","title":"Architecting Peer-to-Peer Serverless Distributed Machine Learning\n  Training for Improved Fault Tolerance","summary":"  Distributed Machine Learning refers to the practice of training a model on\nmultiple computers or devices that can be called nodes. Additionally,\nserverless computing is a new paradigm for cloud computing that uses functions\nas a computational unit. Serverless computing can be effective for distributed\nlearning systems by enabling automated resource scaling, less manual\nintervention, and cost reduction. By distributing the workload, distributed\nmachine learning can speed up the training process and allow more complex\nmodels to be trained. Several topologies of distributed machine learning have\nbeen established (centralized, parameter server, peer-to-peer). However, the\nparameter server architecture may have limitations in terms of fault tolerance,\nincluding a single point of failure and complex recovery processes. Moreover,\ntraining machine learning in a peer-to-peer (P2P) architecture can offer\nbenefits in terms of fault tolerance by eliminating the single point of\nfailure. In a P2P architecture, each node or worker can act as both a server\nand a client, which allows for more decentralized decision making and\neliminates the need for a central coordinator. In this position paper, we\npropose exploring the use of serverless computing in distributed machine\nlearning training and comparing the performance of P2P architecture with the\nparameter server architecture, focusing on cost reduction and fault tolerance.\n","authors":["Amine Barrak","Fabio Petrillo","Fehmi Jaafar"],"pdf_url":"https://arxiv.org/pdf/2302.13995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.12708v3","updated":"2023-02-27T17:30:01Z","published":"2022-06-25T18:44:06Z","title":"Bayesian Optimization Over Iterative Learners with Structured Responses:\n  A Budget-aware Planning Approach","summary":"  The rising growth of deep neural networks (DNNs) and datasets in size\nmotivates the need for efficient solutions for simultaneous model selection and\ntraining. Many methods for hyperparameter optimization (HPO) of iterative\nlearners, including DNNs, attempt to solve this problem by querying and\nlearning a response surface while searching for the optimum of that surface.\nHowever, many of these methods make myopic queries, do not consider prior\nknowledge about the response structure, and/or perform a biased cost-aware\nsearch, all of which exacerbate identifying the best-performing model when a\ntotal cost budget is specified. This paper proposes a novel approach referred\nto as {\\bf B}udget-{\\bf A}ware {\\bf P}lanning for {\\bf I}terative Learners\n(BAPI) to solve HPO problems under a constrained cost budget. BAPI is an\nefficient non-myopic Bayesian optimization solution that accounts for the\nbudget and leverages the prior knowledge about the objective function and cost\nfunction to select better configurations and to take more informed decisions\nduring the evaluation (training). Experiments on diverse HPO benchmarks for\niterative learners show that BAPI performs better than state-of-the-art\nbaselines in most cases.\n","authors":["Syrine Belakaria","Janardhan Rao Doppa","Nicolo Fusi","Rishit Sheth"],"pdf_url":"https://arxiv.org/pdf/2206.12708v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13991v1","updated":"2023-02-27T17:30:00Z","published":"2023-02-27T17:30:00Z","title":"Learning to Generalize towards Unseen Domains via a Content-Aware Style\n  Invariant Framework for Disease Detection from Chest X-rays","summary":"  Performance degradation due to source domain mismatch is a longstanding\nchallenge in deep learning-based medical image analysis, particularly for chest\nX-rays. Several methods have been proposed to address this domain shift, such\nas utilizing adversarial learning or multi-domain mixups to extract\ndomain-invariant high-level features. However, these methods do not explicitly\naccount for or regularize the content and style attributes of the extracted\ndomain-invariant features. Recent studies have demonstrated that CNN models\nexhibit a strong bias toward styles (i.e., textures) rather than content, in\nstark contrast to the human-vision system. Explainable representations are\nparamount for a robust and generalizable understanding of medical images. Thus,\nthe learned high-level semantic features need to be both content-specific,\ni.e., pathology-specific and domain-agnostic, as well as style invariant.\nInspired by this, we propose a novel framework that improves cross-domain\nperformances by focusing more on content while reducing style bias. We employ a\nstyle randomization module at both image and feature levels to create stylized\nperturbation features while preserving the content using an end-to-end\nframework. We extract the global features from the backbone model for the same\nchest X-ray with and without style randomized. We apply content consistency\nregularization between them to tweak the framework's sensitivity toward content\nmarkers for accurate predictions. Extensive experiments on unseen domain test\ndatasets demonstrate that our proposed pipeline is more robust in the presence\nof domain shifts and achieves state-of-the-art performance. Our code is\navailable via\nhttps://github.com/rafizunaed/domain_agnostic_content_aware_style_invariant.\n","authors":["Mohammad Zunaed","Md. Aynal Haque","Taufiq Hasan"],"pdf_url":"https://arxiv.org/pdf/2302.13991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.10938v3","updated":"2023-02-27T17:22:15Z","published":"2022-04-22T21:46:52Z","title":"A Multi-level Alignment Training Scheme for Video-and-Language Grounding","summary":"  To solve video-and-language grounding tasks, the key is for the network to\nunderstand the connection between the two modalities. For a pair of video and\nlanguage description, their semantic relation is reflected by their encodings'\nsimilarity. A good multi-modality encoder should be able to well capture both\ninputs' semantics and encode them in the shared feature space where embedding\ndistance gets properly translated into their semantic similarity. In this work,\nwe focused on this semantic connection between video and language, and\ndeveloped a multi-level alignment training scheme to directly shape the\nencoding process. Global and segment levels of video-language alignment pairs\nwere designed, based on the information similarity ranging from high-level\ncontext to fine-grained semantics. The contrastive loss was used to contrast\nthe encodings' similarities between the positive and negative alignment pairs,\nand to ensure the network is trained in such a way that similar information is\nencoded closely in the shared feature space while information of different\nsemantics is kept apart. Our multi-level alignment training can be applied to\nvarious video-and-language grounding tasks. Together with the task-specific\ntraining loss, our framework achieved comparable performance to previous\nstate-of-the-arts on multiple video QA and retrieval datasets.\n","authors":["Yubo Zhang","Feiyang Niu","Qing Ping","Govind Thattai"],"pdf_url":"https://arxiv.org/pdf/2204.10938v3.pdf","comment":"Accepted at ICDM 2022 FOMO-VL workshop"},{"id":"http://arxiv.org/abs/2210.13382v4","updated":"2023-02-27T17:09:15Z","published":"2022-10-24T16:29:55Z","title":"Emergent World Representations: Exploring a Sequence Model Trained on a\n  Synthetic Task","summary":"  Language models show a surprising range of capabilities, but the source of\ntheir apparent competence is unclear. Do these networks just memorize a\ncollection of surface statistics, or do they rely on internal representations\nof the process that generates the sequences they see? We investigate this\nquestion by applying a variant of the GPT model to the task of predicting legal\nmoves in a simple board game, Othello. Although the network has no a priori\nknowledge of the game or its rules, we uncover evidence of an emergent\nnonlinear internal representation of the board state. Interventional\nexperiments indicate this representation can be used to control the output of\nthe network and create \"latent saliency maps\" that can help explain predictions\nin human terms.\n","authors":["Kenneth Li","Aspen K. Hopkins","David Bau","Fernanda Viégas","Hanspeter Pfister","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2210.13382v4.pdf","comment":"ICLR 2023 oral (notable-top-5%):\n  https://openreview.net/forum?id=DeG07_TcZvT ; code:\n  https://github.com/likenneth/othello_world"},{"id":"http://arxiv.org/abs/2112.15446v3","updated":"2023-02-27T17:03:07Z","published":"2021-12-28T20:06:28Z","title":"Uniform-in-Phase-Space Data Selection with Iterative Normalizing Flows","summary":"  Improvements in computational and experimental capabilities are rapidly\nincreasing the amount of scientific data that is routinely generated. In\napplications that are constrained by memory and computational intensity,\nexcessively large datasets may hinder scientific discovery, making data\nreduction a critical component of data-driven methods. Datasets are growing in\ntwo directions: the number of data points and their dimensionality. Whereas\ndimension reduction typically aims at describing each data sample on\nlower-dimensional space, the focus here is on reducing the number of data\npoints. A strategy is proposed to select data points such that they uniformly\nspan the phase-space of the data. The algorithm proposed relies on estimating\nthe probability map of the data and using it to construct an acceptance\nprobability. An iterative method is used to accurately estimate the probability\nof the rare data points when only a small subset of the dataset is used to\nconstruct the probability map. Instead of binning the phase-space to estimate\nthe probability map, its functional form is approximated with a normalizing\nflow. Therefore, the method naturally extends to high-dimensional datasets. The\nproposed framework is demonstrated as a viable pathway to enable data-efficient\nmachine learning when abundant data is available. An implementation of the\nmethod is available in a companion repository\n(https://github.com/NREL/Phase-space-sampling).\n","authors":["Malik Hassanaly","Bruce A. Perry","Michael E. Mueller","Shashank Yellapantula"],"pdf_url":"https://arxiv.org/pdf/2112.15446v3.pdf","comment":"26 pages, 23 figures, 5 tables"},{"id":"http://arxiv.org/abs/2209.06128v2","updated":"2023-02-27T17:02:51Z","published":"2022-09-06T14:59:00Z","title":"A Scalable Recommendation Engine for New Users and Items","summary":"  In many digital contexts such as online news and e-tailing with many new\nusers and items, recommendation systems face several challenges: i) how to make\ninitial recommendations to users with little or no response history (i.e.,\ncold-start problem), ii) how to learn user preferences on items (test and\nlearn), and iii) how to scale across many users and items with myriad\ndemographics and attributes. While many recommendation systems accommodate\naspects of these challenges, few if any address all. This paper introduces a\nCollaborative Filtering (CF) Multi-armed Bandit (B) with Attributes (A)\nrecommendation system (CFB-A) to jointly accommodate all of these\nconsiderations. Empirical applications including an offline test on MovieLens\ndata, synthetic data simulations, and an online grocery experiment indicate the\nCFB-A leads to substantial improvement on cumulative average rewards (e.g.,\ntotal money or time spent, clicks, purchased quantities, average ratings, etc.)\nrelative to the most powerful extant baseline methods.\n","authors":["Boya Xu","Yiting Deng","Carl Mela"],"pdf_url":"https://arxiv.org/pdf/2209.06128v2.pdf","comment":"59 pages, 13 figures"},{"id":"http://arxiv.org/abs/2302.13960v1","updated":"2023-02-27T17:02:11Z","published":"2023-02-27T17:02:11Z","title":"Acquisition Conditioned Oracle for Nongreedy Active Feature Acquisition","summary":"  We develop novel methodology for active feature acquisition (AFA), the study\nof how to sequentially acquire a dynamic (on a per instance basis) subset of\nfeatures that minimizes acquisition costs whilst still yielding accurate\npredictions. The AFA framework can be useful in a myriad of domains, including\nhealth care applications where the cost of acquiring additional features for a\npatient (in terms of time, money, risk, etc.) can be weighed against the\nexpected improvement to diagnostic performance. Previous approaches for AFA\nhave employed either: deep learning RL techniques, which have difficulty\ntraining policies in the AFA MDP due to sparse rewards and a complicated action\nspace; deep learning surrogate generative models, which require modeling\ncomplicated multidimensional conditional distributions; or greedy policies,\nwhich fail to account for how joint feature acquisitions can be informative\ntogether for better predictions. In this work we show that we can bypass many\nof these challenges with a novel, nonparametric oracle based approach, which we\ncoin the acquisition conditioned oracle (ACO). Extensive experiments show the\nsuperiority of the ACO to state-of-the-art AFA methods when acquiring features\nfor both predictions and general decision-making.\n","authors":["Michael Valancius","Max Lennon","Junier Oliva"],"pdf_url":"https://arxiv.org/pdf/2302.13960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.00874v2","updated":"2023-02-27T16:58:18Z","published":"2022-03-02T05:14:11Z","title":"Follow your Nose: Using General Value Functions for Directed Exploration\n  in Reinforcement Learning","summary":"  Improving sample efficiency is a key challenge in reinforcement learning,\nespecially in environments with large state spaces and sparse rewards. In\nliterature, this is resolved either through the use of auxiliary tasks\n(subgoals) or through clever exploration strategies. Exploration methods have\nbeen used to sample better trajectories in large environments while auxiliary\ntasks have been incorporated where the reward is sparse. However, few studies\nhave attempted to tackle both large scale and reward sparsity at the same time.\nThis paper explores the idea of combining exploration with auxiliary task\nlearning using General Value Functions (GVFs) and a directed exploration\nstrategy. We present a way to learn value functions which can be used to sample\nactions and provide directed exploration. Experiments on navigation tasks with\nvarying grid sizes demonstrate the performance advantages over several\ncompetitive baselines.\n","authors":["Durgesh Kalwar","Omkar Shelke","Somjit Nath","Hardik Meisheri","Harshad Khadilkar"],"pdf_url":"https://arxiv.org/pdf/2203.00874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13948v1","updated":"2023-02-27T16:49:35Z","published":"2023-02-27T16:49:35Z","title":"Supervised topological data analysis for MALDI imaging applications","summary":"  We propose a new algebraic topological framework, which obtains intrinsic\ninformation from the MALDI data and transforms it to reflect topological\npersistence in the data. Our framework has two main advantages. First, the\ntopological persistence helps us to distinguish the signal from noise. Second,\nit compresses the MALDI data, which results in saving storage space, and also\noptimizes the computational time for further classification tasks. We introduce\nan algorithm that performs our topological framework and depends on a single\ntuning parameter. Furthermore, we show that it is computationally efficient.\nFollowing the persistence extraction, logistic regression and random forest\nclassifiers are executed based on the resulting persistence transformation\ndiagrams to classify the observational units into binary class labels,\ndescribing the lung cancer subtypes. Further, we utilized the proposed\nframework in a real-world MALDI data set, and the competitiveness of the\nmethods is illustrated via cross-validation.\n","authors":["Gideon Klaila","Vladimir Vutov","Anastasios Stefanou"],"pdf_url":"https://arxiv.org/pdf/2302.13948v1.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.13945v1","updated":"2023-02-27T16:47:49Z","published":"2023-02-27T16:47:49Z","title":"On Differentially Private Federated Linear Contextual Bandits","summary":"  We consider cross-silo federated linear contextual bandit (LCB) problem under\ndifferential privacy. In this setting, multiple silos or agents interact with\nthe local users and communicate via a central server to realize collaboration\nwhile without sacrificing each user's privacy. We identify two issues in the\nstate-of-the-art algorithm of \\cite{dubey2020differentially}: (i) failure of\nclaimed privacy protection and (ii) noise miscalculation in regret bound. To\nresolve these issues, we take a two-step principled approach. First, we design\nan algorithmic framework consisting of a generic federated LCB algorithm and\nflexible privacy protocols. Then, leveraging the proposed framework, we study\nfederated LCBs under two different privacy constraints. We first establish\nprivacy and regret guarantees under silo-level local differential privacy,\nwhich fix the issues present in state-of-the-art algorithm. To further improve\nthe regret performance, we next consider shuffle model of differential privacy,\nunder which we show that our algorithm can achieve nearly ``optimal'' regret\nwithout a trusted server. We accomplish this via two different schemes -- one\nrelies on a new result on privacy amplification via shuffling for DP mechanisms\nand another one leverages the integration of a shuffle protocol for vector sum\ninto the tree-based mechanism, both of which might be of independent interest.\nFinally, we support our theoretical results with numerical evaluations over\ncontextual bandit instances generated from both synthetic and real-life data.\n","authors":["Xingyu Zhou","Sayak Ray Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2302.13945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13942v1","updated":"2023-02-27T16:45:50Z","published":"2023-02-27T16:45:50Z","title":"Inseq: An Interpretability Toolkit for Sequence Generation Models","summary":"  Past work in natural language processing interpretability focused mainly on\npopular classification tasks while largely overlooking generation settings,\npartly due to a lack of dedicated tools. In this work, we introduce Inseq, a\nPython library to democratize access to interpretability analyses of sequence\ngeneration models. Inseq enables intuitive and optimized extraction of models'\ninternal information and feature importance scores for popular decoder-only and\nencoder-decoder Transformers architectures. We showcase its potential by\nadopting it to highlight gender biases in machine translation models and locate\nfactual knowledge inside GPT-2. Thanks to its extensible interface supporting\ncutting-edge techniques such as contrastive feature attribution, Inseq can\ndrive future advances in explainable natural language generation, centralizing\ngood practices and enabling fair and reproducible model evaluations.\n","authors":["Gabriele Sarti","Nils Feldhus","Ludwig Sickert","Oskar van der Wal"],"pdf_url":"https://arxiv.org/pdf/2302.13942v1.pdf","comment":"Library: https://github.com/inseq-team/inseq, Documentation:\n  https://inseq.readthedocs.io, v0.4"},{"id":"http://arxiv.org/abs/2302.13941v1","updated":"2023-02-27T16:45:04Z","published":"2023-02-27T16:45:04Z","title":"A Reinforcement Learning Approach for Scheduling Problems With Improved\n  Generalization Through Order Swapping","summary":"  The scheduling of production resources (such as associating jobs to machines)\nplays a vital role for the manufacturing industry not only for saving energy\nbut also for increasing the overall efficiency. Among the different job\nscheduling problems, the JSSP is addressed in this work. JSSP falls into the\ncategory of NP-hard COP, in which solving the problem through exhaustive search\nbecomes unfeasible. Simple heuristics such as FIFO, LPT and metaheuristics such\nas Taboo search are often adopted to solve the problem by truncating the search\nspace. The viability of the methods becomes inefficient for large problem sizes\nas it is either far from the optimum or time consuming. In recent years, the\nresearch towards using DRL to solve COP has gained interest and has shown\npromising results in terms of solution quality and computational efficiency. In\nthis work, we provide an novel approach to solve the JSSP examining the\nobjectives generalization and solution effectiveness using DRL. In particular,\nwe employ the PPO algorithm that adopts the policy-gradient paradigm that is\nfound to perform well in the constrained dispatching of jobs. We incorporated\nan OSM in the environment to achieve better generalized learning of the\nproblem. The performance of the presented approach is analyzed in depth by\nusing a set of available benchmark instances and comparing our results with the\nwork of other groups.\n","authors":["Deepak Vivekanandan","Samuel Wirth","Patrick Karlbauer","Noah Klarmann"],"pdf_url":"https://arxiv.org/pdf/2302.13941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13939v1","updated":"2023-02-27T16:43:04Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking neural networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, we successfully implement `SpikeGPT', a generative\nlanguage model with pure binary, event-driven spiking activation units. We\ntrain the proposed model on three model variants: 45M, 125M and 260M\nparameters. To the best of our knowledge, this is 4x larger than any functional\nbackprop-trained SNN to date. We achieve this by modifying the transformer\nblock to replace multi-head self attention to reduce quadratic computational\ncomplexity to linear with increasing sequence length. Input tokens are instead\nstreamed in sequentially to our attention mechanism (as with typical SNNs). Our\npreliminary experiments show that SpikeGPT remains competitive with non-spiking\nmodels on tested benchmarks, while maintaining 5x less energy consumption when\nprocessed on neuromorphic hardware that can leverage sparse, event-driven\nactivations. Our code implementation is available at\nhttps://github.com/ridgerchu/SpikeGPT.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13934v1","updated":"2023-02-27T16:34:21Z","published":"2023-02-27T16:34:21Z","title":"Statistical Learning under Heterogenous Distribution Shift","summary":"  This paper studies the prediction of a target $\\mathbf{z}$ from a pair of\nrandom variables $(\\mathbf{x},\\mathbf{y})$, where the ground-truth predictor is\nadditive $\\mathbb{E}[\\mathbf{z} \\mid \\mathbf{x},\\mathbf{y}] =\nf_\\star(\\mathbf{x}) +g_{\\star}(\\mathbf{y})$. We study the performance of\nempirical risk minimization (ERM) over functions $f+g$, $f \\in \\mathcal{F}$ and\n$g \\in \\mathcal{G}$, fit on a given training distribution, but evaluated on a\ntest distribution which exhibits covariate shift. We show that, when the class\n$\\mathcal{F}$ is \"simpler\" than $\\mathcal{G}$ (measured, e.g., in terms of its\nmetric entropy), our predictor is more resilient to \\emph{heterogenous\ncovariate shifts} in which the shift in $\\mathbf{x}$ is much greater than that\nin $\\mathbf{y}$. These results rely on a novel H\\\"older style inequality for\nthe Dudley integral which may be of independent interest. Moreover, we\ncorroborate our theoretical findings with experiments demonstrating improved\nresilience to shifts in \"simpler\" features across numerous domains.\n","authors":["Max Simchowitz","Anurag Ajay","Pulkit Agrawal","Akshay Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2302.13934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13929v1","updated":"2023-02-27T16:28:23Z","published":"2023-02-27T16:28:23Z","title":"Efficient Informed Proposals for Discrete Distributions via Newton's\n  Series Approximation","summary":"  Gradients have been exploited in proposal distributions to accelerate the\nconvergence of Markov chain Monte Carlo algorithms on discrete distributions.\nHowever, these methods require a natural differentiable extension of the target\ndiscrete distribution, which often does not exist or does not provide effective\ngradient guidance. In this paper, we develop a gradient-like proposal for any\ndiscrete distribution without this strong requirement. Built upon a\nlocally-balanced proposal, our method efficiently approximates the discrete\nlikelihood ratio via Newton's series expansion to enable a large and efficient\nexploration in discrete spaces. We show that our method can also be viewed as a\nmultilinear extension, thus inheriting its desired properties. We prove that\nour method has a guaranteed convergence rate with or without the\nMetropolis-Hastings step. Furthermore, our method outperforms a number of\npopular alternatives in several different experiments, including the facility\nlocation problem, extractive text summarization, and image retrieval.\n","authors":["Yue Xiang","Dongyao Zhu","Bowen Lei","Dongkuan Xu","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13929v1.pdf","comment":"Published at AISTATS 2023"},{"id":"http://arxiv.org/abs/2207.05480v4","updated":"2023-02-27T16:25:52Z","published":"2022-07-12T11:46:49Z","title":"Temporal Disentanglement of Representations for Improved Generalisation\n  in Reinforcement Learning","summary":"  Reinforcement Learning (RL) agents are often unable to generalise well to\nenvironment variations in the state space that were not observed during\ntraining. This issue is especially problematic for image-based RL, where a\nchange in just one variable, such as the background colour, can change many\npixels in the image. The changed pixels can lead to drastic changes in the\nagent's latent representation of the image, causing the learned policy to fail.\nTo learn more robust representations, we introduce TEmporal Disentanglement\n(TED), a self-supervised auxiliary task that leads to disentangled image\nrepresentations exploiting the sequential nature of RL observations. We find\nempirically that RL algorithms utilising TED as an auxiliary task adapt more\nquickly to changes in environment variables with continued training compared to\nstate-of-the-art representation learning methods. Since TED enforces a\ndisentangled structure of the representation, our experiments also show that\npolicies trained with TED generalise better to unseen values of variables\nirrelevant to the task (e.g. background colour) as well as unseen values of\nvariables that affect the optimal policy (e.g. goal positions).\n","authors":["Mhairi Dunion","Trevor McInroe","Kevin Sebastian Luck","Josiah P. Hanna","Stefano V. Albrecht"],"pdf_url":"https://arxiv.org/pdf/2207.05480v4.pdf","comment":"International Conference on Learning Representations (ICLR), 2023"},{"id":"http://arxiv.org/abs/2302.11974v2","updated":"2023-02-27T16:21:51Z","published":"2023-02-23T12:46:11Z","title":"LightCTS: A Lightweight Framework for Correlated Time Series Forecasting","summary":"  Correlated time series (CTS) forecasting plays an essential role in many\npractical applications, such as traffic management and server load control.\nMany deep learning models have been proposed to improve the accuracy of CTS\nforecasting. However, while models have become increasingly complex and\ncomputationally intensive, they struggle to improve accuracy. Pursuing a\ndifferent direction, this study aims instead to enable much more efficient,\nlightweight models that preserve accuracy while being able to be deployed on\nresource-constrained devices. To achieve this goal, we characterize popular CTS\nforecasting models and yield two observations that indicate directions for\nlightweight CTS forecasting. On this basis, we propose the LightCTS framework\nthat adopts plain stacking of temporal and spatial operators instead of\nalternate stacking that is much more computationally expensive. Moreover,\nLightCTS features light temporal and spatial operator modules, called L-TCN and\nGL-Former, that offer improved computational efficiency without compromising\ntheir feature extraction capabilities. LightCTS also encompasses a last-shot\ncompression scheme to reduce redundant temporal features and speed up\nsubsequent computations. Experiments with single-step and multi-step\nforecasting benchmark datasets show that LightCTS is capable of nearly\nstate-of-the-art accuracy at much reduced computational and storage overheads.\n","authors":["Zhichen Lai","Dalin Zhang","Huan Li","Christian S. Jensen","Hua Lu","Yan Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.11974v2.pdf","comment":"accepted by ACM SIGMOD 2023"},{"id":"http://arxiv.org/abs/2302.13918v1","updated":"2023-02-27T16:08:43Z","published":"2023-02-27T16:08:43Z","title":"U-Statistics for Importance-Weighted Variational Inference","summary":"  We propose the use of U-statistics to reduce variance for gradient estimation\nin importance-weighted variational inference. The key observation is that,\ngiven a base gradient estimator that requires $m > 1$ samples and a total of $n\n> m$ samples to be used for estimation, lower variance is achieved by averaging\nthe base estimator on overlapping batches of size $m$ than disjoint batches, as\ncurrently done. We use classical U-statistic theory to analyze the variance\nreduction, and propose novel approximations with theoretical guarantees to\nensure computational efficiency. We find empirically that U-statistic variance\nreduction can lead to modest to significant improvements in inference\nperformance on a range of models, with little computational cost.\n","authors":["Javier Burroni","Kenta Takatsu","Justin Domke","Daniel Sheldon"],"pdf_url":"https://arxiv.org/pdf/2302.13918v1.pdf","comment":"Accepted at Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2206.04797v3","updated":"2023-02-27T16:07:28Z","published":"2022-06-06T21:56:11Z","title":"Memory-efficient model-based deep learning with convergence and\n  robustness guarantees","summary":"  Computational imaging has been revolutionized by compressed sensing\nalgorithms, which offer guaranteed uniqueness, convergence, and stability\nproperties. Model-based deep learning methods that combine imaging physics with\nlearned regularization priors have emerged as more powerful alternatives for\nimage recovery. The main focus of this paper is to introduce a memory efficient\nmodel-based algorithm with similar theoretical guarantees as CS methods. The\nproposed iterative algorithm alternates between a gradient descent involving\nthe score function and a conjugate gradient algorithm to encourage data\nconsistency. The score function is modeled as a monotone convolutional neural\nnetwork. Our analysis shows that the monotone constraint is necessary and\nsufficient to enforce the uniqueness of the fixed point in arbitrary inverse\nproblems. In addition, it also guarantees the convergence to a fixed point,\nwhich is robust to input perturbations. We introduce two implementations of the\nproposed MOL framework, which differ in the way the monotone property is\nimposed. The first approach enforces a strict monotone constraint, while the\nsecond one relies on an approximation. The guarantees are not valid for the\nsecond approach in the strict sense. However, our empirical studies show that\nthe convergence and robustness of both approaches are comparable, while the\nless constrained approximate implementation offers better performance. The\nproposed deep equilibrium formulation is significantly more memory efficient\nthan unrolled methods, which allows us to apply it to 3D or 2D+time problems\nthat current unrolled algorithms cannot handle.\n","authors":["Aniket Pramanik","Mathews Jacob"],"pdf_url":"https://arxiv.org/pdf/2206.04797v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16126v2","updated":"2023-02-27T16:04:41Z","published":"2022-11-29T12:03:54Z","title":"Joint Neural Architecture and Hyperparameter Search for Correlated Time\n  Series Forecasting","summary":"  Sensors in cyber-physical systems often capture interconnected processes and\nthus emit correlated time series (CTS), the forecasting of which enables\nimportant applications. The key to successful CTS forecasting is to uncover the\ntemporal dynamics of time series and the spatial correlations among time\nseries. Deep learning-based solutions exhibit impressive performance at\ndiscerning these aspects. In particular, automated CTS forecasting, where the\ndesign of an optimal deep learning architecture is automated, enables\nforecasting accuracy that surpasses what has been achieved by manual\napproaches. However, automated CTS solutions remain in their infancy and are\nonly able to find optimal architectures for predefined hyperparameters and\nscale poorly to large-scale CTS. To overcome these limitations, we propose\nSEARCH, a joint, scalable framework, to automatically devise effective CTS\nforecasting models. Specifically, we encode each candidate architecture and\naccompanying hyperparameters into a joint graph representation. We introduce an\nefficient Architecture-Hyperparameter Comparator (AHC) to rank all\narchitecture-hyperparameter pairs, and we then further evaluate the top-ranked\npairs to select a final result. Extensive experiments on six benchmark datasets\ndemonstrate that SEARCH not only eliminates manual efforts but also is capable\nof better performance than manually designed and existing automatically\ndesigned CTS models. In addition, it shows excellent scalability to large CTS.\n","authors":["Xinle Wu","Dalin Zhang","Miao Zhang","Chenjuan Guo","Bin Yang","Christian S. Jensen"],"pdf_url":"https://arxiv.org/pdf/2211.16126v2.pdf","comment":"accepted by SIGMOD 2023"},{"id":"http://arxiv.org/abs/2302.13915v1","updated":"2023-02-27T16:02:28Z","published":"2023-02-27T16:02:28Z","title":"TwERC: High Performance Ensembled Candidate Generation for Ads\n  Recommendation at Twitter","summary":"  Recommendation systems are a core feature of social media companies with\ntheir uses including recommending organic and promoted contents. Many modern\nrecommendation systems are split into multiple stages - candidate generation\nand heavy ranking - to balance computational cost against recommendation\nquality. We focus on the candidate generation phase of a large-scale ads\nrecommendation problem in this paper, and present a machine learning first\nheterogeneous re-architecture of this stage which we term TwERC. We show that a\nsystem that combines a real-time light ranker with sourcing strategies capable\nof capturing additional information provides validated gains. We present two\nstrategies. The first strategy uses a notion of similarity in the interaction\ngraph, while the second strategy caches previous scores from the ranking stage.\nThe graph based strategy achieves a 4.08% revenue gain and the rankscore based\nstrategy achieves a 1.38% gain. These two strategies have biases that\ncomplement both the light ranker and one another. Finally, we describe a set of\nmetrics that we believe are valuable as a means of understanding the complex\nproduct trade offs inherent in industrial candidate generation systems.\n","authors":["Vanessa Cai","Pradeep Prabakar","Manuel Serrano Rebuelta","Lucas Rosen","Federico Monti","Katarzyna Janocha","Tomo Lazovich","Jeetu Raj","Yedendra Shrinivasan","Hao Li","Thomas Markovich"],"pdf_url":"https://arxiv.org/pdf/2302.13915v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.02676v4","updated":"2023-02-27T16:00:50Z","published":"2023-02-06T10:28:16Z","title":"Chain of Hindsight Aligns Language Models with Feedback","summary":"  Learning from human preferences is important for language models to be\nhelpful and useful for humans, and to align with human and social values. Prior\nwork have achieved remarkable successes by learning from human feedback to\nunderstand and follow instructions. Nonetheless, these methods are either\nfounded on hand-picked model generations that are favored by human annotators,\nrendering them ineffective in terms of data utilization and challenging to\napply in general, or they depend on reward functions and reinforcement\nlearning, which are prone to imperfect reward function and extremely\nchallenging to optimize. In this work, we propose a novel technique, Chain of\nHindsight, that is easy to optimize and can learn from any form of feedback,\nregardless of its polarity. Our idea is inspired by how humans learn from\nextensive feedback presented in the form of languages. We convert all types of\nfeedback into sentences, which are then used to fine-tune the model, allowing\nus to take advantage of the language comprehension capabilities of language\nmodels. We condition the model on a sequence of model generations paired with\nfeedback. By doing so, models are trained to generate outputs based on\nfeedback, and models can learn to identify and correct negative attributes or\nerrors. Applying our method to large language models, we observed that Chain of\nHindsight significantly surpasses previous methods in aligning language models\nwith human preferences. We observed significant improvements on summarization\nand dialogue tasks and our approach is markedly preferred in human evaluations.\n","authors":["Hao Liu","Carmelo Sferrazza","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.02676v4.pdf","comment":"Added more ablation studies and released code"},{"id":"http://arxiv.org/abs/2302.13875v1","updated":"2023-02-27T15:25:21Z","published":"2023-02-27T15:25:21Z","title":"Evaluating Robustness and Uncertainty of Graph Models Under Structural\n  Distributional Shifts","summary":"  In reliable decision-making systems based on machine learning, models have to\nbe robust to distributional shifts or provide the uncertainty of their\npredictions. In node-level problems of graph learning, distributional shifts\ncan be especially complex since the samples are interdependent. To evaluate the\nperformance of graph models, it is important to test them on diverse and\nmeaningful distributional shifts. However, most graph benchmarks that consider\ndistributional shifts for node-level problems focus mainly on node features,\nwhile data in graph problems is primarily defined by its structural properties.\nIn this work, we propose a general approach for inducing diverse distributional\nshifts based on graph structure. We use this approach to create data splits\naccording to several structural node properties: popularity, locality, and\ndensity. In our experiments, we thoroughly evaluate the proposed distributional\nshifts and show that they are quite challenging for existing graph models. We\nhope that the proposed approach will be helpful for the further development of\nreliable graph machine learning.\n","authors":["Gleb Bazhenov","Denis Kuznedelev","Andrey Malinin","Artem Babenko","Liudmila Prokhorenkova"],"pdf_url":"https://arxiv.org/pdf/2302.13875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03023v2","updated":"2023-02-27T15:03:28Z","published":"2023-02-06T18:58:38Z","title":"V1T: large-scale mouse V1 response prediction using a Vision Transformer","summary":"  Accurate predictive models of the visual cortex neural response to natural\nvisual stimuli remain a challenge in computational neuroscience. In this work,\nwe introduce V1T, a novel Vision Transformer based architecture that learns a\nshared visual and behavioral representation across animals. We evaluate our\nmodel on two large datasets recorded from mouse primary visual cortex and\noutperform previous convolution-based models by more than 12.7% in prediction\nperformance. Moreover, we show that the attention weights learned by the\nTransformer correlate with the population receptive fields. Our model thus sets\na new benchmark for neural response prediction and captures characteristic\nfeatures of the visual cortex.\n","authors":["Bryan M. Li","Isabel M. Cornacchia","Nathalie L. Rochefort","Arno Onken"],"pdf_url":"https://arxiv.org/pdf/2302.03023v2.pdf","comment":"updated references and added link to code repository"},{"id":"http://arxiv.org/abs/2302.13861v1","updated":"2023-02-27T15:02:04Z","published":"2023-02-27T15:02:04Z","title":"Differentially Private Diffusion Models Generate Useful Synthetic Images","summary":"  The ability to generate privacy-preserving synthetic versions of sensitive\nimage datasets could unlock numerous ML applications currently constrained by\ndata availability. Due to their astonishing image generation quality, diffusion\nmodels are a prime candidate for generating high-quality synthetic data.\nHowever, recent studies have found that, by default, the outputs of some\ndiffusion models do not preserve training data privacy. By privately\nfine-tuning ImageNet pre-trained diffusion models with more than 80M\nparameters, we obtain SOTA results on CIFAR-10 and Camelyon17 in terms of both\nFID and the accuracy of downstream classifiers trained on synthetic data. We\ndecrease the SOTA FID on CIFAR-10 from 26.2 to 9.8, and increase the accuracy\nfrom 51.0% to 88.0%. On synthetic data from Camelyon17, we achieve a downstream\naccuracy of 91.1% which is close to the SOTA of 96.5% when training on the real\ndata. We leverage the ability of generative models to create infinite amounts\nof data to maximise the downstream prediction performance, and further show how\nto use synthetic data for hyperparameter tuning. Our results demonstrate that\ndiffusion models fine-tuned with differential privacy can produce useful and\nprovably private synthetic data, even in applications with significant\ndistribution shift between the pre-training and fine-tuning distributions.\n","authors":["Sahra Ghalebikesabi","Leonard Berrada","Sven Gowal","Ira Ktena","Robert Stanforth","Jamie Hayes","Soham De","Samuel L. Smith","Olivia Wiles","Borja Balle"],"pdf_url":"https://arxiv.org/pdf/2302.13861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08955v3","updated":"2023-02-27T14:59:01Z","published":"2022-12-17T21:26:22Z","title":"Trusting the Explainers: Teacher Validation of Explainable Artificial\n  Intelligence for Course Design","summary":"  Deep learning models for learning analytics have become increasingly popular\nover the last few years; however, these approaches are still not widely adopted\nin real-world settings, likely due to a lack of trust and transparency. In this\npaper, we tackle this issue by implementing explainable AI methods for\nblack-box neural networks. This work focuses on the context of online and\nblended learning and the use case of student success prediction models. We use\na pairwise study design, enabling us to investigate controlled differences\nbetween pairs of courses. Our analyses cover five course pairs that differ in\none educationally relevant aspect and two popular instance-based explainable AI\nmethods (LIME and SHAP). We quantitatively compare the distances between the\nexplanations across courses and methods. We then validate the explanations of\nLIME and SHAP with 26 semi-structured interviews of university-level educators\nregarding which features they believe contribute most to student success, which\nexplanations they trust most, and how they could transform these insights into\nactionable course design decisions. Our results show that quantitatively,\nexplainers significantly disagree with each other about what is important, and\nqualitatively, experts themselves do not agree on which explanations are most\ntrustworthy. All code, extended results, and the interview protocol are\nprovided at https://github.com/epfl-ml4ed/trusting-explainers.\n","authors":["Vinitra Swamy","Sijia Du","Mirko Marras","Tanja Käser"],"pdf_url":"https://arxiv.org/pdf/2212.08955v3.pdf","comment":"Accepted as a full paper (Best Paper nominee) at LAK 2023: The 13th\n  International Learning Analytics and Knowledge Conference, March 13-17, 2023,\n  Arlington, Texas, USA"},{"id":"http://arxiv.org/abs/2208.06677v4","updated":"2023-02-27T14:58:59Z","published":"2022-08-13T16:04:39Z","title":"Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep\n  Models","summary":"  In deep learning, different kinds of deep networks typically need different\noptimizers, which have to be chosen after multiple trials, making the training\nprocess inefficient. To relieve this issue and consistently improve the model\ntraining speed across deep networks, we propose the ADAptive Nesterov momentum\nalgorithm, Adan for short. Adan first reformulates the vanilla Nesterov\nacceleration to develop a new Nesterov momentum estimation (NME) method, which\navoids the extra overhead of computing gradient at the extrapolation point.\nThen Adan adopts NME to estimate the gradient's first- and second-order moments\nin adaptive gradient algorithms for convergence acceleration. Besides, we prove\nthat Adan finds an $\\epsilon$-approximate first-order stationary point within\n$O(\\epsilon^{-3.5})$ stochastic gradient complexity on the non-convex\nstochastic problems (e.g., deep learning problems), matching the best-known\nlower bound. Extensive experimental results show that Adan consistently\nsurpasses the corresponding SoTA optimizers on vision, language, and RL tasks\nand sets new SoTAs for many popular networks and frameworks, e.g., ResNet,\nConvNext, ViT, Swin, MAE, DETR, GPT-2, Transformer-XL, and BERT. More\nsurprisingly, Adan can use half of the training cost (epochs) of SoTA\noptimizers to achieve higher or comparable performance on ViT, GPT-2, MAE,\ne.t.c., and also shows great tolerance to a large range of minibatch size,\ne.g., from 1k to 32k. Code is released at https://github.com/sail-sg/Adan, and\nhas been used in multiple popular deep learning frameworks or projects.\n","authors":["Xingyu Xie","Pan Zhou","Huan Li","Zhouchen Lin","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2208.06677v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.15860v3","updated":"2023-02-27T14:57:41Z","published":"2021-06-30T07:41:51Z","title":"Understanding Adversarial Attacks on Observations in Deep Reinforcement\n  Learning","summary":"  Deep reinforcement learning models are vulnerable to adversarial attacks that\ncan decrease a victim's cumulative expected reward by manipulating the victim's\nobservations. Despite the efficiency of previous optimization-based methods for\ngenerating adversarial noise in supervised learning, such methods might not be\nable to achieve the lowest cumulative reward since they do not explore the\nenvironmental dynamics in general. In this paper, we provide a framework to\nbetter understand the existing methods by reformulating the problem of\nadversarial attacks on reinforcement learning in the function space. Our\nreformulation generates an optimal adversary in the function space of the\ntargeted attacks, repelling them via a generic two-stage framework. In the\nfirst stage, we train a deceptive policy by hacking the environment, and\ndiscover a set of trajectories routing to the lowest reward or the worst-case\nperformance. Next, the adversary misleads the victim to imitate the deceptive\npolicy by perturbing the observations. Compared to existing approaches, we\ntheoretically show that our adversary is stronger under an appropriate noise\nlevel. Extensive experiments demonstrate our method's superiority in terms of\nefficiency and effectiveness, achieving the state-of-the-art performance in\nboth Atari and MuJoCo environments.\n","authors":["You Qiaoben","Chengyang Ying","Xinning Zhou","Hang Su","Jun Zhu","Bo Zhang"],"pdf_url":"https://arxiv.org/pdf/2106.15860v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13851v1","updated":"2023-02-27T14:52:15Z","published":"2023-02-27T14:52:15Z","title":"Implicit Poisoning Attacks in Two-Agent Reinforcement Learning:\n  Adversarial Policies for Training-Time Attacks","summary":"  In targeted poisoning attacks, an attacker manipulates an agent-environment\ninteraction to force the agent into adopting a policy of interest, called\ntarget policy. Prior work has primarily focused on attacks that modify standard\nMDP primitives, such as rewards or transitions. In this paper, we study\ntargeted poisoning attacks in a two-agent setting where an attacker implicitly\npoisons the effective environment of one of the agents by modifying the policy\nof its peer. We develop an optimization framework for designing optimal\nattacks, where the cost of the attack measures how much the solution deviates\nfrom the assumed default policy of the peer agent. We further study the\ncomputational properties of this optimization framework. Focusing on a tabular\nsetting, we show that in contrast to poisoning attacks based on MDP primitives\n(transitions and (unbounded) rewards), which are always feasible, it is NP-hard\nto determine the feasibility of implicit poisoning attacks. We provide\ncharacterization results that establish sufficient conditions for the\nfeasibility of the attack problem, as well as an upper and a lower bound on the\noptimal cost of the attack. We propose two algorithmic approaches for finding\nan optimal adversarial policy: a model-based approach with tabular policies and\na model-free approach with parametric/neural policies. We showcase the efficacy\nof the proposed algorithms through experiments.\n","authors":["Mohammad Mohammadi","Jonathan Nöther","Debmalya Mandal","Adish Singla","Goran Radanovic"],"pdf_url":"https://arxiv.org/pdf/2302.13851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.09202v2","updated":"2023-02-27T14:50:58Z","published":"2021-07-15T16:54:38Z","title":"Compressing Multisets with Large Alphabets using Bits-Back Coding","summary":"  Current methods which compress multisets at an optimal rate have\ncomputational complexity that scales linearly with alphabet size, making them\ntoo slow to be practical in many real-world settings. We show how to convert a\ncompression algorithm for sequences into one for multisets, in exchange for an\nadditional complexity term that is quasi-linear in sequence length. This allows\nus to compress multisets of exchangeable symbols at an optimal rate, with\ncomputational complexity decoupled from the alphabet size. The key insight is\nto avoid encoding the multiset directly, and instead compress a proxy sequence,\nusing a technique called `bits-back coding'. We demonstrate the method\nexperimentally on tasks which are intractable with previous optimal-rate\nmethods: compression of multisets of images and JavaScript Object Notation\n(JSON) files. Code for our experiments is available at\nhttps://github.com/facebookresearch/multiset-compression.\n","authors":["Daniel Severo","James Townsend","Ashish Khisti","Alireza Makhzani","Karen Ullrich"],"pdf_url":"https://arxiv.org/pdf/2107.09202v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13849v1","updated":"2023-02-27T14:50:34Z","published":"2023-02-27T14:50:34Z","title":"Optimal Prediction Using Expert Advice and Randomized Littlestone\n  Dimension","summary":"  A classical result in online learning characterizes the optimal mistake bound\nachievable by deterministic learners using the Littlestone dimension\n(Littlestone '88). We prove an analogous result for randomized learners: we\nshow that the optimal expected mistake bound in learning a class $\\mathcal{H}$\nequals its randomized Littlestone dimension, which is the largest $d$ for which\nthere exists a tree shattered by $\\mathcal{H}$ whose average depth is $2d$. We\nfurther study optimal mistake bounds in the agnostic case, as a function of the\nnumber of mistakes made by the best function in $\\mathcal{H}$, denoted by $k$.\nWe show that the optimal randomized mistake bound for learning a class with\nLittlestone dimension $d$ is $k + \\Theta (\\sqrt{k d} + d )$. This also implies\nan optimal deterministic mistake bound of $2k + O (\\sqrt{k d} + d )$, thus\nresolving an open question which was studied by Auer and Long ['99].\n  As an application of our theory, we revisit the classical problem of\nprediction using expert advice: about 30 years ago Cesa-Bianchi, Freund,\nHaussler, Helmbold, Schapire and Warmuth studied prediction using expert\nadvice, provided that the best among the $n$ experts makes at most $k$\nmistakes, and asked what are the optimal mistake bounds. Cesa-Bianchi, Freund,\nHelmbold, and Warmuth ['93, '96] provided a nearly optimal bound for\ndeterministic learners, and left the randomized case as an open problem. We\nresolve this question by providing an optimal learning rule in the randomized\ncase, and showing that its expected mistake bound equals half of the\ndeterministic bound, up to negligible additive terms. This improves upon\nprevious works by Cesa-Bianchi, Freund, Haussler, Helmbold, Schapire and\nWarmuth ['93, '97], by Abernethy, Langford, and Warmuth ['06], and by Br\\^anzei\nand Peres ['19], which handled the regimes $k \\ll \\log n$ or $k \\gg \\log n$.\n","authors":["Yuval Filmus","Steve Hanneke","Idan Mehalel","Shay Moran"],"pdf_url":"https://arxiv.org/pdf/2302.13849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13846v1","updated":"2023-02-27T14:49:02Z","published":"2023-02-27T14:49:02Z","title":"Domain Adaptive Decision Trees: Implications for Accuracy and Fairness","summary":"  In uses of pre-trained machine learning models, it is a known issue that the\ntarget population in which the model is being deployed may not have been\nreflected in the source population with which the model was trained. This can\nresult in a biased model when deployed, leading to a reduction in model\nperformance. One risk is that, as the population changes, certain demographic\ngroups will be under-served or otherwise disadvantaged by the model, even as\nthey become more represented in the target population. The field of domain\nadaptation proposes techniques for a situation where label data for the target\npopulation does not exist, but some information about the target distribution\ndoes exist. In this paper we contribute to the domain adaptation literature by\nintroducing domain-adaptive decision trees (DADT). We focus on decision trees\ngiven their growing popularity due to their interpretability and performance\nrelative to other more complex models. With DADT we aim to improve the accuracy\nof models trained in a source domain (or training data) that differs from the\ntarget domain (or test data). We propose an in-processing step that adjusts the\ninformation gain split criterion with outside information corresponding to the\ndistribution of the target population. We demonstrate DADT on real data and\nfind that it improves accuracy over a standard decision tree when testing in a\nshifted target population. We also study the change in fairness under\ndemographic parity and equal opportunity. Results show an improvement in\nfairness with the use of DADT.\n","authors":["Jose M. Alvarez","Kristen M. Scott","Salvatore Ruggieri","Bettina Berendt"],"pdf_url":"https://arxiv.org/pdf/2302.13846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.07833v3","updated":"2023-02-27T14:43:48Z","published":"2022-07-16T04:44:16Z","title":"Explain Influence Maximization with Sobol Indices","summary":"  Due to its vast application on online social networks, Influence Maximization\n(IM) has garnered considerable attention over the last couple of decades.\nCurrent IM research lacks human-comprehensible explanations of how the seed set\nresults in the influence effect, hence reducing the trustworthiness of existing\nsolutions despite their applicability. Due to the intricacy of IM, the majority\nof current research concentrate on estimating first-order spreading power and\noften is regard the interplay between flows dispersed from different seeds.\nThis study uses Sobol indices, the cornerstone of variance-based sensitivity\nanalysis, to decompose the influence effect to individual seeds and their\ninteractions. The Sobol indices are tailored for IM contexts by modeling the\nseed selection as binary variables. This explanation method is universally\napplicable to all network types, IM techniques, and diffusion models. Based on\nthe explanation method, a general framework dubbed SobolIM is proposed to\nimprove the performance of current IM studies by over-selecting nodes followed\nby an elimination strategy. Experiments on synthetic and real-world graphs\ndemonstrate that the explanation of the impact effect can dependably identify\nthe key high-order interaction between seeds across a variety of networks and\nIM methods. SobolIM is empirically proved to be superior on effectiveness and\ncompetitive on efficiency.\n","authors":["Zonghan Zhang","Zhiqian Chen"],"pdf_url":"https://arxiv.org/pdf/2207.07833v3.pdf","comment":"Accepted by SDM 2023"},{"id":"http://arxiv.org/abs/2302.05209v2","updated":"2023-02-27T14:37:43Z","published":"2023-02-10T12:25:08Z","title":"A Survey on Causal Reinforcement Learning","summary":"  While Reinforcement Learning (RL) achieves tremendous success in sequential\ndecision-making problems of many domains, it still faces key challenges of data\ninefficiency and the lack of interpretability. Interestingly, many researchers\nhave leveraged insights from the causality literature recently, bringing forth\nflourishing works to unify the merits of causality and address well the\nchallenges from RL. As such, it is of great necessity and significance to\ncollate these Causal Reinforcement Learning (CRL) works, offer a review of CRL\nmethods, and investigate the potential functionality from causality toward RL.\nIn particular, we divide existing CRL approaches into two categories according\nto whether their causality-based information is given in advance or not. We\nfurther analyze each category in terms of the formalization of different\nmodels, ranging from the Markov Decision Process (MDP), Partially Observed\nMarkov Decision Process (POMDP), Multi-Arm Bandits (MAB), and Dynamic Treatment\nRegime (DTR). Moreover, we summarize the evaluation matrices and open sources\nwhile we discuss emerging applications, along with promising prospects for the\nfuture development of CRL.\n","authors":["Yan Zeng","Ruichu Cai","Fuchun Sun","Libo Huang","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2302.05209v2.pdf","comment":"29 pages, 20 figures"},{"id":"http://arxiv.org/abs/2302.13834v1","updated":"2023-02-27T14:37:16Z","published":"2023-02-27T14:37:16Z","title":"Denoising Diffusion Samplers","summary":"  Denoising diffusion models are a popular class of generative models providing\nstate-of-the-art results in many domains. One adds gradually noise to data\nusing a diffusion to transform the data distribution into a Gaussian\ndistribution. Samples from the generative model are then obtained by simulating\nan approximation of the time-reversal of this diffusion initialized by Gaussian\nsamples. Practically, the intractable score terms appearing in the\ntime-reversed process are approximated using score matching techniques. We\nexplore here a similar idea to sample approximately from unnormalized\nprobability density functions and estimate their normalizing constants. We\nconsider a process where the target density diffuses towards a Gaussian.\nDenoising Diffusion Samplers (DDS) are obtained by approximating the\ncorresponding time-reversal. While score matching is not applicable in this\ncontext, we can leverage many of the ideas introduced in generative modeling\nfor Monte Carlo sampling. Existing theoretical results from denoising diffusion\nmodels also provide theoretical guarantees for DDS. We discuss the connections\nbetween DDS, optimal control and Schr\\\"odinger bridges and finally demonstrate\nDDS experimentally on a variety of challenging sampling tasks.\n","authors":["Francisco Vargas","Will Grathwohl","Arnaud Doucet"],"pdf_url":"https://arxiv.org/pdf/2302.13834v1.pdf","comment":"In The Eleventh International Conference on Learning Representations,\n  2023"},{"id":"http://arxiv.org/abs/2302.13797v1","updated":"2023-02-27T14:16:36Z","published":"2023-02-27T14:16:36Z","title":"Learning Large Neighborhood Search for Vehicle Routing in Airport Ground\n  Handling","summary":"  Dispatching vehicle fleets to serve flights is a key task in airport ground\nhandling (AGH). Due to the notable growth of flights, it is challenging to\nsimultaneously schedule multiple types of operations (services) for a large\nnumber of flights, where each type of operation is performed by one specific\nvehicle fleet. To tackle this issue, we first represent the operation\nscheduling as a complex vehicle routing problem and formulate it as a mixed\ninteger linear programming (MILP) model. Then given the graph representation of\nthe MILP model, we propose a learning assisted large neighborhood search (LNS)\nmethod using data generated based on real scenarios, where we integrate\nimitation learning and graph convolutional network (GCN) to learn a destroy\noperator to automatically select variables, and employ an off-the-shelf solver\nas the repair operator to reoptimize the selected variables. Experimental\nresults based on a real airport show that the proposed method allows for\nhandling up to 200 flights with 10 types of operations simultaneously, and\noutperforms state-of-the-art methods. Moreover, the learned method performs\nconsistently accompanying different solvers, and generalizes well on larger\ninstances, verifying the versatility and scalability of our method.\n","authors":["Jianan Zhou","Yaoxin Wu","Zhiguang Cao","Wen Song","Jie Zhang","Zhenghua Chen"],"pdf_url":"https://arxiv.org/pdf/2302.13797v1.pdf","comment":"Accepted by IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)"},{"id":"http://arxiv.org/abs/2009.02653v3","updated":"2023-02-27T13:52:42Z","published":"2020-09-06T06:13:09Z","title":"A Survey on Machine Learning from Few Samples","summary":"  Few sample learning (FSL) is significant and challenging in the field of\nmachine learning. The capability of learning and generalizing from very few\nsamples successfully is a noticeable demarcation separating artificial\nintelligence and human intelligence since humans can readily establish their\ncognition to novelty from just a single or a handful of examples whereas\nmachine learning algorithms typically entail hundreds or thousands of\nsupervised samples to guarantee generalization ability. Despite the long\nhistory dated back to the early 2000s and the widespread attention in recent\nyears with booming deep learning technologies, little surveys or reviews for\nFSL are available until now. In this context, we extensively review 300+ papers\nof FSL spanning from the 2000s to 2019 and provide a timely and comprehensive\nsurvey for FSL. In this survey, we review the evolution history as well as the\ncurrent progress on FSL, categorize FSL approaches into the generative model\nbased and discriminative model based kinds in principle, and emphasize\nparticularly on the meta learning based FSL approaches. We also summarize\nseveral recently emerging extensional topics of FSL and review the latest\nadvances on these topics. Furthermore, we highlight the important FSL\napplications covering many research hotspots in computer vision, natural\nlanguage processing, audio and speech, reinforcement learning and robotic, data\nanalysis, etc. Finally, we conclude the survey with a discussion on promising\ntrends in the hope of providing guidance and insights to follow-up researches.\n","authors":["Jiang Lu","Pinghua Gong","Jieping Ye","Jianwei Zhang","Changshui Zhang"],"pdf_url":"https://arxiv.org/pdf/2009.02653v3.pdf","comment":"30 pages, Accepted by Pattern Recognition, 2023"},{"id":"http://arxiv.org/abs/2302.13763v1","updated":"2023-02-27T13:45:15Z","published":"2023-02-27T13:45:15Z","title":"Efficient and Low Overhead Website Fingerprinting Attacks and Defenses\n  based on TCP/IP Traffic","summary":"  Website fingerprinting attack is an extensively studied technique used in a\nweb browser to analyze traffic patterns and thus infer confidential information\nabout users. Several website fingerprinting attacks based on machine learning\nand deep learning tend to use the most typical features to achieve a\nsatisfactory performance of attacking rate. However, these attacks suffer from\nseveral practical implementation factors, such as a skillfully pre-processing\nstep or a clean dataset. To defend against such attacks, random packet defense\n(RPD) with a high cost of excessive network overhead is usually applied. In\nthis work, we first propose a practical filter-assisted attack against RPD,\nwhich can filter out the injected noises using the statistical characteristics\nof TCP/IP traffic. Then, we propose a list-assisted defensive mechanism to\ndefend the proposed attack method. To achieve a configurable trade-off between\nthe defense and the network overhead, we further improve the list-based defense\nby a traffic splitting mechanism, which can combat the mentioned attacks as\nwell as save a considerable amount of network overhead. In the experiments, we\ncollect real-life traffic patterns using three mainstream browsers, i.e.,\nMicrosoft Edge, Google Chrome, and Mozilla Firefox, and extensive results\nconducted on the closed and open-world datasets show the effectiveness of the\nproposed algorithms in terms of defense accuracy and network efficiency.\n","authors":["Guodong Huang","Chuan Ma","Ming Ding","Yuwen Qian","Chunpeng Ge","Liming Fang","Zhe Liu"],"pdf_url":"https://arxiv.org/pdf/2302.13763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08571v2","updated":"2023-02-27T13:39:00Z","published":"2022-12-15T13:50:13Z","title":"Statistical Design and Analysis for Robust Machine Learning: A Case\n  Study from COVID-19","summary":"  Since early in the coronavirus disease 2019 (COVID-19) pandemic, there has\nbeen interest in using artificial intelligence methods to predict COVID-19\ninfection status based on vocal audio signals, for example cough recordings.\nHowever, existing studies have limitations in terms of data collection and of\nthe assessment of the performances of the proposed predictive models. This\npaper rigorously assesses state-of-the-art machine learning techniques used to\npredict COVID-19 infection status based on vocal audio signals, using a dataset\ncollected by the UK Health Security Agency. This dataset includes acoustic\nrecordings and extensive study participant meta-data. We provide guidelines on\ntesting the performance of methods to classify COVID-19 infection status based\non acoustic features and we discuss how these can be extended more generally to\nthe development and assessment of predictive methods based on public health\ndatasets.\n","authors":["Davide Pigoli","Kieran Baker","Jobie Budd","Lorraine Butler","Harry Coppock","Sabrina Egglestone","Steven G. Gilmour","Chris Holmes","David Hurley","Radka Jersakova","Ivan Kiskin","Vasiliki Koutra","Jonathon Mellor","George Nicholson","Joe Packham","Selina Patel","Richard Payne","Stephen J. Roberts","Björn W. Schuller","Ana Tendero-Cañadas","Tracey Thornley","Alexander Titcomb"],"pdf_url":"https://arxiv.org/pdf/2212.08571v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13754v1","updated":"2023-02-27T13:32:47Z","published":"2023-02-27T13:32:47Z","title":"Combining Slow and Fast: Complementary Filtering for Dynamics Learning","summary":"  Modeling an unknown dynamical system is crucial in order to predict the\nfuture behavior of the system. A standard approach is training recurrent models\non measurement data. While these models typically provide exact short-term\npredictions, accumulating errors yield deteriorated long-term behavior. In\ncontrast, models with reliable long-term predictions can often be obtained,\neither by training a robust but less detailed model, or by leveraging\nphysics-based simulations. In both cases, inaccuracies in the models yield a\nlack of short-time details. Thus, different models with contrastive properties\non different time horizons are available. This observation immediately raises\nthe question: Can we obtain predictions that combine the best of both worlds?\nInspired by sensor fusion tasks, we interpret the problem in the frequency\ndomain and leverage classical methods from signal processing, in particular\ncomplementary filters. This filtering technique combines two signals by\napplying a high-pass filter to one signal, and low-pass filtering the other.\nEssentially, the high-pass filter extracts high-frequencies, whereas the\nlow-pass filter extracts low frequencies. Applying this concept to dynamics\nmodel learning enables the construction of models that yield accurate long- and\nshort-term predictions. Here, we propose two methods, one being purely\nlearning-based and the other one being a hybrid model that requires an\nadditional physics-based simulator.\n","authors":["Katharina Ensinger","Sebastian Ziesche","Barbara Rakitsch","Michael Tiemann","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2302.13754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13752v1","updated":"2023-02-27T13:31:21Z","published":"2023-02-27T13:31:21Z","title":"A Brief Survey on the Approximation Theory for Sequence Modelling","summary":"  We survey current developments in the approximation theory of sequence\nmodelling in machine learning. Particular emphasis is placed on classifying\nexisting results for various model architectures through the lens of classical\napproximation paradigms, and the insights one can gain from these results. We\nalso outline some future research directions towards building a theory of\nsequence modelling.\n","authors":["Haotian Jiang","Qianxiao Li","Zhong Li","Shida Wang"],"pdf_url":"https://arxiv.org/pdf/2302.13752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10321v2","updated":"2023-02-27T13:25:55Z","published":"2023-01-24T21:47:33Z","title":"Learning Dynamical Systems from Data: A Simple Cross-Validation\n  Perspective, Part V: Sparse Kernel Flows for 132 Chaotic Dynamical Systems","summary":"  Regressing the vector field of a dynamical system from a finite number of\nobserved states is a natural way to learn surrogate models for such systems. A\nsimple and interpretable way to learn a dynamical system from data is to\ninterpolate its vector-field with a data-adapted kernel which can be learned by\nusing Kernel Flows. The method of Kernel Flows is a trainable machine learning\nmethod that learns the optimal parameters of a kernel based on the premise that\na kernel is good if there is no significant loss in accuracy if half of the\ndata is used. The objective function could be a short-term prediction or some\nother objective for other variants of Kernel Flows). However, this method is\nlimited by the choice of the base kernel. In this paper, we introduce the\nmethod of \\emph{Sparse Kernel Flows } in order to learn the ``best'' kernel by\nstarting from a large dictionary of kernels. It is based on sparsifying a\nkernel that is a linear combination of elemental kernels. We apply this\napproach to a library of 132 chaotic systems.\n","authors":["Lu Yang","Xiuwen Sun","Boumediene Hamzi","Houman Owhadi","Naiming Xie"],"pdf_url":"https://arxiv.org/pdf/2301.10321v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13726v1","updated":"2023-02-27T12:44:48Z","published":"2023-02-27T12:44:48Z","title":"(Re)$^2$H2O: Autonomous Driving Scenario Generation via Reversely\n  Regularized Hybrid Offline-and-Online Reinforcement Learning","summary":"  Autonomous driving and its widespread adoption have long held tremendous\npromise. Nevertheless, without a trustworthy and thorough testing procedure,\nnot only does the industry struggle to mass-produce autonomous vehicles (AV),\nbut neither the general public nor policymakers are convinced to accept the\ninnovations. Generating safety-critical scenarios that present significant\nchallenges to AV is an essential first step in testing. Real-world datasets\ninclude naturalistic but overly safe driving behaviors, whereas simulation\nwould allow for unrestricted exploration of diverse and aggressive traffic\nscenarios. Conversely, higher-dimensional searching space in simulation\ndisables efficient scenario generation without real-world data distribution as\nimplicit constraints. In order to marry the benefits of both, it seems\nappealing to learn to generate scenarios from both offline real-world and\nonline simulation data simultaneously. Therefore, we tailor a Reversely\nRegularized Hybrid Offline-and-Online ((Re)$^2$H2O) Reinforcement Learning\nrecipe to additionally penalize Q-values on real-world data and reward Q-values\non simulated data, which ensures the generated scenarios are both varied and\nadversarial. Through extensive experiments, our solution proves to produce more\nrisky scenarios than competitive baselines and it can generalize to work with\nvarious autonomous driving models. In addition, these generated scenarios are\nalso corroborated to be capable of fine-tuning AV performance.\n","authors":["Haoyi Niu","Kun Ren","Yizhou Xu","Ziyuan Yang","Yichen Lin","Yi Zhang","Jianming Hu"],"pdf_url":"https://arxiv.org/pdf/2302.13726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.02938v2","updated":"2023-02-27T12:40:17Z","published":"2022-05-04T12:41:36Z","title":"Immiscible Color Flows in Optimal Transport Networks for Image\n  Classification","summary":"  In classification tasks, it is crucial to meaningfully exploit the\ninformation contained in data. While much of the work in addressing these tasks\nis devoted to building complex algorithmic infrastructures to process inputs in\na black-box fashion, less is known about how to exploit the various facets of\nthe data, before inputting this into an algorithm. Here, we focus on this\nlatter perspective, by proposing a physics-inspired dynamical system that\nadapts Optimal Transport principles to effectively leverage color distributions\nof images. Our dynamics regulates immiscible fluxes of colors traveling on a\nnetwork built from images. Instead of aggregating colors together, it treats\nthem as different commodities that interact with a shared capacity on edges.\nThe resulting optimal flows can then be fed into standard classifiers to\ndistinguish images in different classes. We show how our method can outperform\ncompeting approaches on image classification tasks in datasets where color\ninformation matters.\n","authors":["Alessandro Lonardi","Diego Baptista","Caterina De Bacco"],"pdf_url":"https://arxiv.org/pdf/2205.02938v2.pdf","comment":"23 pages, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2302.13711v1","updated":"2023-02-27T12:18:19Z","published":"2023-02-27T12:18:19Z","title":"Internal-Coordinate Density Modelling of Protein Structure: Covariance\n  Matters","summary":"  After the recent ground-breaking advances in protein structure prediction,\none of the remaining challenges in protein machine learning is to reliably\npredict distributions of structural states. Parametric models of small-scale\nfluctuations are difficult to fit due to complex covariance structures between\ndegrees of freedom in the protein chain, often causing models to either violate\nlocal or global structural constraints. In this paper, we present a new\nstrategy for modelling protein densities in internal coordinates, which uses\nconstraints in 3D space to induce covariance structure between the internal\ndegrees of freedom. We illustrate the potential of the procedure by\nconstructing a variational autoencoder with full covariance output induced by\nthe constraints implied by the conditional mean in 3D, and demonstrate that our\napproach makes it possible to scale density models of internal coordinates to\nfull-size proteins.\n","authors":["Marloes Arts","Jes Frellsen","Wouter Boomsma"],"pdf_url":"https://arxiv.org/pdf/2302.13711v1.pdf","comment":"Pages: 8 main, 2 references, 3 appendix. Figures: 5 main, 2 appendix"},{"id":"http://arxiv.org/abs/2302.13710v1","updated":"2023-02-27T12:17:43Z","published":"2023-02-27T12:17:43Z","title":"Global Algorithms for Mean-Variance Optimization in Markov Decision\n  Processes","summary":"  Dynamic optimization of mean and variance in Markov decision processes (MDPs)\nis a long-standing challenge caused by the failure of dynamic programming. In\nthis paper, we propose a new approach to find the globally optimal policy for\ncombined metrics of steady-state mean and variance in an infinite-horizon\nundiscounted MDP. By introducing the concepts of pseudo mean and pseudo\nvariance, we convert the original problem to a bilevel MDP problem, where the\ninner one is a standard MDP optimizing pseudo mean-variance and the outer one\nis a single parameter selection problem optimizing pseudo mean. We use the\nsensitivity analysis of MDPs to derive the properties of this bilevel problem.\nBy solving inner standard MDPs for pseudo mean-variance optimization, we can\nidentify worse policy spaces dominated by optimal policies of the pseudo\nproblems. We propose an optimization algorithm which can find the globally\noptimal policy by repeatedly removing worse policy spaces. The convergence and\ncomplexity of the algorithm are studied. Another policy dominance property is\nalso proposed to further improve the algorithm efficiency. Numerical\nexperiments demonstrate the performance and efficiency of our algorithms. To\nthe best of our knowledge, our algorithm is the first that efficiently finds\nthe globally optimal policy of mean-variance optimization in MDPs. These\nresults are also valid for solely minimizing the variance metrics in MDPs.\n","authors":["Li Xia","Shuai Ma"],"pdf_url":"https://arxiv.org/pdf/2302.13710v1.pdf","comment":"A breakthrough to develop globally optimal algorithms to solve the\n  steady-state mean-variance MDP problem"},{"id":"http://arxiv.org/abs/2302.13700v1","updated":"2023-02-27T11:59:28Z","published":"2023-02-27T11:59:28Z","title":"Imaginary Voice: Face-styled Diffusion Model for Text-to-Speech","summary":"  The goal of this work is zero-shot text-to-speech synthesis, with speaking\nstyles and voices learnt from facial characteristics. Inspired by the natural\nfact that people can imagine the voice of someone when they look at his or her\nface, we introduce a face-styled diffusion text-to-speech (TTS) model within a\nunified framework learnt from visible attributes, called Face-TTS. This is the\nfirst time that face images are used as a condition to train a TTS model.\n  We jointly train cross-model biometrics and TTS models to preserve speaker\nidentity between face images and generated speech segments. We also propose a\nspeaker feature binding loss to enforce the similarity of the generated and the\nground truth speech segments in speaker embedding space. Since the biometric\ninformation is extracted directly from the face image, our method does not\nrequire extra fine-tuning steps to generate speech from unseen and unheard\nspeakers. We train and evaluate the model on the LRS3 dataset, an in-the-wild\naudio-visual corpus containing background noise and diverse speaking styles.\nThe project page is https://facetts.github.io.\n","authors":["Jiyoung Lee","Joon Son Chung","Soo-Whan Chung"],"pdf_url":"https://arxiv.org/pdf/2302.13700v1.pdf","comment":"ICASSP 2023. Project page: https://facetts.github.io"},{"id":"http://arxiv.org/abs/2302.13696v1","updated":"2023-02-27T11:55:24Z","published":"2023-02-27T11:55:24Z","title":"Moderate Adaptive Linear Units (MoLU)","summary":"  We propose a new high-performance activation function, Moderate Adaptive\nLinear Units (MoLU), for the deep neural network. The MoLU is a simple,\nbeautiful and powerful activation function that can be a good main activation\nfunction among hundreds of activation functions. Because the MoLU is made up of\nthe elementary functions, not only it is a infinite diffeomorphism (i.e. smooth\nand infinitely differentiable over whole domains), but also it decreases\ntraining time.\n","authors":["Hankyul Koh","Joon-hyuk Ko","Wonho Jhe"],"pdf_url":"https://arxiv.org/pdf/2302.13696v1.pdf","comment":"4 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.13693v1","updated":"2023-02-27T11:53:03Z","published":"2023-02-27T11:53:03Z","title":"Learning Topology-Specific Experts for Molecular Property Prediction","summary":"  Recently, graph neural networks (GNNs) have been successfully applied to\npredicting molecular properties, which is one of the most classical\ncheminformatics tasks with various applications. Despite their effectiveness,\nwe empirically observe that training a single GNN model for diverse molecules\nwith distinct structural patterns limits its prediction performance. In this\npaper, motivated by this observation, we propose \\proposed to leverage\ntopology-specific prediction models (referred to as experts), each of which is\nresponsible for each molecular group sharing similar topological semantics.\nThat is, each expert learns topology-specific discriminative features while\nbeing trained with its corresponding topological group. To tackle the key\nchallenge of grouping molecules by their topological patterns, we introduce a\nclustering-based gating module that assigns an input molecule into one of the\nclusters and further optimizes the gating module with two different types of\nself-supervision: topological semantics induced by GNNs and molecular\nscaffolds, respectively. Extensive experiments demonstrate that \\proposed has\nboosted the performance for molecular property prediction and also achieved\nbetter generalization for new molecules with unseen scaffolds than baselines.\nThe code is available at https://github.com/kimsu55/ToxExpert.\n","authors":["Su Kim","Dongha Lee","SeongKu Kang","Seonghyeon Lee","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2302.13693v1.pdf","comment":"11 pages with 8 figures"},{"id":"http://arxiv.org/abs/2302.04179v4","updated":"2023-02-27T11:40:10Z","published":"2023-02-08T16:38:55Z","title":"A Scale-Independent Multi-Objective Reinforcement Learning with\n  Convergence Analysis","summary":"  Many sequential decision-making problems need optimization of different\nobjectives which possibly conflict with each other. The conventional way to\ndeal with a multi-task problem is to establish a scalar objective function\nbased on a linear combination of different objectives. However, for the case of\nhaving conflicting objectives with different scales, this method needs a\ntrial-and-error approach to properly find proper weights for the combination.\nAs such, in most cases, this approach cannot guarantee an optimal Pareto\nsolution. In this paper, we develop a single-agent scale-independent\nmulti-objective reinforcement learning on the basis of the Advantage\nActor-Critic (A2C) algorithm. A convergence analysis is then done for the\ndevised multi-objective algorithm providing a convergence-in-mean guarantee. We\nthen perform some experiments over a multi-task problem to evaluate the\nperformance of the proposed algorithm. Simulation results show the superiority\nof developed multi-objective A2C approach against the single-objective\nalgorithm.\n","authors":["Mohsen Amidzadeh"],"pdf_url":"https://arxiv.org/pdf/2302.04179v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04910v4","updated":"2023-02-27T11:39:09Z","published":"2022-06-10T07:23:51Z","title":"NAGphormer: A Tokenized Graph Transformer for Node Classification in\n  Large Graphs","summary":"  The graph Transformer emerges as a new architecture and has shown superior\nperformance on various graph mining tasks. In this work, we observe that\nexisting graph Transformers treat nodes as independent tokens and construct a\nsingle long sequence composed of all node tokens so as to train the Transformer\nmodel, causing it hard to scale to large graphs due to the quadratic complexity\non the number of nodes for the self-attention computation. To this end, we\npropose a Neighborhood Aggregation Graph Transformer (NAGphormer) that treats\neach node as a sequence containing a series of tokens constructed by our\nproposed Hop2Token module. For each node, Hop2Token aggregates the neighborhood\nfeatures from different hops into different representations and thereby\nproduces a sequence of token vectors as one input. In this way, NAGphormer\ncould be trained in a mini-batch manner and thus could scale to large graphs.\nMoreover, we mathematically show that as compared to a category of advanced\nGraph Neural Networks (GNNs), the decoupled Graph Convolutional Network,\nNAGphormer could learn more informative node representations from the multi-hop\nneighborhoods. Extensive experiments on benchmark datasets from small to large\nare conducted to demonstrate that NAGphormer consistently outperforms existing\ngraph Transformers and mainstream GNNs. Code is available at\nhttps://github.com/JHL-HUST/NAGphormer.\n","authors":["Jinsong Chen","Kaiyuan Gao","Gaichao Li","Kun He"],"pdf_url":"https://arxiv.org/pdf/2206.04910v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2008.12952v2","updated":"2023-02-27T11:24:00Z","published":"2020-08-29T10:09:02Z","title":"Efficient Robustness Certificates for Discrete Data: Sparsity-Aware\n  Randomized Smoothing for Graphs, Images and More","summary":"  Existing techniques for certifying the robustness of models for discrete data\neither work only for a small class of models or are general at the expense of\nefficiency or tightness. Moreover, they do not account for sparsity in the\ninput which, as our findings show, is often essential for obtaining non-trivial\nguarantees. We propose a model-agnostic certificate based on the randomized\nsmoothing framework which subsumes earlier work and is tight, efficient, and\nsparsity-aware. Its computational complexity does not depend on the number of\ndiscrete categories or the dimension of the input (e.g. the graph size), making\nit highly scalable. We show the effectiveness of our approach on a wide variety\nof models, datasets, and tasks -- specifically highlighting its use for Graph\nNeural Networks. So far, obtaining provable guarantees for GNNs has been\ndifficult due to the discrete and non-i.i.d. nature of graph data. Our method\ncan certify any GNN and handles perturbations to both the graph structure and\nthe node attributes.\n","authors":["Aleksandar Bojchevski","Johannes Gasteiger","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2008.12952v2.pdf","comment":"Proceedings of the 37th International Conference on Machine Learning\n  (ICML 2020)"},{"id":"http://arxiv.org/abs/2210.00226v4","updated":"2023-02-27T11:21:37Z","published":"2022-10-01T09:04:17Z","title":"Towards Understanding and Mitigating Dimensional Collapse in\n  Heterogeneous Federated Learning","summary":"  Federated learning aims to train models collaboratively across different\nclients without the sharing of data for privacy considerations. However, one\nmajor challenge for this learning paradigm is the {\\em data heterogeneity}\nproblem, which refers to the discrepancies between the local data distributions\namong various clients. To tackle this problem, we first study how data\nheterogeneity affects the representations of the globally aggregated models.\nInterestingly, we find that heterogeneous data results in the global model\nsuffering from severe {\\em dimensional collapse}, in which representations tend\nto reside in a lower-dimensional space instead of the ambient space. Moreover,\nwe observe a similar phenomenon on models locally trained on each client and\ndeduce that the dimensional collapse on the global model is inherited from\nlocal models. In addition, we theoretically analyze the gradient flow dynamics\nto shed light on how data heterogeneity result in dimensional collapse for\nlocal models. To remedy this problem caused by the data heterogeneity, we\npropose {\\sc FedDecorr}, a novel method that can effectively mitigate\ndimensional collapse in federated learning. Specifically, {\\sc FedDecorr}\napplies a regularization term during local training that encourages different\ndimensions of representations to be uncorrelated. {\\sc FedDecorr}, which is\nimplementation-friendly and computationally-efficient, yields consistent\nimprovements over baselines on standard benchmark datasets. Code:\nhttps://github.com/bytedance/FedDecorr.\n","authors":["Yujun Shi","Jian Liang","Wenqing Zhang","Vincent Y. F. Tan","Song Bai"],"pdf_url":"https://arxiv.org/pdf/2210.00226v4.pdf","comment":"camera ready version of ICLR 2023"},{"id":"http://arxiv.org/abs/2302.12695v2","updated":"2023-02-27T10:58:12Z","published":"2023-02-24T15:48:23Z","title":"Cross-Lingual Transfer of Cognitive Processing Complexity","summary":"  When humans read a text, their eye movements are influenced by the structural\ncomplexity of the input sentences. This cognitive phenomenon holds across\nlanguages and recent studies indicate that multilingual language models utilize\nstructural similarities between languages to facilitate cross-lingual transfer.\nWe use sentence-level eye-tracking patterns as a cognitive indicator for\nstructural complexity and show that the multilingual model XLM-RoBERTa can\nsuccessfully predict varied patterns for 13 typologically diverse languages,\ndespite being fine-tuned only on English data. We quantify the sensitivity of\nthe model to structural complexity and distinguish a range of complexity\ncharacteristics. Our results indicate that the model develops a meaningful bias\ntowards sentence length but also integrates cross-lingual differences. We\nconduct a control experiment with randomized word order and find that the model\nseems to additionally capture more complex structural information.\n","authors":["Charlotte Pouw","Nora Hollenstein","Lisa Beinborn"],"pdf_url":"https://arxiv.org/pdf/2302.12695v2.pdf","comment":"Accepted at Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2302.13653v1","updated":"2023-02-27T10:47:15Z","published":"2023-02-27T10:47:15Z","title":"Equilibrium Bandits: Learning Optimal Equilibria of Unknown Dynamics","summary":"  Consider a decision-maker that can pick one out of $K$ actions to control an\nunknown system, for $T$ turns. The actions are interpreted as different\nconfigurations or policies. Holding the same action fixed, the system\nasymptotically converges to a unique equilibrium, as a function of this action.\nThe dynamics of the system are unknown to the decision-maker, which can only\nobserve a noisy reward at the end of every turn. The decision-maker wants to\nmaximize its accumulated reward over the $T$ turns. Learning what equilibria\nare better results in higher rewards, but waiting for the system to converge to\nequilibrium costs valuable time. Existing bandit algorithms, either stochastic\nor adversarial, achieve linear (trivial) regret for this problem. We present a\nnovel algorithm, termed Upper Equilibrium Concentration Bound (UECB), that\nknows to switch an action quickly if it is not worth it to wait until the\nequilibrium is reached. This is enabled by employing convergence bounds to\ndetermine how far the system is from equilibrium. We prove that UECB achieves a\nregret of $\\mathcal{O}(\\log(T)+\\tau_c\\log(\\tau_c)+\\tau_c\\log\\log(T))$ for this\nequilibrium bandit problem where $\\tau_c$ is the worst case approximate\nconvergence time to equilibrium. We then show that both epidemic control and\ngame control are special cases of equilibrium bandits, where $\\tau_c\\log\n\\tau_c$ typically dominates the regret. We then test UECB numerically for both\nof these applications.\n","authors":["Siddharth Chandak","Ilai Bistritz","Nicholas Bambos"],"pdf_url":"https://arxiv.org/pdf/2302.13653v1.pdf","comment":"Accepted at the 22nd International Conference on Autonomous Agents\n  and Multiagent Systems (2023)"},{"id":"http://arxiv.org/abs/2302.13652v1","updated":"2023-02-27T10:40:41Z","published":"2023-02-27T10:40:41Z","title":"Duration-aware pause insertion using pre-trained language model for\n  multi-speaker text-to-speech","summary":"  Pause insertion, also known as phrase break prediction and phrasing, is an\nessential part of TTS systems because proper pauses with natural duration\nsignificantly enhance the rhythm and intelligibility of synthetic speech.\nHowever, conventional phrasing models ignore various speakers' different styles\nof inserting silent pauses, which can degrade the performance of the model\ntrained on a multi-speaker speech corpus. To this end, we propose more powerful\npause insertion frameworks based on a pre-trained language model. Our approach\nuses bidirectional encoder representations from transformers (BERT) pre-trained\non a large-scale text corpus, injecting speaker embedding to capture various\nspeaker characteristics. We also leverage duration-aware pause insertion for\nmore natural multi-speaker TTS. We develop and evaluate two types of models.\nThe first improves conventional phrasing models on the position prediction of\nrespiratory pauses (RPs), i.e., silent pauses at word transitions without\npunctuation. It performs speaker-conditioned RP prediction considering\ncontextual information and is used to demonstrate the effect of speaker\ninformation on the prediction. The second model is further designed for\nphoneme-based TTS models and performs duration-aware pause insertion,\npredicting both RPs and punctuation-indicated pauses (PIPs) that are\ncategorized by duration. The evaluation results show that our models improve\nthe precision and recall of pause insertion and the rhythm of synthetic speech.\n","authors":["Dong Yang","Tomoki Koriyama","Yuki Saito","Takaaki Saeki","Detai Xin","Hiroshi Saruwatari"],"pdf_url":"https://arxiv.org/pdf/2302.13652v1.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2302.13638v1","updated":"2023-02-27T10:08:21Z","published":"2023-02-27T10:08:21Z","title":"Predicting the Performance of a Computing System with Deep Networks","summary":"  Predicting the performance and energy consumption of computing hardware is\ncritical for many modern applications. This will inform procurement decisions,\ndeployment decisions, and autonomic scaling. Existing approaches to\nunderstanding the performance of hardware largely focus around benchmarking --\nleveraging standardised workloads which seek to be representative of an\nend-user's needs. Two key challenges are present; benchmark workloads may not\nbe representative of an end-user's workload, and benchmark scores are not\neasily obtained for all hardware. Within this paper, we demonstrate the\npotential to build Deep Learning models to predict benchmark scores for unseen\nhardware. We undertake our evaluation with the openly available SPEC 2017\nbenchmark results. We evaluate three different networks, one fully-connected\nnetwork along with two Convolutional Neural Networks (one bespoke and one\nResNet inspired) and demonstrate impressive $R^2$ scores of 0.96, 0.98 and 0.94\nrespectively.\n","authors":["Mehmet Cengiz","Matthew Forshaw","Amir Atapour-Abarghouei","Andrew Stephen McGough"],"pdf_url":"https://arxiv.org/pdf/2302.13638v1.pdf","comment":"8 pages, 9 figures, 4 tables, ICPE2023"},{"id":"http://arxiv.org/abs/2204.08922v3","updated":"2023-02-27T10:06:06Z","published":"2022-04-01T10:10:27Z","title":"Feature Structure Distillation with Centered Kernel Alignment in BERT\n  Transferring","summary":"  Knowledge distillation is an approach to transfer information on\nrepresentations from a teacher to a student by reducing their difference. A\nchallenge of this approach is to reduce the flexibility of the student's\nrepresentations inducing inaccurate learning of the teacher's knowledge. To\nresolve it in transferring, we investigate distillation of structures of\nrepresentations specified to three types: intra-feature, local inter-feature,\nglobal inter-feature structures. To transfer them, we introduce feature\nstructure distillation methods based on the Centered Kernel Alignment, which\nassigns a consistent value to similar features structures and reveals more\ninformative relations. In particular, a memory-augmented transfer method with\nclustering is implemented for the global structures. The methods are\nempirically analyzed on the nine tasks for language understanding of the GLUE\ndataset with Bidirectional Encoder Representations from Transformers (BERT),\nwhich is a representative neural language model. In the results, the proposed\nmethods effectively transfer the three types of structures and improve\nperformance compared to state-of-the-art distillation methods. Indeed, the code\nfor the methods is available in https://github.com/maroo-sky/FSD.\n","authors":["Hee-Jun Jung","Doyeon Kim","Seung-Hoon Na","Kangil Kim"],"pdf_url":"https://arxiv.org/pdf/2204.08922v3.pdf","comment":"This work has been submitted to the ELSEVIER for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2302.13631v1","updated":"2023-02-27T09:58:09Z","published":"2023-02-27T09:58:09Z","title":"Curriculum Based Multi-Task Learning for Parkinson's Disease Detection","summary":"  There is great interest in developing radiological classifiers for diagnosis,\nstaging, and predictive modeling in progressive diseases such as Parkinson's\ndisease (PD), a neurodegenerative disease that is difficult to detect in its\nearly stages. Here we leverage severity-based meta-data on the stages of\ndisease to define a curriculum for training a deep convolutional neural network\n(CNN). Typically, deep learning networks are trained by randomly selecting\nsamples in each mini-batch. By contrast, curriculum learning is a training\nstrategy that aims to boost classifier performance by starting with examples\nthat are easier to classify. Here we define a curriculum to progressively\nincrease the difficulty of the training data corresponding to the Hoehn and\nYahr (H&Y) staging system for PD (total N=1,012; 653 PD patients, 359 controls;\nage range: 20.0-84.9 years). Even with our multi-task setting using pre-trained\nCNNs and transfer learning, PD classification based on T1-weighted (T1-w) MRI\nwas challenging (ROC AUC: 0.59-0.65), but curriculum training boosted\nperformance (by 3.9%) compared to our baseline model. Future work with\nmultimodal imaging may further boost performance.\n","authors":["Nikhil J. Dhinagar","Conor Owens-Walton","Emily Laltoo","Christina P. Boyle","Yao-Liang Chen","Philip Cook","Corey McMillan","Chih-Chien Tsai","J-J Wang","Yih-Ru Wu","Ysbrand van der Werf","Paul M. Thompson"],"pdf_url":"https://arxiv.org/pdf/2302.13631v1.pdf","comment":"Accepted for publication at the 20th IEEE International Symposium on\n  Biomedical Imaging, ISBI 2023"},{"id":"http://arxiv.org/abs/2302.13608v1","updated":"2023-02-27T09:17:35Z","published":"2023-02-27T09:17:35Z","title":"DeepSeq: Deep Sequential Circuit Learning","summary":"  Circuit representation learning is a promising research direction in the\nelectronic design automation (EDA) field. With sufficient data for\npre-training, the learned general yet effective representation can help to\nsolve multiple downstream EDA tasks by fine-tuning it on a small set of\ntask-related data. However, existing solutions only target combinational\ncircuits, significantly limiting their applications. In this work, we propose\nDeepSeq, a novel representation learning framework for sequential netlists.\nSpecifically, we introduce a dedicated graph neural network (GNN) with a\ncustomized propagation scheme to exploit the temporal correlations between\ngates in sequential circuits. To ensure effective learning, we propose to use a\nmulti-task training objective with two sets of strongly related supervision:\nlogic probability and transition probability at each node. A novel dual\nattention aggregation mechanism is introduced to facilitate learning both tasks\nefficiently. Experimental results on various benchmark circuits show that\nDeepSeq outperforms other GNN models for sequential circuit learning. We\nevaluate the generalization capability of DeepSeq on a downstream power\nestimation task. After fine-tuning, DeepSeq can accurately estimate power\nacross various circuits under different workloads.\n","authors":["Sadaf Khan","Zhengyuan Shi","Min Li","Qiang Xu"],"pdf_url":"https://arxiv.org/pdf/2302.13608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13602v1","updated":"2023-02-27T09:10:08Z","published":"2023-02-27T09:10:08Z","title":"The Role of Pre-training Data in Transfer Learning","summary":"  The transfer learning paradigm of model pre-training and subsequent\nfine-tuning produces high-accuracy models. While most studies recommend scaling\nthe pre-training size to benefit most from transfer learning, a question\nremains: what data and method should be used for pre-training? We investigate\nthe impact of pre-training data distribution on the few-shot and full\nfine-tuning performance using 3 pre-training methods (supervised, contrastive\nlanguage-image and image-image), 7 pre-training datasets, and 9 downstream\ndatasets. Through extensive controlled experiments, we find that the choice of\nthe pre-training data source is essential for the few-shot transfer, but its\nrole decreases as more data is made available for fine-tuning. Additionally, we\nexplore the role of data curation and examine the trade-offs between label\nnoise and the size of the pre-training dataset. We find that using 2000X more\npre-training data from LAION can match the performance of supervised ImageNet\npre-training. Furthermore, we investigate the effect of pre-training methods,\ncomparing language-image contrastive vs. image-image contrastive, and find that\nthe latter leads to better downstream accuracy\n","authors":["Rahim Entezari","Mitchell Wortsman","Olga Saukh","M. Moein Shariatnia","Hanie Sedghi","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2302.13602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09859v2","updated":"2023-02-27T09:03:44Z","published":"2022-08-21T09:53:32Z","title":"Emergence of hierarchical modes from deep learning","summary":"  Large-scale deep neural networks consume expensive training costs, but the\ntraining results in less-interpretable weight matrices constructing the\nnetworks. Here, we propose a mode decomposition learning that can interpret the\nweight matrices as a hierarchy of latent modes. These modes are akin to\npatterns in physics studies of memory networks, but the least number of modes\nincreases only logarithmically with the network width, and becomes even a\nconstant when the width further grows. The mode decomposition learning not only\nsaves a significant large amount of training costs, but also explains the\nnetwork performance with the leading modes, displaying a striking piecewise\npower-law behavior. The modes specify a progressively compact latent space\nacross the network hierarchy, making a more disentangled subspaces compared to\nstandard training. Our mode decomposition learning is also studied in an\nanalytic on-line learning setting, which reveals multi-stage of learning\ndynamics with a continuous specialization of hidden nodes. Therefore, the\nproposed mode decomposition learning points to a cheap and interpretable route\ntowards the magical deep learning.\n","authors":["Chan Li","Haiping Huang"],"pdf_url":"https://arxiv.org/pdf/2208.09859v2.pdf","comment":"5 pages +11 pages (SM), 4+10 figures, revised version to the journal"},{"id":"http://arxiv.org/abs/2302.13582v1","updated":"2023-02-27T08:40:45Z","published":"2023-02-27T08:40:45Z","title":"Neural Graph Revealers","summary":"  Sparse graph recovery methods works well where the data follows their\nassumptions but often they are not designed for doing downstream probabilistic\nqueries. This limits their adoption to only identifying connections among the\ninput variables. On the other hand, the Probabilistic Graphical Models (PGMs)\nassumes an underlying base graph between variables and learns a distribution\nover them. PGM design choices are carefully made such that the inference &\nsampling algorithms are efficient. This brings in certain restrictions and\noften simplifying assumptions. In this work, we propose Neural Graph Revealers\n(NGRs), that are an attempt to efficiently merge the sparse graph recovery\nmethods with PGMs into a single flow. The problem setting consists of an input\ndata X with D features and M samples and the task is to recover a sparse graph\nshowing connection between the features. NGRs view the neural networks as a\n`white box' or more specifically as a multitask learning framework. We\nintroduce `Graph-constrained path norm' that NGRs leverage to learn a graphical\nmodel that captures complex non-linear functional dependencies between the\nfeatures in the form of an undirected sparse graph. Furthermore, NGRs can\nhandle multimodal inputs like images, text, categorical data, embeddings etc.\nwhich is not straightforward to incorporate in the existing methods. We show\nexperimental results of doing sparse graph recovery and probabilistic inference\non data from Gaussian graphical models and a multimodal infant mortality\ndataset by CDC.\n","authors":["Harsh Shrivastava","Urszula Chajewska"],"pdf_url":"https://arxiv.org/pdf/2302.13582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13580v1","updated":"2023-02-27T08:34:37Z","published":"2023-02-27T08:34:37Z","title":"Joint Task and Data Oriented Semantic Communications: A Deep Separate\n  Source-channel Coding Scheme","summary":"  Semantic communications are expected to accomplish various semantic tasks\nwith relatively less spectrum resource by exploiting the semantic feature of\nsource data. To simultaneously serve both the data transmission and semantic\ntasks, joint data compression and semantic analysis has become pivotal issue in\nsemantic communications. This paper proposes a deep separate source-channel\ncoding (DSSCC) framework for the joint task and data oriented semantic\ncommunications (JTD-SC) and utilizes the variational autoencoder approach to\nsolve the rate-distortion problem with semantic distortion. First, by analyzing\nthe Bayesian model of the DSSCC framework, we derive a novel rate-distortion\noptimization problem via the Bayesian inference approach for general data\ndistributions and semantic tasks. Next, for a typical application of joint\nimage transmission and classification, we combine the variational autoencoder\napproach with a forward adaption scheme to effectively extract image features\nand adaptively learn the density information of the obtained features. Finally,\nan iterative training algorithm is proposed to tackle the overfitting issue of\ndeep learning models. Simulation results reveal that the proposed scheme\nachieves better coding gain as well as data recovery and classification\nperformance in most scenarios, compared to the classical compression schemes\nand the emerging deep joint source-channel schemes.\n","authors":["Jianhao Huang","Dongxu Li","Chuan Huang","Xiaoqi Qin","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13578v1","updated":"2023-02-27T08:30:46Z","published":"2023-02-27T08:30:46Z","title":"Online Black-Box Confidence Estimation of Deep Neural Networks","summary":"  Autonomous driving (AD) and advanced driver assistance systems (ADAS)\nincreasingly utilize deep neural networks (DNNs) for improved perception or\nplanning. Nevertheless, DNNs are quite brittle when the data distribution\nduring inference deviates from the data distribution during training. This\nrepresents a challenge when deploying in partly unknown environments like in\nthe case of ADAS. At the same time, the standard confidence of DNNs remains\nhigh even if the classification reliability decreases. This is problematic\nsince following motion control algorithms consider the apparently confident\nprediction as reliable even though it might be considerably wrong. To reduce\nthis problem real-time capable confidence estimation is required that better\naligns with the actual reliability of the DNN classification. Additionally, the\nneed exists for black-box confidence estimation to enable the homogeneous\ninclusion of externally developed components to an entire system. In this work\nwe explore this use case and introduce the neighborhood confidence (NHC) which\nestimates the confidence of an arbitrary DNN for classification. The metric can\nbe used for black-box systems since only the top-1 class output is required and\ndoes not need access to the gradients, the training dataset or a hold-out\nvalidation dataset. Evaluation on different data distributions, including small\nin-domain distribution shifts, out-of-domain data or adversarial attacks, shows\nthat the NHC performs better or on par with a comparable method for online\nwhite-box confidence estimation in low data regimes which is required for\nreal-time capable AD/ADAS.\n","authors":["Fabian Woitschek","Georg Schneider"],"pdf_url":"https://arxiv.org/pdf/2302.13578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13571v1","updated":"2023-02-27T08:16:39Z","published":"2023-02-27T08:16:39Z","title":"FLAG: Fast Label-Adaptive Aggregation for Multi-label Classification in\n  Federated Learning","summary":"  Federated learning aims to share private data to maximize the data utility\nwithout privacy leakage. Previous federated learning research mainly focuses on\nmulti-class classification problems. However, multi-label classification is a\ncrucial research problem close to real-world data properties. Nevertheless, a\nlimited number of federated learning studies explore this research problem.\nExisting studies of multi-label federated learning did not consider the\ncharacteristics of multi-label data, i.e., they used the concept of multi-class\nclassification to verify their methods' performance, which means it will not be\nfeasible to apply their methods to real-world applications. Therefore, this\nstudy proposed a new multi-label federated learning framework with a\nClustering-based Multi-label Data Allocation (CMDA) and a novel aggregation\nmethod, Fast Label-Adaptive Aggregation (FLAG), for multi-label classification\nin the federated learning environment. The experimental results demonstrate\nthat our methods only need less than 50\\% of training epochs and communication\nrounds to surpass the performance of state-of-the-art federated learning\nmethods.\n","authors":["Shih-Fang Chang","Benny Wei-Yun Hsu","Tien-Yu Chang","Vincent S. Tseng"],"pdf_url":"https://arxiv.org/pdf/2302.13571v1.pdf","comment":"16 pages, 6 figures, and 2 tables"},{"id":"http://arxiv.org/abs/2210.15887v2","updated":"2023-02-27T08:13:45Z","published":"2022-10-28T04:32:59Z","title":"Nonparallel High-Quality Audio Super Resolution with Domain Adaptation\n  and Resampling CycleGANs","summary":"  Neural audio super-resolution models are typically trained on low- and\nhigh-resolution audio signal pairs. Although these methods achieve highly\naccurate super-resolution if the acoustic characteristics of the input data are\nsimilar to those of the training data, challenges remain: the models suffer\nfrom quality degradation for out-of-domain data, and paired data are required\nfor training. To address these problems, we propose Dual-CycleGAN, a\nhigh-quality audio super-resolution method that can utilize unpaired data based\non two connected cycle consistent generative adversarial networks (CycleGAN).\nOur method decomposes the super-resolution method into domain adaptation and\nresampling processes to handle acoustic mismatch in the unpaired low- and\nhigh-resolution signals. The two processes are then jointly optimized within\nthe CycleGAN framework. Experimental results verify that the proposed method\nsignificantly outperforms conventional methods when paired data are not\navailable. Code and audio samples are available from\nhttps://chomeyama.github.io/DualCycleGAN-Demo/.\n","authors":["Reo Yoneyama","Ryuichi Yamamoto","Kentaro Tachibana"],"pdf_url":"https://arxiv.org/pdf/2210.15887v2.pdf","comment":"Acceptted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.13570v1","updated":"2023-02-27T08:10:58Z","published":"2023-02-27T08:10:58Z","title":"Physical Adversarial Attacks on Deep Neural Networks for Traffic Sign\n  Recognition: A Feasibility Study","summary":"  Deep Neural Networks (DNNs) are increasingly applied in the real world in\nsafety critical applications like advanced driver assistance systems. An\nexample for such use case is represented by traffic sign recognition systems.\nAt the same time, it is known that current DNNs can be fooled by adversarial\nattacks, which raises safety concerns if those attacks can be applied under\nrealistic conditions. In this work we apply different black-box attack methods\nto generate perturbations that are applied in the physical environment and can\nbe used to fool systems under different environmental conditions. To the best\nof our knowledge we are the first to combine a general framework for physical\nattacks with different black-box attack methods and study the impact of the\ndifferent methods on the success rate of the attack under the same setting. We\nshow that reliable physical adversarial attacks can be performed with different\nmethods and that it is also possible to reduce the perceptibility of the\nresulting perturbations. The findings highlight the need for viable defenses of\na DNN even in the black-box case, but at the same time form the basis for\nsecuring a DNN with methods like adversarial training which utilizes\nadversarial attacks to augment the original training data.\n","authors":["Fabian Woitschek","Georg Schneider"],"pdf_url":"https://arxiv.org/pdf/2302.13570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15533v3","updated":"2023-02-27T08:09:43Z","published":"2022-10-27T15:19:09Z","title":"Source-Filter HiFi-GAN: Fast and Pitch Controllable High-Fidelity Neural\n  Vocoder","summary":"  Our previous work, the unified source-filter GAN (uSFGAN) vocoder, introduced\na novel architecture based on the source-filter theory into the parallel\nwaveform generative adversarial network to achieve high voice quality and pitch\ncontrollability. However, the high temporal resolution inputs result in high\ncomputation costs. Although the HiFi-GAN vocoder achieves fast high-fidelity\nvoice generation thanks to the efficient upsampling-based generator\narchitecture, the pitch controllability is severely limited. To realize a fast\nand pitch-controllable high-fidelity neural vocoder, we introduce the\nsource-filter theory into HiFi-GAN by hierarchically conditioning the resonance\nfiltering network on a well-estimated source excitation information. According\nto the experimental results, our proposed method outperforms HiFi-GAN and\nuSFGAN on a singing voice generation in voice quality and synthesis speed on a\nsingle CPU. Furthermore, unlike the uSFGAN vocoder, the proposed method can be\neasily adopted/integrated in real-time applications and end-to-end systems.\n","authors":["Reo Yoneyama","Yi-Chiao Wu","Tomoki Toda"],"pdf_url":"https://arxiv.org/pdf/2210.15533v3.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.13567v1","updated":"2023-02-27T07:57:52Z","published":"2023-02-27T07:57:52Z","title":"Towards Audit Requirements for AI-based Systems in Mobility Applications","summary":"  Various mobility applications like advanced driver assistance systems\nincreasingly utilize artificial intelligence (AI) based functionalities.\nTypically, deep neural networks (DNNs) are used as these provide the best\nperformance on the challenging perception, prediction or planning tasks that\noccur in real driving environments. However, current regulations like UNECE R\n155 or ISO 26262 do not consider AI-related aspects and are only applied to\ntraditional algorithm-based systems. The non-existence of AI-specific standards\nor norms prevents the practical application and can harm the trust level of\nusers. Hence, it is important to extend existing standardization for security\nand safety to consider AI-specific challenges and requirements. To take a step\ntowards a suitable regulation we propose 50 technical requirements or best\npractices that extend existing regulations and address the concrete needs for\nDNN-based systems. We show the applicability, usefulness and meaningfulness of\nthe proposed requirements by performing an exemplary audit of a DNN-based\ntraffic sign recognition system using three of the proposed requirements.\n","authors":["Devi Padmavathi Alagarswamy","Christian Berghoff","Vasilios Danos","Fabian Langer","Thora Markert","Georg Schneider","Arndt von Twickel","Fabian Woitschek"],"pdf_url":"https://arxiv.org/pdf/2302.13567v1.pdf","comment":"To appear in Proceedings of the 9th International Conference on\n  Information Systems Security and Privacy"},{"id":"http://arxiv.org/abs/2207.01773v3","updated":"2023-02-27T07:54:48Z","published":"2022-07-05T02:22:05Z","title":"Approximating Discontinuous Nash Equilibrial Values of Two-Player\n  General-Sum Differential Games","summary":"  Finding Nash equilibrial policies for two-player differential games requires\nsolving Hamilton-Jacobi-Isaacs (HJI) PDEs. Self-supervised learning has been\nused to approximate solutions of such PDEs while circumventing the curse of\ndimensionality. However, this method fails to learn discontinuous PDE solutions\ndue to its sampling nature, leading to poor safety performance of the resulting\ncontrollers in robotics applications when player rewards are discontinuous.\nThis paper investigates two potential solutions to this problem: a hybrid\nmethod that leverages both supervised Nash equilibria and the HJI PDE, and a\nvalue-hardening method where a sequence of HJIs are solved with a gradually\nhardening reward. We compare these solutions using the resulting generalization\nand safety performance in two vehicle interaction simulation studies with 5D\nand 9D state spaces, respectively. Results show that with informative\nsupervision (e.g., collision and near-collision demonstrations) and the low\ncost of self-supervised learning, the hybrid method achieves better safety\nperformance than the supervised, self-supervised, and value hardening\napproaches on equal computational budget. Value hardening fails to generalize\nin the higher-dimensional case without informative supervision. Lastly, we show\nthat the neural activation function needs to be continuously differentiable for\nlearning PDEs and its choice can be case dependent.\n","authors":["Lei Zhang","Mukesh Ghimire","Wenlong Zhang","Zhe Xu","Yi Ren"],"pdf_url":"https://arxiv.org/pdf/2207.01773v3.pdf","comment":"Accepted by ICRA 2023"},{"id":"http://arxiv.org/abs/2302.13565v1","updated":"2023-02-27T07:49:05Z","published":"2023-02-27T07:49:05Z","title":"Invariant Representations of Embedded Simplicial Complexes","summary":"  Analyzing embedded simplicial complexes, such as triangular meshes and\ngraphs, is an important problem in many fields. We propose a new approach for\nanalyzing embedded simplicial complexes in a subdivision-invariant and\nisometry-invariant way using only topological and geometric information. Our\napproach is based on creating and analyzing sufficient statistics and uses a\ngraph neural network. We demonstrate the effectiveness of our approach using a\nsynthetic mesh data set.\n","authors":["Taejin Paik"],"pdf_url":"https://arxiv.org/pdf/2302.13565v1.pdf","comment":"28 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2302.13563v1","updated":"2023-02-27T07:48:06Z","published":"2023-02-27T07:48:06Z","title":"Deep Imbalanced Time-series Forecasting via Local Discrepancy Density","summary":"  Time-series forecasting models often encounter abrupt changes in a given\nperiod of time which generally occur due to unexpected or unknown events.\nDespite their scarce occurrences in the training set, abrupt changes incur loss\nthat significantly contributes to the total loss. Therefore, they act as noisy\ntraining samples and prevent the model from learning generalizable patterns,\nnamely the normal states. Based on our findings, we propose a reweighting\nframework that down-weights the losses incurred by abrupt changes and\nup-weights those by normal states. For the reweighting framework, we first\ndefine a measurement termed Local Discrepancy (LD) which measures the degree of\nabruptness of a change in a given period of time. Since a training set is\nmostly composed of normal states, we then consider how frequently the temporal\nchanges appear in the training set based on LD. Our reweighting framework is\napplicable to existing time-series forecasting models regardless of the\narchitectures. Through extensive experiments on 12 time-series forecasting\nmodels over eight datasets with various in-output sequence lengths, we\ndemonstrate that applying our reweighting framework reduces MSE by 10.1% on\naverage and by up to 18.6% in the state-of-the-art model.\n","authors":["Junwoo Park","Jungsoo Lee","Youngin Cho","Woncheol Shin","Dongmin Kim","Jaegul Choo","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2302.13563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13562v1","updated":"2023-02-27T07:47:23Z","published":"2023-02-27T07:47:23Z","title":"Communication-efficient Federated Learning with Single-Step Synthetic\n  Features Compressor for Faster Convergence","summary":"  Reducing communication overhead in federated learning (FL) is challenging but\ncrucial for large-scale distributed privacy-preserving machine learning. While\nmethods utilizing sparsification or others can largely lower the communication\noverhead, the convergence rate is also greatly compromised. In this paper, we\npropose a novel method, named single-step synthetic features compressor (3SFC),\nto achieve communication-efficient FL by directly constructing a tiny synthetic\ndataset based on raw gradients. Thus, 3SFC can achieve an extremely low\ncompression rate when the constructed dataset contains only one data sample.\nMoreover, 3SFC's compressing phase utilizes a similarity-based objective\nfunction so that it can be optimized with just one step, thereby considerably\nimproving its performance and robustness. In addition, to minimize the\ncompressing error, error feedback (EF) is also incorporated into 3SFC.\nExperiments on multiple datasets and models suggest that 3SFC owns\nsignificantly better convergence rates compared to competing methods with lower\ncompression rates (up to 0.02%). Furthermore, ablation studies and\nvisualizations show that 3SFC can carry more information than competing methods\nfor every communication round, further validating its effectiveness.\n","authors":["Yuhao Zhou","Mingjia Shi","Qing Ye","Yanan Sun","Jiancheng Lv"],"pdf_url":"https://arxiv.org/pdf/2302.13562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02653v2","updated":"2023-02-27T07:30:08Z","published":"2023-02-06T09:49:58Z","title":"L'explicabilité au service de l'extraction de connaissances :\n  application à des données médicales","summary":"  The use of machine learning has increased dramatically in the last decade.\nThe lack of transparency is now a limiting factor, which the field of\nexplainability wants to address. Furthermore, one of the challenges of data\nmining is to present the statistical relationships of a dataset when they can\nbe highly non-linear. One of the strengths of supervised learning is its\nability to find complex statistical relationships that explainability allows to\nrepresent in an intelligible way. This paper shows that explanations can be\nused to extract knowledge from data and shows how feature selection, data\nsubgroup analysis and selection of highly informative instances benefit from\nexplanations. We then present a complete data processing pipeline using these\nmethods on medical data. -- --\n  L'utilisation de l'apprentissage automatique a connu un bond cette derni\\`ere\nd\\'ecennie. Le manque de transparence est aujourd'hui un frein, que le domaine\nde l'explicabilit\\'e veut r\\'esoudre. Par ailleurs, un des d\\'efis de\nl'exploration de donn\\'ees est de pr\\'esenter les relations statistiques d'un\njeu de donn\\'ees alors que celles-ci peuvent \\^etre hautement non-lin\\'eaires.\nUne des forces de l'apprentissage supervis\\'e est sa capacit\\'e \\`a trouver des\nrelations statistiques complexes que l'explicabilit\\'e permet de repr\\'esenter\nde mani\\`ere intelligible. Ce papier montre que les explications permettent de\nfaire de l'extraction de connaissance sur des donn\\'ees et comment la\ns\\'election de variables, l'analyse de sous-groupes de donn\\'ees et la\ns\\'election d'instances avec un fort pouvoir informatif b\\'en\\'eficient des\nexplications. Nous pr\\'esentons alors un pipeline complet de traitement des\ndonn\\'ees utilisant ces m\\'ethodes pour l'exploration de donn\\'ees m\\'edicales.\n","authors":["Robin Cugny","Emmanuel Doumard","Elodie Escriva","Haomiao Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02653v2.pdf","comment":"6 pages, in French language, 3 figures, EXPLAIN'AI Workshop, in\n  French"},{"id":"http://arxiv.org/abs/2302.13551v1","updated":"2023-02-27T07:10:33Z","published":"2023-02-27T07:10:33Z","title":"Invariant Layers for Graphs with Nodes of Different Types","summary":"  Neural networks that satisfy invariance with respect to input permutations\nhave been widely studied in machine learning literature. However, in many\napplications, only a subset of all input permutations is of interest. For\nheterogeneous graph data, one can focus on permutations that preserve node\ntypes. We fully characterize linear layers invariant to such permutations. We\nverify experimentally that implementing these layers in graph neural network\narchitectures allows learning important node interactions more effectively than\nexisting techniques. We show that the dimension of space of these layers is\ngiven by a generalization of Bell numbers, extending the work (Maron et al.,\n2019). We further narrow the invariant network design space by addressing a\nquestion about the sizes of tensor layers necessary for function approximation\non graph data. Our findings suggest that function approximation on a graph with\n$n$ nodes can be done with tensors of sizes $\\leq n$, which is tighter than the\nbest-known bound $\\leq n(n-1)/2$. For $d \\times d$ image data with translation\nsymmetry, our methods give a tight upper bound $2d - 1$ (instead of $d^{4}$) on\nsizes of invariant tensor generators via a surprising connection to Davenport\nconstants.\n","authors":["Dmitry Rybin","Ruoyu Sun","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2302.13551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15206v2","updated":"2023-02-27T07:00:27Z","published":"2022-10-27T06:35:09Z","title":"Learning on the Job: Self-Rewarding Offline-to-Online Finetuning for\n  Industrial Insertion of Novel Connectors from Vision","summary":"  Learning-based methods in robotics hold the promise of generalization, but\nwhat can be done if a learned policy does not generalize to a new situation? In\nprinciple, if an agent can at least evaluate its own success (i.e., with a\nreward classifier that generalizes well even when the policy does not), it\ncould actively practice the task and finetune the policy in this situation. We\nstudy this problem in the setting of industrial insertion tasks, such as\ninserting connectors in sockets and setting screws. Existing algorithms rely on\nprecise localization of the connector or socket and carefully managed physical\nsetups, such as assembly lines, to succeed at the task. But in unstructured\nenvironments such as homes or even some industrial settings, robots cannot rely\non precise localization and may be tasked with previously unseen connectors.\nOffline reinforcement learning on a variety of connector insertion tasks is a\npotential solution, but what if the robot is tasked with inserting previously\nunseen connector? In such a scenario, we will still need methods that can\nrobustly solve such tasks with online practice. One of the main observations we\nmake in this work is that, with a suitable representation learning and domain\ngeneralization approach, it can be significantly easier for the reward function\nto generalize to a new but structurally similar task (e.g., inserting a new\ntype of connector) than for the policy. This means that a learned reward\nfunction can be used to facilitate the finetuning of the robot's policy in\nsituations where the policy fails to generalize in zero shot, but the reward\nfunction generalizes successfully. We show that such an approach can be\ninstantiated in the real world, pretrained on 50 different connectors, and\nsuccessfully finetuned to new connectors via the learned reward function.\nVideos can be viewed at https://sites.google.com/view/learningonthejob\n","authors":["Ashvin Nair","Brian Zhu","Gokul Narayanan","Eugen Solowjow","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2210.15206v2.pdf","comment":"10 pages. To be presented at ICRA 2023"},{"id":"http://arxiv.org/abs/2206.00356v2","updated":"2023-02-27T06:58:28Z","published":"2022-06-01T09:43:10Z","title":"A Survey on Deep Learning for Skin Lesion Segmentation","summary":"  Skin cancer is a major public health problem that could benefit from\ncomputer-aided diagnosis to reduce the burden of this common disease. Skin\nlesion segmentation from images is an important step toward achieving this\ngoal. However, the presence of natural and artificial artifacts (e.g., hair and\nair bubbles), intrinsic factors (e.g., lesion shape and contrast), and\nvariations in image acquisition conditions make skin lesion segmentation a\nchallenging task. Recently, various researchers have explored the applicability\nof deep learning models to skin lesion segmentation. In this survey, we\ncross-examine 177 research papers that deal with deep learning-based\nsegmentation of skin lesions. We analyze these works along several dimensions,\nincluding input data (datasets, preprocessing, and synthetic data generation),\nmodel design (architecture, modules, and losses), and evaluation aspects (data\nannotation requirements and segmentation performance). We discuss these\ndimensions both from the viewpoint of select seminal works, and from a\nsystematic viewpoint, examining how those choices have influenced current\ntrends, and how their limitations should be addressed. To facilitate\ncomparisons, we summarize all examined works in a comprehensive table as well\nas an interactive table available online at\nhttps://github.com/sfu-mial/skin-lesion-segmentation-survey.\n","authors":["Zahra Mirikharaji","Kumar Abhishek","Alceu Bissoto","Catarina Barata","Sandra Avila","Eduardo Valle","M. Emre Celebi","Ghassan Hamarneh"],"pdf_url":"https://arxiv.org/pdf/2206.00356v2.pdf","comment":"55 pages, 10 figures; Mirikharaji and Abhishek: Joint first authors;\n  Celebi and Hamarneh: Joint senior authors"},{"id":"http://arxiv.org/abs/2302.13546v1","updated":"2023-02-27T06:55:00Z","published":"2023-02-27T06:55:00Z","title":"Self-Supervised Pre-Training for Deep Image Prior-Based Robust PET Image\n  Denoising","summary":"  Deep image prior (DIP) has been successfully applied to positron emission\ntomography (PET) image restoration, enabling represent implicit prior using\nonly convolutional neural network architecture without training dataset,\nwhereas the general supervised approach requires massive low- and high-quality\nPET image pairs. To answer the increased need for PET imaging with DIP, it is\nindispensable to improve the performance of the underlying DIP itself. Here, we\npropose a self-supervised pre-training model to improve the DIP-based PET image\ndenoising performance. Our proposed pre-training model acquires transferable\nand generalizable visual representations from only unlabeled PET images by\nrestoring various degraded PET images in a self-supervised approach. We\nevaluated the proposed method using clinical brain PET data with various\nradioactive tracers ($^{18}$F-florbetapir, $^{11}$C-Pittsburgh compound-B,\n$^{18}$F-fluoro-2-deoxy-D-glucose, and $^{15}$O-CO$_{2}$) acquired from\ndifferent PET scanners. The proposed method using the self-supervised\npre-training model achieved robust and state-of-the-art denoising performance\nwhile retaining spatial details and quantification accuracy compared to other\nunsupervised methods and pre-training model. These results highlight the\npotential that the proposed method is particularly effective against rare\ndiseases and probes and helps reduce the scan time or the radiotracer dose\nwithout affecting the patients.\n","authors":["Yuya Onishi","Fumio Hashimoto","Kibo Ote","Keisuke Matsubara","Masanobu Ibaraki"],"pdf_url":"https://arxiv.org/pdf/2302.13546v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.13542v1","updated":"2023-02-27T06:40:11Z","published":"2023-02-27T06:40:11Z","title":"Continuous descriptor-based control for deep audio synthesis","summary":"  Despite significant advances in deep models for music generation, the use of\nthese techniques remains restricted to expert users. Before being democratized\namong musicians, generative models must first provide expressive control over\nthe generation, as this conditions the integration of deep generative models in\ncreative workflows. In this paper, we tackle this issue by introducing a deep\ngenerative audio model providing expressive and continuous descriptor-based\ncontrol, while remaining lightweight enough to be embedded in a hardware\nsynthesizer. We enforce the controllability of real-time generation by\nexplicitly removing salient musical features in the latent space using an\nadversarial confusion criterion. User-specified features are then reintroduced\nas additional conditioning information, allowing for continuous control of the\ngeneration, akin to a synthesizer knob. We assess the performance of our method\non a wide variety of sounds including instrumental, percussive and speech\nrecordings while providing both timbre and attributes transfer, allowing new\nways of generating sounds.\n","authors":["Ninon Devis","Nils Demerlé","Sarah Nabi","David Genova","Philippe Esling"],"pdf_url":"https://arxiv.org/pdf/2302.13542v1.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2212.01348v2","updated":"2023-02-27T06:39:00Z","published":"2022-12-02T18:07:56Z","title":"Predict-and-Critic: Accelerated End-to-End Predictive Control for Cloud\n  Computing through Reinforcement Learning","summary":"  Cloud computing holds the promise of reduced costs through economies of\nscale. To realize this promise, cloud computing vendors typically solve\nsequential resource allocation problems, where customer workloads are packed on\nshared hardware. Virtual machines (VM) form the foundation of modern cloud\ncomputing as they help logically abstract user compute from shared physical\ninfrastructure. Traditionally, VM packing problems are solved by predicting\ndemand, followed by a Model Predictive Control (MPC) optimization over a future\nhorizon. We introduce an approximate formulation of an industrial VM packing\nproblem as an MILP with soft-constraints parameterized by the predictions.\nRecently, predict-and-optimize (PnO) was proposed for end-to-end training of\nprediction models by back-propagating the cost of decisions through the\noptimization problem. But, PnO is unable to scale to the large prediction\nhorizons prevalent in cloud computing. To tackle this issue, we propose the\nPredict-and-Critic (PnC) framework that outperforms PnO with just a two-step\nhorizon by leveraging reinforcement learning. PnC jointly trains a prediction\nmodel and a terminal Q function that approximates cost-to-go over a long\nhorizon, by back-propagating the cost of decisions through the optimization\nproblem \\emph{and from the future}. The terminal Q function allows us to solve\na much smaller two-step horizon optimization problem than the multi-step\nhorizon necessary in PnO. We evaluate PnO and the PnC framework on two\ndatasets, three workloads, and with disturbances not modeled in the\noptimization problem. We find that PnC significantly improves decision quality\nover PnO, even when the optimization problem is not a perfect representation of\nreality. We also find that hardening the soft constraints of the MILP and\nback-propagating through the constraints improves decision quality for both PnO\nand PnC.\n","authors":["Kaustubh Sridhar","Vikramank Singh","Balakrishnan Narayanaswamy","Abishek Sankararaman"],"pdf_url":"https://arxiv.org/pdf/2212.01348v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.14688v2","updated":"2023-02-27T06:31:51Z","published":"2022-03-28T12:41:41Z","title":"Training speaker recognition systems with limited data","summary":"  This work considers training neural networks for speaker recognition with a\nmuch smaller dataset size compared to contemporary work. We artificially\nrestrict the amount of data by proposing three subsets of the popular VoxCeleb2\ndataset. These subsets are restricted to 50\\,k audio files (versus over 1\\,M\nfiles available), and vary on the axis of number of speakers and session\nvariability. We train three speaker recognition systems on these subsets; the\nX-vector, ECAPA-TDNN, and wav2vec2 network architectures. We show that the\nself-supervised, pre-trained weights of wav2vec2 substantially improve\nperformance when training data is limited. Code and data subsets are available\nat https://github.com/nikvaessen/w2v2-speaker-few-samples.\n","authors":["Nik Vaessen","David A. van Leeuwen"],"pdf_url":"https://arxiv.org/pdf/2203.14688v2.pdf","comment":"accepted to Interspeech 2022"},{"id":"http://arxiv.org/abs/2208.08744v2","updated":"2023-02-27T06:26:30Z","published":"2022-08-18T09:57:03Z","title":"Global Convergence of Two-timescale Actor-Critic for Solving Linear\n  Quadratic Regulator","summary":"  The actor-critic (AC) reinforcement learning algorithms have been the\npowerhouse behind many challenging applications. Nevertheless, its convergence\nis fragile in general. To study its instability, existing works mostly consider\nthe uncommon double-loop variant or basic models with finite state and action\nspace. We investigate the more practical single-sample two-timescale AC for\nsolving the canonical linear quadratic regulator (LQR) problem, where the actor\nand the critic update only once with a single sample in each iteration on an\nunbounded continuous state and action space. Existing analysis cannot conclude\nthe convergence for such a challenging case. We develop a new analysis\nframework that allows establishing the global convergence to an\n$\\epsilon$-optimal solution with at most an $\\mathcal{O}(\\epsilon^{-2.5})$\nsample complexity. To our knowledge, this is the first finite-time convergence\nanalysis for the single sample two-timescale AC for solving LQR with global\noptimality. The sample complexity improves those of other variants by orders,\nwhich sheds light on the practical wisdom of single sample algorithms. We also\nfurther validate our theoretical findings via comprehensive simulation\ncomparisons.\n","authors":["Xuyang Chen","Jingliang Duan","Yingbin Liang","Lin Zhao"],"pdf_url":"https://arxiv.org/pdf/2208.08744v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13537v1","updated":"2023-02-27T06:26:09Z","published":"2023-02-27T06:26:09Z","title":"Global optimization in the discrete and variable-dimension\n  conformational space: The case of crystal with the strongest atomic cohesion","summary":"  We introduce a computational method to optimize target physical properties in\nthe full configuration space regarding atomic composition, chemical\nstoichiometry, and crystal structure. The approach combines the universal\npotential of the crystal graph neural network and Bayesian optimization. The\nproposed approach effectively obtains the crystal structure with the strongest\natomic cohesion from all possible crystals. Several new crystals with high\natomic cohesion are identified and confirmed by density functional theory for\nthermodynamic and dynamic stability. Our method introduces a novel approach to\ninverse materials design with additional functional properties for practical\napplications.\n","authors":["Guanjian Cheng","Xin-Gao Gong","Wan-Jian Yin"],"pdf_url":"https://arxiv.org/pdf/2302.13537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13536v1","updated":"2023-02-27T06:24:20Z","published":"2023-02-27T06:24:20Z","title":"Natural Gradient Hybrid Variational Inference with Application to Deep\n  Mixed Models","summary":"  Stochastic models with global parameters $\\bm{\\theta}$ and latent variables\n$\\bm{z}$ are common, and variational inference (VI) is popular for their\nestimation. This paper uses a variational approximation (VA) that comprises a\nGaussian with factor covariance matrix for the marginal of $\\bm{\\theta}$, and\nthe exact conditional posterior of $\\bm{z}|\\bm{\\theta}$. Stochastic\noptimization for learning the VA only requires generation of $\\bm{z}$ from its\nconditional posterior, while $\\bm{\\theta}$ is updated using the natural\ngradient, producing a hybrid VI method. We show that this is a well-defined\nnatural gradient optimization algorithm for the joint posterior of\n$(\\bm{z},\\bm{\\theta})$. Fast to compute expressions for the Tikhonov damped\nFisher information matrix required to compute a stable natural gradient update\nare derived. We use the approach to estimate probabilistic Bayesian neural\nnetworks with random output layer coefficients to allow for heterogeneity.\nSimulations show that using the natural gradient is more efficient than using\nthe ordinary gradient, and that the approach is faster and more accurate than\ntwo leading benchmark natural gradient VI methods. In a financial application\nwe show that accounting for industry level heterogeneity using the deep model\nimproves the accuracy of probabilistic prediction of asset pricing models.\n","authors":["Weiben Zhang","Michael Stanley Smith","Worapree Maneesoonthorn","Ruben Loaiza-Maya"],"pdf_url":"https://arxiv.org/pdf/2302.13536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08175v2","updated":"2023-02-27T06:18:41Z","published":"2023-02-16T09:44:55Z","title":"A numerical approximation method for the Fisher-Rao distance between\n  multivariate normal distributions","summary":"  We present a simple method to approximate Rao's distance between multivariate\nnormal distributions based on discretizing curves joining normal distributions\nand approximating Rao distances between successive nearby normal distributions\non the curve by Jeffreys divergence. We consider experimentally the linear\ninterpolation curves in the ordinary, natural and expectation parameterizations\nof the normal distributions, and compare these curves with a curve derived from\nthe Calvo and Oller's isometric embedding of the Fisher-Rao $d$-variate normal\nmanifold into the cone of $(d+1)\\times (d+1)$ symmetric positive-definite\nmatrices [Journal of multivariate analysis 35.2 (1990): 223-242]. We report on\nour experiments and assess the quality of our approximation technique by\ncomparing the numerical approximations with lower and upper bounds. Finally, we\npresent some information-geometric properties of the Calvo and Oller's\nisometric embedding.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2302.08175v2.pdf","comment":"15 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.13534v1","updated":"2023-02-27T06:09:10Z","published":"2023-02-27T06:09:10Z","title":"Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL\n  with General Regularizers and Multiple Optimal Arms","summary":"  We study the problem of designing adaptive multi-armed bandit algorithms that\nperform optimally in both the stochastic setting and the adversarial setting\nsimultaneously (often known as a best-of-both-world guarantee). A line of\nrecent works shows that when configured and analyzed properly, the\nFollow-the-Regularized-Leader (FTRL) algorithm, originally designed for the\nadversarial setting, can in fact optimally adapt to the stochastic setting as\nwell. Such results, however, critically rely on an assumption that there exists\none unique optimal arm. Recently, Ito (2021) took the first step to remove such\nan undesirable uniqueness assumption for one particular FTRL algorithm with the\n$\\frac{1}{2}$-Tsallis entropy regularizer. In this work, we significantly\nimprove and generalize this result, showing that uniqueness is unnecessary for\nFTRL with a broad family of regularizers and a new learning rate schedule. For\nsome regularizers, our regret bounds also improve upon prior results even when\nuniqueness holds. We further provide an application of our results to the\ndecoupled exploration and exploitation problem, demonstrating that our\ntechniques are broadly applicable.\n","authors":["Tiancheng Jin","Junyan Liu","Haipeng Luo"],"pdf_url":"https://arxiv.org/pdf/2302.13534v1.pdf","comment":"74 Pages"},{"id":"http://arxiv.org/abs/2205.04944v3","updated":"2023-02-27T05:57:05Z","published":"2022-05-10T14:57:56Z","title":"Hybrid Far- and Near-Field Channel Estimation for THz Ultra-Massive MIMO\n  via Fixed Point Networks","summary":"  Terahertz ultra-massive multiple-input multiple-output (THz UM-MIMO) is\nenvisioned as one of the key enablers of 6G wireless systems. Due to the joint\neffect of its array aperture and small wavelength, the near-field region of THz\nUM-MIMO is greatly enlarged. The high-dimensional channel of such systems thus\nconsists of a stochastic mixture of far and near fields, which renders channel\nestimation extremely challenging. Previous works based on uni-field assumptions\ncannot capture the hybrid far- and near-field features, thus suffering\nsignificant performance loss. This motivates us to consider hybrid-field\nchannel estimation. We draw inspirations from fixed point theory to develop an\nefficient deep learning based channel estimator with adaptive complexity and\nlinear convergence guarantee. Built upon classic orthogonal approximate message\npassing, we transform each iteration into a contractive mapping, comprising a\nclosed-form linear estimator and a neural network based non-linear estimator. A\nmajor algorithmic innovation involves applying fixed point iteration to compute\nthe channel estimate while modeling neural networks with arbitrary depth and\nadapting to the hybrid-field channel conditions. Simulation results verify our\ntheoretical analysis and show significant performance gains over\nstate-of-the-art approaches in the estimation accuracy and convergence rate.\n","authors":["Wentao Yu","Yifei Shen","Hengtao He","Xianghao Yu","Jun Zhang","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2205.04944v3.pdf","comment":"6 pages, 3 figures, accepted by IEEE Globecom 2022. Source code is\n  publicly available at\n  https://github.com/wyuaq/FPN-OAMP-THz-Channel-Estimation"},{"id":"http://arxiv.org/abs/2205.13891v2","updated":"2023-02-27T05:56:12Z","published":"2022-05-27T10:45:15Z","title":"Transformers from an Optimization Perspective","summary":"  Deep learning models such as the Transformer are often constructed by\nheuristics and experience. To provide a complementary foundation, in this work\nwe study the following problem: Is it possible to find an energy function\nunderlying the Transformer model, such that descent steps along this energy\ncorrespond with the Transformer forward pass? By finding such a function, we\ncan view Transformers as the unfolding of an interpretable optimization process\nacross iterations. This unfolding perspective has been frequently adopted in\nthe past to elucidate more straightforward deep models such as MLPs and CNNs;\nhowever, it has thus far remained elusive obtaining a similar equivalence for\nmore complex models with self-attention mechanisms like the Transformer. To\nthis end, we first outline several major obstacles before providing companion\ntechniques to at least partially address them, demonstrating for the first time\na close association between energy function minimization and deep layers with\nself-attention. This interpretation contributes to our intuition and\nunderstanding of Transformers, while potentially laying the ground-work for new\nmodel designs.\n","authors":["Yongyi Yang","Zengfeng Huang","David Wipf"],"pdf_url":"https://arxiv.org/pdf/2205.13891v2.pdf","comment":"This paper was published as a conference paper at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2210.15898v2","updated":"2023-02-27T05:37:28Z","published":"2022-10-28T05:13:50Z","title":"Toward Equation of Motion for Deep Neural Networks: Continuous-time\n  Gradient Descent and Discretization Error Analysis","summary":"  We derive and solve an ``Equation of Motion'' (EoM) for deep neural networks\n(DNNs), a differential equation that precisely describes the discrete learning\ndynamics of DNNs. Differential equations are continuous but have played a\nprominent role even in the study of discrete optimization (gradient descent\n(GD) algorithms). However, there still exist gaps between differential\nequations and the actual learning dynamics of DNNs due to discretization error.\nIn this paper, we start from gradient flow (GF) and derive a counter term that\ncancels the discretization error between GF and GD. As a result, we obtain EoM,\na continuous differential equation that precisely describes the discrete\nlearning dynamics of GD. We also derive discretization error to show to what\nextent EoM is precise. In addition, we apply EoM to two specific cases: scale-\nand translation-invariant layers. EoM highlights differences between\ncontinuous-time and discrete-time GD, indicating the importance of the counter\nterm for a better description of the discrete learning dynamics of GD. Our\nexperimental results support our theoretical findings.\n","authors":["Taiki Miyagawa"],"pdf_url":"https://arxiv.org/pdf/2210.15898v2.pdf","comment":"NeurIPS 2022 (https://openreview.net/forum?id=qq84D17BPu). 1 min & 4\n  mins short presentation videos are available; feel free to email me :)"},{"id":"http://arxiv.org/abs/2302.13522v1","updated":"2023-02-27T05:21:35Z","published":"2023-02-27T05:21:35Z","title":"IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size\n  of Public Graph Datasets for Deep Learning Research","summary":"  Graph neural networks (GNNs) have shown high potential for a variety of\nreal-world, challenging applications, but one of the major obstacles in GNN\nresearch is the lack of large-scale flexible datasets. Most existing public\ndatasets for GNNs are relatively small, which limits the ability of GNNs to\ngeneralize to unseen data. The few existing large-scale graph datasets provide\nvery limited labeled data. This makes it difficult to determine if the GNN\nmodel's low accuracy for unseen data is inherently due to insufficient training\ndata or if the model failed to generalize. Additionally, datasets used to train\nGNNs need to offer flexibility to enable a thorough study of the impact of\nvarious factors while training GNN models.\n  In this work, we introduce the Illinois Graph Benchmark (IGB), a research\ndataset tool that the developers can use to train, scrutinize and\nsystematically evaluate GNN models with high fidelity. IGB includes both\nhomogeneous and heterogeneous graphs of enormous sizes, with more than 40% of\ntheir nodes labeled. Compared to the largest graph datasets publicly available,\nthe IGB provides over 162X more labeled data for deep learning practitioners\nand developers to create and evaluate models with higher accuracy. The IGB\ndataset is designed to be flexible, enabling the study of various GNN\narchitectures, embedding generation techniques, and analyzing system\nperformance issues. IGB is open-sourced, supports DGL and PyG frameworks, and\ncomes with releases of the raw text that we believe foster emerging language\nmodels and GNN research projects. An early public version of IGB is available\nat https://github.com/IllinoisGraphBenchmark/IGB-Datasets.\n","authors":["Arpandeep Khatua","Vikram Sharma Mailthody","Bhagyashree Taleka","Tengfei Ma","Xiang Song","Wen-mei Hwu"],"pdf_url":"https://arxiv.org/pdf/2302.13522v1.pdf","comment":"Under Review in KDD'23 conference"},{"id":"http://arxiv.org/abs/2205.09329v2","updated":"2023-02-27T04:55:14Z","published":"2022-05-19T05:36:35Z","title":"Dataset Pruning: Reducing Training Data by Examining Generalization\n  Influence","summary":"  The great success of deep learning heavily relies on increasingly larger\ntraining data, which comes at a price of huge computational and infrastructural\ncosts. This poses crucial questions that, do all training data contribute to\nmodel's performance? How much does each individual training sample or a\nsub-training-set affect the model's generalization, and how to construct the\nsmallest subset from the entire training data as a proxy training set without\nsignificantly sacrificing the model's performance? To answer these, we propose\ndataset pruning, an optimization-based sample selection method that can (1)\nexamine the influence of removing a particular set of training samples on\nmodel's generalization ability with theoretical guarantee, and (2) construct\nthe smallest subset of training data that yields strictly constrained\ngeneralization gap. The empirically observed generalization gap of dataset\npruning is substantially consistent with our theoretical expectations.\nFurthermore, the proposed method prunes 40% training examples on the CIFAR-10\ndataset, halves the convergence time with only 1.3% test accuracy decrease,\nwhich is superior to previous score-based sample selection methods.\n","authors":["Shuo Yang","Zeke Xie","Hanyu Peng","Min Xu","Mingming Sun","Ping Li"],"pdf_url":"https://arxiv.org/pdf/2205.09329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13514v1","updated":"2023-02-27T04:31:49Z","published":"2023-02-27T04:31:49Z","title":"Winning through Collaboration by Applying Federated Learning in\n  Manufacturing Industry","summary":"  In manufacturing settings, data collection and analysis is often a\ntime-consuming, challenging, and costly process. It also hinders the use of\nadvanced machine learning and data-driven methods which requires a substantial\namount of offline training data to generate good results. It is particularly\nchallenging for small manufacturers who do not share the resources of a large\nenterprise. Recently, with the introduction of the Internet of Things (IoT),\ndata can be collected in an integrated manner across the factory in real-time,\nsent to the cloud for advanced analysis, and used to update the machine\nlearning model sequentially. Nevertheless, small manufacturers face two\nobstacles in reaping the benefits of IoT: they may be unable to afford or\ngenerate enough data to operate a private cloud, and they may be hesitant to\nshare their raw data with a public cloud. Federated learning (FL) is an\nemerging concept of collaborative learning that can help small-scale industries\naddress these issues and learn from each other without sacrificing their\nprivacy. It can bring together diverse and geographically dispersed\nmanufacturers under the same analytics umbrella to create a win-win situation.\nHowever, the widespread adoption of FL across multiple manufacturing\norganizations remains a significant challenge. This work aims to identify and\nillustrate these challenges and provide potential solutions to overcome them.\n","authors":["Farzana Islam","Ahmed Shoyeb Raihan","Imtiaz Ahmed"],"pdf_url":"https://arxiv.org/pdf/2302.13514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13512v1","updated":"2023-02-27T04:24:13Z","published":"2023-02-27T04:24:13Z","title":"Changes in Commuter Behavior from COVID-19 Lockdowns in the Atlanta\n  Metropolitan Area","summary":"  This paper analyzes the impact of COVID-19 related lockdowns in the Atlanta,\nGeorgia metropolitan area by examining commuter patterns in three periods:\nprior to, during, and after the pandemic lockdown. A cellular phone location\ndataset is utilized in a novel pipeline to infer the home and work locations of\nthousands of users from the Density-based Spatial Clustering of Applications\nwith Noise (DBSCAN) algorithm. The coordinates derived from the clustering are\nput through a reverse geocoding process from which word embeddings are\nextracted in order to categorize the industry of each work place based on the\nworkplace name and Point of Interest (POI) mapping. Frequencies of commute from\nhome locations to work locations are analyzed in and across all three time\nperiods. Public health and economic factors are discussed to explain potential\nreasons for the observed changes in commuter patterns.\n","authors":["Tejas Santanam","Anthony Trasatti","Hanyu Zhang","Connor Riley","Pascal Van Hentenryck","Ramayya Krishnan"],"pdf_url":"https://arxiv.org/pdf/2302.13512v1.pdf","comment":"7 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2209.09991v2","updated":"2023-02-27T04:19:35Z","published":"2022-09-20T20:48:52Z","title":"Optimizing Crop Management with Reinforcement Learning and Imitation\n  Learning","summary":"  Crop management, including nitrogen (N) fertilization and irrigation\nmanagement, has a significant impact on the crop yield, economic profit, and\nthe environment. Although management guidelines exist, it is challenging to\nfind the optimal management practices given a specific planting environment and\na crop. Previous work used reinforcement learning (RL) and crop simulators to\nsolve the problem, but the trained policies either have limited performance or\nare not deployable in the real world. In this paper, we present an intelligent\ncrop management system which optimizes the N fertilization and irrigation\nsimultaneously via RL, imitation learning (IL), and crop simulations using the\nDecision Support System for Agrotechnology Transfer (DSSAT). We first use deep\nRL, in particular, deep Q-network, to train management policies that require\nall state information from the simulator as observations (denoted as full\nobservation). We then invoke IL to train management policies that only need a\nlimited amount of state information that can be readily obtained in the real\nworld (denoted as partial observation) by mimicking the actions of the\npreviously RL-trained policies under full observation. We conduct experiments\non a case study using maize in Florida and compare trained policies with a\nmaize management guideline in simulations. Our trained policies under both full\nand partial observations achieve better outcomes, resulting in a higher profit\nor a similar profit with a smaller environmental impact. Moreover, the\npartial-observation management policies are directly deployable in the real\nworld as they use readily available information.\n","authors":["Ran Tao","Pan Zhao","Jing Wu","Nicolas F. Martin","Matthew T. Harrison","Carla Ferreira","Zahra Kalantari","Naira Hovakimyan"],"pdf_url":"https://arxiv.org/pdf/2209.09991v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00195v4","updated":"2023-02-27T04:17:11Z","published":"2022-09-01T03:27:33Z","title":"To Store or Not? Online Data Selection for Federated Learning with\n  Limited Storage","summary":"  Machine learning models have been deployed in mobile networks to deal with\nmassive data from different layers to enable automated network management and\nintelligence on devices. To overcome high communication cost and severe privacy\nconcerns of centralized machine learning, federated learning (FL) has been\nproposed to achieve distributed machine learning among networked devices. While\nthe computation and communication limitation has been widely studied, the\nimpact of on-device storage on the performance of FL is still not explored.\nWithout an effective data selection policy to filter the massive streaming data\non devices, classical FL can suffer from much longer model training time\n($4\\times$) and significant inference accuracy reduction ($7\\%$), observed in\nour experiments. In this work, we take the first step to consider the online\ndata selection for FL with limited on-device storage. We first define a new\ndata valuation metric for data evaluation and selection in FL with theoretical\nguarantees for speeding up model convergence and enhancing final model\naccuracy, simultaneously. We further design {\\ttfamily ODE}, a framework of\n\\textbf{O}nline \\textbf{D}ata s\\textbf{E}lection for FL, to coordinate\nnetworked devices to store valuable data samples. Experimental results on one\nindustrial dataset and three public datasets show the remarkable advantages of\n{\\ttfamily ODE} over the state-of-the-art approaches. Particularly, on the\nindustrial dataset, {\\ttfamily ODE} achieves as high as $2.5\\times$ speedup of\ntraining time and $6\\%$ increase in inference accuracy, and is robust to\nvarious factors in practical environments.\n","authors":["Chen Gong","Zhenzhe Zheng","Yunfeng Shao","Bingshuai Li","Fan Wu","Guihai Chen"],"pdf_url":"https://arxiv.org/pdf/2209.00195v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13507v1","updated":"2023-02-27T04:06:17Z","published":"2023-02-27T04:06:17Z","title":"Active Reward Learning from Online Preferences","summary":"  Robot policies need to adapt to human preferences and/or new environments.\nHuman experts may have the domain knowledge required to help robots achieve\nthis adaptation. However, existing works often require costly offline\nre-training on human feedback, and those feedback usually need to be frequent\nand too complex for the humans to reliably provide. To avoid placing undue\nburden on human experts and allow quick adaptation in critical real-world\nsituations, we propose designing and sparingly presenting easy-to-answer\npairwise action preference queries in an online fashion. Our approach designs\nqueries and determines when to present them to maximize the expected value\nderived from the queries' information. We demonstrate our approach with\nexperiments in simulation, human user studies, and real robot experiments. In\nthese settings, our approach outperforms baseline techniques while presenting\nfewer queries to human experts. Experiment videos, code and appendices are\nfound at https://sites.google.com/view/onlineactivepreferences.\n","authors":["Vivek Myers","Erdem Bıyık","Dorsa Sadigh"],"pdf_url":"https://arxiv.org/pdf/2302.13507v1.pdf","comment":"11 pages, 8 figures, 1 table. Published in the 2023 IEEE\n  International Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2108.03712v4","updated":"2023-02-27T04:01:34Z","published":"2021-08-08T19:11:41Z","title":"Generalizing Dynamic Mode Decomposition: Balancing Accuracy and\n  Expressiveness in Koopman Approximations","summary":"  This paper tackles the data-driven approximation of unknown dynamical systems\nusing Koopman-operator methods. Given a dictionary of functions, these methods\napproximate the projection of the action of the operator on the\nfinite-dimensional subspace spanned by the dictionary. We propose the Tunable\nSymmetric Subspace Decomposition algorithm to refine the dictionary, balancing\nits expressiveness and accuracy. Expressiveness corresponds to the ability of\nthe dictionary to describe the evolution of as many observables as possible and\naccuracy corresponds to the ability to correctly predict their evolution. Based\non the observation that Koopman-invariant subspaces give rise to exact\npredictions, we reason that prediction accuracy is a function of the degree of\ninvariance of the subspace generated by the dictionary and provide a\ndata-driven measure to measure invariance proximity. The proposed algorithm\niteratively prunes the initial functional space to identify a refined\ndictionary of functions that satisfies the desired level of accuracy while\nretaining as much of the original expressiveness as possible. We provide a full\ncharacterization of the algorithm properties and show that it generalizes both\nExtended Dynamic Mode Decomposition and Symmetric Subspace Decomposition.\nSimulations on planar systems show the effectiveness of the proposed methods in\nproducing Koopman approximations of tunable accuracy that capture relevant\ninformation about the dynamical system.\n","authors":["Masih Haseli","Jorge Cortés"],"pdf_url":"https://arxiv.org/pdf/2108.03712v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.08802v3","updated":"2023-02-27T03:46:44Z","published":"2021-12-16T11:39:21Z","title":"UNIREX: A Unified Learning Framework for Language Model Rationale\n  Extraction","summary":"  An extractive rationale explains a language model's (LM's) prediction on a\ngiven task instance by highlighting the text inputs that most influenced the\nprediction. Ideally, rationale extraction should be faithful (reflective of\nLM's actual behavior) and plausible (convincing to humans), without\ncompromising the LM's (i.e., task model's) task performance. Although\nattribution algorithms and select-predict pipelines are commonly used in\nrationale extraction, they both rely on certain heuristics that hinder them\nfrom satisfying all three desiderata. In light of this, we propose UNIREX, a\nflexible learning framework that generalizes rationale extractor optimization\nas follows: (1) specify architecture for a learned rationale extractor; (2)\nselect explainability objectives (i.e., faithfulness and plausibility\ncriteria); and (3) jointly the train task model and rationale extractor on the\ntask using the selected objectives. UNIREX enables replacing prior works'\nheuristic design choices with a generic learned rationale extractor in (1) and\noptimizing it for all three desiderata in (2)-(3). To facilitate comparison\nbetween methods with respect to multiple desiderata, we introduce the\nNormalized Relative Gain (NRG) metric. Across five text classification\ndatasets, our best UNIREX configuration outperforms baselines by an average of\n32.9% NRG. Plus, we find that UNIREX-trained rationale extractors can even\ngeneralize to unseen datasets and tasks.\n","authors":["Aaron Chan","Maziar Sanjabi","Lambert Mathias","Liang Tan","Shaoliang Nie","Xiaochang Peng","Xiang Ren","Hamed Firooz"],"pdf_url":"https://arxiv.org/pdf/2112.08802v3.pdf","comment":"ICML 2022"},{"id":"http://arxiv.org/abs/2202.00519v2","updated":"2023-02-27T03:43:40Z","published":"2022-02-01T16:11:21Z","title":"MotifExplainer: a Motif-based Graph Neural Network Explainer","summary":"  We consider the explanation problem of Graph Neural Networks (GNNs). Most\nexisting GNN explanation methods identify the most important edges or nodes but\nfail to consider substructures, which are more important for graph data. The\nonly method that considers subgraphs tries to search all possible subgraphs and\nidentify the most significant subgraphs. However, the subgraphs identified may\nnot be recurrent or statistically important. In this work, we propose a novel\nmethod, known as MotifExplainer, to explain GNNs by identifying important\nmotifs, recurrent and statistically significant patterns in graphs. Our\nproposed motif-based methods can provide better human-understandable\nexplanations than methods based on nodes, edges, and regular subgraphs. Given\nan input graph and a pre-trained GNN model, our method first extracts motifs in\nthe graph using well-designed motif extraction rules. Then we generate motif\nembedding by feeding motifs into the pre-trained GNN. Finally, we employ an\nattention-based method to identify the most influential motifs as explanations\nfor the final prediction results. The empirical studies on both synthetic and\nreal-world datasets demonstrate the effectiveness of our method.\n","authors":["Zhaoning Yu","Hongyang Gao"],"pdf_url":"https://arxiv.org/pdf/2202.00519v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05650v2","updated":"2023-02-27T03:43:31Z","published":"2023-02-11T10:50:33Z","title":"SLOTH: Structured Learning and Task-based Optimization for Time Series\n  Forecasting on Hierarchies","summary":"  Multivariate time series forecasting with hierarchical structure is widely\nused in real-world applications, e.g., sales predictions for the geographical\nhierarchy formed by cities, states, and countries. The hierarchical time series\n(HTS) forecasting includes two sub-tasks, i.e., forecasting and reconciliation.\nIn the previous works, hierarchical information is only integrated in the\nreconciliation step to maintain coherency, but not in forecasting step for\naccuracy improvement. In this paper, we propose two novel tree-based feature\nintegration mechanisms, i.e., top-down convolution and bottom-up attention to\nleverage the information of the hierarchical structure to improve the\nforecasting performance. Moreover, unlike most previous reconciliation methods\nwhich either rely on strong assumptions or focus on coherent constraints\nonly,we utilize deep neural optimization networks, which not only achieve\ncoherency without any assumptions, but also allow more flexible and realistic\nconstraints to achieve task-based targets, e.g., lower under-estimation penalty\nand meaningful decision-making loss to facilitate the subsequent downstream\ntasks. Experiments on real-world datasets demonstrate that our tree-based\nfeature integration mechanism achieves superior performances on hierarchical\nforecasting tasks compared to the state-of-the-art methods, and our neural\noptimization networks can be applied to real-world tasks effectively without\nany additional effort under coherence and task-based constraints\n","authors":["Fan Zhou","Chen Pan","Lintao Ma","Yu Liu","Shiyu Wang","James Zhang","Xinxin Zhu","Xuanwei Hu","Yunhua Hu","Yangfei Zheng","Lei Lei","Yun Hu"],"pdf_url":"https://arxiv.org/pdf/2302.05650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13493v1","updated":"2023-02-27T03:35:02Z","published":"2023-02-27T03:35:02Z","title":"The Provable Benefits of Unsupervised Data Sharing for Offline\n  Reinforcement Learning","summary":"  Self-supervised methods have become crucial for advancing deep learning by\nleveraging data itself to reduce the need for expensive annotations. However,\nthe question of how to conduct self-supervised offline reinforcement learning\n(RL) in a principled way remains unclear. In this paper, we address this issue\nby investigating the theoretical benefits of utilizing reward-free data in\nlinear Markov Decision Processes (MDPs) within a semi-supervised setting.\n  Further, we propose a novel, Provable Data Sharing algorithm (PDS) to utilize\nsuch reward-free data for offline RL. PDS uses additional penalties on the\nreward function learned from labeled data to prevent overestimation, ensuring a\nconservative algorithm. Our results on various offline RL tasks demonstrate\nthat PDS significantly improves the performance of offline RL algorithms with\nreward-free data. Overall, our work provides a promising approach to leveraging\nthe benefits of unlabeled data in offline RL while maintaining theoretical\nguarantees. We believe our findings will contribute to developing more robust\nself-supervised RL methods.\n","authors":["Hao Hu","Yiqin Yang","Qianchuan Zhao","Chongjie Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13493v1.pdf","comment":"Eleventh International Conference on Learning Representations (ICLR),\n  2023"},{"id":"http://arxiv.org/abs/2210.03221v5","updated":"2023-02-27T03:29:28Z","published":"2022-10-06T21:29:17Z","title":"PQLM -- Multilingual Decentralized Portable Quantum Language Model for\n  Privacy Protection","summary":"  With careful manipulation, malicious agents can reverse engineer private\ninformation encoded in pre-trained language models. Security concerns motivate\nthe development of quantum pre-training. In this work, we propose a highly\nPortable Quantum Language Model (PQLM) that can easily transmit information to\ndownstream tasks on classical machines. The framework consists of a cloud PQLM\nbuilt with random Variational Quantum Classifiers (VQC) and local models for\ndownstream applications. We demonstrate the ad hoc portability of the quantum\nmodel by extracting only the word embeddings and effectively applying them to\ndownstream tasks on classical machines. Our PQLM exhibits comparable\nperformance to its classical counterpart on both intrinsic evaluation (loss,\nperplexity) and extrinsic evaluation (multilingual sentiment analysis accuracy)\nmetrics. We also perform ablation studies on the factors affecting PQLM\nperformance to analyze model stability. Our work establishes a theoretical\nfoundation for a portable quantum pre-trained language model that could be\ntrained on private data and made available for public use with privacy\nprotection guarantees.\n","authors":["Shuyue Stella Li","Xiangyu Zhang","Shu Zhou","Hongchao Shu","Ruixing Liang","Hexin Liu","Leibny Paola Garcia"],"pdf_url":"https://arxiv.org/pdf/2210.03221v5.pdf","comment":"5 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2110.08419v2","updated":"2023-02-27T03:14:07Z","published":"2021-10-16T00:20:04Z","title":"Robustness Challenges in Model Distillation and Pruning for Natural\n  Language Understanding","summary":"  Recent work has focused on compressing pre-trained language models (PLMs)\nlike BERT where the major focus has been to improve the in-distribution\nperformance for downstream tasks. However, very few of these studies have\nanalyzed the impact of compression on the generalizability and robustness of\ncompressed models for out-of-distribution (OOD) data. Towards this end, we\nstudy two popular model compression techniques including knowledge distillation\nand pruning and show that the compressed models are significantly less robust\nthan their PLM counterparts on OOD test sets although they obtain similar\nperformance on in-distribution development sets for a task. Further analysis\nindicates that the compressed models overfit on the shortcut samples and\ngeneralize poorly on the hard ones. We further leverage this observation to\ndevelop a regularization strategy for robust model compression based on sample\nuncertainty. Experimental results on several natural language understanding\ntasks demonstrate that our bias mitigation framework improves the OOD\ngeneralization of the compressed models, while not sacrificing the\nin-distribution task performance.\n","authors":["Mengnan Du","Subhabrata Mukherjee","Yu Cheng","Milad Shokouhi","Xia Hu","Ahmed Hassan Awadallah"],"pdf_url":"https://arxiv.org/pdf/2110.08419v2.pdf","comment":"Accepted by EACL 2023"},{"id":"http://arxiv.org/abs/2301.00944v2","updated":"2023-02-27T03:08:38Z","published":"2023-01-03T04:09:38Z","title":"Temporal Difference Learning with Compressed Updates: Error-Feedback\n  meets Reinforcement Learning","summary":"  In large-scale machine learning, recent works have studied the effects of\ncompressing gradients in stochastic optimization in order to alleviate the\ncommunication bottleneck. These works have collectively revealed that\nstochastic gradient descent (SGD) is robust to structured perturbations such as\nquantization, sparsification, and delays. Perhaps surprisingly, despite the\nsurge of interest in large-scale, multi-agent reinforcement learning, almost\nnothing is known about the analogous question: Are common reinforcement\nlearning (RL) algorithms also robust to similar perturbations? In this paper,\nwe investigate this question by studying a variant of the classical temporal\ndifference (TD) learning algorithm with a perturbed update direction, where a\ngeneral compression operator is used to model the perturbation. Our main\ntechnical contribution is to show that compressed TD algorithms, coupled with\nan error-feedback mechanism used widely in optimization, exhibit the same\nnon-asymptotic theoretical guarantees as their SGD counterparts. We then extend\nour results significantly to nonlinear stochastic approximation algorithms and\nmulti-agent settings. In particular, we prove that for multi-agent TD learning,\none can achieve linear convergence speedups in the number of agents while\ncommunicating just $\\tilde{O}(1)$ bits per agent at each time step. Our work is\nthe first to provide finite-time results in RL that account for general\ncompression operators and error-feedback in tandem with linear function\napproximation and Markovian sampling. Our analysis hinges on studying the drift\nof a novel Lyapunov function that captures the dynamics of a memory variable\nintroduced by error feedback.\n","authors":["Aritra Mitra","George J. Pappas","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2301.00944v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12692v2","updated":"2023-02-27T02:55:39Z","published":"2023-02-24T15:35:36Z","title":"Language Models are Few-shot Learners for Prognostic Prediction","summary":"  Clinical prediction is an essential task in the healthcare industry. However,\nthe recent success of transformers, on which large language models are built,\nhas not been extended to this domain. In this research, we explore the use of\ntransformers and language models in prognostic prediction for immunotherapy\nusing real-world patients' clinical data and molecular profiles. This paper\ninvestigates the potential of transformers to improve clinical prediction\ncompared to conventional machine learning approaches and addresses the\nchallenge of few-shot learning in predicting rare disease areas. The study\nbenchmarks the efficacy of baselines and language models on prognostic\nprediction across multiple cancer types and investigates the impact of\ndifferent pretrained language models under few-shot regimes. The results\ndemonstrate significant improvements in accuracy and highlight the potential of\nNLP in clinical research to improve early detection and intervention for\ndifferent diseases. Anonymous codes are available at\n\\url{https://anonymous.4open.science/r/table2text-88ED}.\n","authors":["Zekai Chen","Mariann Micsinai Balan","Kevin Brown"],"pdf_url":"https://arxiv.org/pdf/2302.12692v2.pdf","comment":"7 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2302.12304v2","updated":"2023-02-27T02:49:51Z","published":"2023-02-23T19:59:24Z","title":"Uncertainty Injection: A Deep Learning Method for Robust Optimization","summary":"  This paper proposes a paradigm of uncertainty injection for training deep\nlearning model to solve robust optimization problems. The majority of existing\nstudies on deep learning focus on the model learning capability, while assuming\nthe quality and accuracy of the inputs data can be guaranteed. However, in\nrealistic applications of deep learning for solving optimization problems, the\naccuracy of inputs, which are the problem parameters in this case, plays a\nlarge role. This is because, in many situations, it is often costly or sometime\nimpossible to obtain the problem parameters accurately, and correspondingly, it\nis highly desirable to develop learning algorithms that can account for the\nuncertainties in the input and produce solutions that are robust against these\nuncertainties. This paper presents a novel uncertainty injection scheme for\ntraining machine learning models that are capable of implicitly accounting for\nthe uncertainties and producing statistically robust solutions. We further\nidentify the wireless communications as an application field where\nuncertainties are prevalent in problem parameters such as the channel\ncoefficients. We show the effectiveness of the proposed training scheme in two\napplications: the robust power loading for multiuser\nmultiple-input-multiple-output (MIMO) downlink transmissions; and the robust\npower control for device-to-device (D2D) networks.\n","authors":["Wei Cui","Wei Yu"],"pdf_url":"https://arxiv.org/pdf/2302.12304v2.pdf","comment":"13 pages, 7 figures. To appear in IEEE Transactions on Wireless\n  Communications"},{"id":"http://arxiv.org/abs/2302.13485v1","updated":"2023-02-27T02:49:06Z","published":"2023-02-27T02:49:06Z","title":"FedCLIP: Fast Generalization and Personalization for CLIP in Federated\n  Learning","summary":"  Federated learning (FL) has emerged as a new paradigm for privacy-preserving\ncomputation in recent years. Unfortunately, FL faces two critical challenges\nthat hinder its actual performance: data distribution heterogeneity and high\nresource costs brought by large foundation models. Specifically, the non-IID\ndata in different clients make existing FL algorithms hard to converge while\nthe high resource costs, including computational and communication costs that\nincrease the deployment difficulty in real-world scenarios. In this paper, we\npropose an effective yet simple method, named FedCLIP, to achieve fast\ngeneralization and personalization for CLIP in federated learning. Concretely,\nwe design an attention-based adapter for the large model, CLIP, and the rest\noperations merely depend on adapters. Lightweight adapters can make the most\nuse of pretrained model information and ensure models be adaptive for clients\nin specific tasks. Simultaneously, small-scale operations can mitigate the\ncomputational burden and communication burden caused by large models. Extensive\nexperiments are conducted on three datasets with distribution shifts.\nQualitative and quantitative results demonstrate that FedCLIP significantly\noutperforms other baselines (9% overall improvements on PACS) and effectively\nreduces computational and communication costs (283x faster than FedAVG). Our\ncode will be available at: https://github.com/microsoft/PersonalizedFL.\n","authors":["Wang Lu","Xixu Hu","Jindong Wang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2302.13485v1.pdf","comment":"Technical report; code is at:\n  https://github.com/microsoft/PersonalizedFL"},{"id":"http://arxiv.org/abs/2302.13483v1","updated":"2023-02-27T02:42:27Z","published":"2023-02-27T02:42:27Z","title":"CrystalBox: Future-Based Explanations for DRL Network Controllers","summary":"  Lack of explainability is a key factor limiting the practical adoption of\nhigh-performant Deep Reinforcement Learning (DRL) controllers. Explainable RL\nfor networking hitherto used salient input features to interpret a controller's\nbehavior. However, these feature-based solutions do not completely explain the\ncontroller's decision-making process. Often, operators are interested in\nunderstanding the impact of a controller's actions on performance in the\nfuture, which feature-based solutions cannot capture.\n  In this paper, we present CrystalBox, a framework that explains a\ncontroller's behavior in terms of the future impact on key network performance\nmetrics. CrystalBox employs a novel learning-based approach to generate\nsuccinct and expressive explanations. We use reward components of the DRL\nnetwork controller, which are key performance metrics meaningful to operators,\nas the basis for explanations. CrystalBox is generalizable and can work across\nboth discrete and continuous control environments without any changes to the\ncontroller or the DRL workflow. Using adaptive bitrate streaming and congestion\ncontrol, we demonstrate CrytalBox's ability to generate high-fidelity\nfuture-based explanations. We additionally present three practical use cases of\nCrystalBox: cross-state explainability, guided reward design, and network\nobservability.\n","authors":["Sagar Patel","Sangeetha Abdu Jyothi","Nina Narodytska"],"pdf_url":"https://arxiv.org/pdf/2302.13483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10230v2","updated":"2023-02-27T02:30:19Z","published":"2023-01-24T18:54:29Z","title":"Double Matching Under Complementary Preferences","summary":"  In this paper, we propose a new algorithm for addressing the problem of\nmatching markets with complementary preferences, where agents' preferences are\nunknown a priori and must be learned from data. The presence of complementary\npreferences can lead to instability in the matching process, making this\nproblem challenging to solve. To overcome this challenge, we formulate the\nproblem as a bandit learning framework and propose the Multi-agent Multi-type\nThompson Sampling (MMTS) algorithm. The algorithm combines the strengths of\nThompson Sampling for exploration with a double matching technique to achieve a\nstable matching outcome. Our theoretical analysis demonstrates the\neffectiveness of MMTS as it is able to achieve stability at every matching\nstep, satisfies the incentive-compatibility property, and has a sublinear\nBayesian regret over time. Our approach provides a useful method for addressing\ncomplementary preferences in real-world scenarios.\n","authors":["Yuantong Li","Guang Cheng","Xiaowu Dai"],"pdf_url":"https://arxiv.org/pdf/2301.10230v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.04853v5","updated":"2023-02-27T02:23:00Z","published":"2022-04-11T03:32:17Z","title":"Neural Lagrangian Schrödinger Bridge: Diffusion Modeling for\n  Population Dynamics","summary":"  Population dynamics is the study of temporal and spatial variation in the\nsize of populations of organisms and is a major part of population ecology. One\nof the main difficulties in analyzing population dynamics is that we can only\nobtain observation data with coarse time intervals from fixed-point\nobservations due to experimental costs or measurement constraints. Recently,\nmodeling population dynamics by using continuous normalizing flows (CNFs) and\ndynamic optimal transport has been proposed to infer the sample trajectories\nfrom a fixed-point observed population. While the sample behavior in CNFs is\ndeterministic, the actual sample in biological systems moves in an essentially\nrandom yet directional manner. Moreover, when a sample moves from point A to\npoint B in dynamical systems, its trajectory typically follows the principle of\nleast action in which the corresponding action has the smallest possible value.\nTo satisfy these requirements of the sample trajectories, we formulate the\nLagrangian Schr\\\"odinger bridge (LSB) problem and propose to solve it\napproximately by modeling the advection-diffusion process with regularized\nneural SDE. We also develop a model architecture that enables faster\ncomputation of the loss function. Experimental results show that the proposed\nmethod can efficiently approximate the population-level dynamics even for\nhigh-dimensional data and that using the prior knowledge introduced by the\nLagrangian enables us to estimate the sample-level dynamics with stochastic\nbehavior.\n","authors":["Takeshi Koshizuka","Issei Sato"],"pdf_url":"https://arxiv.org/pdf/2204.04853v5.pdf","comment":"Published at ICLR 2023 (notable top 25%)"},{"id":"http://arxiv.org/abs/2209.14687v3","updated":"2023-02-27T02:17:13Z","published":"2022-09-29T11:12:27Z","title":"Diffusion Posterior Sampling for General Noisy Inverse Problems","summary":"  Diffusion models have been recently studied as powerful generative inverse\nproblem solvers, owing to their high quality reconstructions and the ease of\ncombining existing iterative solvers. However, most works focus on solving\nsimple linear inverse problems in noiseless settings, which significantly\nunder-represents the complexity of real-world problems. In this work, we extend\ndiffusion solvers to efficiently handle general noisy (non)linear inverse\nproblems via approximation of the posterior sampling. Interestingly, the\nresulting posterior sampling scheme is a blended version of diffusion sampling\nwith the manifold constrained gradient without a strict measurement consistency\nprojection step, yielding a more desirable generative path in noisy settings\ncompared to the previous studies. Our method demonstrates that diffusion models\ncan incorporate various measurement noise statistics such as Gaussian and\nPoisson, and also efficiently handle noisy nonlinear inverse problems such as\nFourier phase retrieval and non-uniform deblurring. Code available at\nhttps://github.com/DPS2022/diffusion-posterior-sampling\n","authors":["Hyungjin Chung","Jeongsol Kim","Michael T. Mccann","Marc L. Klasky","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2209.14687v3.pdf","comment":"ICLR 2023 spotlight"},{"id":"http://arxiv.org/abs/2302.12095v2","updated":"2023-02-27T02:13:38Z","published":"2023-02-22T11:01:20Z","title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution\n  Perspective","summary":"  ChatGPT is a recent chatbot service released by OpenAI and is receiving\nincreasing attention over the past few months. While evaluations of various\naspects of ChatGPT have been done, its robustness, i.e., the performance to\nunexpected inputs, is still unclear to the public. Robustness is of particular\nconcern in responsible AI, especially for safety-critical applications. In this\npaper, we conduct a thorough evaluation of the robustness of ChatGPT from the\nadversarial and out-of-distribution (OOD) perspective. To do so, we employ the\nAdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart\nreview and DDXPlus medical diagnosis datasets for OOD evaluation. We select\nseveral popular foundation models as baselines. Results show that ChatGPT shows\nconsistent advantages on most adversarial and OOD classification and\ntranslation tasks. However, the absolute performance is far from perfection,\nwhich suggests that adversarial and OOD robustness remains a significant threat\nto foundation models. Moreover, ChatGPT shows astounding performance in\nunderstanding dialogue-related texts and we find that it tends to provide\ninformal suggestions for medical tasks instead of definitive answers. Finally,\nwe present in-depth discussions of possible research directions.\n","authors":["Jindong Wang","Xixu Hu","Wenxin Hou","Hao Chen","Runkai Zheng","Yidong Wang","Linyi Yang","Haojun Huang","Wei Ye","Xiubo Geng","Binxin Jiao","Yue Zhang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2302.12095v2.pdf","comment":"Ongoing work; code is at: https://github.com/microsoft/robustlearn"},{"id":"http://arxiv.org/abs/2302.13473v1","updated":"2023-02-27T02:06:18Z","published":"2023-02-27T02:06:18Z","title":"Towards Interpretable Federated Learning","summary":"  Federated learning (FL) enables multiple data owners to build machine\nlearning models collaboratively without exposing their private local data. In\norder for FL to achieve widespread adoption, it is important to balance the\nneed for performance, privacy-preservation and interpretability, especially in\nmission critical applications such as finance and healthcare. Thus,\ninterpretable federated learning (IFL) has become an emerging topic of research\nattracting significant interest from the academia and the industry alike. Its\ninterdisciplinary nature can be challenging for new researchers to pick up. In\nthis paper, we bridge this gap by providing (to the best of our knowledge) the\nfirst survey on IFL. We propose a unique IFL taxonomy which covers relevant\nworks enabling FL models to explain the prediction results, support model\ndebugging, and provide insights into the contributions made by individual data\nowners or data samples, which in turn, is crucial for allocating rewards fairly\nto motivate active and reliable participation in FL. We conduct comprehensive\nanalysis of the representative IFL approaches, the commonly adopted performance\nevaluation metrics, and promising directions towards building versatile IFL\ntechniques.\n","authors":["Anran Li","Rui Liu","Ming Hu","Luu Anh Tuan","Han Yu"],"pdf_url":"https://arxiv.org/pdf/2302.13473v1.pdf","comment":"Survey of interpretable federated learning"},{"id":"http://arxiv.org/abs/2302.13464v1","updated":"2023-02-27T01:33:31Z","published":"2023-02-27T01:33:31Z","title":"Randomness in ML Defenses Helps Persistent Attackers and Hinders\n  Evaluators","summary":"  It is becoming increasingly imperative to design robust ML defenses. However,\nrecent work has found that many defenses that initially resist state-of-the-art\nattacks can be broken by an adaptive adversary. In this work we take steps to\nsimplify the design of defenses and argue that white-box defenses should eschew\nrandomness when possible. We begin by illustrating a new issue with the\ndeployment of randomized defenses that reduces their security compared to their\ndeterministic counterparts. We then provide evidence that making defenses\ndeterministic simplifies robustness evaluation, without reducing the\neffectiveness of a truly robust defense. Finally, we introduce a new defense\nevaluation framework that leverages a defense's deterministic nature to better\nevaluate its adversarial robustness.\n","authors":["Keane Lucas","Matthew Jagielski","Florian Tramèr","Lujo Bauer","Nicholas Carlini"],"pdf_url":"https://arxiv.org/pdf/2302.13464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.13999v3","updated":"2023-02-27T01:24:00Z","published":"2020-06-24T19:01:05Z","title":"MCAL: Minimum Cost Human-Machine Active Labeling","summary":"  Today, ground-truth generation uses data sets annotated by cloud-based\nannotation services. These services rely on human annotation, which can be\nprohibitively expensive. In this paper, we consider the problem of hybrid\nhuman-machine labeling, which trains a classifier to accurately auto-label part\nof the data set. However, training the classifier can be expensive too. We\npropose an iterative approach that minimizes total overall cost by, at each\nstep, jointly determining which samples to label using humans and which to\nlabel using the trained classifier. We validate our approach on well known\npublic data sets such as Fashion-MNIST, CIFAR-10, CIFAR-100, and ImageNet. In\nsome cases, our approach has 6x lower overall cost relative to human labeling\nthe entire data set, and is always cheaper than the cheapest competing\nstrategy.\n","authors":["Hang Qiu","Krishna Chintalapudi","Ramesh Govindan"],"pdf_url":"https://arxiv.org/pdf/2006.13999v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2112.09355v2","updated":"2023-02-27T01:18:26Z","published":"2021-12-17T07:26:31Z","title":"From Deterioration to Acceleration: A Calibration Approach to\n  Rehabilitating Step Asynchronism in Federated Optimization","summary":"  In the setting of federated optimization, where a global model is aggregated\nperiodically, step asynchronism occurs when participants conduct model training\nby efficiently utilizing their computational resources. It is well acknowledged\nthat step asynchronism leads to objective inconsistency under non-i.i.d. data,\nwhich degrades the model's accuracy. To address this issue, we propose a new\nalgorithm FedaGrac, which calibrates the local direction to a predictive global\norientation. Taking advantage of the estimated orientation, we guarantee that\nthe aggregated model does not excessively deviate from the global optimum while\nfully utilizing the local updates of faster nodes. We theoretically prove that\nFedaGrac holds an improved order of convergence rate than the state-of-the-art\napproaches and eliminates the negative effect of step asynchronism. Empirical\nresults show that our algorithm accelerates the training and enhances the final\naccuracy.\n","authors":["Feijie Wu","Song Guo","Haozhao Wang","Zhihao Qu","Haobo Zhang","Jie Zhang","Ziming Liu"],"pdf_url":"https://arxiv.org/pdf/2112.09355v2.pdf","comment":"Accepted by IEEE Transactions on Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2302.13457v1","updated":"2023-02-27T01:05:17Z","published":"2023-02-27T01:05:17Z","title":"A Self-Supervised Learning-based Approach to Clustering Multivariate\n  Time-Series Data with Missing Values (SLAC-Time): An Application to Traumatic\n  Brain Injury Phenotyping","summary":"  Self-supervised learning approaches provide a promising direction for\nclustering multivariate time-series data. However, real-world time-series data\noften include missing values, and the existing approaches require imputing\nmissing values before clustering, which may cause extensive computations and\nnoise and result in invalid interpretations. To address these challenges, we\npresent a Self-supervised Learning-based Approach to Clustering multivariate\nTime-series data with missing values (SLAC-Time). SLAC-Time is a\nTransformer-based clustering method that uses time-series forecasting as a\nproxy task for leveraging unlabeled data and learning more robust time-series\nrepresentations. This method jointly learns the neural network parameters and\nthe cluster assignments of the learned representations. It iteratively clusters\nthe learned representations with the K-means method and then utilizes the\nsubsequent cluster assignments as pseudo-labels to update the model parameters.\nTo evaluate our proposed approach, we applied it to clustering and phenotyping\nTraumatic Brain Injury (TBI) patients in the TRACK-TBI dataset. Our experiments\ndemonstrate that SLAC-Time outperforms the baseline K-means clustering\nalgorithm in terms of silhouette coefficient, Calinski Harabasz index, Dunn\nindex, and Davies Bouldin index. We identified three TBI phenotypes that are\ndistinct from one another in terms of clinically significant variables as well\nas clinical outcomes, including the Extended Glasgow Outcome Scale (GOSE)\nscore, Intensive Care Unit (ICU) length of stay, and mortality rate. The\nexperiments show that the TBI phenotypes identified by SLAC-Time can be\npotentially used for developing targeted clinical trials and therapeutic\nstrategies.\n","authors":["Hamid Ghaderi","Brandon Foreman","Amin Nayebi","Sindhu Tipirneni","Chandan K. Reddy","Vignesh Subbian"],"pdf_url":"https://arxiv.org/pdf/2302.13457v1.pdf","comment":"Submitted to the Journal of Biomedical Informatics"},{"id":"http://arxiv.org/abs/2302.13451v1","updated":"2023-02-27T00:44:22Z","published":"2023-02-27T00:44:22Z","title":"Low latency transformers for speech processing","summary":"  The transformer is a widely-used building block in modern neural networks.\nHowever, when applied to audio data, the transformer's acausal behaviour, which\nwe term Acausal Attention (AA), has generally limited its application to\noffline tasks. In this paper we introduce Streaming Attention (SA), which\noperates causally with fixed latency, and requires lower compute and memory\nresources than AA to train. Next, we introduce Low Latency Streaming Attention\n(LLSA), a method which combines multiple SA layers without latency build-up\nproportional to the layer count. Comparative analysis between AA, SA and LLSA\non Automatic Speech Recognition (ASR) and Speech Emotion Recognition (SER)\ntasks are presented. The results show that causal SA-based networks with fixed\nlatencies of a few seconds (e.g. 1.8 seconds) and LLSA networks with latencies\nas short as 300 ms can perform comparably with acausal (AA) networks. We\nconclude that SA and LLSA methods retain many of the benefits of conventional\nacausal transformers, but with latency characteristics that make them practical\nto run in real-time streaming applications.\n","authors":["Jianbo Ma","Siqi Pan","Deepak Chandran","Andrea Fanelli","Richard Cartwright"],"pdf_url":"https://arxiv.org/pdf/2302.13451v1.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.13447v1","updated":"2023-02-27T00:32:01Z","published":"2023-02-27T00:32:01Z","title":"Optimizing Federated Learning in LEO Satellite Constellations via\n  Intra-Plane Model Propagation and Sink Satellite Scheduling","summary":"  The advances in satellite technology developments have recently seen a large\nnumber of small satellites being launched into space on Low Earth orbit (LEO)\nto collect massive data such as Earth observational imagery. The traditional\nway which downloads such data to a ground station (GS) to train a machine\nlearning (ML) model is not desirable due to the bandwidth limitation and\nintermittent connectivity between LEO satellites and the GS. Satellite edge\ncomputing (SEC), on the other hand, allows each satellite to train an ML model\nonboard and uploads only the model to the GS which appears to be a promising\nconcept. This paper proposes FedLEO, a novel federated learning (FL) framework\nthat realizes the concept of SEC and overcomes the limitation (slow\nconvergence) of existing FL-based solutions. FedLEO (1) augments the\nconventional FL's star topology with ``horizontal'' intra-plane communication\npathways in which model propagation among satellites takes place; (2) optimally\nschedules communication between ``sink'' satellites and the GS by exploiting\nthe predictability of satellite orbiting patterns. We evaluate FedLEO\nextensively and benchmark it with the state of the art. Our results show that\nFedLEO drastically expedites FL convergence, without sacrificing -- in fact it\nconsiderably increases -- the model accuracy.\n","authors":["Mohamed Elmahallawy","Tie Luo"],"pdf_url":"https://arxiv.org/pdf/2302.13447v1.pdf","comment":"2023 IEEE International Conference on Communications (ICC 2023)"},{"id":"http://arxiv.org/abs/2302.13445v1","updated":"2023-02-27T00:30:01Z","published":"2023-02-27T00:30:01Z","title":"Dynamic Resource Allocation for Metaverse Applications with Deep\n  Reinforcement Learning","summary":"  This work proposes a novel framework to dynamically and effectively manage\nand allocate different types of resources for Metaverse applications, which are\nforecasted to demand massive resources of various types that have never been\nseen before. Specifically, by studying functions of Metaverse applications, we\nfirst propose an effective solution to divide applications into groups, namely\nMetaInstances, where common functions can be shared among applications to\nenhance resource usage efficiency. Then, to capture the real-time, dynamic, and\nuncertain characteristics of request arrival and application departure\nprocesses, we develop a semi-Markov decision process-based framework and\npropose an intelligent algorithm that can gradually learn the optimal admission\npolicy to maximize the revenue and resource usage efficiency for the Metaverse\nservice provider and at the same time enhance the Quality-of-Service for\nMetaverse users. Extensive simulation results show that our proposed approach\ncan achieve up to 120% greater revenue for the Metaverse service providers and\nup to 178.9% higher acceptance probability for Metaverse application requests\nthan those of other baselines.\n","authors":["Nam H. Chu","Diep N. Nguyen","Dinh Thai Hoang","Khoa T. Phan","Eryk Dutkiewicz","Dusit Niyato","Tao Shu"],"pdf_url":"https://arxiv.org/pdf/2302.13445v1.pdf","comment":"To be published in the Proceedings of the IEEE WCNC 2023"},{"id":"http://arxiv.org/abs/2104.05158v7","updated":"2023-02-27T00:21:53Z","published":"2021-04-12T02:15:55Z","title":"Software-Hardware Co-design for Fast and Scalable Training of Deep\n  Learning Recommendation Models","summary":"  Deep learning recommendation models (DLRMs) are used across many\nbusiness-critical services at Facebook and are the single largest AI\napplication in terms of infrastructure demand in its data-centers. In this\npaper we discuss the SW/HW co-designed solution for high-performance\ndistributed training of large-scale DLRMs. We introduce a high-performance\nscalable software stack based on PyTorch and pair it with the new evolution of\nZion platform, namely ZionEX. We demonstrate the capability to train very large\nDLRMs with up to 12 Trillion parameters and show that we can attain 40X speedup\nin terms of time to solution over previous systems. We achieve this by (i)\ndesigning the ZionEX platform with dedicated scale-out network, provisioned\nwith high bandwidth, optimal topology and efficient transport (ii) implementing\nan optimized PyTorch-based training stack supporting both model and data\nparallelism (iii) developing sharding algorithms capable of hierarchical\npartitioning of the embedding tables along row, column dimensions and load\nbalancing them across multiple workers; (iv) adding high-performance core\noperators while retaining flexibility to support optimizers with fully\ndeterministic updates (v) leveraging reduced precision communications,\nmulti-level memory hierarchy (HBM+DDR+SSD) and pipelining. Furthermore, we\ndevelop and briefly comment on distributed data ingestion and other supporting\nservices that are required for the robust and efficient end-to-end training in\nproduction environments.\n","authors":["Dheevatsa Mudigere","Yuchen Hao","Jianyu Huang","Zhihao Jia","Andrew Tulloch","Srinivas Sridharan","Xing Liu","Mustafa Ozdal","Jade Nie","Jongsoo Park","Liang Luo","Jie Amy Yang","Leon Gao","Dmytro Ivchenko","Aarti Basant","Yuxi Hu","Jiyan Yang","Ehsan K. Ardestani","Xiaodong Wang","Rakesh Komuravelli","Ching-Hsiang Chu","Serhat Yilmaz","Huayu Li","Jiyuan Qian","Zhuobo Feng","Yinbin Ma","Junjie Yang","Ellie Wen","Hong Li","Lin Yang","Chonglin Sun","Whitney Zhao","Dimitry Melts","Krishna Dhulipala","KR Kishore","Tyler Graf","Assaf Eisenman","Kiran Kumar Matam","Adi Gangidi","Guoqiang Jerry Chen","Manoj Krishnan","Avinash Nayak","Krishnakumar Nair","Bharath Muthiah","Mahmoud khorashadi","Pallab Bhattacharya","Petr Lapukhov","Maxim Naumov","Ajit Mathews","Lin Qiao","Mikhail Smelyanskiy","Bill Jia","Vijay Rao"],"pdf_url":"https://arxiv.org/pdf/2104.05158v7.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.13668v1","updated":"2023-02-27T11:09:13Z","published":"2023-02-27T11:09:13Z","title":"Contrastive Video Question Answering via Video Graph Transformer","summary":"  We propose to perform video question answering (VideoQA) in a Contrastive\nmanner via a Video Graph Transformer model (CoVGT). CoVGT's uniqueness and\nsuperiority are three-fold: 1) It proposes a dynamic graph transformer module\nwhich encodes video by explicitly capturing the visual objects, their relations\nand dynamics, for complex spatio-temporal reasoning. 2) It designs separate\nvideo and text transformers for contrastive learning between the video and text\nto perform QA, instead of multi-modal transformer for answer classification.\nFine-grained video-text communication is done by additional cross-modal\ninteraction modules. 3) It is optimized by the joint fully- and self-supervised\ncontrastive objectives between the correct and incorrect answers, as well as\nthe relevant and irrelevant questions respectively. With superior video\nencoding and QA solution, we show that CoVGT can achieve much better\nperformances than previous arts on video reasoning tasks. Its performances even\nsurpass those models that are pretrained with millions of external data. We\nfurther show that CoVGT can also benefit from cross-modal pretraining, yet with\norders of magnitude smaller data. The results demonstrate the effectiveness and\nsuperiority of CoVGT, and additionally reveal its potential for more\ndata-efficient pretraining. We hope our success can advance VideoQA beyond\ncoarse recognition/description towards fine-grained relation reasoning of video\ncontents. Our code will be available at https://github.com/doc-doc/CoVGT.\n","authors":["Junbin Xiao","Pan Zhou","Angela Yao","Yicong Li","Richang Hong","Shuicheng Yan","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2302.13668v1.pdf","comment":"Manuscript was submitted for reviewing at IEEE T-PAMI on 11 Oct.\n  2022. This version is with small modification"},{"id":"http://arxiv.org/abs/2302.13469v1","updated":"2023-02-27T01:46:57Z","published":"2023-02-27T01:46:57Z","title":"Memory-augmented Contrastive Learning for Talking Head Generation","summary":"  Given one reference facial image and a piece of speech as input, talking head\ngeneration aims to synthesize a realistic-looking talking head video. However,\ngenerating a lip-synchronized video with natural head movements is challenging.\nThe same speech clip can generate multiple possible lip and head movements,\nthat is, there is no one-to-one mapping relationship between them. To overcome\nthis problem, we propose a Speech Feature Extractor (SFE) based on\nmemory-augmented self-supervised contrastive learning, which introduces the\nmemory module to store multiple different speech mapping results. In addition,\nwe introduce the Mixed Density Networks (MDN) into the landmark regression task\nto generate multiple predicted facial landmarks. Extensive qualitative and\nquantitative experiments show that the quality of our facial animation is\nsignificantly superior to that of the state-of-the-art (SOTA). The code has\nbeen released at https://github.com/Yaxinzhao97/MACL.git.\n","authors":["Jianrong Wang","Yaxin Zhao","Li Liu","Hongkai Fan","Tianyi Xu","Qi Li","Sen Li"],"pdf_url":"https://arxiv.org/pdf/2302.13469v1.pdf","comment":"ICASSP 2023"}]},"2023-02-26T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.13439v1","updated":"2023-02-26T23:46:29Z","published":"2023-02-26T23:46:29Z","title":"Navigating the Grey Area: Expressions of Overconfidence and Uncertainty\n  in Language Models","summary":"  Despite increasingly fluent, relevant, and coherent language generation,\nmajor gaps remain between how humans and machines use language. We argue that a\nkey dimension that is missing from our understanding of language models (LMs)\nis the model's ability to interpret and generate expressions of uncertainty.\nWhether it be the weatherperson announcing a chance of rain or a doctor giving\na diagnosis, information is often not black-and-white and expressions of\nuncertainty provide nuance to support human-decision making. The increasing\ndeployment of LMs in the wild motivates us to investigate whether LMs are\ncapable of interpreting expressions of uncertainty and how LMs' behaviors\nchange when learning to emit their own expressions of uncertainty. When\ninjecting expressions of uncertainty into prompts (e.g., \"I think the answer\nis...\"), we discover that GPT3's generations vary upwards of 80% in accuracy\nbased on the expression used. We analyze the linguistic characteristics of\nthese expressions and find a drop in accuracy when naturalistic expressions of\ncertainty are present. We find similar effects when teaching models to emit\ntheir own expressions of uncertainty, where model calibration suffers when\nteaching models to emit certainty rather than uncertainty. Together, these\nresults highlight the challenges of building LMs that interpret and generate\ntrustworthy expressions of uncertainty.\n","authors":["Kaitlyn Zhou","Dan Jurafsky","Tatsunori Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2302.13439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13412v1","updated":"2023-02-26T21:48:25Z","published":"2023-02-26T21:48:25Z","title":"The Lindstrom's Characterizability of Abstract Logic Systems for\n  Analytic Structures Based on Measures","summary":"  In 1969, Per Lindstrom proved his celebrated theorem characterising the\nfirst-order logic and established criteria for the first-order definability of\nformal theories for discrete structures. K. J. Barwise, S. Shelah, J. Vaananen\nand others extended Lindstrom's characterizability program to classes of\ninfinitary logic systems, including a recent paper by M. Dzamonja and J.\nVaananen on Karp's chain logic, which satisfies interpolation, undefinability\nof well-order, and is maximal in the class of logic systems with these\nproperties. The novelty of the chain logic is in its new definition of\nsatisfability. In our paper, we give a framework for Lindstrom's type\ncharacterizability of predicate logic systems interpreted semantically in\nmodels with objects based on measures (analytic structures). In particular,\nHajek's Logic of Integral is redefined as an abstract logic with a new type of\nHajek's satisfiability and constitutes a maximal logic in the class of logic\nsystems for describing analytic structures with Lebesgue integrals and\nsatisfying compactness, elementary chain condition, and weak negation.\n","authors":["Krystian Jobczyk","Mirna Dzamonja"],"pdf_url":"https://arxiv.org/pdf/2302.13412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13410v1","updated":"2023-02-26T21:41:15Z","published":"2023-02-26T21:41:15Z","title":"User-Centric Evaluation of OCR Systems for Kwak'wala","summary":"  There has been recent interest in improving optical character recognition\n(OCR) for endangered languages, particularly because a large number of\ndocuments and books in these languages are not in machine-readable formats. The\nperformance of OCR systems is typically evaluated using automatic metrics such\nas character and word error rates. While error rates are useful for the\ncomparison of different models and systems, they do not measure whether and how\nthe transcriptions produced from OCR tools are useful to downstream users. In\nthis paper, we present a human-centric evaluation of OCR systems, focusing on\nthe Kwak'wala language as a case study. With a user study, we show that\nutilizing OCR reduces the time spent in the manual transcription of culturally\nvaluable documents -- a task that is often undertaken by endangered language\ncommunity members and researchers -- by over 50%. Our results demonstrate the\npotential benefits that OCR tools can have on downstream language documentation\nand revitalization efforts.\n","authors":["Shruti Rijhwani","Daisy Rosenblum","Michayla King","Antonios Anastasopoulos","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2302.13410v1.pdf","comment":"Accepted to the Sixth Workshop on Computational Methods in the Study\n  of Endangered Languages (ComputEL 2023)"},{"id":"http://arxiv.org/abs/2302.13403v1","updated":"2023-02-26T20:55:19Z","published":"2023-02-26T20:55:19Z","title":"Tweets Under the Rubble: Detection of Messages Calling for Help in\n  Earthquake Disaster","summary":"  The importance of social media is again exposed in the recent tragedy of the\n2023 Turkey and Syria earthquake. Many victims who were trapped under the\nrubble called for help by posting messages in Twitter. We present an\ninteractive tool to provide situational awareness for missing and trapped\npeople, and disaster relief for rescue and donation efforts. The system (i)\ncollects tweets, (ii) classifies the ones calling for help, (iii) extracts\nimportant entity tags, and (iv) visualizes them in an interactive map screen.\nOur initial experiments show that the performance in terms of the F1 score is\nup to 98.30 for tweet classification, and 84.32 for entity extraction. The\ndemonstration, dataset, and other related files can be accessed at\nhttps://github.com/avaapm/deprem\n","authors":["Cagri Toraman","Izzet Emre Kucukkaya","Oguzhan Ozcelik","Umitcan Sahin"],"pdf_url":"https://arxiv.org/pdf/2302.13403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06990v2","updated":"2023-02-26T20:25:00Z","published":"2022-10-11T23:20:12Z","title":"Exploring Segmentation Approaches for Neural Machine Translation of\n  Code-Switched Egyptian Arabic-English Text","summary":"  Data sparsity is one of the main challenges posed by code-switching (CS),\nwhich is further exacerbated in the case of morphologically rich languages. For\nthe task of machine translation (MT), morphological segmentation has proven\nsuccessful in alleviating data sparsity in monolingual contexts; however, it\nhas not been investigated for CS settings. In this paper, we study the\neffectiveness of different segmentation approaches on MT performance, covering\nmorphology-based and frequency-based segmentation techniques. We experiment on\nMT from code-switched Arabic-English to English. We provide detailed analysis,\nexamining a variety of conditions, such as data size and sentences with\ndifferent degrees of CS. Empirical results show that morphology-aware\nsegmenters perform the best in segmentation tasks but under-perform in MT.\nNevertheless, we find that the choice of the segmentation setup to use for MT\nis highly dependent on the data size. For extreme low-resource scenarios, a\ncombination of frequency and morphology-based segmentations is shown to perform\nthe best. For more resourced settings, such a combination does not bring\nsignificant improvements over the use of frequency-based segmentation.\n","authors":["Marwa Gaser","Manuel Mager","Injy Hamed","Nizar Habash","Slim Abdennadher","Ngoc Thang Vu"],"pdf_url":"https://arxiv.org/pdf/2210.06990v2.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2302.13382v1","updated":"2023-02-26T18:40:38Z","published":"2023-02-26T18:40:38Z","title":"Comparing Sentence-Level Suggestions to Message-Level Suggestions in\n  AI-Mediated Communication","summary":"  Traditionally, writing assistance systems have focused on short or even\nsingle-word suggestions. Recently, large language models like GPT-3 have made\nit possible to generate significantly longer natural-sounding suggestions,\noffering more advanced assistance opportunities. This study explores the\ntrade-offs between sentence- vs. message-level suggestions for AI-mediated\ncommunication. We recruited 120 participants to act as staffers from\nlegislators' offices who often need to respond to large volumes of constituent\nconcerns. Participants were asked to reply to emails with different types of\nassistance. The results show that participants receiving message-level\nsuggestions responded faster and were more satisfied with the experience, as\nthey mainly edited the suggested drafts. In addition, the texts they wrote were\nevaluated as more helpful by others. In comparison, participants receiving\nsentence-level assistance retained a higher sense of agency, but took longer\nfor the task as they needed to plan the flow of their responses and decide when\nto use suggestions. Our findings have implications for designing\ntask-appropriate communication assistance systems.\n","authors":["Liye Fu","Benjamin Newman","Maurice Jakesch","Sarah Kreps"],"pdf_url":"https://arxiv.org/pdf/2302.13382v1.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2302.13376v1","updated":"2023-02-26T18:28:20Z","published":"2023-02-26T18:28:20Z","title":"Efficient Ensemble Architecture for Multimodal Acoustic and Textual\n  Embeddings in Punctuation Restoration using Time-Delay Neural Networks","summary":"  Punctuation restoration plays an essential role in the post-processing\nprocedure of automatic speech recognition, but model efficiency is a key\nrequirement for this task. To that end, we present EfficientPunct, an ensemble\nmethod with a multimodal time-delay neural network that outperforms the current\nbest model by 1.0 F1 points, using less than a tenth of its parameters to\nprocess embeddings. We streamline a speech recognizer to efficiently output\nhidden layer latent vectors as audio embeddings for punctuation restoration, as\nwell as BERT to extract meaningful text embeddings. By using forced alignment\nand temporal convolutions, we eliminate the need for multi-head attention-based\nfusion, greatly increasing computational efficiency but also raising\nperformance. EfficientPunct sets a new state of the art, in terms of both\nperformance and efficiency, with an ensemble that weights BERT's purely\nlanguage-based predictions slightly more than the multimodal network's\npredictions.\n","authors":["Xing Yi Liu","Homayoon Beigi"],"pdf_url":"https://arxiv.org/pdf/2302.13376v1.pdf","comment":"6 pages, 1 figure, 5 tables, technical report at Recognition\n  Technologies, Inc"},{"id":"http://arxiv.org/abs/2302.08399v4","updated":"2023-02-26T18:18:38Z","published":"2023-02-16T16:18:03Z","title":"Large Language Models Fail on Trivial Alterations to Theory-of-Mind\n  Tasks","summary":"  Intuitive psychology is a pillar of common-sense reasoning. The replication\nof this reasoning in machine intelligence is an important stepping-stone on the\nway to human-like artificial intelligence. Several recent tasks and benchmarks\nfor examining this reasoning in Large-Large Models have focused in particular\non belief attribution in Theory-of-Mind tasks. These tasks have shown both\nsuccesses and failures. We consider in particular a recent purported success\ncase, and show that small variations that maintain the principles of ToM turn\nthe results on their head. We argue that in general, the zero-hypothesis for\nmodel evaluation in intuitive psychology should be skeptical, and that outlying\nfailure cases should outweigh average success rates. We also consider what\npossible future successes on Theory-of-Mind tasks by more powerful LLMs would\nmean for ToM tasks with people.\n","authors":["Tomer Ullman"],"pdf_url":"https://arxiv.org/pdf/2302.08399v4.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2302.13344v1","updated":"2023-02-26T16:32:52Z","published":"2023-02-26T16:32:52Z","title":"Tailoring Language Generation Models under Total Variation Distance","summary":"  The standard paradigm of neural language generation adopts maximum likelihood\nestimation (MLE) as the optimizing method. From a distributional view, MLE in\nfact minimizes the Kullback-Leibler divergence (KLD) between the distribution\nof the real data and that of the model. However, this approach forces the model\nto distribute non-zero (sometimes large) probability mass to all training\nsamples regardless of their quality. Moreover, in the attempt to cover the\nlow-probability regions in the data distribution, the model systematically\noverestimates the probability of corrupted text sequences, which we conjecture\nis one of the main reasons for text degeneration during autoregressive\ndecoding. To remedy this problem, we leverage the total variation distance\n(TVD) with its robustness to outliers, and develop practical bounds to apply it\nto language generation. Then, we introduce the TaiLr objective that balances\nthe tradeoff of estimating TVD. Intuitively, TaiLr downweights real data\nsamples that have low model probabilities with tunable penalization intensity.\nExperimental results show that our method alleviates the overestimation of\ndegenerated sequences without sacrificing diversity and improves generation\nquality on a wide range of text generation tasks.\n","authors":["Haozhe Ji","Pei Ke","Zhipeng Hu","Rongsheng Zhang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2302.13344v1.pdf","comment":"Published in ICLR 2023 (notable-top-5%)"},{"id":"http://arxiv.org/abs/2302.12246v2","updated":"2023-02-26T15:18:50Z","published":"2023-02-23T18:58:59Z","title":"Active Prompting with Chain-of-Thought for Large Language Models","summary":"  The increasing scale of large language models (LLMs) brings emergent\nabilities to various complex tasks requiring reasoning, such as arithmetic and\ncommonsense reasoning. It is known that the effective design of task-specific\nprompts is critical for LLMs' ability to produce high-quality answers. In\nparticular, an effective approach for complex question-and-answer tasks is\nexample-based prompting with chain-of-thought (CoT) reasoning, which\nsignificantly improves the performance of LLMs. However, current CoT methods\nrely on a fixed set of human-annotated exemplars, which are not necessarily the\nmost effective examples for different tasks. This paper proposes a new method,\nActive-Prompt, to adapt LLMs to different tasks with task-specific example\nprompts (annotated with human-designed CoT reasoning). For this purpose, we\npropose a solution to the key problem of determining which questions are the\nmost important and helpful ones to annotate from a pool of task-specific\nqueries. By borrowing ideas from the related problem of uncertainty-based\nactive learning, we introduce several metrics to characterize the uncertainty\nso as to select the most uncertain questions for annotation. Experimental\nresults demonstrate the superiority of our proposed method, achieving\nstate-of-the-art on eight complex reasoning tasks. Further analyses of\ndifferent uncertainty metrics, pool sizes, zero-shot learning, and\naccuracy-uncertainty relationship demonstrate the effectiveness of our method.\nOur code will be available at https://github.com/shizhediao/active-prompt.\n","authors":["Shizhe Diao","Pengcheng Wang","Yong Lin","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.12246v2.pdf","comment":"20 pages, 3 figures, 11 tables"},{"id":"http://arxiv.org/abs/2302.13321v1","updated":"2023-02-26T13:38:42Z","published":"2023-02-26T13:38:42Z","title":"Multi-Modality in Music: Predicting Emotion in Music from High-Level\n  Audio Features and Lyrics","summary":"  This paper aims to test whether a multi-modal approach for music emotion\nrecognition (MER) performs better than a uni-modal one on high-level song\nfeatures and lyrics. We use 11 song features retrieved from the Spotify API,\ncombined lyrics features including sentiment, TF-IDF, and Anew to predict\nvalence and arousal (Russell, 1980) scores on the Deezer Mood Detection Dataset\n(DMDD) (Delbouys et al., 2018) with 4 different regression models. We find that\nout of the 11 high-level song features, mainly 5 contribute to the performance,\nmulti-modal features do better than audio alone when predicting valence. We\nmade our code publically available.\n","authors":["Tibor Krols","Yana Nikolova","Ninell Oldenburg"],"pdf_url":"https://arxiv.org/pdf/2302.13321v1.pdf","comment":"12 pages, incl. 2 pages appendix"},{"id":"http://arxiv.org/abs/2302.13311v1","updated":"2023-02-26T13:04:04Z","published":"2023-02-26T13:04:04Z","title":"Understanding Social Media Cross-Modality Discourse in Linguistic Space","summary":"  The multimedia communications with texts and images are popular on social\nmedia. However, limited studies concern how images are structured with texts to\nform coherent meanings in human cognition. To fill in the gap, we present a\nnovel concept of cross-modality discourse, reflecting how human readers couple\nimage and text understandings. Text descriptions are first derived from images\n(named as subtitles) in the multimedia contexts. Five labels -- entity-level\ninsertion, projection and concretization and scene-level restatement and\nextension -- are further employed to shape the structure of subtitles and texts\nand present their joint meanings. As a pilot study, we also build the very\nfirst dataset containing 16K multimedia tweets with manually annotated\ndiscourse labels. The experimental results show that the multimedia encoder\nbased on multi-head attention with captions is able to obtain\nthe-state-of-the-art results.\n","authors":["Chunpu Xu","Hanzhuo Tan","Jing Li","Piji Li"],"pdf_url":"https://arxiv.org/pdf/2302.13311v1.pdf","comment":"EMNLP 2022 Findings"},{"id":"http://arxiv.org/abs/2112.00384v3","updated":"2023-02-26T12:28:02Z","published":"2021-12-01T10:08:24Z","title":"Exploration into Translation-Equivariant Image Quantization","summary":"  This is an exploratory study that discovers the current image quantization\n(vector quantization) do not satisfy translation equivariance in the quantized\nspace due to aliasing. Instead of focusing on anti-aliasing, we propose a\nsimple yet effective way to achieve translation-equivariant image quantization\nby enforcing orthogonality among the codebook embeddings. To explore the\nadvantages of translation-equivariant image quantization, we conduct three\nproof-of-concept experiments with a carefully controlled dataset: (1)\ntext-to-image generation, where the quantized image indices are the target to\npredict, (2) image-to-text generation, where the quantized image indices are\ngiven as a condition, (3) using a smaller training set to analyze sample\nefficiency. From the strictly controlled experiments, we empirically verify\nthat the translation-equivariant image quantizer improves not only sample\nefficiency but also the accuracy over VQGAN up to +11.9% in text-to-image\ngeneration and +3.9% in image-to-text generation.\n","authors":["Woncheol Shin","Gyubok Lee","Jiyoung Lee","Eunyi Lyou","Joonseok Lee","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2112.00384v3.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2211.07126v2","updated":"2023-02-26T11:51:12Z","published":"2022-11-14T05:39:45Z","title":"Discharge Summary Hospital Course Summarisation of In Patient Electronic\n  Health Record Text with Clinical Concept Guided Deep Pre-Trained Transformer\n  Models","summary":"  Brief Hospital Course (BHC) summaries are succinct summaries of an entire\nhospital encounter, embedded within discharge summaries, written by senior\nclinicians responsible for the overall care of a patient. Methods to\nautomatically produce summaries from inpatient documentation would be\ninvaluable in reducing clinician manual burden of summarising documents under\nhigh time-pressure to admit and discharge patients. Automatically producing\nthese summaries from the inpatient course, is a complex, multi-document\nsummarisation task, as source notes are written from various perspectives (e.g.\nnursing, doctor, radiology), during the course of the hospitalisation. We\ndemonstrate a range of methods for BHC summarisation demonstrating the\nperformance of deep learning summarisation models across extractive and\nabstractive summarisation scenarios. We also test a novel ensemble extractive\nand abstractive summarisation model that incorporates a medical concept\nontology (SNOMED) as a clinical guidance signal and shows superior performance\nin 2 real-world clinical data sets.\n","authors":["Thomas Searle","Zina Ibrahim","James Teo","Richard Dobson"],"pdf_url":"https://arxiv.org/pdf/2211.07126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10186v2","updated":"2023-02-26T11:05:37Z","published":"2023-02-16T21:45:35Z","title":"E2E Spoken Entity Extraction for Virtual Agents","summary":"  This paper reimagines some aspects of speech processing using speech\nencoders, specifically about extracting entities directly from speech, with no\nintermediate textual representation. In human-computer conversations,\nextracting entities such as names, postal addresses and email addresses from\nspeech is a challenging task. In this paper, we study the impact of fine-tuning\npre-trained speech encoders on extracting spoken entities in human-readable\nform directly from speech without the need for text transcription. We\nillustrate that such a direct approach optimizes the encoder to transcribe only\nthe entity relevant portions of speech, ignoring the superfluous portions such\nas carrier phrases and spellings of entities. In the context of dialogs from an\nenterprise virtual agent, we demonstrate that the 1-step approach outperforms\nthe typical 2-step cascade of first generating lexical transcriptions followed\nby text-based entity extraction for identifying spoken entities.\n","authors":["Karan Singla","Yeon-Jun Kim","Ryan Price","Shahab Jalalvand","Srinivas Bangalore"],"pdf_url":"https://arxiv.org/pdf/2302.10186v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09432v2","updated":"2023-02-26T10:50:09Z","published":"2023-02-18T22:20:37Z","title":"BBT-Fin: Comprehensive Construction of Chinese Financial Domain\n  Pre-trained Language Model, Corpus and Benchmark","summary":"  To advance Chinese financial natural language processing (NLP), we introduce\nBBT-FinT5, a new Chinese financial pre-training language model based on the T5\nmodel. To support this effort, we have built BBT-FinCorpus, a large-scale\nfinancial corpus with approximately 300GB of raw text from four different\nsources. In general domain NLP, comprehensive benchmarks like GLUE and\nSuperGLUE have driven significant advancements in language model pre-training\nby enabling head-to-head comparisons among models. Drawing inspiration from\nthese benchmarks, we propose BBT-CFLEB, a Chinese Financial Language\nunderstanding and generation Evaluation Benchmark, which includes six datasets\ncovering both understanding and generation tasks. Our aim is to facilitate\nresearch in the development of NLP within the Chinese financial domain. Our\nmodel, corpus and benchmark are released at\nhttps://github.com/ssymmetry/BBT-FinCUGE-Applications. Our work belongs to the\nBig Bang Transformer (BBT), a large-scale pre-trained language model project.\n","authors":["Dakuan Lu","Hengkui Wu","Jiaqing Liang","Yipei Xu","Qianyu He","Yipeng Geng","Mengkun Han","Yingsi Xin","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2302.09432v2.pdf","comment":"Changed author order"},{"id":"http://arxiv.org/abs/2205.12679v2","updated":"2023-02-26T08:14:05Z","published":"2022-05-25T11:38:48Z","title":"Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning","summary":"  There is a rising interest in further exploring the zero-shot learning\npotential of large pre-trained language models (PLMs). A new paradigm called\ndata-generation-based zero-shot learning has achieved impressive success. In\nthis paradigm, the synthesized data from the PLM acts as the carrier of\nknowledge, which is used to train a task-specific model with orders of\nmagnitude fewer parameters than the PLM, achieving both higher performance and\nefficiency than prompt-based zero-shot learning methods on PLMs. The main\nhurdle of this approach is that the synthesized data from PLM usually contains\na significant portion of low-quality samples. Fitting on such data will greatly\nhamper the performance of the task-specific model, making it unreliable for\ndeployment. Previous methods remedy this issue mainly by filtering synthetic\ndata using heuristic metrics(e.g., output confidence), or refining the data\nwith the help of a human expert, which comes with excessive manual tuning or\nexpensive costs. In this paper, we propose a novel noise-robust re-weighting\nframework SunGen to automatically construct high-quality data for zero-shot\nclassification problems. Our framework features the ability to learn the sample\nweights indicating data quality without requiring any human annotation. We\ntheoretically and empirically verify the ability of our method to help\nconstruct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8%\nrelative improvement than the baseline on average accuracy across eight\ndifferent established text classification tasks.\n","authors":["Jiahui Gao","Renjie Pi","Yong Lin","Hang Xu","Jiacheng Ye","Zhiyong Wu","Weizhong Zhang","Xiaodan Liang","Zhenguo Li","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2205.12679v2.pdf","comment":"ICLR 2023 camera ready with 23 pages"},{"id":"http://arxiv.org/abs/2302.13241v1","updated":"2023-02-26T05:52:52Z","published":"2023-02-26T05:52:52Z","title":"Cross-Lingual Question Answering over Knowledge Base as Reading\n  Comprehension","summary":"  Although many large-scale knowledge bases (KBs) claim to contain multilingual\ninformation, their support for many non-English languages is often incomplete.\nThis incompleteness gives birth to the task of cross-lingual question answering\nover knowledge base (xKBQA), which aims to answer questions in languages\ndifferent from that of the provided KB. One of the major challenges facing\nxKBQA is the high cost of data annotation, leading to limited resources\navailable for further exploration. Another challenge is mapping KB schemas and\nnatural language expressions in the questions under cross-lingual settings. In\nthis paper, we propose a novel approach for xKBQA in a reading comprehension\nparadigm. We convert KB subgraphs into passages to narrow the gap between KB\nschemas and questions, which enables our model to benefit from recent advances\nin multilingual pre-trained language models (MPLMs) and cross-lingual machine\nreading comprehension (xMRC). Specifically, we use MPLMs, with considerable\nknowledge of cross-lingual mappings, for cross-lingual reading comprehension.\nExisting high-quality xMRC datasets can be further utilized to finetune our\nmodel, greatly alleviating the data scarcity issue in xKBQA. Extensive\nexperiments on two xKBQA datasets in 12 languages show that our approach\noutperforms various baselines and achieves strong few-shot and zero-shot\nperformance. Our dataset and code are released for further research.\n","authors":["Chen Zhang","Yuxuan Lai","Yansong Feng","Xingyu Shen","Haowei Du","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.13241v1.pdf","comment":"14 pages, 4 figures, EACL 2023 (findings)"},{"id":"http://arxiv.org/abs/2302.02069v2","updated":"2023-02-26T04:00:43Z","published":"2023-02-04T02:44:48Z","title":"Heterogeneous Federated Knowledge Graph Embedding Learning and\n  Unlearning","summary":"  Federated Learning (FL) recently emerges as a paradigm to train a global\nmachine learning model across distributed clients without sharing raw data.\nKnowledge Graph (KG) embedding represents KGs in a continuous vector space,\nserving as the backbone of many knowledge-driven applications. As a promising\ncombination, federated KG embedding can fully take advantage of knowledge\nlearned from different clients while preserving the privacy of local data.\nHowever, realistic problems such as data heterogeneity and knowledge forgetting\nstill remain to be concerned. In this paper, we propose FedLU, a novel FL\nframework for heterogeneous KG embedding learning and unlearning. To cope with\nthe drift between local optimization and global convergence caused by data\nheterogeneity, we propose mutual knowledge distillation to transfer local\nknowledge to global, and absorb global knowledge back. Moreover, we present an\nunlearning method based on cognitive neuroscience, which combines retroactive\ninterference and passive decay to erase specific knowledge from local clients\nand propagate to the global model by reusing knowledge distillation. We\nconstruct new datasets for assessing realistic performance of the\nstate-of-the-arts. Extensive experiments show that FedLU achieves superior\nresults in both link prediction and knowledge forgetting.\n","authors":["Xiangrong Zhu","Guangyao Li","Wei Hu"],"pdf_url":"https://arxiv.org/pdf/2302.02069v2.pdf","comment":"Accepted in the ACM Web Conference (WWW 2023)"},{"id":"http://arxiv.org/abs/2302.13222v1","updated":"2023-02-26T03:26:26Z","published":"2023-02-26T03:26:26Z","title":"Speech Corpora Divergence Based Unsupervised Data Selection for ASR","summary":"  Selecting application scenarios matching data is important for the automatic\nspeech recognition (ASR) training, but it is difficult to measure the matching\ndegree of the training corpus. This study proposes a unsupervised target-aware\ndata selection method based on speech corpora divergence (SCD), which can\nmeasure the similarity between two speech corpora. We first use the\nself-supervised Hubert model to discretize the speech corpora into label\nsequence and calculate the N-gram probability distribution. Then we calculate\nthe Kullback-Leibler divergence between the N-grams as the SCD. Finally, we can\nchoose the subset which has minimum SCD to the target corpus for annotation and\ntraining. Compared to previous data selection method, the SCD data selection\nmethod can focus on more acoustic details and guarantee the diversity of the\nselected set. We evaluate our method on different accents from Common Voice.\nExperiments show that the proposed SCD data selection can realize 14.8%\nrelative improvements to the random selection, comparable or even superior to\nthe result of supervised selection.\n","authors":["Changfeng Gao","Gaofeng Cheng","Pengyuan Zhang","Yonghong Yan"],"pdf_url":"https://arxiv.org/pdf/2302.13222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13201v1","updated":"2023-02-26T00:57:29Z","published":"2023-02-26T00:57:29Z","title":"CLICKER: Attention-Based Cross-Lingual Commonsense Knowledge Transfer","summary":"  Recent advances in cross-lingual commonsense reasoning (CSR) are facilitated\nby the development of multilingual pre-trained models (mPTMs). While mPTMs show\nthe potential to encode commonsense knowledge for different languages,\ntransferring commonsense knowledge learned in large-scale English corpus to\nother languages is challenging. To address this problem, we propose the\nattention-based Cross-LIngual Commonsense Knowledge transfER (CLICKER)\nframework, which minimizes the performance gaps between English and non-English\nlanguages in commonsense question-answering tasks. CLICKER effectively improves\ncommonsense reasoning for non-English languages by differentiating\nnon-commonsense knowledge from commonsense knowledge. Experimental results on\npublic benchmarks demonstrate that CLICKER achieves remarkable improvements in\nthe cross-lingual CSR task for languages other than English.\n","authors":["Ruolin Su","Zhongkai Sun","Sixing Lu","Chengyuan Ma","Chenlei Guo"],"pdf_url":"https://arxiv.org/pdf/2302.13201v1.pdf","comment":"Accepted by ICASSP 2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2210.08645v2","updated":"2023-02-26T23:08:17Z","published":"2022-10-16T21:58:54Z","title":"An efficient deep neural network to find small objects in large 3D\n  images","summary":"  3D imaging enables accurate diagnosis by providing spatial information about\norgan anatomy. However, using 3D images to train AI models is computationally\nchallenging because they consist of 10x or 100x more pixels than their 2D\ncounterparts. To be trained with high-resolution 3D images, convolutional\nneural networks resort to downsampling them or projecting them to 2D. We\npropose an effective alternative, a neural network that enables efficient\nclassification of full-resolution 3D medical images. Compared to off-the-shelf\nconvolutional neural networks, our network, 3D Globally-Aware Multiple Instance\nClassifier (3D-GMIC), uses 77.98%-90.05% less GPU memory and 91.23%-96.02% less\ncomputation. While it is trained only with image-level labels, without\nsegmentation labels, it explains its predictions by providing pixel-level\nsaliency maps. On a dataset collected at NYU Langone Health, including 85,526\npatients with full-field 2D mammography (FFDM), synthetic 2D mammography, and\n3D mammography, 3D-GMIC achieves an AUC of 0.831 (95% CI: 0.769-0.887) in\nclassifying breasts with malignant findings using 3D mammography. This is\ncomparable to the performance of GMIC on FFDM (0.816, 95% CI: 0.737-0.878) and\nsynthetic 2D (0.826, 95% CI: 0.754-0.884), which demonstrates that 3D-GMIC\nsuccessfully classified large 3D images despite focusing computation on a\nsmaller percentage of its input compared to GMIC. Therefore, 3D-GMIC identifies\nand utilizes extremely small regions of interest from 3D images consisting of\nhundreds of millions of pixels, dramatically reducing associated computational\nchallenges. 3D-GMIC generalizes well to BCS-DBT, an external dataset from Duke\nUniversity Hospital, achieving an AUC of 0.848 (95% CI: 0.798-0.896).\n","authors":["Jungkyu Park","Jakub Chłędowski","Stanisław Jastrzębski","Jan Witowski","Yanqi Xu","Linda Du","Sushma Gaddam","Eric Kim","Alana Lewin","Ujas Parikh","Anastasia Plaunova","Sardius Chen","Alexandra Millet","James Park","Kristine Pysarenko","Shalin Patel","Julia Goldberg","Melanie Wegener","Linda Moy","Laura Heacock","Beatriu Reig","Krzysztof J. Geras"],"pdf_url":"https://arxiv.org/pdf/2210.08645v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13434v1","updated":"2023-02-26T23:02:33Z","published":"2023-02-26T23:02:33Z","title":"Spatial-temporal Transformer-guided Diffusion based Data Augmentation\n  for Efficient Skeleton-based Action Recognition","summary":"  Recently, skeleton-based human action has become a hot research topic because\nthe compact representation of human skeletons brings new blood to this research\ndomain. As a result, researchers began to notice the importance of using RGB or\nother sensors to analyze human action by extracting skeleton information.\nLeveraging the rapid development of deep learning (DL), a significant number of\nskeleton-based human action approaches have been presented with fine-designed\nDL structures recently. However, a well-trained DL model always demands\nhigh-quality and sufficient data, which is hard to obtain without costing high\nexpenses and human labor. In this paper, we introduce a novel data augmentation\nmethod for skeleton-based action recognition tasks, which can effectively\ngenerate high-quality and diverse sequential actions. In order to obtain\nnatural and realistic action sequences, we propose denoising diffusion\nprobabilistic models (DDPMs) that can generate a series of synthetic action\nsequences, and their generation process is precisely guided by a\nspatial-temporal transformer (ST-Trans). Experimental results show that our\nmethod outperforms the state-of-the-art (SOTA) motion generation approaches on\ndifferent naturality and diversity metrics. It proves that its high-quality\nsynthetic data can also be effectively deployed to existing action recognition\nmodels with significant performance improvement.\n","authors":["Yifan Jiang","Han Chen","Hanseok Ko"],"pdf_url":"https://arxiv.org/pdf/2302.13434v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.12853v2","updated":"2023-02-26T22:43:40Z","published":"2022-08-26T19:50:46Z","title":"Domain Adaptation with Adversarial Training on Penultimate Activations","summary":"  Enhancing model prediction confidence on target data is an important\nobjective in Unsupervised Domain Adaptation (UDA). In this paper, we explore\nadversarial training on penultimate activations, i.e., input features of the\nfinal linear classification layer. We show that this strategy is more efficient\nand better correlated with the objective of boosting prediction confidence than\nadversarial training on input images or intermediate features, as used in\nprevious works. Furthermore, with activation normalization commonly used in\ndomain adaptation to reduce domain gap, we derive two variants and\nsystematically analyze the effects of normalization on our adversarial\ntraining. This is illustrated both in theory and through empirical analysis on\nreal adaptation tasks. Extensive experiments are conducted on popular UDA\nbenchmarks under both standard setting and source-data free setting. The\nresults validate that our method achieves the best scores against previous\narts. Code is available at https://github.com/tsun/APA.\n","authors":["Tao Sun","Cheng Lu","Haibin Ling"],"pdf_url":"https://arxiv.org/pdf/2208.12853v2.pdf","comment":"AAAI 2023 Oral"},{"id":"http://arxiv.org/abs/2302.13408v1","updated":"2023-02-26T21:34:19Z","published":"2023-02-26T21:34:19Z","title":"Generative Models for 3D Point Clouds","summary":"  Point clouds are rich geometric data structures, where their three\ndimensional structure offers an excellent domain for understanding the\nrepresentation learning and generative modeling in 3D space. In this work, we\naim to improve the performance of point cloud latent-space generative models by\nexperimenting with transformer encoders, latent-space flow models, and\nautoregressive decoders. We analyze and compare both generation and\nreconstruction performance of these models on various object types.\n","authors":["Lingjie Kong","Pankaj Rajak","Siamak Shakeri"],"pdf_url":"https://arxiv.org/pdf/2302.13408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10774v4","updated":"2023-02-26T19:43:42Z","published":"2022-07-21T22:17:21Z","title":"Focused Decoding Enables 3D Anatomical Detection by Transformers","summary":"  Detection Transformers represent end-to-end object detection approaches based\non a Transformer encoder-decoder architecture, exploiting the attention\nmechanism for global relation modeling. Although Detection Transformers deliver\nresults on par with or even superior to their highly optimized CNN-based\ncounterparts operating on 2D natural images, their success is closely coupled\nto access to a vast amount of training data. This, however, restricts the\nfeasibility of employing Detection Transformers in the medical domain, as\naccess to annotated data is typically limited. To tackle this issue and\nfacilitate the advent of medical Detection Transformers, we propose a novel\nDetection Transformer for 3D anatomical structure detection, dubbed Focused\nDecoder. Focused Decoder leverages information from an anatomical region atlas\nto simultaneously deploy query anchors and restrict the cross-attention's field\nof view to regions of interest, which allows for a precise focus on relevant\nanatomical structures. We evaluate our proposed approach on two publicly\navailable CT datasets and demonstrate that Focused Decoder not only provides\nstrong detection results and thus alleviates the need for a vast amount of\nannotated data but also exhibits exceptional and highly intuitive\nexplainability of results via attention weights. Our code is available at\nhttps://github.com/bwittmann/transoar.\n","authors":["Bastian Wittmann","Fernando Navarro","Suprosanna Shit","Bjoern Menze"],"pdf_url":"https://arxiv.org/pdf/2207.10774v4.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2023:003"},{"id":"http://arxiv.org/abs/2302.13392v1","updated":"2023-02-26T19:22:36Z","published":"2023-02-26T19:22:36Z","title":"NSANet: Noise Seeking Attention Network","summary":"  LiDAR (Light Detection and Ranging) technology has remained popular in\ncapturing natural and built environments for numerous applications. The recent\ntechnological advancements in electro-optical engineering have aided in\nobtaining laser returns at a higher pulse repetition frequency (PRF), which\nconsiderably increased the density of the 3D point cloud. Conventional\ntechniques with lower PRF had a single pulse-in-air (SPIA) zone, large enough\nto avoid a mismatch among pulse pairs at the receiver. New multiple\npulses-in-air (MPIA) technology guarantees various windows of operational\nranges for a single flight line and no blind zones. The disadvantage of the\ntechnology is the projection of atmospheric returns closer to the same\npulse-in-air zone of adjacent terrain points likely to intersect with objects\nof interest. These noise properties compromise the perceived quality of the\nscene and encourage the development of new noise-filtering neural networks, as\nexisting filters are significantly ineffective. We propose a novel\ndual-attention noise-filtering neural network called Noise Seeking Attention\nNetwork (NSANet) that uses physical priors and local spatial attention to\nfilter noise. Our research is motivated by two psychology theories of feature\nintegration and attention engagement to prove the role of attention in computer\nvision at the encoding and decoding phase. The presented results of NSANet show\nthe inclination towards attention engagement theory and a performance boost\ncompared to the state-of-the-art noise-filtering deep convolutional neural\nnetworks.\n","authors":["Maryam Jameela","Gunho Sohn"],"pdf_url":"https://arxiv.org/pdf/2302.13392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13390v1","updated":"2023-02-26T19:16:57Z","published":"2023-02-26T19:16:57Z","title":"MDF-Net: Multimodal Dual-Fusion Network for Abnormality Detection using\n  CXR Images and Clinical Data","summary":"  This study aims to investigate the effects of including patients' clinical\ninformation on the performance of deep learning (DL) classifiers for disease\nlocation in chest X-ray images. Although current classifiers achieve high\nperformance using chest X-ray images alone, our interviews with radiologists\nindicate that clinical data is highly informative and essential for\ninterpreting images and making proper diagnoses. In this work, we propose a\nnovel architecture consisting of two fusion methods that enable the model to\nsimultaneously process patients' clinical data (structured data) and chest\nX-rays (image data). Since these data modalities are in different dimensional\nspaces, we propose a spatial arrangement strategy, termed spatialization, to\nfacilitate the multimodal learning process in a Mask R-CNN model. We performed\nan extensive experimental evaluation comprising three datasets with different\nmodalities: MIMIC CXR (chest X-ray images), MIMIC IV-ED (patients' clinical\ndata), and REFLACX (annotations of disease locations in chest X-rays). Results\nshow that incorporating patients' clinical data in a DL model together with the\nproposed fusion methods improves the performance of disease localization in\nchest X-rays by 12\\% in terms of Average Precision compared to a standard Mask\nR-CNN using only chest X-rays. Further ablation studies also emphasize the\nimportance of multimodal DL architectures and the incorporation of patients'\nclinical data in disease localisation.\n  The architecture proposed in this work is publicly available to promote the\nscientific reproducibility of our study\n(https://github.com/ChihchengHsieh/multimodal-abnormalities-detection).\n","authors":["Chihcheng Hsieh","Isabel Blanco Nobre","Sandra Costa Sousa","Chun Ouyang","Margot Brereton","Jacinto C. Nascimento","Joaquim Jorge","Catarina Moreira"],"pdf_url":"https://arxiv.org/pdf/2302.13390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12228v2","updated":"2023-02-26T18:59:29Z","published":"2023-02-23T18:46:41Z","title":"Designing an Encoder for Fast Personalization of Text-to-Image Models","summary":"  Text-to-image personalization aims to teach a pre-trained diffusion model to\nreason about novel, user provided concepts, embedding them into new scenes\nguided by natural language prompts. However, current personalization approaches\nstruggle with lengthy training times, high storage requirements or loss of\nidentity. To overcome these limitations, we propose an encoder-based\ndomain-tuning approach. Our key insight is that by underfitting on a large set\nof concepts from a given domain, we can improve generalization and create a\nmodel that is more amenable to quickly adding novel concepts from the same\ndomain. Specifically, we employ two components: First, an encoder that takes as\nan input a single image of a target concept from a given domain, e.g. a\nspecific face, and learns to map it into a word-embedding representing the\nconcept. Second, a set of regularized weight-offsets for the text-to-image\nmodel that learn how to effectively ingest additional concepts. Together, these\ncomponents are used to guide the learning of unseen concepts, allowing us to\npersonalize a model using only a single image and as few as 5 training steps -\naccelerating personalization from dozens of minutes to seconds, while\npreserving quality.\n","authors":["Rinon Gal","Moab Arar","Yuval Atzmon","Amit H. Bermano","Gal Chechik","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2302.12228v2.pdf","comment":"Project page at https://tuning-encoder.github.io/"},{"id":"http://arxiv.org/abs/2212.12206v3","updated":"2023-02-26T18:25:09Z","published":"2022-12-23T08:48:34Z","title":"Principled and Efficient Transfer Learning of Deep Models via Neural\n  Collapse","summary":"  As model size continues to grow and access to labeled training data remains\nlimited, transfer learning has become a popular approach in many scientific and\nengineering fields. This study explores the phenomenon of neural collapse (NC)\nin transfer learning for classification problems, which is characterized by the\nlast-layer features and classifiers of deep networks having zero within-class\nvariability in features and maximally and equally separated between-class\nfeature means. Through the lens of NC, in this work the following findings on\ntransfer learning are discovered: (i) preventing within-class variability\ncollapse to a certain extent during model pre-training on source data leads to\nbetter transferability, as it preserves the intrinsic structures of the input\ndata better; (ii) obtaining features with more NC on downstream data during\nfine-tuning results in better test accuracy. These results provide new insight\ninto commonly used heuristics in model pre-training, such as loss design, data\naugmentation, and projection heads, and lead to more efficient and principled\nmethods for fine-tuning large pre-trained models. Compared to full model\nfine-tuning, our proposed fine-tuning methods achieve comparable or even better\nperformance while reducing fine-tuning parameters by at least 70% as well as\nalleviating overfitting.\n","authors":["Xiao Li","Sheng Liu","Jinxin Zhou","Xinyu Lu","Carlos Fernandez-Granda","Zhihui Zhu","Qing Qu"],"pdf_url":"https://arxiv.org/pdf/2212.12206v3.pdf","comment":"First two authors contributed equally, 29 pages, 14 figures, and 7\n  tables"},{"id":"http://arxiv.org/abs/2302.13375v1","updated":"2023-02-26T18:22:13Z","published":"2023-02-26T18:22:13Z","title":"Perceiving Unseen 3D Objects by Poking the Objects","summary":"  We present a novel approach to interactive 3D object perception for robots.\nUnlike previous perception algorithms that rely on known object models or a\nlarge amount of annotated training data, we propose a poking-based approach\nthat automatically discovers and reconstructs 3D objects. The poking process\nnot only enables the robot to discover unseen 3D objects but also produces\nmulti-view observations for 3D reconstruction of the objects. The reconstructed\nobjects are then memorized by neural networks with regular supervised learning\nand can be recognized in new test images. The experiments on real-world data\nshow that our approach could unsupervisedly discover and reconstruct unseen 3D\nobjects with high quality, and facilitate real-world applications such as\nrobotic grasping. The code and supplementary materials are available at the\nproject page: https://zju3dv.github.io/poking_perception.\n","authors":["Linghao Chen","Yunzhou Song","Hujun Bao","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.13375v1.pdf","comment":"Accepted to ICRA 2023. Project page:\n  https://zju3dv.github.io/poking_perception"},{"id":"http://arxiv.org/abs/2302.13372v1","updated":"2023-02-26T18:19:24Z","published":"2023-02-26T18:19:24Z","title":"Localizing Moments in Long Video Via Multimodal Guidance","summary":"  The recent introduction of the large-scale long-form MAD dataset for language\ngrounding in videos has enabled researchers to investigate the performance of\ncurrent state-of-the-art methods in the long-form setup, with unexpected\nfindings. In fact, current grounding methods alone fail at tackling this\nchallenging task and setup due to their inability to process long video\nsequences. In this work, we propose an effective way to circumvent the\nlong-form burden by introducing a new component to grounding pipelines: a\nGuidance model. The purpose of the Guidance model is to efficiently remove\nirrelevant video segments from the search space of grounding methods by\ncoarsely aligning the sentence to chunks of the movies and then applying legacy\ngrounding methods where high correlation is found. We term these video segments\nas non-describable moments. This two-stage approach reveals to be effective in\nboosting the performance of several different grounding baselines on the\nchallenging MAD dataset, achieving new state-of-the-art performance.\n","authors":["Wayner Barrios","Mattia Soldan","Fabian Caba Heilbron","Alberto Mario Ceballos-Arroyo","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2302.13372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.01929v4","updated":"2023-02-26T17:43:27Z","published":"2020-10-05T11:39:04Z","title":"EqCo: Equivalent Rules for Self-supervised Contrastive Learning","summary":"  In this paper, we propose EqCo (Equivalent Rules for Contrastive Learning) to\nmake self-supervised learning irrelevant to the number of negative samples in\nthe contrastive learning framework. Inspired by the InfoMax principle, we point\nthat the margin term in contrastive loss needs to be adaptively scaled\naccording to the number of negative pairs in order to keep steady mutual\ninformation bound and gradient magnitude. EqCo bridges the performance gap\namong a wide range of negative sample sizes, so that for the first time, we can\nuse only a few negative pairs (e.g., 16 per query) to perform self-supervised\ncontrastive training on large-scale vision datasets like ImageNet, while with\nalmost no accuracy drop. This is quite a contrast to the widely used large\nbatch training or memory bank mechanism in current practices. Equipped with\nEqCo, our simplified MoCo (SiMo) achieves comparable accuracy with MoCov2 on\nImageNet (linear evaluation protocol) while only involves 16 negative pairs per\nquery instead of 65536, suggesting that large quantities of negative samples is\nnot a critical factor in contrastive learning frameworks.\n","authors":["Benjin Zhu","Junqiang Huang","Zeming Li","Xiangyu Zhang","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2010.01929v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13345v1","updated":"2023-02-26T16:36:28Z","published":"2023-02-26T16:36:28Z","title":"Analysis of Deep Image Quality Models","summary":"  Subjective image quality measures based on deep neural networks are very\nrelated to models of visual neuroscience. This connection benefits engineering\nbut, more interestingly, the freedom to optimize deep networks in different\nways, make them an excellent tool to explore the principles behind visual\nperception (both human and artificial). Recently, a myriad of networks have\nbeen successfully optimized for many interesting visual tasks. Although these\nnets were not specifically designed to predict image quality or other\npsychophysics, they have shown surprising human-like behavior. The reasons for\nthis remain unclear.\n  In this work, we perform a thorough analysis of the perceptual properties of\npre-trained nets (particularly their ability to predict image quality) by\nisolating different factors: the goal (the function), the data (learning\nenvironment), the architecture, and the readout: selected layer(s), fine-tuning\nof channel relevance, and use of statistical descriptors as opposed to plain\nreadout of responses.\n  Several conclusions can be drawn. All the models correlate better with human\nopinion than SSIM. More importantly, some of the nets are in pair of\nstate-of-the-art with no extra refinement or perceptual information. Nets\ntrained for supervised tasks such as classification correlate substantially\nbetter with humans than LPIPS (a net specifically tuned for image quality).\nInterestingly, self-supervised tasks such as jigsaw also perform better than\nLPIPS. Simpler architectures are better than very deep nets. In simpler nets,\ncorrelation with humans increases with depth as if deeper layers were closer to\nhuman judgement. This is not true in very deep nets. Consistently with reports\non illusions and contrast sensitivity, small changes in the image environment\ndoes not make a big difference. Finally, the explored statistical descriptors\nand concatenations had no major impact.\n","authors":["Pablo Hernández-Cámara","Jorge Vila-Tomás","Valero Laparra","Jesús Malo"],"pdf_url":"https://arxiv.org/pdf/2302.13345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13336v1","updated":"2023-02-26T15:45:19Z","published":"2023-02-26T15:45:19Z","title":"Key-Exchange Convolutional Auto-Encoder for Data Augmentation in Early\n  Knee OsteoArthritis Classification","summary":"  Knee OsteoArthritis (KOA) is a prevalent musculoskeletal condition that\nimpairs the mobility of senior citizens. The lack of sufficient data in the\nmedical field is always a challenge for training a learning model due to the\nhigh cost of labelling. At present, Deep neural network training strongly\ndepends on data augmentation to improve the model's generalization capability\nand avoid over-fitting. However, existing data augmentation operations, such as\nrotation, gamma correction, etc., are designed based on the original data,\nwhich does not substantially increase the data diversity. In this paper, we\npropose a learning model based on the convolutional Auto-Encoder and a hybrid\nloss strategy to generate new data for early KOA (KL-0 vs KL-2) diagnosis. Four\nhidden layers are designed among the encoder and decoder, which represent the\nkey and unrelated features of each input, respectively. Then, two key feature\nvectors are exchanged to obtain the generated images. To do this, a hybrid loss\nfunction is derived using different loss functions with optimized weights to\nsupervise the reconstruction and key-exchange learning. Experimental results\nshow that the generated data are valid as they can significantly improve the\nmodel's classification performance.\n","authors":["Zhe Wang","Aladine Chetouani","Rachid Jennane"],"pdf_url":"https://arxiv.org/pdf/2302.13336v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13334v1","updated":"2023-02-26T15:34:05Z","published":"2023-02-26T15:34:05Z","title":"Knowledge Restore and Transfer for Multi-label Class-Incremental\n  Learning","summary":"  Current class-incremental learning research mainly focuses on single-label\nclassification tasks while multi-label class-incremental learning (MLCIL) with\nmore practical application scenarios is rarely studied. Although there have\nbeen many anti-forgetting methods to solve the problem of catastrophic\nforgetting in class-incremental learning, these methods have difficulty in\nsolving the MLCIL problem due to label absence and information dilution. In\nthis paper, we propose a knowledge restore and transfer (KRT) framework for\nMLCIL, which includes a dynamic pseudo-label (DPL) module to restore the old\nclass knowledge and an incremental cross-attention(ICA) module to save\nsession-specific knowledge and transfer old class knowledge to the new model\nsufficiently. Besides, we propose a token loss to jointly optimize the\nincremental cross-attention module. Experimental results on MS-COCO and PASCAL\nVOC datasets demonstrate the effectiveness of our method for improving\nrecognition performance and mitigating forgetting on multi-label\nclass-incremental learning tasks.\n","authors":["Songlin Dong","Haoyu Luo","Yuhang He","Xing Wei Yihong Gong"],"pdf_url":"https://arxiv.org/pdf/2302.13334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13331v1","updated":"2023-02-26T15:08:15Z","published":"2023-02-26T15:08:15Z","title":"Learning Input-agnostic Manipulation Directions in StyleGAN with Text\n  Guidance","summary":"  With the advantages of fast inference and human-friendly flexible\nmanipulation, image-agnostic style manipulation via text guidance enables new\napplications that were not previously available. The state-of-the-art\ntext-guided image-agnostic manipulation method embeds the representation of\neach channel of StyleGAN independently in the Contrastive Language-Image\nPre-training (CLIP) space, and provides it in the form of a Dictionary to\nquickly find out the channel-wise manipulation direction during inference time.\nHowever, in this paper we argue that this dictionary which is constructed by\ncontrolling single channel individually is limited to accommodate the\nversatility of text guidance since the collective and interactive relation\namong multiple channels are not considered. Indeed, we show that it fails to\ndiscover a large portion of manipulation directions that can be found by\nexisting methods, which manually manipulates latent space without texts. To\nalleviate this issue, we propose a novel method that learns a Dictionary, whose\nentry corresponds to the representation of a single channel, by taking into\naccount the manipulation effect coming from the interaction with multiple other\nchannels. We demonstrate that our strategy resolves the inability of previous\nmethods in finding diverse known directions from unsupervised methods and\nunknown directions from random text while maintaining the real-time inference\nspeed and disentanglement ability.\n","authors":["Yoonjeon Kim","Hyunsu Kim","Junho Kim","Yunjey Choi","Eunho Yang"],"pdf_url":"https://arxiv.org/pdf/2302.13331v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2206.12512v3","updated":"2023-02-26T15:05:43Z","published":"2022-06-24T23:44:42Z","title":"Placental Vessel Segmentation and Registration in Fetoscopy: Literature\n  Review and MICCAI FetReg2021 Challenge Findings","summary":"  Fetoscopy laser photocoagulation is a widely adopted procedure for treating\nTwin-to-Twin Transfusion Syndrome (TTTS). The procedure involves\nphotocoagulation pathological anastomoses to regulate blood exchange among\ntwins. The procedure is particularly challenging due to the limited field of\nview, poor manoeuvrability of the fetoscope, poor visibility, and variability\nin illumination. These challenges may lead to increased surgery time and\nincomplete ablation. Computer-assisted intervention (CAI) can provide surgeons\nwith decision support and context awareness by identifying key structures in\nthe scene and expanding the fetoscopic field of view through video mosaicking.\nResearch in this domain has been hampered by the lack of high-quality data to\ndesign, develop and test CAI algorithms. Through the Fetoscopic Placental\nVessel Segmentation and Registration (FetReg2021) challenge, which was\norganized as part of the MICCAI2021 Endoscopic Vision challenge, we released\nthe first largescale multicentre TTTS dataset for the development of\ngeneralized and robust semantic segmentation and video mosaicking algorithms.\nFor this challenge, we released a dataset of 2060 images, pixel-annotated for\nvessels, tool, fetus and background classes, from 18 in-vivo TTTS fetoscopy\nprocedures and 18 short video clips. Seven teams participated in this challenge\nand their model performance was assessed on an unseen test dataset of 658\npixel-annotated images from 6 fetoscopic procedures and 6 short clips. The\nchallenge provided an opportunity for creating generalized solutions for\nfetoscopic scene understanding and mosaicking. In this paper, we present the\nfindings of the FetReg2021 challenge alongside reporting a detailed literature\nreview for CAI in TTTS fetoscopy. Through this challenge, its analysis and the\nrelease of multi-centre fetoscopic data, we provide a benchmark for future\nresearch in this field.\n","authors":["Sophia Bano","Alessandro Casella","Francisco Vasconcelos","Abdul Qayyum","Abdesslam Benzinou","Moona Mazher","Fabrice Meriaudeau","Chiara Lena","Ilaria Anita Cintorrino","Gaia Romana De Paolis","Jessica Biagioli","Daria Grechishnikova","Jing Jiao","Bizhe Bai","Yanyan Qiao","Binod Bhattarai","Rebati Raman Gaire","Ronast Subedi","Eduard Vazquez","Szymon Płotka","Aneta Lisowska","Arkadiusz Sitek","George Attilakos","Ruwan Wimalasundera","Anna L David","Dario Paladini","Jan Deprest","Elena De Momi","Leonardo S Mattos","Sara Moccia","Danail Stoyanov"],"pdf_url":"https://arxiv.org/pdf/2206.12512v3.pdf","comment":"Accepted at MedIA (Medical Image Analysis)"},{"id":"http://arxiv.org/abs/2212.07328v2","updated":"2023-02-26T14:55:50Z","published":"2022-12-14T16:48:21Z","title":"Modeling Multimodal Aleatoric Uncertainty in Segmentation with Mixture\n  of Stochastic Experts","summary":"  Equipping predicted segmentation with calibrated uncertainty is essential for\nsafety-critical applications. In this work, we focus on capturing the\ndata-inherent uncertainty (aka aleatoric uncertainty) in segmentation,\ntypically when ambiguities exist in input images. Due to the high-dimensional\noutput space and potential multiple modes in segmenting ambiguous images, it\nremains challenging to predict well-calibrated uncertainty for segmentation. To\ntackle this problem, we propose a novel mixture of stochastic experts (MoSE)\nmodel, where each expert network estimates a distinct mode of the aleatoric\nuncertainty and a gating network predicts the probabilities of an input image\nbeing segmented in those modes. This yields an efficient two-level uncertainty\nrepresentation. To learn the model, we develop a Wasserstein-like loss that\ndirectly minimizes the distribution distance between the MoSE and ground truth\nannotations. The loss can easily integrate traditional segmentation quality\nmeasures and be efficiently optimized via constraint relaxation. We validate\nour method on the LIDC-IDRI dataset and a modified multimodal Cityscapes\ndataset. Results demonstrate that our method achieves the state-of-the-art or\ncompetitive performance on all metrics.\n","authors":["Zhitong Gao","Yucong Chen","Chuyu Zhang","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2212.07328v2.pdf","comment":"Published in ICLR 2023"},{"id":"http://arxiv.org/abs/2210.10897v2","updated":"2023-02-26T13:55:23Z","published":"2022-10-19T21:27:25Z","title":"Distribution Shift Detection for Deep Neural Networks","summary":"  To deploy and operate deep neural models in production, the quality of their\npredictions, which might be contaminated benignly or manipulated maliciously by\ninput distributional deviations, must be monitored and assessed. Specifically,\nwe study the case of monitoring the healthy operation of a deep neural network\n(DNN) receiving a stream of data, with the aim of detecting input\ndistributional deviations over which the quality of the network's predictions\nis potentially damaged. Using selective prediction principles, we propose a\ndistribution deviation detection method for DNNs. The proposed method is\nderived from a tight coverage generalization bound computed over a sample of\ninstances drawn from the true underlying distribution. Based on this bound, our\ndetector continuously monitors the operation of the network over a test window\nand fires off an alarm whenever a deviation is detected. This novel detection\nmethod consistently and significantly outperforms the state of the art with\nrespect to the CIFAR-10 and ImageNet datasets, thus establishing a new\nperformance bar for this task, while being substantially more efficient in time\nand space complexities.\n","authors":["Guy Bar-Shalom","Yonatan Geifman","Ran El-Yaniv"],"pdf_url":"https://arxiv.org/pdf/2210.10897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.05790v3","updated":"2023-02-26T13:32:36Z","published":"2021-11-09T15:36:10Z","title":"Early Myocardial Infarction Detection over Multi-view Echocardiography","summary":"  Myocardial infarction (MI) is the leading cause of mortality in the world\nthat occurs due to a blockage of the coronary arteries feeding the myocardium.\nAn early diagnosis of MI and its localization can mitigate the extent of\nmyocardial damage by facilitating early therapeutic interventions. Following\nthe blockage of a coronary artery, the regional wall motion abnormality (RWMA)\nof the ischemic myocardial segments is the earliest change to set in.\nEchocardiography is the fundamental tool to assess any RWMA. Assessing the\nmotion of the left ventricle (LV) wall only from a single echocardiography view\nmay lead to missing the diagnosis of MI as the RWMA may not be visible on that\nspecific view. Therefore, in this study, we propose to fuse apical 4-chamber\n(A4C) and apical 2-chamber (A2C) views in which a total of 12 myocardial\nsegments can be analyzed for MI detection. The proposed method first estimates\nthe motion of the LV wall by Active Polynomials (APs), which extract and track\nthe endocardial boundary to compute myocardial segment displacements. The\nfeatures are extracted from the A4C and A2C view displacements, which are\nconcatenated and fed into the classifiers to detect MI. The main contributions\nof this study are 1) creation of a new benchmark dataset by including both A4C\nand A2C views in a total of 260 echocardiography recordings, which is publicly\nshared with the research community, 2) improving the performance of the prior\nwork of threshold-based APs by a Machine Learning based approach, and 3) a\npioneer MI detection approach via multi-view echocardiography by fusing the\ninformation of A4C and A2C views. Experimental results show that the proposed\nmethod achieves 90.91% sensitivity and 86.36% precision for MI detection over\nmulti-view echocardiography. The software implementation is shared at\nhttps://github.com/degerliaysen/MultiEchoAI.\n","authors":["Aysen Degerli","Serkan Kiranyaz","Tahir Hamid","Rashid Mazhar","Moncef Gabbouj"],"pdf_url":"https://arxiv.org/pdf/2111.05790v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13317v1","updated":"2023-02-26T13:24:46Z","published":"2023-02-26T13:24:46Z","title":"TransferD2: Automated Defect Detection Approach in Smart Manufacturing\n  using Transfer Learning Techniques","summary":"  Quality assurance is crucial in the smart manufacturing industry as it\nidentifies the presence of defects in finished products before they are shipped\nout. Modern machine learning techniques can be leveraged to provide rapid and\naccurate detection of these imperfections. We, therefore, propose a transfer\nlearning approach, namely TransferD2, to correctly identify defects on a\ndataset of source objects and extend its application to new unseen target\nobjects. We present a data enhancement technique to generate a large dataset\nfrom the small source dataset for building a classifier. We then integrate\nthree different pre-trained models (Xception, ResNet101V2, and\nInceptionResNetV2) into the classifier network and compare their performance on\nsource and target data. We use the classifier to detect the presence of\nimperfections on the unseen target data using pseudo-bounding boxes. Our\nresults show that ResNet101V2 performs best on the source data with an accuracy\nof 95.72%. Xception performs best on the target data with an accuracy of 91.00%\nand also provides a more accurate prediction of the defects on the target\nimages. Throughout the experiment, the results also indicate that the choice of\na pre-trained model is not dependent on the depth of the network. Our proposed\napproach can be applied in defect detection applications where insufficient\ndata is available for training a model and can be extended to identify\nimperfections in new unseen data.\n","authors":["Atah Nuh Mih","Hung Cao","Joshua Pickard","Monica Wachowicz","Rickey Dubay"],"pdf_url":"https://arxiv.org/pdf/2302.13317v1.pdf","comment":"Keywords: Transfer Learning, Smart Manufacturing, Defect Detection,\n  Deflectometry Data, Data Enhancement, Product Quality Assurance"},{"id":"http://arxiv.org/abs/2302.13314v1","updated":"2023-02-26T13:13:51Z","published":"2023-02-26T13:13:51Z","title":"Data-Efficient Sequence-Based Visual Place Recognition with Highly\n  Compressed JPEG Images","summary":"  Visual Place Recognition (VPR) is a fundamental task that allows a robotic\nplatform to successfully localise itself in the environment. For decentralised\nVPR applications where the visual data has to be transmitted between several\nagents, the communication channel may restrict the localisation process when\nlimited bandwidth is available. JPEG is an image compression standard that can\nemploy high compression ratios to facilitate lower data transmission for VPR\napplications. However, when applying high levels of JPEG compression, both the\nimage clarity and size are drastically reduced. In this paper, we incorporate\nsequence-based filtering in a number of well-established, learnt and non-learnt\nVPR techniques to overcome the performance loss resulted from introducing high\nlevels of JPEG compression. The sequence length that enables 100% place\nmatching performance is reported and an analysis of the amount of data required\nfor each VPR technique to perform the transfer on the entire spectrum of JPEG\ncompression is provided. Moreover, the time required by each VPR technique to\nperform place matching is investigated, on both uniformly and non-uniformly\nJPEG compressed data. The results show that it is beneficial to use a highly\ncompressed JPEG dataset with an increased sequence length, as similar levels of\nVPR performance are reported at a significantly reduced bandwidth. The results\npresented in this paper also emphasize that there is a trade-off between the\namount of data transferred and the total time required to perform VPR. Our\nexperiments also suggest that is often favourable to compress the query images\nto the same quality of the map, as more efficient place matching can be\nperformed. The experiments are conducted on several VPR datasets, under mild to\nextreme JPEG compression.\n","authors":["Mihnea-Alexandru Tomita","Bruno Ferrarini","Michael Milford","Klaus McDonald-Maier","Shoaib Ehsan"],"pdf_url":"https://arxiv.org/pdf/2302.13314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.16107v3","updated":"2023-02-26T13:06:56Z","published":"2021-03-30T06:41:42Z","title":"Large Scale Visual Food Recognition","summary":"  Food recognition plays an important role in food choice and intake, which is\nessential to the health and well-being of humans. It is thus of importance to\nthe computer vision community, and can further support many food-oriented\nvision and multimodal tasks. Unfortunately, we have witnessed remarkable\nadvancements in generic visual recognition for released large-scale datasets,\nyet largely lags in the food domain. In this paper, we introduce Food2K, which\nis the largest food recognition dataset with 2,000 categories and over 1\nmillion images.Compared with existing food recognition datasets, Food2K\nbypasses them in both categories and images by one order of magnitude, and thus\nestablishes a new challenging benchmark to develop advanced models for food\nvisual representation learning. Furthermore, we propose a deep progressive\nregion enhancement network for food recognition, which mainly consists of two\ncomponents, namely progressive local feature learning and region feature\nenhancement. The former adopts improved progressive training to learn diverse\nand complementary local features, while the latter utilizes self-attention to\nincorporate richer context with multiple scales into local features for further\nlocal feature enhancement. Extensive experiments on Food2K demonstrate the\neffectiveness of our proposed method. More importantly, we have verified better\ngeneralization ability of Food2K in various tasks, including food recognition,\nfood image retrieval, cross-modal recipe retrieval, food detection and\nsegmentation. Food2K can be further explored to benefit more food-relevant\ntasks including emerging and more complex ones (e.g., nutritional understanding\nof food), and the trained models on Food2K can be expected as backbones to\nimprove the performance of more food-relevant tasks. We also hope Food2K can\nserve as a large scale fine-grained visual recognition benchmark.\n","authors":["Weiqing Min","Zhiling Wang","Yuxin Liu","Mengjiang Luo","Liping Kang","Xiaoming Wei","Xiaolin Wei","Shuqiang Jiang"],"pdf_url":"https://arxiv.org/pdf/2103.16107v3.pdf","comment":"Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence"},{"id":"http://arxiv.org/abs/2212.07555v3","updated":"2023-02-26T12:38:55Z","published":"2022-12-14T23:59:24Z","title":"IMos: Intent-Driven Full-Body Motion Synthesis for Human-Object\n  Interactions","summary":"  Can we make virtual characters in a scene interact with their surrounding\nobjects through simple instructions? Is it possible to synthesize such motion\nplausibly with a diverse set of objects and instructions? Inspired by these\nquestions, we present the first framework to synthesize the full-body motion of\nvirtual human characters performing specified actions with 3D objects placed\nwithin their reach. Our system takes textual instructions specifying the\nobjects and the associated intentions of the virtual characters as input and\noutputs diverse sequences of full-body motions. This contrasts existing works,\nwhere full-body action synthesis methods generally do not consider object\ninteractions, and human-object interaction methods focus mainly on synthesizing\nhand or finger movements for grasping objects. We accomplish our objective by\ndesigning an intent-driven fullbody motion generator, which uses a pair of\ndecoupled conditional variational auto-regressors to learn the motion of the\nbody parts in an autoregressive manner. We also optimize the 6-DoF pose of the\nobjects such that they plausibly fit within the hands of the synthesized\ncharacters. We compare our proposed method with the existing methods of motion\nsynthesis and establish a new and stronger state-of-the-art for the task of\nintent-driven motion synthesis.\n","authors":["Anindita Ghosh","Rishabh Dabral","Vladislav Golyanik","Christian Theobalt","Philipp Slusallek"],"pdf_url":"https://arxiv.org/pdf/2212.07555v3.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2112.00384v3","updated":"2023-02-26T12:28:02Z","published":"2021-12-01T10:08:24Z","title":"Exploration into Translation-Equivariant Image Quantization","summary":"  This is an exploratory study that discovers the current image quantization\n(vector quantization) do not satisfy translation equivariance in the quantized\nspace due to aliasing. Instead of focusing on anti-aliasing, we propose a\nsimple yet effective way to achieve translation-equivariant image quantization\nby enforcing orthogonality among the codebook embeddings. To explore the\nadvantages of translation-equivariant image quantization, we conduct three\nproof-of-concept experiments with a carefully controlled dataset: (1)\ntext-to-image generation, where the quantized image indices are the target to\npredict, (2) image-to-text generation, where the quantized image indices are\ngiven as a condition, (3) using a smaller training set to analyze sample\nefficiency. From the strictly controlled experiments, we empirically verify\nthat the translation-equivariant image quantizer improves not only sample\nefficiency but also the accuracy over VQGAN up to +11.9% in text-to-image\ngeneration and +3.9% in image-to-text generation.\n","authors":["Woncheol Shin","Gyubok Lee","Jiyoung Lee","Eunyi Lyou","Joonseok Lee","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2112.00384v3.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.13301v1","updated":"2023-02-26T12:07:25Z","published":"2023-02-26T12:07:25Z","title":"Pillar R-CNN for Point Cloud 3D Object Detection","summary":"  The performance of point cloud 3D object detection hinges on effectively\nrepresenting raw points, grid-based voxels or pillars. Recent two-stage 3D\ndetectors typically take the point-voxel-based R-CNN paradigm, i.e., the first\nstage resorts to the 3D voxel-based backbone for 3D proposal generation on\nbird-eye-view (BEV) representation and the second stage refines them via the\nintermediate point representation. Their primary mechanisms involve the\nutilization of intermediary keypoints to restore the substantial 3D structure\ncontext from the converted BEV representation. The skilled point-voxel feature\ninteraction, however, makes the entire detection pipeline more complex and\ncompute-intensive. In this paper, we take a different viewpoint -- the\npillar-based BEV representation owns sufficient capacity to preserve the 3D\nstructure. In light of the latest advances in BEV-based perception, we devise a\nconceptually simple yet effective two-stage 3D detection architecture, named\nPillar R-CNN. On top of densified BEV feature maps, Pillar R-CNN can easily\nintroduce the feature pyramid architecture to generate 3D proposals at various\nscales and take the simple 2D R-CNN style detect head for box refinement. Our\nPillar R-CNN performs favorably against state-of-the-art 3D detectors on the\nlarge-scale Waymo Open Dataset but at a small extra cost. It should be\nhighlighted that further exploration into BEV perception for applications\ninvolving autonomous driving is now possible thanks to the effective and\nelegant Pillar R-CNN architecture.\n","authors":["Guangsheng Shi","Ruifeng Li","Chao Ma"],"pdf_url":"https://arxiv.org/pdf/2302.13301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06908v2","updated":"2023-02-26T11:03:38Z","published":"2023-02-14T08:51:47Z","title":"DiffFaceSketch: High-Fidelity Face Image Synthesis with Sketch-Guided\n  Latent Diffusion Model","summary":"  Synthesizing face images from monochrome sketches is one of the most\nfundamental tasks in the field of image-to-image translation. However, it is\nstill challenging to (1)~make models learn the high-dimensional face features\nsuch as geometry and color, and (2)~take into account the characteristics of\ninput sketches. Existing methods often use sketches as indirect inputs (or as\nauxiliary inputs) to guide the models, resulting in the loss of sketch features\nor the alteration of geometry information. In this paper, we introduce a\nSketch-Guided Latent Diffusion Model (SGLDM), an LDM-based network architect\ntrained on the paired sketch-face dataset. We apply a Multi-Auto-Encoder (AE)\nto encode the different input sketches from different regions of a face from\npixel space to a feature map in latent space, which enables us to reduce the\ndimension of the sketch input while preserving the geometry-related information\nof local face details. We build a sketch-face paired dataset based on the\nexisting method that extracts the edge map from an image. We then introduce a\nStochastic Region Abstraction (SRA), an approach to augment our dataset to\nimprove the robustness of SGLDM to handle sketch input with arbitrary\nabstraction. The evaluation study shows that SGLDM can synthesize high-quality\nface images with different expressions, facial accessories, and hairstyles from\nvarious sketches with different abstraction levels.\n","authors":["Yichen Peng","Chunqi Zhao","Haoran Xie","Tsukasa Fukusato","Kazunori Miyata"],"pdf_url":"https://arxiv.org/pdf/2302.06908v2.pdf","comment":"10 pages, 12 figures, and 2 tables, project page:\n  https://puckikk1202.github.io/difffacesketch2023/"},{"id":"http://arxiv.org/abs/2302.13293v1","updated":"2023-02-26T11:02:34Z","published":"2023-02-26T11:02:34Z","title":"PDIWS: Thermal Imaging Dataset for Person Detection in Intrusion Warning\n  Systems","summary":"  In this paper, we present a synthetic thermal imaging dataset for Person\nDetection in Intrusion Warning Systems (PDIWS). The dataset consists of a\ntraining set with 2000 images and a test set with 500 images. Each image is\nsynthesized by compounding a subject (intruder) with a background using the\nmodified Poisson image editing method. There are a total of 50 different\nbackgrounds and nearly 1000 subjects divided into five classes according to\nfive human poses: creeping, crawling, stooping, climbing and other. The\npresence of the intruder will be confirmed if the first four poses are\ndetected. Advanced object detection algorithms have been implemented with this\ndataset and give relatively satisfactory results, with the highest mAP values\nof 95.5% and 90.9% for IoU of 0.5 and 0.75 respectively. The dataset is freely\npublished online for research purposes at\nhttps://github.com/thuan-researcher/Intruder-Thermal-Dataset.\n","authors":["Nguyen Duc Thuan","Le Hai Anh","Hoang Si Hong"],"pdf_url":"https://arxiv.org/pdf/2302.13293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13288v1","updated":"2023-02-26T10:39:08Z","published":"2023-02-26T10:39:08Z","title":"Learning Pairwise Interaction for Generalizable DeepFake Detection","summary":"  A fast-paced development of DeepFake generation techniques challenge the\ndetection schemes designed for known type DeepFakes. A reliable Deepfake\ndetection approach must be agnostic to generation types, which can present\ndiverse quality and appearance. Limited generalizability across different\ngeneration schemes will restrict the wide-scale deployment of detectors if they\nfail to handle unseen attacks in an open set scenario. We propose a new\napproach, Multi-Channel Xception Attention Pairwise Interaction (MCX-API), that\nexploits the power of pairwise learning and complementary information from\ndifferent color space representations in a fine-grained manner. We first\nvalidate our idea on a publicly available dataset in a intra-class setting\n(closed set) with four different Deepfake schemes. Further, we report all the\nresults using balanced-open-set-classification (BOSC) accuracy in an\ninter-class setting (open-set) using three public datasets. Our experiments\nindicate that our proposed method can generalize better than the\nstate-of-the-art Deepfakes detectors. We obtain 98.48% BOSC accuracy on the\nFF++ dataset and 90.87% BOSC accuracy on the CelebDF dataset suggesting a\npromising direction for generalization of DeepFake detection. We further\nutilize t-SNE and attention maps to interpret and visualize the decision-making\nprocess of our proposed network. https://github.com/xuyingzhongguo/MCX-API\n","authors":["Ying Xu","Kiran Raja","Luisa Verdoliva","Marius Pedersen"],"pdf_url":"https://arxiv.org/pdf/2302.13288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13286v1","updated":"2023-02-26T10:35:45Z","published":"2023-02-26T10:35:45Z","title":"Benchmarking of Cancelable Biometrics for Deep Templates","summary":"  In this paper, we benchmark several cancelable biometrics (CB) schemes on\ndifferent biometric characteristics. We consider BioHashing, Multi-Layer\nPerceptron (MLP) Hashing, Bloom Filters, and two schemes based on\nIndex-of-Maximum (IoM) Hashing (i.e., IoM-URP and IoM-GRP). In addition to the\nmentioned CB schemes, we introduce a CB scheme (as a baseline) based on\nuser-specific random transformations followed by binarization. We evaluate the\nunlinkability, irreversibility, and recognition performance (which are the\nrequired criteria by the ISO/IEC 24745 standard) of these CB schemes on deep\nlearning based templates extracted from different physiological and behavioral\nbiometric characteristics including face, voice, finger vein, and iris. In\naddition, we provide an open-source implementation of all the experiments\npresented to facilitate the reproducibility of our results.\n","authors":["Hatef Otroshi Shahreza","Pietro Melzi","Dailé Osorio-Roig","Christian Rathgeb","Christoph Busch","Sébastien Marcel","Ruben Tolosana","Ruben Vera-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2302.13286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13279v1","updated":"2023-02-26T09:48:57Z","published":"2023-02-26T09:48:57Z","title":"Makeup Extraction of 3D Representation via Illumination-Aware Image\n  Decomposition","summary":"  Facial makeup enriches the beauty of not only real humans but also virtual\ncharacters; therefore, makeup for 3D facial models is highly in demand in\nproductions. However, painting directly on 3D faces and capturing real-world\nmakeup are costly, and extracting makeup from 2D images often struggles with\nshading effects and occlusions. This paper presents the first method for\nextracting makeup for 3D facial models from a single makeup portrait. Our\nmethod consists of the following three steps. First, we exploit the strong\nprior of 3D morphable models via regression-based inverse rendering to extract\ncoarse materials such as geometry and diffuse/specular albedos that are\nrepresented in the UV space. Second, we refine the coarse materials, which may\nhave missing pixels due to occlusions. We apply inpainting and optimization.\nFinally, we extract the bare skin, makeup, and an alpha matte from the diffuse\nalbedo. Our method offers various applications for not only 3D facial models\nbut also 2D portrait images. The extracted makeup is well-aligned in the UV\nspace, from which we build a large-scale makeup dataset and a parametric makeup\nmodel for 3D faces. Our disentangled materials also yield robust makeup\ntransfer and illumination-aware makeup interpolation/removal without a\nreference image.\n","authors":["Xingchao Yang","Takafumi Taketomi","Yoshihiro Kanamori"],"pdf_url":"https://arxiv.org/pdf/2302.13279v1.pdf","comment":"Eurographics 2023"},{"id":"http://arxiv.org/abs/2302.13275v1","updated":"2023-02-26T09:00:35Z","published":"2023-02-26T09:00:35Z","title":"Learning cross space mapping via DNN using large scale click-through\n  logs","summary":"  The gap between low-level visual signals and high-level semantics has been\nprogressively bridged by continuous development of deep neural network (DNN).\nWith recent progress of DNN, almost all image classification tasks have\nachieved new records of accuracy. To extend the ability of DNN to image\nretrieval tasks, we proposed a unified DNN model for image-query similarity\ncalculation by simultaneously modeling image and query in one network. The\nunified DNN is named the cross space mapping (CSM) model, which contains two\nparts, a convolutional part and a query-embedding part. The image and query are\nmapped to a common vector space via these two parts respectively, and\nimage-query similarity is naturally defined as an inner product of their\nmappings in the space. To ensure good generalization ability of the DNN, we\nlearn weights of the DNN from a large number of click-through logs which\nconsists of 23 million clicked image-query pairs between 1 million images and\n11.7 million queries. Both the qualitative results and quantitative results on\nan image retrieval evaluation task with 1000 queries demonstrate the\nsuperiority of the proposed method.\n","authors":["Wei Yu","Kuiyuan Yang","Yalong Bai","Hongxun Yao","Yong Rui"],"pdf_url":"https://arxiv.org/pdf/2302.13275v1.pdf","comment":"Accepted by IEEE Transactions on Multimedia 2015"},{"id":"http://arxiv.org/abs/2302.12172v2","updated":"2023-02-26T08:53:09Z","published":"2023-02-23T17:13:25Z","title":"Unified Chest X-ray and Radiology Report Generation Model with\n  Multi-view Chest X-rays","summary":"  Generated synthetic data in medical research can substitute privacy and\nsecurity-sensitive data with a large-scale curated dataset, reducing data\ncollection and annotation costs. As part of this effort, we propose UniXGen, a\nunified chest X-ray and report generation model, with the following\ncontributions. First, we design a unified model for bidirectional chest X-ray\nand report generation by adopting a vector quantization method to discretize\nchest X-rays into discrete visual tokens and formulating both tasks as sequence\ngeneration tasks. Second, we introduce several special tokens to generate chest\nX-rays with specific views that can be useful when the desired views are\nunavailable. Furthermore, UniXGen can flexibly take various inputs from single\nto multiple views to take advantage of the additional findings available in\nother X-ray views. We adopt an efficient transformer for computational and\nmemory efficiency to handle the long-range input sequence of multi-view chest\nX-rays with high resolution and long paragraph reports. In extensive\nexperiments, we show that our unified model has a synergistic effect on both\ngeneration tasks, as opposed to training only the task-specific models. We also\nfind that view-specific special tokens can distinguish between different views\nand properly generate specific views even if they do not exist in the dataset,\nand utilizing multi-view chest X-rays can faithfully capture the abnormal\nfindings in the additional X-rays. The source code is publicly available at:\nhttps://github.com/ttumyche/UniXGen.\n","authors":["Hyungyung Lee","Wonjae Kim","Jin-Hwa Kim","Tackeun Kim","Jihang Kim","Leonard Sunwoo","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2302.12172v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13269v1","updated":"2023-02-26T08:46:07Z","published":"2023-02-26T08:46:07Z","title":"Exploring Opinion-unaware Video Quality Assessment with Semantic\n  Affinity Criterion","summary":"  Recent learning-based video quality assessment (VQA) algorithms are expensive\nto implement due to the cost of data collection of human quality opinions, and\nare less robust across various scenarios due to the biases of these opinions.\nThis motivates our exploration on opinion-unaware (a.k.a zero-shot) VQA\napproaches. Existing approaches only considers low-level naturalness in spatial\nor temporal domain, without considering impacts from high-level semantics. In\nthis work, we introduce an explicit semantic affinity index for opinion-unaware\nVQA using text-prompts in the contrastive language-image pre-training (CLIP)\nmodel. We also aggregate it with different traditional low-level naturalness\nindexes through gaussian normalization and sigmoid rescaling strategies.\nComposed of aggregated semantic and technical metrics, the proposed Blind\nUnified Opinion-Unaware Video Quality Index via Semantic and Technical Metric\nAggregation (BUONA-VISTA) outperforms existing opinion-unaware VQA methods by\nat least 20% improvements, and is more robust than opinion-aware approaches.\n","authors":["Haoning Wu","Liang Liao","Jingwen Hou","Chaofeng Chen","Erli Zhang","Annan Wang","Wenxiu Sun","Qiong Yan","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2302.13269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13263v1","updated":"2023-02-26T08:26:26Z","published":"2023-02-26T08:26:26Z","title":"PaRK-Detect: Towards Efficient Multi-Task Satellite Imagery Road\n  Extraction via Patch-Wise Keypoints Detection","summary":"  Automatically extracting roads from satellite imagery is a fundamental yet\nchallenging computer vision task in the field of remote sensing. Pixel-wise\nsemantic segmentation-based approaches and graph-based approaches are two\nprevailing schemes. However, prior works show the imperfections that semantic\nsegmentation-based approaches yield road graphs with low connectivity, while\ngraph-based methods with iterative exploring paradigms and smaller receptive\nfields focus more on local information and are also time-consuming. In this\npaper, we propose a new scheme for multi-task satellite imagery road\nextraction, Patch-wise Road Keypoints Detection (PaRK-Detect). Building on top\nof D-LinkNet architecture and adopting the structure of keypoint detection, our\nframework predicts the position of patch-wise road keypoints and the adjacent\nrelationships between them to construct road graphs in a single pass.\nMeanwhile, the multi-task framework also performs pixel-wise semantic\nsegmentation and generates road segmentation masks. We evaluate our approach\nagainst the existing state-of-the-art methods on DeepGlobe, Massachusetts\nRoads, and RoadTracer datasets and achieve competitive or better results. We\nalso demonstrate a considerable outperformance in terms of inference speed.\n","authors":["Shenwei Xie","Wanfeng Zheng","Zhenglin Xian","Junli Yang","Chuang Zhang","Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2302.13263v1.pdf","comment":"Accepted at BMVC 2022 (Oral). 13 pages, 5 figures.\n  https://bmvc2022.mpi-inf.mpg.de/381/"},{"id":"http://arxiv.org/abs/2209.09489v4","updated":"2023-02-26T08:22:09Z","published":"2022-09-20T06:02:57Z","title":"Perceptual Quality Assessment for Digital Human Heads","summary":"  Digital humans are attracting more and more research interest during the last\ndecade, the generation, representation, rendering, and animation of which have\nbeen put into large amounts of effort. However, the quality assessment of\ndigital humans has fallen behind. Therefore, to tackle the challenge of digital\nhuman quality assessment issues, we propose the first large-scale quality\nassessment database for three-dimensional (3D) scanned digital human heads\n(DHHs). The constructed database consists of 55 reference DHHs and 1,540\ndistorted DHHs along with the subjective perceptual ratings. Then, a simple yet\neffective full-reference (FR) projection-based method is proposed to evaluate\nthe visual quality of DHHs. The pretrained Swin Transformer tiny is employed\nfor hierarchical feature extraction and the multi-head attention module is\nutilized for feature fusion. The experimental results reveal that the proposed\nmethod exhibits state-of-the-art performance among the mainstream FR metrics.\nThe database is released at https://github.com/zzc-1998/DHHQA.\n","authors":["Zicheng Zhang","Yingjie Zhou","Wei Sun","Xiongkuo Min","Yuzhe Wu","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2209.09489v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13256v1","updated":"2023-02-26T08:02:39Z","published":"2023-02-26T08:02:39Z","title":"Continuous Space-Time Video Super-Resolution Utilizing Long-Range\n  Temporal Information","summary":"  In this paper, we consider the task of space-time video super-resolution\n(ST-VSR), namely, expanding a given source video to a higher frame rate and\nresolution simultaneously. However, most existing schemes either consider a\nfixed intermediate time and scale in the training stage or only accept a preset\nnumber of input frames (e.g., two adjacent frames) that fails to exploit\nlong-range temporal information. To address these problems, we propose a\ncontinuous ST-VSR (C-STVSR) method that can convert the given video to any\nframe rate and spatial resolution. To achieve time-arbitrary interpolation, we\npropose a forward warping guided frame synthesis module and an\noptical-flow-guided context consistency loss to better approximate extreme\nmotion and preserve similar structures among input and prediction frames. In\naddition, we design a memory-friendly cascading depth-to-space module to\nrealize continuous spatial upsampling. Meanwhile, with the sophisticated\nreorganization of optical flow, the proposed method is memory friendly, making\nit possible to propagate information from long-range neighboring frames and\nachieve better reconstruction quality. Extensive experiments show that the\nproposed algorithm has good flexibility and achieves better performance on\nvarious datasets compared with the state-of-the-art methods in both objective\nevaluations and subjective visual effects.\n","authors":["Yuantong Zhang","Daiqin Yang","Zhenzhong Chen","Wenpeng Ding"],"pdf_url":"https://arxiv.org/pdf/2302.13256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05970v3","updated":"2023-02-26T07:19:18Z","published":"2022-06-13T08:33:14Z","title":"Hypernetwork-Based Adaptive Image Restoration","summary":"  Adaptive image restoration models can restore images with different\ndegradation levels at inference time without the need to retrain the model. We\npresent an approach that is highly accurate and allows a significant reduction\nin the number of parameters. In contrast to existing methods, our approach can\nrestore images using a single fixed-size model, regardless of the number of\ndegradation levels. On popular datasets, our approach yields state-of-the-art\nresults in terms of size and accuracy for a variety of image restoration tasks,\nincluding denoising, deJPEG, and super-resolution.\n","authors":["Shai Aharon","Gil Ben-Artzi"],"pdf_url":"https://arxiv.org/pdf/2206.05970v3.pdf","comment":"5 pages, 5 Figures, ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.13251v1","updated":"2023-02-26T07:10:09Z","published":"2023-02-26T07:10:09Z","title":"Robust Cross-domain CT Image Reconstruction via Bayesian Noise\n  Uncertainty Alignment","summary":"  In this work, we tackle the problem of robust computed tomography (CT)\nreconstruction issue under a cross-domain scenario, i.e., the training CT data\nas the source domain and the testing CT data as the target domain are collected\nfrom different anatomical regions. Due to the mismatches of the scan region and\ncorresponding scan protocols, there is usually a difference of noise\ndistributions between source and target domains (a.k.a. noise distribution\nshifts), resulting in a catastrophic deterioration of the reconstruction\nperformance on target domain. To render a robust cross-domain CT reconstruction\nperformance, instead of using deterministic models (e.g., convolutional neural\nnetwork), a Bayesian-endowed probabilistic framework is introduced into robust\ncross-domain CT reconstruction task due to its impressive robustness. Under\nthis probabilistic framework, we propose to alleviate the noise distribution\nshifts between source and target domains via implicit noise modeling schemes in\nthe latent space and image space, respectively. Specifically, a novel Bayesian\nnoise uncertainty alignment (BNUA) method is proposed to conduct implicit noise\ndistribution modeling and alignment in the latent space. Moreover, an\nadversarial learning manner is imposed to reduce the discrepancy of noise\ndistribution between two domains in the image space via a novel residual\ndistribution alignment (RDA). Extensive experiments on the head and abdomen\nscans show that our proposed method can achieve a better performance of robust\ncross-domain CT reconstruction than existing approaches in terms of both\nquantitative and qualitative results.\n","authors":["Kecheng Chen","Haoliang Li","Renjie Wan","Hong Yan"],"pdf_url":"https://arxiv.org/pdf/2302.13251v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2112.02250v2","updated":"2023-02-26T04:54:44Z","published":"2021-12-04T05:38:50Z","title":"Dense Extreme Inception Network for Edge Detection","summary":"  <<<This is a pre-acceptance version, please, go through Pattern Recognition\nJournal on Sciencedirect to read the final version>>>. Edge detection is the\nbasis of many computer vision applications. State of the art predominantly\nrelies on deep learning with two decisive factors: dataset content and\nnetwork's architecture. Most of the publicly available datasets are not curated\nfor edge detection tasks. Here, we offer a solution to this constraint. First,\nwe argue that edges, contours and boundaries, despite their overlaps, are three\ndistinct visual features requiring separate benchmark datasets. To this end, we\npresent a new dataset of edges. Second, we propose a novel architecture, termed\nDense Extreme Inception Network for Edge Detection (DexiNed), that can be\ntrained from scratch without any pre-trained weights. DexiNed outperforms other\nalgorithms in the presented dataset. It also generalizes well to other datasets\nwithout any fine-tuning. The higher quality of DexiNed is also perceptually\nevident thanks to the sharper and finer edges it outputs.\n","authors":["Xavier Soria","Angel Sappa","Patricio Humanante","Arash Akbarinia"],"pdf_url":"https://arxiv.org/pdf/2112.02250v2.pdf","comment":"Manuscript published by Pattern Recognition journal in 2023"},{"id":"http://arxiv.org/abs/2208.01838v2","updated":"2023-02-26T03:54:20Z","published":"2022-08-03T04:34:28Z","title":"Re-Attention Transformer for Weakly Supervised Object Localization","summary":"  Weakly supervised object localization is a challenging task which aims to\nlocalize objects with coarse annotations such as image categories. Existing\ndeep network approaches are mainly based on class activation map, which focuses\non highlighting discriminative local region while ignoring the full object. In\naddition, the emerging transformer-based techniques constantly put a lot of\nemphasis on the backdrop that impedes the ability to identify complete objects.\nTo address these issues, we present a re-attention mechanism termed token\nrefinement transformer (TRT) that captures the object-level semantics to guide\nthe localization well. Specifically, TRT introduces a novel module named token\npriority scoring module (TPSM) to suppress the effects of background noise\nwhile focusing on the target object. Then, we incorporate the class activation\nmap as the semantically aware input to restrain the attention map to the target\nobject. Extensive experiments on two benchmarks showcase the superiority of our\nproposed method against existing methods with image category annotations.\nSource code is available in\n\\url{https://github.com/su-hui-zz/ReAttentionTransformer}.\n","authors":["Hui Su","Yue Ye","Zhiwei Chen","Mingli Song","Lechao Cheng"],"pdf_url":"https://arxiv.org/pdf/2208.01838v2.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.13207v1","updated":"2023-02-26T02:20:18Z","published":"2023-02-26T02:20:18Z","title":"Stereo X-ray Tomography","summary":"  X-ray tomography is a powerful volumetric imaging technique, but detailed\nthree dimensional (3D) imaging requires the acquisition of a large number of\nindividual X-ray images, which is time consuming. For applications where\nspatial information needs to be collected quickly, for example, when studying\ndynamic processes, standard X-ray tomography is therefore not applicable.\nInspired by stereo vision, in this paper, we develop X-ray imaging methods that\nwork with two X-ray projection images. In this setting, without the use of\nadditional strong prior information, we no longer have enough information to\nfully recover the 3D tomographic images. However, up to a point, we are\nnevertheless able to extract spatial locations of point and line features. From\nstereo vision, it is well known that, for a known imaging geometry, once the\nsame point is identified in two images taken from different directions, then\nthe point's location in 3D space is exactly specified. The challenge is the\nmatching of points between images. As X-ray transmission images are\nfundamentally different from the surface reflection images used in standard\ncomputer vision, we here develop a different feature identification and\nmatching approach. In fact, once point like features are identified, if there\nare limited points in the image, then they can often be matched exactly. In\nfact, by utilising a third observation from an appropriate direction, matching\nbecomes unique. Once matched, point locations in 3D space are easily computed\nusing geometric considerations. Linear features, with clear end points, can be\nlocated using a similar approach.\n","authors":["Zhenduo Shang","Thomas Blumensath"],"pdf_url":"https://arxiv.org/pdf/2302.13207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11557v2","updated":"2023-02-26T00:34:58Z","published":"2023-02-22T18:53:57Z","title":"K-Diag: Knowledge-enhanced Disease Diagnosis in Radiographic Imaging","summary":"  In this paper, we consider the problem of disease diagnosis. Unlike the\nconventional learning paradigm that treats labels independently, we propose a\nknowledge-enhanced framework, that enables training visual representation with\nthe guidance of medical domain knowledge. In particular, we make the following\ncontributions: First, to explicitly incorporate experts' knowledge, we propose\nto learn a neural representation for the medical knowledge graph via\ncontrastive learning, implicitly establishing relations between different\nmedical concepts. Second, while training the visual encoder, we keep the\nparameters of the knowledge encoder frozen and propose to learn a set of prompt\nvectors for efficient adaptation. Third, we adopt a Transformer-based\ndisease-query module for cross-model fusion, which naturally enables\nexplainable diagnosis results via cross attention. To validate the\neffectiveness of our proposed framework, we conduct thorough experiments on\nthree x-ray imaging datasets across different anatomy structures, showing our\nmodel is able to exploit the implicit relations between diseases/findings, thus\nis beneficial to the commonly encountered problem in the medical domain,\nnamely, long-tailed and zero-shot recognition, which conventional methods\neither struggle or completely fail to realize.\n","authors":["Chaoyi Wu","Xiaoman Zhang","Yanfeng Wang","Ya Zhang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2302.11557v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.13403v1","updated":"2023-02-26T20:55:19Z","published":"2023-02-26T20:55:19Z","title":"Tweets Under the Rubble: Detection of Messages Calling for Help in\n  Earthquake Disaster","summary":"  The importance of social media is again exposed in the recent tragedy of the\n2023 Turkey and Syria earthquake. Many victims who were trapped under the\nrubble called for help by posting messages in Twitter. We present an\ninteractive tool to provide situational awareness for missing and trapped\npeople, and disaster relief for rescue and donation efforts. The system (i)\ncollects tweets, (ii) classifies the ones calling for help, (iii) extracts\nimportant entity tags, and (iv) visualizes them in an interactive map screen.\nOur initial experiments show that the performance in terms of the F1 score is\nup to 98.30 for tweet classification, and 84.32 for entity extraction. The\ndemonstration, dataset, and other related files can be accessed at\nhttps://github.com/avaapm/deprem\n","authors":["Cagri Toraman","Izzet Emre Kucukkaya","Oguzhan Ozcelik","Umitcan Sahin"],"pdf_url":"https://arxiv.org/pdf/2302.13403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13400v1","updated":"2023-02-26T20:11:59Z","published":"2023-02-26T20:11:59Z","title":"Cross-lingual Knowledge Transfer via Distillation for Multilingual\n  Information Retrieval","summary":"  In this paper, we introduce the approach behind our submission for the MIRACL\nchallenge, a WSDM 2023 Cup competition that centers on ad-hoc retrieval across\n18 diverse languages. Our solution contains two neural-based models. The first\nmodel is a bi-encoder re-ranker, on which we apply a cross-lingual distillation\ntechnique to transfer ranking knowledge from English to the target language\nspace. The second model is a cross-encoder re-ranker trained on multilingual\nretrieval data generated using neural machine translation. We further fine-tune\nboth models using MIRACL training data and ensemble multiple rank lists to\nobtain the final result. According to the MIRACL leaderboard, our approach\nranks 8th for the Test-A set and 2nd for the Test-B set among the 16 known\nlanguages.\n","authors":["Zhiqi Huang","Puxuan Yu","James Allan"],"pdf_url":"https://arxiv.org/pdf/2302.13400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13401v1","updated":"2023-02-26T20:15:00Z","published":"2023-02-26T20:15:00Z","title":"From Audio to Symbolic Encoding","summary":"  Automatic music transcription (AMT) aims to convert raw audio to symbolic\nmusic representation. As a fundamental problem of music information retrieval\n(MIR), AMT is considered a difficult task even for trained human experts due to\noverlap of multiple harmonics in the acoustic signal. On the other hand, speech\nrecognition, as one of the most popular tasks in natural language processing,\naims to translate human spoken language to texts. Based on the similar nature\nof AMT and speech recognition (as they both deal with tasks of translating\naudio signal to symbolic encoding), this paper investigated whether a generic\nneural network architecture could possibly work on both tasks. In this paper,\nwe introduced our new neural network architecture built on top of the current\nstate-of-the-art Onsets and Frames, and compared the performances of its\nmultiple variations on AMT task. We also tested our architecture with the task\nof speech recognition. For AMT, our models were able to produce better results\ncompared to the model trained using the state-of-art architecture; however,\nalthough similar architecture was able to be trained on the speech recognition\ntask, it did not generate very ideal result compared to other task-specific\nmodels.\n","authors":["Shenli Yuan","Lingjie Kong","Jiushuang Guo"],"pdf_url":"https://arxiv.org/pdf/2302.13401v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.13438v1","updated":"2023-02-26T23:30:18Z","published":"2023-02-26T23:30:18Z","title":"P4L: Privacy Preserving Peer-to-Peer Learning for Infrastructureless\n  Setups","summary":"  Distributed (or Federated) learning enables users to train machine learning\nmodels on their very own devices, while they share only the gradients of their\nmodels usually in a differentially private way (utility loss). Although such a\nstrategy provides better privacy guarantees than the traditional centralized\napproach, it requires users to blindly trust a centralized infrastructure that\nmay also become a bottleneck with the increasing number of users. In this\npaper, we design and implement P4L: a privacy preserving peer-to-peer learning\nsystem for users to participate in an asynchronous, collaborative learning\nscheme without requiring any sort of infrastructure or relying on differential\nprivacy. Our design uses strong cryptographic primitives to preserve both the\nconfidentiality and utility of the shared gradients, a set of peer-to-peer\nmechanisms for fault tolerance and user churn, proximity and cross device\ncommunications. Extensive simulations under different network settings and ML\nscenarios for three real-life datasets show that P4L provides competitive\nperformance to baselines, while it is resilient to different poisoning attacks.\nWe implement P4L and experimental results show that the performance overhead\nand power consumption is minimal (less than 3mAh of discharge).\n","authors":["Ioannis Arapakis","Panagiotis Papadopoulos","Kleomenis Katevas","Diego Perino"],"pdf_url":"https://arxiv.org/pdf/2302.13438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13435v1","updated":"2023-02-26T23:19:11Z","published":"2023-02-26T23:19:11Z","title":"Scalable Weight Reparametrization for Efficient Transfer Learning","summary":"  This paper proposes a novel, efficient transfer learning method, called\nScalable Weight Reparametrization (SWR) that is efficient and effective for\nmultiple downstream tasks. Efficient transfer learning involves utilizing a\npre-trained model trained on a larger dataset and repurposing it for downstream\ntasks with the aim of maximizing the reuse of the pre-trained model. However,\nprevious works have led to an increase in updated parameters and task-specific\nmodules, resulting in more computations, especially for tiny models.\nAdditionally, there has been no practical consideration for controlling the\nnumber of updated parameters. To address these issues, we suggest learning a\npolicy network that can decide where to reparametrize the pre-trained model,\nwhile adhering to a given constraint for the number of updated parameters. The\npolicy network is only used during the transfer learning process and not\nafterward. As a result, our approach attains state-of-the-art performance in a\nproposed multi-lingual keyword spotting and a standard benchmark,\nImageNet-to-Sketch, while requiring zero additional computations and\nsignificantly fewer additional parameters.\n","authors":["Byeonggeun Kim","Jun-Tae Lee","Seunghan yang","Simyung Chang"],"pdf_url":"https://arxiv.org/pdf/2302.13435v1.pdf","comment":"ICASSP2023 Accepted"},{"id":"http://arxiv.org/abs/2210.08645v2","updated":"2023-02-26T23:08:17Z","published":"2022-10-16T21:58:54Z","title":"An efficient deep neural network to find small objects in large 3D\n  images","summary":"  3D imaging enables accurate diagnosis by providing spatial information about\norgan anatomy. However, using 3D images to train AI models is computationally\nchallenging because they consist of 10x or 100x more pixels than their 2D\ncounterparts. To be trained with high-resolution 3D images, convolutional\nneural networks resort to downsampling them or projecting them to 2D. We\npropose an effective alternative, a neural network that enables efficient\nclassification of full-resolution 3D medical images. Compared to off-the-shelf\nconvolutional neural networks, our network, 3D Globally-Aware Multiple Instance\nClassifier (3D-GMIC), uses 77.98%-90.05% less GPU memory and 91.23%-96.02% less\ncomputation. While it is trained only with image-level labels, without\nsegmentation labels, it explains its predictions by providing pixel-level\nsaliency maps. On a dataset collected at NYU Langone Health, including 85,526\npatients with full-field 2D mammography (FFDM), synthetic 2D mammography, and\n3D mammography, 3D-GMIC achieves an AUC of 0.831 (95% CI: 0.769-0.887) in\nclassifying breasts with malignant findings using 3D mammography. This is\ncomparable to the performance of GMIC on FFDM (0.816, 95% CI: 0.737-0.878) and\nsynthetic 2D (0.826, 95% CI: 0.754-0.884), which demonstrates that 3D-GMIC\nsuccessfully classified large 3D images despite focusing computation on a\nsmaller percentage of its input compared to GMIC. Therefore, 3D-GMIC identifies\nand utilizes extremely small regions of interest from 3D images consisting of\nhundreds of millions of pixels, dramatically reducing associated computational\nchallenges. 3D-GMIC generalizes well to BCS-DBT, an external dataset from Duke\nUniversity Hospital, achieving an AUC of 0.848 (95% CI: 0.798-0.896).\n","authors":["Jungkyu Park","Jakub Chłędowski","Stanisław Jastrzębski","Jan Witowski","Yanqi Xu","Linda Du","Sushma Gaddam","Eric Kim","Alana Lewin","Ujas Parikh","Anastasia Plaunova","Sardius Chen","Alexandra Millet","James Park","Kristine Pysarenko","Shalin Patel","Julia Goldberg","Melanie Wegener","Linda Moy","Laura Heacock","Beatriu Reig","Krzysztof J. Geras"],"pdf_url":"https://arxiv.org/pdf/2210.08645v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13434v1","updated":"2023-02-26T23:02:33Z","published":"2023-02-26T23:02:33Z","title":"Spatial-temporal Transformer-guided Diffusion based Data Augmentation\n  for Efficient Skeleton-based Action Recognition","summary":"  Recently, skeleton-based human action has become a hot research topic because\nthe compact representation of human skeletons brings new blood to this research\ndomain. As a result, researchers began to notice the importance of using RGB or\nother sensors to analyze human action by extracting skeleton information.\nLeveraging the rapid development of deep learning (DL), a significant number of\nskeleton-based human action approaches have been presented with fine-designed\nDL structures recently. However, a well-trained DL model always demands\nhigh-quality and sufficient data, which is hard to obtain without costing high\nexpenses and human labor. In this paper, we introduce a novel data augmentation\nmethod for skeleton-based action recognition tasks, which can effectively\ngenerate high-quality and diverse sequential actions. In order to obtain\nnatural and realistic action sequences, we propose denoising diffusion\nprobabilistic models (DDPMs) that can generate a series of synthetic action\nsequences, and their generation process is precisely guided by a\nspatial-temporal transformer (ST-Trans). Experimental results show that our\nmethod outperforms the state-of-the-art (SOTA) motion generation approaches on\ndifferent naturality and diversity metrics. It proves that its high-quality\nsynthetic data can also be effectively deployed to existing action recognition\nmodels with significant performance improvement.\n","authors":["Yifan Jiang","Han Chen","Hanseok Ko"],"pdf_url":"https://arxiv.org/pdf/2302.13434v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.12853v2","updated":"2023-02-26T22:43:40Z","published":"2022-08-26T19:50:46Z","title":"Domain Adaptation with Adversarial Training on Penultimate Activations","summary":"  Enhancing model prediction confidence on target data is an important\nobjective in Unsupervised Domain Adaptation (UDA). In this paper, we explore\nadversarial training on penultimate activations, i.e., input features of the\nfinal linear classification layer. We show that this strategy is more efficient\nand better correlated with the objective of boosting prediction confidence than\nadversarial training on input images or intermediate features, as used in\nprevious works. Furthermore, with activation normalization commonly used in\ndomain adaptation to reduce domain gap, we derive two variants and\nsystematically analyze the effects of normalization on our adversarial\ntraining. This is illustrated both in theory and through empirical analysis on\nreal adaptation tasks. Extensive experiments are conducted on popular UDA\nbenchmarks under both standard setting and source-data free setting. The\nresults validate that our method achieves the best scores against previous\narts. Code is available at https://github.com/tsun/APA.\n","authors":["Tao Sun","Cheng Lu","Haibin Ling"],"pdf_url":"https://arxiv.org/pdf/2208.12853v2.pdf","comment":"AAAI 2023 Oral"},{"id":"http://arxiv.org/abs/2302.13425v1","updated":"2023-02-26T22:30:08Z","published":"2023-02-26T22:30:08Z","title":"A Survey on Uncertainty Quantification Methods for Deep Neural Networks:\n  An Uncertainty Source Perspective","summary":"  Deep neural networks (DNNs) have achieved tremendous success in making\naccurate predictions for computer vision, natural language processing, as well\nas science and engineering domains. However, it is also well-recognized that\nDNNs sometimes make unexpected, incorrect, but overconfident predictions. This\ncan cause serious consequences in high-stake applications, such as autonomous\ndriving, medical diagnosis, and disaster response. Uncertainty quantification\n(UQ) aims to estimate the confidence of DNN predictions beyond prediction\naccuracy. In recent years, many UQ methods have been developed for DNNs. It is\nof great practical value to systematically categorize these UQ methods and\ncompare their advantages and disadvantages. However, existing surveys mostly\nfocus on categorizing UQ methodologies from a neural network architecture\nperspective or a Bayesian perspective and ignore the source of uncertainty that\neach methodology can incorporate, making it difficult to select an appropriate\nUQ method in practice. To fill the gap, this paper presents a systematic\ntaxonomy of UQ methods for DNNs based on the types of uncertainty sources (data\nuncertainty versus model uncertainty). We summarize the advantages and\ndisadvantages of methods in each category. We show how our taxonomy of UQ\nmethodologies can potentially help guide the choice of UQ method in different\nmachine learning problems (e.g., active learning, robustness, and reinforcement\nlearning). We also identify current research gaps and propose several future\nresearch directions.\n","authors":["Wenchong He","Zhe Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.13425v1.pdf","comment":"39 pages, 14 figures"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.13321v1","updated":"2023-02-26T13:38:42Z","published":"2023-02-26T13:38:42Z","title":"Multi-Modality in Music: Predicting Emotion in Music from High-Level\n  Audio Features and Lyrics","summary":"  This paper aims to test whether a multi-modal approach for music emotion\nrecognition (MER) performs better than a uni-modal one on high-level song\nfeatures and lyrics. We use 11 song features retrieved from the Spotify API,\ncombined lyrics features including sentiment, TF-IDF, and Anew to predict\nvalence and arousal (Russell, 1980) scores on the Deezer Mood Detection Dataset\n(DMDD) (Delbouys et al., 2018) with 4 different regression models. We find that\nout of the 11 high-level song features, mainly 5 contribute to the performance,\nmulti-modal features do better than audio alone when predicting valence. We\nmade our code publically available.\n","authors":["Tibor Krols","Yana Nikolova","Ninell Oldenburg"],"pdf_url":"https://arxiv.org/pdf/2302.13321v1.pdf","comment":"12 pages, incl. 2 pages appendix"},{"id":"http://arxiv.org/abs/2302.13311v1","updated":"2023-02-26T13:04:04Z","published":"2023-02-26T13:04:04Z","title":"Understanding Social Media Cross-Modality Discourse in Linguistic Space","summary":"  The multimedia communications with texts and images are popular on social\nmedia. However, limited studies concern how images are structured with texts to\nform coherent meanings in human cognition. To fill in the gap, we present a\nnovel concept of cross-modality discourse, reflecting how human readers couple\nimage and text understandings. Text descriptions are first derived from images\n(named as subtitles) in the multimedia contexts. Five labels -- entity-level\ninsertion, projection and concretization and scene-level restatement and\nextension -- are further employed to shape the structure of subtitles and texts\nand present their joint meanings. As a pilot study, we also build the very\nfirst dataset containing 16K multimedia tweets with manually annotated\ndiscourse labels. The experimental results show that the multimedia encoder\nbased on multi-head attention with captions is able to obtain\nthe-state-of-the-art results.\n","authors":["Chunpu Xu","Hanzhuo Tan","Jing Li","Piji Li"],"pdf_url":"https://arxiv.org/pdf/2302.13311v1.pdf","comment":"EMNLP 2022 Findings"},{"id":"http://arxiv.org/abs/2302.06908v2","updated":"2023-02-26T11:03:38Z","published":"2023-02-14T08:51:47Z","title":"DiffFaceSketch: High-Fidelity Face Image Synthesis with Sketch-Guided\n  Latent Diffusion Model","summary":"  Synthesizing face images from monochrome sketches is one of the most\nfundamental tasks in the field of image-to-image translation. However, it is\nstill challenging to (1)~make models learn the high-dimensional face features\nsuch as geometry and color, and (2)~take into account the characteristics of\ninput sketches. Existing methods often use sketches as indirect inputs (or as\nauxiliary inputs) to guide the models, resulting in the loss of sketch features\nor the alteration of geometry information. In this paper, we introduce a\nSketch-Guided Latent Diffusion Model (SGLDM), an LDM-based network architect\ntrained on the paired sketch-face dataset. We apply a Multi-Auto-Encoder (AE)\nto encode the different input sketches from different regions of a face from\npixel space to a feature map in latent space, which enables us to reduce the\ndimension of the sketch input while preserving the geometry-related information\nof local face details. We build a sketch-face paired dataset based on the\nexisting method that extracts the edge map from an image. We then introduce a\nStochastic Region Abstraction (SRA), an approach to augment our dataset to\nimprove the robustness of SGLDM to handle sketch input with arbitrary\nabstraction. The evaluation study shows that SGLDM can synthesize high-quality\nface images with different expressions, facial accessories, and hairstyles from\nvarious sketches with different abstraction levels.\n","authors":["Yichen Peng","Chunqi Zhao","Haoran Xie","Tsukasa Fukusato","Kazunori Miyata"],"pdf_url":"https://arxiv.org/pdf/2302.06908v2.pdf","comment":"10 pages, 12 figures, and 2 tables, project page:\n  https://puckikk1202.github.io/difffacesketch2023/"},{"id":"http://arxiv.org/abs/2302.13273v1","updated":"2023-02-26T08:53:20Z","published":"2023-02-26T08:53:20Z","title":"Two-Stream Joint-Training for Speaker Independent\n  Acoustic-to-Articulatory Inversion","summary":"  Acoustic-to-articulatory inversion (AAI) aims to estimate the parameters of\narticulators from speech audio. There are two common challenges in AAI, which\nare the limited data and the unsatisfactory performance in speaker independent\nscenario. Most current works focus on extracting features directly from speech\nand ignoring the importance of phoneme information which may limit the\nperformance of AAI. To this end, we propose a novel network called SPN that\nuses two different streams to carry out the AAI task. Firstly, to improve the\nperformance of speaker-independent experiment, we propose a new phoneme stream\nnetwork to estimate the articulatory parameters as the phoneme features. To the\nbest of our knowledge, this is the first work that extracts the\nspeaker-independent features from phonemes to improve the performance of AAI.\nSecondly, in order to better represent the speech information, we train a\nspeech stream network to combine the local features and the global features.\nCompared with state-of-the-art (SOTA), the proposed method reduces 0.18mm on\nRMSE and increases 6.0% on Pearson correlation coefficient in the\nspeaker-independent experiment. The code has been released at\nhttps://github.com/liujinyu123/AAINetwork-SPN.\n","authors":["Jianrong Wang","Jinyu Liu","Li Liu","Xuewei Li","Mei Yu","Jie Gao","Qiang Fang"],"pdf_url":"https://arxiv.org/pdf/2302.13273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13269v1","updated":"2023-02-26T08:46:07Z","published":"2023-02-26T08:46:07Z","title":"Exploring Opinion-unaware Video Quality Assessment with Semantic\n  Affinity Criterion","summary":"  Recent learning-based video quality assessment (VQA) algorithms are expensive\nto implement due to the cost of data collection of human quality opinions, and\nare less robust across various scenarios due to the biases of these opinions.\nThis motivates our exploration on opinion-unaware (a.k.a zero-shot) VQA\napproaches. Existing approaches only considers low-level naturalness in spatial\nor temporal domain, without considering impacts from high-level semantics. In\nthis work, we introduce an explicit semantic affinity index for opinion-unaware\nVQA using text-prompts in the contrastive language-image pre-training (CLIP)\nmodel. We also aggregate it with different traditional low-level naturalness\nindexes through gaussian normalization and sigmoid rescaling strategies.\nComposed of aggregated semantic and technical metrics, the proposed Blind\nUnified Opinion-Unaware Video Quality Index via Semantic and Technical Metric\nAggregation (BUONA-VISTA) outperforms existing opinion-unaware VQA methods by\nat least 20% improvements, and is more robust than opinion-aware approaches.\n","authors":["Haoning Wu","Liang Liao","Jingwen Hou","Chaofeng Chen","Erli Zhang","Annan Wang","Wenxiu Sun","Qiong Yan","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2302.13269v1.pdf","comment":null}]},"2023-02-25T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.13173v1","updated":"2023-02-25T21:42:31Z","published":"2023-02-25T21:42:31Z","title":"MetaAID 2.0: An Extensible Framework for Developing Metaverse\n  Applications via Human-controllable Pre-trained Models","summary":"  Pre-trained models (PM) have achieved promising results in content\ngeneration. However, the space for human creativity and imagination is endless,\nand it is still unclear whether the existing models can meet the needs.\nModel-generated content faces uncontrollable responsibility and potential\nunethical problems. This paper presents the MetaAID 2.0 framework, dedicated to\nhuman-controllable PM information flow. Through the PM information flow, humans\ncan autonomously control their creativity. Through the Universal Resource\nIdentifier extension (URI-extension), the responsibility of the model outputs\ncan be controlled. Our framework includes modules for handling multimodal data\nand supporting transformation and generation. The URI-extension consists of\nURI, detailed description, and URI embeddings, and supports fuzzy retrieval of\nmodel outputs. Based on this framework, we conduct experiments on PM\ninformation flow and URI embeddings, and the results demonstrate the good\nperformance of our system.\n","authors":["Hongyin Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.13173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.05042v3","updated":"2023-02-25T21:05:02Z","published":"2022-04-11T12:23:07Z","title":"Resources for Turkish Natural Language Processing: A critical survey","summary":"  This paper presents a comprehensive survey of corpora and lexical resources\navailable for Turkish. We review a broad range of resources, focusing on the\nones that are publicly available. In addition to providing information about\nthe available linguistic resources, we present a set of recommendations, and\nidentify gaps in the data available for conducting research and building\napplications in Turkish Linguistics and Natural Language Processing.\n","authors":["Çağrı Çöltekin","A. Seza Doğruöz","Özlem Çetinoğlu"],"pdf_url":"https://arxiv.org/pdf/2204.05042v3.pdf","comment":"Published in Language Resources and Evaluation"},{"id":"http://arxiv.org/abs/2302.13149v1","updated":"2023-02-25T20:24:58Z","published":"2023-02-25T20:24:58Z","title":"STACC: Code Comment Classification using SentenceTransformers","summary":"  Code comments are a key resource for information about software artefacts.\nDepending on the use case, only some types of comments are useful. Thus,\nautomatic approaches to classify these comments are proposed. In this work, we\naddress this need by proposing, STACC, a set of SentenceTransformers-based\nbinary classifiers. These lightweight classifiers are trained and tested on the\nNLBSE Code Comment Classification tool competition dataset, and surpass the\nbaseline by a significant margin, achieving an average F1 score of 0.74 against\nthe baseline of 0.31, which is an improvement of 139%. A replication package,\nas well as the models themselves, are publicly available.\n","authors":["Ali Al-Kaswan","Maliheh Izadi","Arie van Deursen"],"pdf_url":"https://arxiv.org/pdf/2302.13149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13139v1","updated":"2023-02-25T18:39:59Z","published":"2023-02-25T18:39:59Z","title":"Prompt-based Learning for Text Readability Assessment","summary":"  We propose the novel adaptation of a pre-trained seq2seq model for\nreadability assessment. We prove that a seq2seq model - T5 or BART - can be\nadapted to discern which text is more difficult from two given texts\n(pairwise). As an exploratory study to prompt-learn a neural network for text\nreadability in a text-to-text manner, we report useful tips for future work in\nseq2seq training and ranking-based approach to readability assessment.\nSpecifically, we test nine input-output formats/prefixes and show that they can\nsignificantly influence the final model performance.\n  Also, we argue that the combination of text-to-text training and pairwise\nranking setup 1) enables leveraging multiple parallel text simplification data\nfor teaching readability and 2) trains a neural model for the general concept\nof readability (therefore, better cross-domain generalization). At last, we\nreport a 99.6% pairwise classification accuracy on Newsela and a 98.7% for\nOneStopEnglish, through a joint training approach.\n","authors":["Bruce W. Lee","Jason Hyung-Jong Lee"],"pdf_url":"https://arxiv.org/pdf/2302.13139v1.pdf","comment":"Accepted to EACL 2023 Findings"},{"id":"http://arxiv.org/abs/2302.13136v1","updated":"2023-02-25T18:29:02Z","published":"2023-02-25T18:29:02Z","title":"Toward Fairness in Text Generation via Mutual Information Minimization\n  based on Importance Sampling","summary":"  Pretrained language models (PLMs), such as GPT2, have achieved remarkable\nempirical performance in text generation tasks. However, pretrained on\nlarge-scale natural language corpora, the generated text from PLMs may exhibit\nsocial bias against disadvantaged demographic groups. To improve the fairness\nof PLMs in text generation, we propose to minimize the mutual information\nbetween the semantics in the generated text sentences and their demographic\npolarity, i.e., the demographic group to which the sentence is referring. In\nthis way, the mentioning of a demographic group (e.g., male or female) is\nencouraged to be independent from how it is described in the generated text,\nthus effectively alleviating the social bias. Moreover, we propose to\nefficiently estimate the upper bound of the above mutual information via\nimportance sampling, leveraging a natural language corpus. We also propose a\ndistillation mechanism that preserves the language modeling ability of the PLMs\nafter debiasing. Empirical results on real-world benchmarks demonstrate that\nthe proposed method yields superior performance in term of both fairness and\nlanguage modeling ability.\n","authors":["Rui Wang","Pengyu Cheng","Ricardo Henao"],"pdf_url":"https://arxiv.org/pdf/2302.13136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13117v1","updated":"2023-02-25T16:45:46Z","published":"2023-02-25T16:45:46Z","title":"Abstractive Text Summarization using Attentive GRU based Encoder-Decoder","summary":"  In todays era huge volume of information exists everywhere. Therefore, it is\nvery crucial to evaluate that information and extract useful, and often\nsummarized, information out of it so that it may be used for relevant purposes.\nThis extraction can be achieved through a crucial technique of artificial\nintelligence, namely, machine learning. Indeed automatic text summarization has\nemerged as an important application of machine learning in text processing. In\nthis paper, an english text summarizer has been built with GRU-based encoder\nand decoder. Bahdanau attention mechanism has been added to overcome the\nproblem of handling long sequences in the input text. A news-summary dataset\nhas been used to train the model. The output is observed to outperform\ncompetitive models in the literature. The generated summary can be used as a\nnewspaper headline.\n","authors":["Tohida Rehman","Suchandan Das","Debarshi Kumar Sanyal","Samiran Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2302.13117v1.pdf","comment":"9 pages, 2 Tables, 5 Figures"},{"id":"http://arxiv.org/abs/2302.13114v1","updated":"2023-02-25T16:33:53Z","published":"2023-02-25T16:33:53Z","title":"Sequential Query Encoding For Complex Query Answering on Knowledge\n  Graphs","summary":"  Query encoding (QE) is proposed as a fast and robust solution to CQA. In the\nencoding process, most existing QE methods first parse the logical query into\nan executable computational direct-acyclic graph (DAG), then use neural\nnetworks to parameterize the operators, and finally, recursively execute these\nneuralized operators. However, the parameterization-and-execution paradigm may\nbe potentially over-complicated, as it can be structurally simplified by a\nsingle neural network encoder. Meanwhile, sequence encoders, like LSTM and\nTransformer, proved to be effective for encoding semantic graphs in related\ntasks. Motivated by this, we propose sequential query encoding (SQE) as an\nalternative to encode queries for CQA. Instead of parameterizing and executing\nthe computational graph, SQE first uses a search-based algorithm to linearize\nthe computational graph to a sequence of tokens and then uses a sequence\nencoder to compute its vector representation. Then this vector representation\nis used as a query embedding to retrieve answers from the embedding space\naccording to similarity scores. Despite its simplicity, SQE demonstrates\nstate-of-the-art neural query encoding performance on FB15k, FB15k-237, and\nNELL on an extended benchmark including twenty-nine types of in-distribution\nqueries. Further experiment shows that SQE also demonstrates comparable\nknowledge inference capability on out-of-distribution queries, whose query\ntypes are not observed during the training process.\n","authors":["Jiaxin Bai","Tianshi Zheng","Yangqiu Song"],"pdf_url":"https://arxiv.org/pdf/2302.13114v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2302.13106v1","updated":"2023-02-25T15:56:06Z","published":"2023-02-25T15:56:06Z","title":"Topic-Selective Graph Network for Topic-Focused Summarization","summary":"  Due to the success of the pre-trained language model (PLM), existing\nPLM-based summarization models show their powerful generative capability.\nHowever, these models are trained on general-purpose summarization datasets,\nleading to generated summaries failing to satisfy the needs of different\nreaders. To generate summaries with topics, many efforts have been made on\ntopic-focused summarization. However, these works generate a summary only\nguided by a prompt comprising topic words. Despite their success, these methods\nstill ignore the disturbance of sentences with non-relevant topics and only\nconduct cross-interaction between tokens by attention module. To address this\nissue, we propose a topic-arc recognition objective and topic-selective graph\nnetwork. First, the topic-arc recognition objective is used to model training,\nwhich endows the capability to discriminate topics for the model. Moreover, the\ntopic-selective graph network can conduct topic-guided cross-interaction on\nsentences based on the results of topic-arc recognition. In the experiments, we\nconduct extensive evaluations on NEWTS and COVIDET datasets. Results show that\nour methods achieve state-of-the-art performance.\n","authors":["Shi Zesheng","Zhou Yucheng"],"pdf_url":"https://arxiv.org/pdf/2302.13106v1.pdf","comment":"PAKDD 2023"},{"id":"http://arxiv.org/abs/2302.13099v1","updated":"2023-02-25T15:16:10Z","published":"2023-02-25T15:16:10Z","title":"HADES: Homologous Automated Document Exploration and Summarization","summary":"  This paper introduces HADES, a novel tool for automatic comparative documents\nwith similar structures. HADES is designed to streamline the work of\nprofessionals dealing with large volumes of documents, such as policy\ndocuments, legal acts, and scientific papers. The tool employs a multi-step\npipeline that begins with processing PDF documents using topic modeling,\nsummarization, and analysis of the most important words for each topic. The\nprocess concludes with an interactive web app with visualizations that\nfacilitate the comparison of the documents. HADES has the potential to\nsignificantly improve the productivity of professionals dealing with high\nvolumes of documents, reducing the time and effort required to complete tasks\nrelated to comparative document analysis. Our package is publically available\non GitHub.\n","authors":["Piotr Wilczyński","Artur Żółkowski","Mateusz Krzyziński","Emilia Wiśnios","Bartosz Pieliński","Stanisław Giziński","Julian Sienkiewicz","Przemysław Biecek"],"pdf_url":"https://arxiv.org/pdf/2302.13099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.11909v7","updated":"2023-02-25T12:52:21Z","published":"2021-03-22T14:54:54Z","title":"Identifying Machine-Paraphrased Plagiarism","summary":"  Employing paraphrasing tools to conceal plagiarized text is a severe threat\nto academic integrity. To enable the detection of machine-paraphrased text, we\nevaluate the effectiveness of five pre-trained word embedding models combined\nwith machine-learning classifiers and eight state-of-the-art neural language\nmodels. We analyzed preprints of research papers, graduation theses, and\nWikipedia articles, which we paraphrased using different configurations of the\ntools SpinBot and SpinnerChief. The best-performing technique, Longformer,\nachieved an average F1 score of 81.0% (F1=99.7% for SpinBot and F1=71.6% for\nSpinnerChief cases), while human evaluators achieved F1=78.4% for SpinBot and\nF1=65.6% for SpinnerChief cases. We show that the automated classification\nalleviates shortcomings of widely-used text-matching systems, such as Turnitin\nand PlagScan. To facilitate future research, all data, code, and two web\napplications showcasing our contributions are openly available at\nhttps://github.com/jpwahle/iconf22-paraphrase.\n","authors":["Jan Philip Wahle","Terry Ruas","Tomáš Foltýnek","Norman Meuschke","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2103.11909v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.05895v2","updated":"2023-02-25T12:37:21Z","published":"2022-04-12T15:45:32Z","title":"XQA-DST: Multi-Domain and Multi-Lingual Dialogue State Tracking","summary":"  Dialogue State Tracking (DST), a crucial component of task-oriented dialogue\n(ToD) systems, keeps track of all important information pertaining to dialogue\nhistory: filling slots with the most probable values throughout the\nconversation. Existing methods generally rely on a predefined set of values and\nstruggle to generalise to previously unseen slots in new domains. To overcome\nthese challenges, we propose a domain-agnostic extractive question answering\n(QA) approach with shared weights across domains. To disentangle the complex\ndomain information in ToDs, we train our DST with a novel domain filtering\nstrategy by excluding out-of-domain question samples. With an independent\nclassifier that predicts the presence of multiple domains given the context,\nour model tackles DST by extracting spans in active domains. Empirical results\ndemonstrate that our model can efficiently leverage domain-agnostic QA datasets\nby two-stage fine-tuning while being both domain-scalable and open-vocabulary\nin DST. It shows strong transferability by achieving zero-shot\ndomain-adaptation results on MultiWOZ 2.1 with an average JGA of 36.7%. It\nfurther achieves cross-lingual transfer with state-of-the-art zero-shot\nresults, 66.2% JGA from English to German and 75.7% JGA from English to Italian\non WOZ 2.0.\n","authors":["Han Zhou","Ignacio Iacobacci","Pasquale Minervini"],"pdf_url":"https://arxiv.org/pdf/2204.05895v2.pdf","comment":"Accepted to Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2302.13048v1","updated":"2023-02-25T10:20:02Z","published":"2023-02-25T10:20:02Z","title":"Human-in-the-Loop Schema Induction","summary":"  Schema induction builds a graph representation explaining how events unfold\nin a scenario. Existing approaches have been based on information retrieval\n(IR) and information extraction(IE), often with limited human curation. We\ndemonstrate a human-in-the-loop schema induction system powered by GPT-3. We\nfirst describe the different modules of our system, including prompting to\ngenerate schematic elements, manual edit of those elements, and conversion of\nthose into a schema graph. By qualitatively comparing our system to previous\nones, we show that our system not only transfers to new domains more easily\nthan previous approaches, but also reduces efforts of human curation thanks to\nour interactive interface.\n","authors":["Tianyi Zhang","Isaac Tham","Zhaoyi Hou","Jiaxuan Ren","Liyang Zhou","Hainiu Xu","Li Zhang","Lara J. Martin","Rotem Dror","Sha Li","Heng Ji","Martha Palmer","Susan Brown","Reece Suchocki","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2302.13048v1.pdf","comment":"10 pages, ACL2023 demo track"},{"id":"http://arxiv.org/abs/2302.13032v1","updated":"2023-02-25T09:10:03Z","published":"2023-02-25T09:10:03Z","title":"SynGen: A Syntactic Plug-and-play Module for Generative Aspect-based\n  Sentiment Analysis","summary":"  Aspect-based Sentiment Analysis (ABSA) is a sentiment analysis task at\nfine-grained level. Recently, generative frameworks have attracted increasing\nattention in ABSA due to their ability to unify subtasks and their continuity\nto upstream pre-training tasks. However, these generative models suffer from\nthe neighboring dependency problem that induces neighboring words to get higher\nattention. In this paper, we propose SynGen, a plug-and-play syntactic\ninformation aware module. As a plug-in module, our SynGen can be easily applied\nto any generative framework backbones. The key insight of our module is to add\nsyntactic inductive bias to attention assignment and thus direct attention to\nthe correct target words. To the best of our knowledge, we are the first one to\nintroduce syntactic information to generative ABSA frameworks. Our module\ndesign is based on two main principles: (1) maintaining the structural\nintegrity of backbone PLMs and (2) disentangling the added syntactic\ninformation and original semantic information. Empirical results on four\npopular ABSA datasets demonstrate that SynGen enhanced model achieves a\ncomparable performance to the state-of-the-art model with relaxed labeling\nspecification and less training consumption.\n","authors":["Chengze Yu","Taiqiang Wu","Jiayi Li","Xingyu Bai","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2302.13032v1.pdf","comment":"4 pages, 2 figure, 2 tables"},{"id":"http://arxiv.org/abs/2205.10178v2","updated":"2023-02-25T08:04:50Z","published":"2022-05-20T13:41:12Z","title":"Visually-Augmented Language Modeling","summary":"  Human language is grounded on multimodal knowledge including visual knowledge\nlike colors, sizes, and shapes. However, current large-scale pre-trained\nlanguage models rely on text-only self-supervised training with massive text\ndata, which precludes them from utilizing relevant visual information when\nnecessary. To address this, we propose a novel pre-training framework, named\nVaLM, to Visually-augment text tokens with retrieved relevant images for\nLanguage Modeling. Specifically, VaLM builds on a novel latent text-image\nalignment method via an image retrieval module to fetch corresponding images\ngiven a textual context. With the visually-augmented context, VaLM uses a\nvisual knowledge fusion layer to enable multimodal grounded language modeling\nby attending to both text context and visual knowledge in images. We evaluate\nVaLM on various visual knowledge-intensive commonsense reasoning tasks, which\nrequire visual information to excel. The experimental results illustrate that\nVaLM outperforms all strong language-only and vision-language baselines with\nsubstantial gains in reasoning object commonsense including color, size, and\nshape. Our code is available at https://github.com/Victorwz/VaLM.\n","authors":["Weizhi Wang","Li Dong","Hao Cheng","Haoyu Song","Xiaodong Liu","Xifeng Yan","Jianfeng Gao","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2205.10178v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2301.04871v2","updated":"2023-02-25T07:41:41Z","published":"2023-01-12T08:37:00Z","title":"Learning to Memorize Entailment and Discourse Relations for\n  Persona-Consistent Dialogues","summary":"  Maintaining engagement and consistency is particularly important in dialogue\nsystems. Existing works have improved the performance of dialogue systems by\nintentionally learning interlocutor personas with sophisticated network\nstructures. One issue with this approach is that it requires more personal\ncorpora with annotations. Additionally, these models typically perform the next\nutterance prediction to generate a response but neglect the discourse coherence\nin the entire conversation. To address these issues, this study proposes a\nmethod of learning to memorize entailment and discourse relations for\npersona-consistent dialogue tasks. Entailment text pairs in natural language\ninference dataset were applied to learn latent entailment relations as external\nmemories by premise-to-hypothesis generation task. Furthermore, an internal\nmemory with a similar architecture was applied to the discourse information in\nthe dialogue. Placing orthogonality restrictions on these two memory spaces\nensures that the latent entailment relations remain dialogue-independent. Both\nmemories collaborate to obtain entailment and discourse representation for the\ngeneration, allowing a deeper understanding of both consistency and coherence.\nExperiments on two large public datasets, PersonaChat and DSTC7-AVSD,\ndemonstrated the effectiveness of the proposed method. Both automatic and human\nevaluations indicate that the proposed model outperforms several strong\nbaselines in terms of both persona consistency and response coherence. Our\nsource code is available at https://github.com/Chenrj233/LMEDR.\n","authors":["Ruijun Chen","Jin Wang","Liang-Chih Yu","Xuejie Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.04871v2.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.13013v1","updated":"2023-02-25T07:32:04Z","published":"2023-02-25T07:32:04Z","title":"Choice Fusion as Knowledge for Zero-Shot Dialogue State Tracking","summary":"  With the demanding need for deploying dialogue systems in new domains with\nless cost, zero-shot dialogue state tracking (DST), which tracks user's\nrequirements in task-oriented dialogues without training on desired domains,\ndraws attention increasingly. Although prior works have leveraged\nquestion-answering (QA) data to reduce the need for in-domain training in DST,\nthey fail to explicitly model knowledge transfer and fusion for tracking\ndialogue states. To address this issue, we propose CoFunDST, which is trained\non domain-agnostic QA datasets and directly uses candidate choices of\nslot-values as knowledge for zero-shot dialogue-state generation, based on a T5\npre-trained language model. Specifically, CoFunDST selects highly-relevant\nchoices to the reference context and fuses them to initialize the decoder to\nconstrain the model outputs. Our experimental results show that our proposed\nmodel achieves outperformed joint goal accuracy compared to existing zero-shot\nDST approaches in most domains on the MultiWOZ 2.1. Extensive analyses\ndemonstrate the effectiveness of our proposed approach for improving zero-shot\nDST learning from QA.\n","authors":["Ruolin Su","Jingfeng Yang","Ting-Wei Wu","Biing-Hwang Juang"],"pdf_url":"https://arxiv.org/pdf/2302.13013v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2205.12542v2","updated":"2023-02-25T07:27:00Z","published":"2022-05-25T07:31:43Z","title":"ER-Test: Evaluating Explanation Regularization Methods for Language\n  Models","summary":"  By explaining how humans would solve a given task, human rationales can\nprovide strong learning signal for neural language models (LMs). Explanation\nregularization (ER) aims to improve LM generalization by pushing the LM's\nmachine rationales (Which input tokens did the LM focus on?) to align with\nhuman rationales (Which input tokens would humans focus on?). Though prior\nworks primarily study ER via in-distribution (ID) evaluation,\nout-of-distribution (OOD) generalization is often more critical in real-world\nscenarios, yet ER's effect on OOD generalization has been underexplored. In\nthis paper, we introduce ER-Test, a framework for evaluating ER models' OOD\ngeneralization along three dimensions: unseen dataset tests, contrast set\ntests, and functional tests. Using ER-Test, we extensively analyze how ER\nmodels' OOD generalization varies with different ER design choices. Across two\ntasks and six datasets, ER-Test shows that ER has little impact on ID\nperformance but can yield large OOD performance gains. Also, we find that ER\ncan improve OOD performance even with limited rationale supervision. ER-Test's\nresults help demonstrate ER's utility and establish best practices for using ER\neffectively.\n","authors":["Brihi Joshi","Aaron Chan","Ziyi Liu","Shaoliang Nie","Maziar Sanjabi","Hamed Firooz","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2205.12542v2.pdf","comment":"Findings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2302.13007v1","updated":"2023-02-25T06:58:16Z","published":"2023-02-25T06:58:16Z","title":"ChatAug: Leveraging ChatGPT for Text Data Augmentation","summary":"  Text data augmentation is an effective strategy for overcoming the challenge\nof limited sample sizes in many natural language processing (NLP) tasks. This\nchallenge is especially prominent in the few-shot learning scenario, where the\ndata in the target domain is generally much scarcer and of lowered quality. A\nnatural and widely-used strategy to mitigate such challenges is to perform data\naugmentation on the training data to better capture the data invariance and\nincrease the sample size. However, current text data augmentation methods\neither can not ensure the correct labeling of the generated data (lacking\nfaithfulness) or can not ensure sufficient diversity in the generated data\n(lacking completeness), or both. Inspired by the recent success of large\nlanguage models, especially the development of ChatGPT, which demonstrated\nimproved language comprehension abilities, in this work, we propose a text data\naugmentation approach based on ChatGPT (named ChatAug). ChatGPT is trained on\ndata with unparalleled linguistic richness and employs a reinforcement training\nprocess with large-scale human feedback, which endows the model with affinity\nto the naturalness of human language. Our text data augmentation approach\nChatAug rephrases each sentence in the training samples into multiple\nconceptually similar but semantically different samples. The augmented samples\ncan then be used in downstream model training. Experiment results on few-shot\nlearning text classification tasks show the superior performance of the\nproposed ChatAug approach over state-of-the-art text data augmentation methods\nin terms of testing accuracy and distribution of the augmented samples.\n","authors":["Haixing Dai","Zhengliang Liu","Wenxiong Liao","Xiaoke Huang","Zihao Wu","Lin Zhao","Wei Liu","Ninghao Liu","Sheng Li","Dajiang Zhu","Hongmin Cai","Quanzheng Li","Dinggang Shen","Tianming Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2302.13007v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15214v5","updated":"2023-02-25T06:55:52Z","published":"2022-09-30T04:03:26Z","title":"Construction and Applications of Billion-Scale Pre-trained Multimodal\n  Business Knowledge Graph","summary":"  Business Knowledge Graphs (KGs) are important to many enterprises today,\nproviding factual knowledge and structured data that steer many products and\nmake them more intelligent. Despite their promising benefits, building business\nKG necessitates solving prohibitive issues of deficient structure and multiple\nmodalities. In this paper, we advance the understanding of the practical\nchallenges related to building KG in non-trivial real-world systems. We\nintroduce the process of building an open business knowledge graph (OpenBG)\nderived from a well-known enterprise, Alibaba Group. Specifically, we define a\ncore ontology to cover various abstract products and consumption demands, with\nfine-grained taxonomy and multimodal facts in deployed applications. OpenBG is\nan open business KG of unprecedented scale: 2.6 billion triples with more than\n88 million entities covering over 1 million core classes/concepts and 2,681\ntypes of relations. We release all the open resources (OpenBG benchmarks)\nderived from it for the community and report experimental results of KG-centric\ntasks. We also run up an online competition based on OpenBG benchmarks, and has\nattracted thousands of teams. We further pre-train OpenBG and apply it to many\nKG- enhanced downstream tasks in business scenarios, demonstrating the\neffectiveness of billion-scale multimodal knowledge for e-commerce. All the\nresources with codes have been released at\n\\url{https://github.com/OpenBGBenchmark/OpenBG}.\n","authors":["Shumin Deng","Chengming Wang","Zhoubo Li","Ningyu Zhang","Zelin Dai","Hehong Chen","Feiyu Xiong","Ming Yan","Qiang Chen","Mosha Chen","Jiaoyan Chen","Jeff Z. Pan","Bryan Hooi","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2209.15214v5.pdf","comment":"OpenBG. Accepted by ICDE 2023. The project is released at\n  \\url{https://github.com/OpenBGBenchmark/OpenBG}"},{"id":"http://arxiv.org/abs/2111.07935v2","updated":"2023-02-25T05:06:16Z","published":"2021-11-15T17:36:41Z","title":"Incorporating Question Answering-Based Signals into Abstractive\n  Summarization via Salient Span Selection","summary":"  In this work, we propose a method for incorporating question-answering (QA)\nsignals into a summarization model. Our method identifies salient noun phrases\n(NPs) in the input document by automatically generating wh-questions that are\nanswered by the NPs and automatically determining whether those questions are\nanswered in the gold summaries. This QA-based signal is incorporated into a\ntwo-stage summarization model which first marks salient NPs in the input\ndocument using a classification model, then conditionally generates a summary.\nOur experiments demonstrate that the models trained using QA-based supervision\ngenerate higher-quality summaries than baseline methods of identifying salient\nspans on benchmark summarization datasets. Further, we show that the content of\nthe generated summaries can be controlled based on which NPs are marked in the\ninput document. Finally, we propose a method of augmenting the training data so\nthe gold summaries are more consistent with the marked input spans used during\ntraining and show how this results in models which learn to better exclude\nunmarked document content.\n","authors":["Daniel Deutsch","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2111.07935v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12979v1","updated":"2023-02-25T04:23:25Z","published":"2023-02-25T04:23:25Z","title":"Jointly Optimizing Translations and Speech Timing to Improve Isochrony\n  in Automatic Dubbing","summary":"  Automatic dubbing (AD) is the task of translating the original speech in a\nvideo into target language speech. The new target language speech should\nsatisfy isochrony; that is, the new speech should be time aligned with the\noriginal video, including mouth movements, pauses, hand gestures, etc. In this\npaper, we propose training a model that directly optimizes both the translation\nas well as the speech duration of the generated translations. We show that this\nsystem generates speech that better matches the timing of the original speech,\ncompared to prior work, while simplifying the system architecture.\n","authors":["Alexandra Chronopoulou","Brian Thompson","Prashant Mathur","Yogesh Virkar","Surafel M. Lakew","Marcello Federico"],"pdf_url":"https://arxiv.org/pdf/2302.12979v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2301.07779v2","updated":"2023-02-25T04:23:12Z","published":"2023-01-18T20:43:13Z","title":"Understanding and Detecting Hallucinations in Neural Machine Translation\n  via Model Introspection","summary":"  Neural sequence generation models are known to \"hallucinate\", by producing\noutputs that are unrelated to the source text. These hallucinations are\npotentially harmful, yet it remains unclear in what conditions they arise and\nhow to mitigate their impact. In this work, we first identify internal model\nsymptoms of hallucinations by analyzing the relative token contributions to the\ngeneration in contrastive hallucinated vs. non-hallucinated outputs generated\nvia source perturbations. We then show that these symptoms are reliable\nindicators of natural hallucinations, by using them to design a lightweight\nhallucination detector which outperforms both model-free baselines and strong\nclassifiers based on quality estimation or large pre-trained models on manually\nannotated English-Chinese and German-English translation test beds.\n","authors":["Weijia Xu","Sweta Agrawal","Eleftheria Briakou","Marianna J. Martindale","Marine Carpuat"],"pdf_url":"https://arxiv.org/pdf/2301.07779v2.pdf","comment":"Accepted at TACL"},{"id":"http://arxiv.org/abs/2208.08063v4","updated":"2023-02-25T03:19:31Z","published":"2022-08-17T04:30:58Z","title":"NECE: Narrative Event Chain Extraction Toolkit","summary":"  To understand a narrative, it is essential to comprehend its main characters\nand the associated major events; however, this can be challenging with lengthy\nand unstructured narrative texts. To address this, we introduce NECE, an\nopen-access, document-level toolkit that automatically extracts and aligns\nnarrative events in the temporal order of their occurrence using sliding window\nmethod. Through extensive human evaluations, we have confirmed the high quality\nof the NECE toolkit, and external validation has demonstrated its potential for\napplication in downstream tasks such as question answering and bias analysis.\nThe NECE toolkit includes both a Python library and a user-friendly web\ninterface; the latter offers custom visualizations of event chains and easy\nnavigation between graphics and text to improve reading efficiency and\nexperience.\n","authors":["Guangxuan Xu","Paulina Toro Isaza","Moshi Li","Akintoye Oloko","Bingsheng Yao","Cassia Sanctos","Aminat Adebiyi","Yufang Hou","Nanyun Peng","Dakuo Wang"],"pdf_url":"https://arxiv.org/pdf/2208.08063v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08043v3","updated":"2023-02-25T03:00:10Z","published":"2023-02-16T02:51:38Z","title":"GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural\n  Networks","summary":"  Graphs can model complex relationships between objects, enabling a myriad of\nWeb applications such as online page/article classification and social\nrecommendation. While graph neural networks(GNNs) have emerged as a powerful\ntool for graph representation learning, in an end-to-end supervised setting,\ntheir performance heavily rely on a large amount of task-specific supervision.\nTo reduce labeling requirement, the \"pre-train, fine-tune\" and \"pre-train,\nprompt\" paradigms have become increasingly common. In particular, prompting is\na popular alternative to fine-tuning in natural language processing, which is\ndesigned to narrow the gap between pre-training and downstream objectives in a\ntask-specific manner. However, existing study of prompting on graphs is still\nlimited, lacking a universal treatment to appeal to different downstream tasks.\nIn this paper, we propose GraphPrompt, a novel pre-training and prompting\nframework on graphs. GraphPrompt not only unifies pre-training and downstream\ntasks into a common task template, but also employs a learnable prompt to\nassist a downstream task in locating the most relevant knowledge from the\npre-train model in a task-specific manner. Finally, we conduct extensive\nexperiments on five public datasets to evaluate and analyze GraphPrompt.\n","authors":["Zemin Liu","Xingtong Yu","Yuan Fang","Xinming Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.08043v3.pdf","comment":"WWW23 research track"},{"id":"http://arxiv.org/abs/2302.12961v1","updated":"2023-02-25T02:20:59Z","published":"2023-02-25T02:20:59Z","title":"Locale Encoding For Scalable Multilingual Keyword Spotting Models","summary":"  A Multilingual Keyword Spotting (KWS) system detects spokenkeywords over\nmultiple locales. Conventional monolingual KWSapproaches do not scale well to\nmultilingual scenarios because ofhigh development/maintenance costs and lack of\nresource sharing.To overcome this limit, we propose two locale-conditioned\nuniversalmodels with locale feature concatenation and feature-wise\nlinearmodulation (FiLM). We compare these models with two baselinemethods:\nlocale-specific monolingual KWS, and a single universalmodel trained over all\ndata. Experiments over 10 localized languagedatasets show that\nlocale-conditioned models substantially improveaccuracy over baseline methods\nacross all locales in different noiseconditions.FiLMperformed the best,\nimproving on average FRRby 61% (relative) compared to monolingual KWS models of\nsimilarsizes.\n","authors":["Pai Zhu","Hyun Jin Park","Alex Park","Angelo Scorza Scarpati","Ignacio Lopez Moreno"],"pdf_url":"https://arxiv.org/pdf/2302.12961v1.pdf","comment":"Accepted for ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.12952v1","updated":"2023-02-25T01:39:13Z","published":"2023-02-25T01:39:13Z","title":"Robust language-based mental health assessments in time and space\n  through social media","summary":"  Compared to physical health, population mental health measurement in the U.S.\nis very coarse-grained. Currently, in the largest population surveys, such as\nthose carried out by the Centers for Disease Control or Gallup, mental health\nis only broadly captured through \"mentally unhealthy days\" or \"sadness\", and\nlimited to relatively infrequent state or metropolitan estimates. Through the\nlarge scale analysis of social media data, robust estimation of population\nmental health is feasible at much higher resolutions, up to weekly estimates\nfor counties. In the present work, we validate a pipeline that uses a sample of\n1.2 billion Tweets from 2 million geo-located users to estimate mental health\nchanges for the two leading mental health conditions, depression and anxiety.\nWe find moderate to large associations between the language-based mental health\nassessments and survey scores from Gallup for multiple levels of granularity,\ndown to the county-week (fixed effects $\\beta = .25$ to $1.58$; $p<.001$).\nLanguage-based assessment allows for the cost-effective and scalable monitoring\nof population mental health at weekly time scales. Such spatially fine-grained\ntime series are well suited to monitor effects of societal events and policies\nas well as enable quasi-experimental study designs in population health and\nother disciplines. Beyond mental health in the U.S., this method generalizes to\na broad set of psychological outcomes and allows for community measurement in\nunder-resourced settings where no traditional survey measures - but social\nmedia data - are available.\n","authors":["Siddharth Mangalik","Johannes C. Eichstaedt","Salvatore Giorgi","Jihu Mun","Farhan Ahmed","Gilvir Gill","Adithya V. Ganesan","Shashanka Subrahmanya","Nikita Soni","Sean A. P. Clouston","H. Andrew Schwartz"],"pdf_url":"https://arxiv.org/pdf/2302.12952v1.pdf","comment":"9 pages, 7 figures, pre-print"},{"id":"http://arxiv.org/abs/2302.12944v1","updated":"2023-02-25T00:41:46Z","published":"2023-02-25T00:41:46Z","title":"Dependency Dialogue Acts -- Annotation Scheme and Case Study","summary":"  In this paper, we introduce Dependency Dialogue Acts (DDA), a novel framework\nfor capturing the structure of speaker-intentions in multi-party dialogues. DDA\ncombines and adapts features from existing dialogue annotation frameworks, and\nemphasizes the multi-relational response structure of dialogues in addition to\nthe dialogue acts and rhetorical relations. It represents the functional,\ndiscourse, and response structure in multi-party multi-threaded conversations.\nA few key features distinguish DDA from existing dialogue annotation frameworks\nsuch as SWBD-DAMSL and the ISO 24617-2 standard. First, DDA prioritizes the\nrelational structure of the dialogue units and the dialog context, annotating\nboth dialog acts and rhetorical relations as response relations to particular\nutterances. Second, DDA embraces overloading in dialogues, encouraging\nannotators to specify multiple response relations and dialog acts for each\ndialog unit. Lastly, DDA places an emphasis on adequately capturing how a\nspeaker is using the full dialog context to plan and organize their speech.\nWith these features, DDA is highly expressive and recall-oriented with regard\nto conversation dynamics between multiple speakers. In what follows, we present\nthe DDA annotation framework and case studies annotating DDA structures in\nmulti-party, multi-threaded conversations.\n","authors":["Jon Z. Cai","Brendan King","Margaret Perkoff","Shiran Dudy","Jie Cao","Marie Grace","Natalia Wojarnik","Ananya Ganesh","James H. Martin","Martha Palmer","Marilyn Walker","Jeffrey Flanigan"],"pdf_url":"https://arxiv.org/pdf/2302.12944v1.pdf","comment":"The 13th International Workshop on Spoken Dialogue Systems Technology"},{"id":"http://arxiv.org/abs/2302.14057v1","updated":"2023-02-25T10:12:34Z","published":"2023-02-25T10:12:34Z","title":"Cross-modal Contrastive Learning for Multimodal Fake News Detection","summary":"  Automatic detection of multimodal fake news has gained a widespread attention\nrecently. Many existing approaches seek to fuse unimodal features to produce\nmultimodal news representations. However, the potential of powerful cross-modal\ncontrastive learning methods for fake news detection has not been well\nexploited. Besides, how to aggregate features from different modalities to\nboost the performance of the decision-making process is still an open question.\nTo address that, we propose COOLANT, a cross-modal contrastive learning\nframework for multimodal fake news detection, aiming to achieve more accurate\nimage-text alignment. To further improve the alignment precision, we leverage\nan auxiliary task to soften the loss term of negative samples during the\ncontrast process. A cross-modal fusion module is developed to learn the\ncross-modality correlations. An attention mechanism with an attention guidance\nmodule is implemented to help effectively and interpretably aggregate the\naligned unimodal representations and the cross-modality correlations. Finally,\nwe evaluate the COOLANT and conduct a comparative study on two widely used\ndatasets, Twitter and Weibo. The experimental results demonstrate that our\nCOOLANT outperforms previous approaches by a large margin and achieves new\nstate-of-the-art results on the two datasets.\n","authors":["Longzheng Wang","Chuang Zhang","Hongbo Xu","Shuai Zhang","Xiaohan Xu","Siqi Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14057v1.pdf","comment":"9 pages, 3 figures"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.13195v1","updated":"2023-02-25T23:47:23Z","published":"2023-02-25T23:47:23Z","title":"nnUNet RASPP for Retinal OCT Fluid Detection, Segmentation and\n  Generalisation over Variations of Data Sources","summary":"  Retinal Optical Coherence Tomography (OCT), a noninvasive cross-sectional\nscan of the eye with qualitative 3D visualization of the retinal anatomy is use\nto study the retinal structure and the presence of pathogens. The advent of the\nretinal OCT has transformed ophthalmology and it is currently paramount for the\ndiagnosis, monitoring and treatment of many eye pathogens including Macular\nEdema which impairs vision severely or Glaucoma that can cause irreversible\nblindness. However the quality of retinal OCT images varies among device\nmanufacturers. Deep Learning methods have had their success in the medical\nimage segmentation community but it is still not clear if the level of success\ncan be generalised across OCT images collected from different device vendors.\nIn this work we propose two variants of the nnUNet [8]. The standard nnUNet and\nan enhanced vision call nnUnet_RASPP (nnU-Net with residual and Atrous Spatial\nPyramid Pooling) both of which are robust and generalise with consistent high\nperformance across images from multiple device vendors. The algorithm was\nvalidated on the MICCAI 2017 RETOUCH challenge dataset [1] acquired from 3\ndevice vendors across 3 medical centers from patients suffering from 2 retinal\ndisease types. Experimental results show that our algorithms outperform the\ncurrent state-of-the-arts algorithms by a clear margin for segmentation\nobtaining a mean Dice Score (DS) of 82.3% for the 3 retinal fluids scoring\n84.0%, 80.0%, 83.0% for Intraretinal Fluid (IRF), Subretinal Fluid (SRF), and\nPigment Epithelium Detachments (PED) respectively on the testing dataset. Also\nwe obtained a perfect Area Under the Curve (AUC) score of 100% for the\ndetection of the presence of fluid for all 3 fluid classes on the testing\ndataset.\n","authors":["Nchongmaje Ndipenoch","Alina Miron","Zidong Wang","Yongmin Li"],"pdf_url":"https://arxiv.org/pdf/2302.13195v1.pdf","comment":"25 pages, 14 figures and 5 tables"},{"id":"http://arxiv.org/abs/2209.14267v2","updated":"2023-02-25T23:26:13Z","published":"2022-09-28T17:33:11Z","title":"Less is More: Rethinking Few-Shot Learning and Recurrent Neural Nets","summary":"  The statistical supervised learning framework assumes an input-output set\nwith a joint probability distribution that is reliably represented by the\ntraining dataset. The learner is then required to output a prediction rule\nlearned from the training dataset's input-output pairs. In this work, we\nprovide meaningful insights into the asymptotic equipartition property (AEP)\n\\citep{Shannon:1948} in the context of machine learning, and illuminate some of\nits potential ramifications for few-shot learning. We provide theoretical\nguarantees for reliable learning under the information-theoretic AEP, and for\nthe generalization error with respect to the sample size. We then focus on a\nhighly efficient recurrent neural net (RNN) framework and propose a\nreduced-entropy algorithm for few-shot learning. We also propose a mathematical\nintuition for the RNN as an approximation of a sparse coding solver. We verify\nthe applicability, robustness, and computational efficiency of the proposed\napproach with image deblurring and optical coherence tomography (OCT) speckle\nsuppression. Our experimental results demonstrate significant potential for\nimproving learning models' sample efficiency, generalization, and time\ncomplexity, that can therefore be leveraged for practical real-time\napplications.\n","authors":["Deborah Pereg","Martin Villiger","Brett Bouma","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2209.14267v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13172v1","updated":"2023-02-25T21:42:00Z","published":"2023-02-25T21:42:00Z","title":"Deep Learning-based Multi-Organ CT Segmentation with Adversarial Data\n  Augmentation","summary":"  In this work, we propose an adversarial attack-based data augmentation method\nto improve the deep-learning-based segmentation algorithm for the delineation\nof Organs-At-Risk (OAR) in abdominal Computed Tomography (CT) to facilitate\nradiation therapy. We introduce Adversarial Feature Attack for Medical Image\n(AFA-MI) augmentation, which forces the segmentation network to learn\nout-of-distribution statistics and improve generalization and robustness to\nnoises. AFA-MI augmentation consists of three steps: 1) generate adversarial\nnoises by Fast Gradient Sign Method (FGSM) on the intermediate features of the\nsegmentation network's encoder; 2) inject the generated adversarial noises into\nthe network, intentionally compromising performance; 3) optimize the network\nwith both clean and adversarial features. Experiments are conducted segmenting\nthe heart, left and right kidney, liver, left and right lung, spinal cord, and\nstomach. We first evaluate the AFA-MI augmentation using nnUnet and TT-Vnet on\nthe test data from a public abdominal dataset and an institutional dataset. In\naddition, we validate how AFA-MI affects the networks' robustness to the noisy\ndata by evaluating the networks with added Gaussian noises of varying\nmagnitudes to the institutional dataset. Network performance is quantitatively\nevaluated using Dice Similarity Coefficient (DSC) for volume-based accuracy.\nAlso, Hausdorff Distance (HD) is applied for surface-based accuracy. On the\npublic dataset, nnUnet with AFA-MI achieves DSC = 0.85 and HD = 6.16\nmillimeters (mm); and TT-Vnet achieves DSC = 0.86 and HD = 5.62 mm. AFA-MI\naugmentation further improves all contour accuracies up to 0.217 DSC score when\ntested on images with Gaussian noises. AFA-MI augmentation is therefore\ndemonstrated to improve segmentation performance and robustness in CT\nmulti-organ segmentation.\n","authors":["Shaoyan Pan","Shao-Yuan Lo","Min Huang","Chaoqiong Ma","Jacob Wynne","Tonghe Wang","Tian Liu","Xiaofeng Yang"],"pdf_url":"https://arxiv.org/pdf/2302.13172v1.pdf","comment":"Accepted at SPIE Medical Imaging 2023"},{"id":"http://arxiv.org/abs/2302.13170v1","updated":"2023-02-25T21:36:39Z","published":"2023-02-25T21:36:39Z","title":"Partial Label Learning for Emotion Recognition from EEG","summary":"  Fully supervised learning has recently achieved promising performance in\nvarious electroencephalography (EEG) learning tasks by training on large\ndatasets with ground truth labels. However, labeling EEG data for affective\nexperiments is challenging, as it can be difficult for participants to\naccurately distinguish between similar emotions, resulting in ambiguous\nlabeling (reporting multiple emotions for one EEG instance). This notion could\ncause model performance degradation, as the ground truth is hidden within\nmultiple candidate labels. To address this issue, Partial Label Learning (PLL)\nhas been proposed to identify the ground truth from candidate labels during the\ntraining phase, and has shown good performance in the computer vision domain.\nHowever, PLL methods have not yet been adopted for EEG representation learning\nor implemented for emotion recognition tasks. In this paper, we adapt and\nre-implement six state-of-the-art PLL approaches for emotion recognition from\nEEG on a large emotion dataset (SEED-V, containing five emotion classes). We\nevaluate the performance of all methods in classical and real-world\nexperiments. The results show that PLL methods can achieve strong results in\naffective computing from EEG and achieve comparable performance to fully\nsupervised learning. We also investigate the effect of label disambiguation, a\nkey step in many PLL methods. The results show that in most cases, label\ndisambiguation would benefit the model when the candidate labels are generated\nbased on their similarities to the ground truth rather than obeying a uniform\ndistribution. This finding suggests the potential of using label\ndisambiguation-based PLL methods for real-world affective tasks. We make the\nsource code of this paper publicly available at:\nhttps://github.com/guangyizhangbci/PLL-Emotion-EEG.\n","authors":["Guangyi Zhang","Ali Etemad"],"pdf_url":"https://arxiv.org/pdf/2302.13170v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2211.06496v3","updated":"2023-02-25T21:33:01Z","published":"2022-11-11T22:16:40Z","title":"Depth and Representation in Vision Models","summary":"  Deep learning models develop successive representations of their input in\nsequential layers, the last of which maps the final representation to the\noutput. Here we investigate the informational content of these representations\nby observing the ability of convolutional image classification models to\nautoencode the model's input using embeddings existing in various layers. We\nfind that the deeper the layer, the less accurate that layer's representation\nof the input is before training. Inaccurate representation results from\nnon-uniqueness in which various distinct inputs give approximately the same\nembedding. Non-unique representation is a consequence of both exact and\napproximate non-invertibility of transformations present in the forward pass.\nLearning to classify natural images leads to an increase in representation\nclarity for early but not late layers, which instead form abstract images.\nRather than simply selecting for features present in the input necessary for\nclassification, deep layer representations are found to transform the input so\nthat it matches representations of the training data such that arbitrary inputs\nare mapped to manifolds learned during training. This work provides support for\nthe theory that the tasks of image recognition and input generation are\ninseparable even for models trained exclusively to classify.\n","authors":["Benjamin L. Badger"],"pdf_url":"https://arxiv.org/pdf/2211.06496v3.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2302.13153v1","updated":"2023-02-25T20:48:15Z","published":"2023-02-25T20:48:15Z","title":"Directed Diffusion: Direct Control of Object Placement through Attention\n  Guidance","summary":"  Text-guided diffusion models such as DALLE-2, IMAGEN, and Stable Diffusion\nare able to generate an effectively endless variety of images given only a\nshort text prompt describing the desired image content. In many cases the\nimages are very high quality as well. However, these models often struggle to\ncompose scenes containing several key objects such as characters in specified\npositional relationships. Unfortunately, this capability to ``direct'' the\nplacement of characters and objects both within and across images is crucial in\nstorytelling, as recognized in the literature on film and animation theory. In\nthis work we take a particularly straightforward approach to providing the\nneeded direction, by injecting ``activation'' at desired positions in the\ncross-attention maps corresponding to the objects under control, while\nattenuating the remainder of the map. The resulting approach is a step toward\ngeneralizing the applicability of text-guided diffusion models beyond single\nimages to collections of related images, as in storybooks. To the best of our\nknowledge, our Directed Diffusion method is the first diffusion technique that\nprovides positional control over multiple objects, while making use of an\nexisting pre-trained model and maintaining a coherent blend between the\npositioned objects and the background. Moreover, it requires only a few lines\nto implement.\n","authors":["Wan-Duo Kurt Ma","J. P. Lewis","W. Bastiaan Kleijn","Thomas Leung"],"pdf_url":"https://arxiv.org/pdf/2302.13153v1.pdf","comment":"Our project page:\n  https://hohonu-vicml.github.io/DirectedDiffusion.Page"},{"id":"http://arxiv.org/abs/2302.13130v1","updated":"2023-02-25T18:12:37Z","published":"2023-02-25T18:12:37Z","title":"Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting","summary":"  Predicting how the world can evolve in the future is crucial for motion\nplanning in autonomous systems. Classical methods are limited because they rely\non costly human annotations in the form of semantic class labels, bounding\nboxes, and tracks or HD maps of cities to plan their motion and thus are\ndifficult to scale to large unlabeled datasets. One promising self-supervised\ntask is 3D point cloud forecasting from unannotated LiDAR sequences. We show\nthat this task requires algorithms to implicitly capture (1) sensor extrinsics\n(i.e., the egomotion of the autonomous vehicle), (2) sensor intrinsics (i.e.,\nthe sampling pattern specific to the particular LiDAR sensor), and (3) the\nshape and motion of other objects in the scene. But autonomous systems should\nmake predictions about the world and not their sensors. To this end, we factor\nout (1) and (2) by recasting the task as one of spacetime (4D) occupancy\nforecasting. But because it is expensive to obtain ground-truth 4D occupancy,\nwe render point cloud data from 4D occupancy predictions given sensor\nextrinsics and intrinsics, allowing one to train and test occupancy algorithms\nwith unannotated LiDAR sequences. This also allows one to evaluate and compare\npoint cloud forecasting algorithms across diverse datasets, sensors, and\nvehicles.\n","authors":["Tarasha Khurana","Peiyun Hu","David Held","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2302.13130v1.pdf","comment":"Project page: https://www.cs.cmu.edu/~tkhurana/ff4d/index.html; Code:\n  https://github.com/tarashakhurana/4d-occ-forecasting"},{"id":"http://arxiv.org/abs/2205.15895v2","updated":"2023-02-25T17:46:47Z","published":"2022-05-31T15:44:29Z","title":"From Keypoints to Object Landmarks via Self-Training Correspondence: A\n  novel approach to Unsupervised Landmark Discovery","summary":"  This paper proposes a novel paradigm for the unsupervised learning of object\nlandmark detectors. Contrary to existing methods that build on auxiliary tasks\nsuch as image generation or equivariance, we propose a self-training approach\nwhere, departing from generic keypoints, a landmark detector and descriptor is\ntrained to improve itself, tuning the keypoints into distinctive landmarks. To\nthis end, we propose an iterative algorithm that alternates between producing\nnew pseudo-labels through feature clustering and learning distinctive features\nfor each pseudo-class through contrastive learning. With a shared backbone for\nthe landmark detector and descriptor, the keypoint locations progressively\nconverge to stable landmarks, filtering those less stable. Compared to previous\nworks, our approach can learn points that are more flexible in terms of\ncapturing large viewpoint changes. We validate our method on a variety of\ndifficult datasets, including LS3D, BBCPose, Human3.6M and PennAction,\nachieving new state of the art results.\n","authors":["Dimitrios Mallis","Enrique Sanchez","Matt Bell","Georgios Tzimiropoulos"],"pdf_url":"https://arxiv.org/pdf/2205.15895v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13125v1","updated":"2023-02-25T17:22:49Z","published":"2023-02-25T17:22:49Z","title":"Non-Intrusive Driver Behavior Characterization From Road-Side Cameras","summary":"  In this paper, we demonstrate a proof of concept for characterizing vehicular\nbehavior using only the roadside cameras of the ITS system. The essential\nadvantage of this method is that it can be implemented in the roadside\ninfrastructure transparently and inexpensively and can have a global view of\neach vehicle's behavior without any involvement of or awareness by the\nindividual vehicles or drivers. By using a setup that includes programmatically\ncontrolled robot cars (to simulate different types of vehicular behaviors) and\nan external video camera set up to capture and analyze the vehicular behavior,\nwe show that the driver classification based on the external video analytics\nyields accuracies that are within 1-2\\% of the accuracies of direct\nvehicle-based characterization. We also show that the residual errors primarily\nrelate to gaps in correct object identification and tracking and thus can be\nfurther reduced with a more sophisticated setup. The characterization can be\nused to enhance both the safety and performance of the traffic flow,\nparticularly in the mixed manual and automated vehicle scenarios that are\nexpected to be common soon.\n","authors":["Pavana Pradeep Kumar","Krishna Kant","Amitangshu Pal"],"pdf_url":"https://arxiv.org/pdf/2302.13125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11306v2","updated":"2023-02-25T14:59:45Z","published":"2023-02-22T11:42:44Z","title":"Human MotionFormer: Transferring Human Motions with Vision Transformers","summary":"  Human motion transfer aims to transfer motions from a target dynamic person\nto a source static one for motion synthesis. An accurate matching between the\nsource person and the target motion in both large and subtle motion changes is\nvital for improving the transferred motion quality. In this paper, we propose\nHuman MotionFormer, a hierarchical ViT framework that leverages global and\nlocal perceptions to capture large and subtle motion matching, respectively. It\nconsists of two ViT encoders to extract input features (i.e., a target motion\nimage and a source human image) and a ViT decoder with several cascaded blocks\nfor feature matching and motion transfer. In each block, we set the target\nmotion feature as Query and the source person as Key and Value, calculating the\ncross-attention maps to conduct a global feature matching. Further, we\nintroduce a convolutional layer to improve the local perception after the\nglobal cross-attention computations. This matching process is implemented in\nboth warping and generation branches to guide the motion transfer. During\ntraining, we propose a mutual learning loss to enable the co-supervision\nbetween warping and generation branches for better motion representations.\nExperiments show that our Human MotionFormer sets the new state-of-the-art\nperformance both qualitatively and quantitatively. Project page:\n\\url{https://github.com/KumapowerLIU/Human-MotionFormer}\n","authors":["Hongyu Liu","Xintong Han","Chengbin Jin","Lihui Qian","Huawei Wei","Zhe Lin","Faqiang Wang","Haoye Dong","Yibing Song","Jia Xu","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2302.11306v2.pdf","comment":"Accepted by ICLR2023"},{"id":"http://arxiv.org/abs/2302.13095v1","updated":"2023-02-25T14:56:35Z","published":"2023-02-25T14:56:35Z","title":"Bayesian Neural Networks Tend to Ignore Complex and Sensitive Concepts","summary":"  In this paper, we focus on mean-field variational Bayesian Neural Networks\n(BNNs) and explore the representation capacity of such BNNs by investigating\nwhich types of concepts are less likely to be encoded by the BNN. It has been\nobserved and studied that a relatively small set of interactive concepts\nusually emerge in the knowledge representation of a sufficiently-trained neural\nnetwork, and such concepts can faithfully explain the network output. Based on\nthis, our study proves that compared to standard deep neural networks (DNNs),\nit is less likely for BNNs to encode complex concepts. Experiments verify our\ntheoretical proofs. Note that the tendency to encode less complex concepts does\nnot necessarily imply weak representation power, considering that complex\nconcepts exhibit low generalization power and high adversarial vulnerability.\n","authors":["Qihan Ren","Huiqi Deng","Yunuo Chen","Siyu Lou","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13094v1","updated":"2023-02-25T14:53:17Z","published":"2023-02-25T14:53:17Z","title":"Knowledge-infused Contrastive Learning for Urban Imagery-based\n  Socioeconomic Prediction","summary":"  Monitoring sustainable development goals requires accurate and timely\nsocioeconomic statistics, while ubiquitous and frequently-updated urban imagery\nin web like satellite/street view images has emerged as an important source for\nsocioeconomic prediction. Especially, recent studies turn to self-supervised\ncontrastive learning with manually designed similarity metrics for urban\nimagery representation learning and further socioeconomic prediction, which\nhowever suffers from effectiveness and robustness issues. To address such\nissues, in this paper, we propose a Knowledge-infused Contrastive Learning\n(KnowCL) model for urban imagery-based socioeconomic prediction. Specifically,\nwe firstly introduce knowledge graph (KG) to effectively model the urban\nknowledge in spatiality, mobility, etc., and then build neural network based\nencoders to learn representations of an urban image in associated semantic and\nvisual spaces, respectively. Finally, we design a cross-modality based\ncontrastive learning framework with a novel image-KG contrastive loss, which\nmaximizes the mutual information between semantic and visual representations\nfor knowledge infusion. Extensive experiments of applying the learnt visual\nrepresentations for socioeconomic prediction on three datasets demonstrate the\nsuperior performance of KnowCL with over 30\\% improvements on $R^2$ compared\nwith baselines. Especially, our proposed KnowCL model can apply to both\nsatellite and street imagery with both effectiveness and transferability\nachieved, which provides insights into urban imagery-based socioeconomic\nprediction.\n","authors":["Yu Liu","Xin Zhang","Jingtao Ding","Yanxin Xi","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2302.13094v1.pdf","comment":"WWW'23"},{"id":"http://arxiv.org/abs/2302.13092v1","updated":"2023-02-25T14:49:09Z","published":"2023-02-25T14:49:09Z","title":"JND-Based Perceptual Optimization For Learned Image Compression","summary":"  Recently, learned image compression schemes have achieved remarkable\nimprovements in image fidelity (e.g., PSNR and MS-SSIM) compared to\nconventional hybrid image coding ones due to their high-efficiency non-linear\ntransform, end-to-end optimization frameworks, etc. However, few of them take\nthe Just Noticeable Difference (JND) characteristic of the Human Visual System\n(HVS) into account and optimize learned image compression towards perceptual\nquality. To address this issue, a JND-based perceptual quality loss is\nproposed. Considering that the amounts of distortion in the compressed image at\ndifferent training epochs under different Quantization Parameters (QPs) are\ndifferent, we develop a distortion-aware adjustor. After combining them\ntogether, we can better assign the distortion in the compressed image with the\nguidance of JND to preserve the high perceptual quality. All these designs\nenable the proposed method to be flexibly applied to various learned image\ncompression schemes with high scalability and plug-and-play advantages.\nExperimental results on the Kodak dataset demonstrate that the proposed method\nhas led to better perceptual quality than the baseline model under the same bit\nrate.\n","authors":["Feng Ding","Jian Jin","Lili Meng","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2302.13092v1.pdf","comment":"5 pages, 5 figures, conference"},{"id":"http://arxiv.org/abs/2302.13091v1","updated":"2023-02-25T14:44:40Z","published":"2023-02-25T14:44:40Z","title":"Concept-Level Explanation for the Generalization of a DNN","summary":"  This paper explains the generalization power of a deep neural network (DNN)\nfrom the perspective of interactive concepts. Many recent studies have\nquantified a clear emergence of interactive concepts encoded by the DNN, which\nhave been observed on different DNNs during the learning process. Therefore, in\nthis paper, we investigate the generalization power of each interactive\nconcept, and we use the generalization power of different interactive concepts\nto explain the generalization power of the entire DNN. Specifically, we define\nthe complexity of each interactive concept. We find that simple concepts can be\nbetter generalized to testing data than complex concepts. The DNN with strong\ngeneralization power usually learns simple concepts more quickly and encodes\nfewer complex concepts. More crucially, we discover the detouring dynamics of\nlearning complex concepts, which explain both the high learning difficulty and\nthe low generalization power of complex concepts.\n","authors":["Huilin Zhou","Hao Zhang","Huiqi Deng","Dongrui Liu","Wen Shen","Shih-Han Chan","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01540v2","updated":"2023-02-25T14:17:27Z","published":"2023-02-03T04:31:13Z","title":"DEVICE: DEpth and VIsual ConcEpts Aware Transformer for TextCaps","summary":"  Text-based image captioning is an important but under-explored task, aiming\nto generate descriptions containing visual objects and scene text. Recent\nstudies have made encouraging progress, but they are still suffering from a\nlack of overall understanding of scenes and generating inaccurate captions. One\npossible reason is that current studies mainly focus on constructing the\nplane-level geometric relationship of scene text without depth information.\nThis leads to insufficient scene text relational reasoning so that models may\ndescribe scene text inaccurately. The other possible reason is that existing\nmethods fail to generate fine-grained descriptions of some visual objects. In\naddition, they may ignore essential visual objects, leading to the scene text\nbelonging to these ignored objects not being utilized. To address the above\nissues, we propose a DEpth and VIsual ConcEpts Aware Transformer (DEVICE) for\nTextCaps. Concretely, to construct three-dimensional geometric relations, we\nintroduce depth information and propose a depth-enhanced feature updating\nmodule to ameliorate OCR token features. To generate more precise and\ncomprehensive captions, we introduce semantic features of detected visual\nobject concepts as auxiliary information. Our DEVICE is capable of generalizing\nscenes more comprehensively and boosting the accuracy of described visual\nentities. Sufficient experiments demonstrate the effectiveness of our proposed\nDEVICE, which outperforms state-of-the-art models on the TextCaps test set. Our\ncode will be publicly available.\n","authors":["Dongsheng Xu","Qingbao Huang","Yi Cai"],"pdf_url":"https://arxiv.org/pdf/2302.01540v2.pdf","comment":"11pages, 7figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2302.13084v1","updated":"2023-02-25T14:09:52Z","published":"2023-02-25T14:09:52Z","title":"UAVSNet: An Encoder-Decoder Architecture based UAV Image Segmentation\n  Network","summary":"  Due to an increased application of Unmanned Aerial Vehicle (UAV) devices like\ndrones, segmentation of aerial images for urban scene understanding has brought\na new research opportunity. Aerial images own so much variability in scale,\nobject appearance, and complex background. The task of semantic segmentation\nwhen capturing the underlying features in a global and local context for the\nUAV images becomes challenging. In this work, we proposed a UAV Segmentation\nNetwork (UAVSNet) for precise semantic segmentation of urban aerial scenes. It\nis a transformer-based encoder-decoder framework that uses multi-scale feature\nrepresentations. The UAVSNet exploits the advantage of a self-attention-based\ntransformer framework and convolution mechanisms in capturing the global and\nlocal context details. This helps the network precisely capture the inherent\nfeature of the aerial images and generate overall semantically rich feature\nrepresentation. The proposed Overlap Token Embedding (OTE) module generates\nmulti-scale features. A decoder network is proposed, which further processes\nthese features using a multi-scale feature fusion policy to enhance the feature\nrepresentation ability of the network. We show the effectiveness of the\nproposed network on UAVid and Urban drone datasets by achieving mIoU of 64.35%\nand 74.64%, respectively.\n","authors":["Satyawant Kumar","Abhishek Kumar","Dong-Gyu Lee"],"pdf_url":"https://arxiv.org/pdf/2302.13084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13080v1","updated":"2023-02-25T13:58:37Z","published":"2023-02-25T13:58:37Z","title":"Does a Neural Network Really Encode Symbolic Concept?","summary":"  Recently, a series of studies have tried to extract interactions between\ninput variables modeled by a DNN and define such interactions as concepts\nencoded by the DNN. However, strictly speaking, there still lacks a solid\nguarantee whether such interactions indeed represent meaningful concepts.\nTherefore, in this paper, we examine the trustworthiness of interaction\nconcepts from four perspectives. Extensive empirical studies have verified that\na well-trained DNN usually encodes sparse, transferable, and discriminative\nconcepts, which is partially aligned with human intuition.\n","authors":["Mingjie Li","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.13080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02019v5","updated":"2023-02-25T13:25:16Z","published":"2022-12-05T04:33:12Z","title":"SASFormer: Transformers for Sparsely Annotated Semantic Segmentation","summary":"  Semantic segmentation based on sparse annotation has advanced in recent\nyears. It labels only part of each object in the image, leaving the remainder\nunlabeled. Most of the existing approaches are time-consuming and often\nnecessitate a multi-stage training strategy. In this work, we propose a simple\nyet effective sparse annotated semantic segmentation framework based on\nsegformer, dubbed SASFormer, that achieves remarkable performance.\nSpecifically, the framework first generates hierarchical patch attention maps,\nwhich are then multiplied by the network predictions to produce correlated\nregions separated by valid labels. Besides, we also introduce the affinity loss\nto ensure consistency between the features of correlation results and network\npredictions. Extensive experiments showcase that our proposed approach is\nsuperior to existing methods and achieves cutting-edge performance. The source\ncode is available at \\url{https://github.com/su-hui-zz/SASFormer}.\n","authors":["Hui Su","Yue Ye","Wei Hua","Lechao Cheng","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2212.02019v5.pdf","comment":"8 pages, 6 figures, 6 tables; version4.0"},{"id":"http://arxiv.org/abs/2302.13075v1","updated":"2023-02-25T13:12:50Z","published":"2023-02-25T13:12:50Z","title":"BOP Challenge 2022 on Detection, Segmentation and Pose Estimation of\n  Specific Rigid Objects","summary":"  We present the evaluation methodology, datasets and results of the BOP\nChallenge 2022, the fourth in a series of public competitions organized with\nthe goal to capture the status quo in the field of 6D object pose estimation\nfrom an RGB/RGB-D image. In 2022, we witnessed another significant improvement\nin the pose estimation accuracy -- the state of the art, which was 56.9 AR$_C$\nin 2019 (Vidal et al.) and 69.8 AR$_C$ in 2020 (CosyPose), moved to new heights\nof 83.7 AR$_C$ (GDRNPP). Out of 49 pose estimation methods evaluated since\n2019, the top 18 are from 2022. Methods based on point pair features, which\nwere introduced in 2010 and achieved competitive results even in 2020, are now\nclearly outperformed by deep learning methods. The synthetic-to-real domain gap\nwas again significantly reduced, with 82.7 AR$_C$ achieved by GDRNPP trained\nonly on synthetic images from BlenderProc. The fastest variant of GDRNPP\nreached 80.5 AR$_C$ with an average time per image of 0.23s. Since most of the\nrecent methods for 6D object pose estimation begin by detecting/segmenting\nobjects, we also started evaluating 2D object detection and segmentation\nperformance based on the COCO metrics. Compared to the Mask R-CNN results from\nCosyPose in 2020, detection improved from 60.3 to 77.3 AP$_C$ and segmentation\nfrom 40.5 to 58.7 AP$_C$. The online evaluation system stays open and is\navailable at: \\href{http://bop.felk.cvut.cz/}{bop.felk.cvut.cz}.\n","authors":["Martin Sundermeyer","Tomas Hodan","Yann Labbe","Gu Wang","Eric Brachmann","Bertram Drost","Carsten Rother","Jiri Matas"],"pdf_url":"https://arxiv.org/pdf/2302.13075v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2009.07378"},{"id":"http://arxiv.org/abs/2302.01243v2","updated":"2023-02-25T13:11:13Z","published":"2023-02-02T17:25:29Z","title":"Human not in the loop: objective sample difficulty measures for\n  Curriculum Learning","summary":"  Curriculum learning is a learning method that trains models in a meaningful\norder from easier to harder samples. A key here is to devise automatic and\nobjective difficulty measures of samples. In the medical domain, previous work\napplied domain knowledge from human experts to qualitatively assess\nclassification difficulty of medical images to guide curriculum learning, which\nrequires extra annotation efforts, relies on subjective human experience, and\nmay introduce bias. In this work, we propose a new automated curriculum\nlearning technique using the variance of gradients (VoG) to compute an\nobjective difficulty measure of samples and evaluated its effects on elbow\nfracture classification from X-ray images. Specifically, we used VoG as a\nmetric to rank each sample in terms of the classification difficulty, where\nhigh VoG scores indicate more difficult cases for classification, to guide the\ncurriculum training process We compared the proposed technique to a baseline\n(without curriculum learning), a previous method that used human annotations on\nclassification difficulty, and anti-curriculum learning. Our experiment results\nshowed comparable and higher performance for the binary and multi-class bone\nfracture classification tasks.\n","authors":["Zhengbo Zhou","Jun Luo","Dooman Arefan","Gene Kitamura","Shandong Wu"],"pdf_url":"https://arxiv.org/pdf/2302.01243v2.pdf","comment":"ISBI 2023"},{"id":"http://arxiv.org/abs/2302.13074v1","updated":"2023-02-25T13:05:57Z","published":"2023-02-25T13:05:57Z","title":"Temporal Segment Transformer for Action Segmentation","summary":"  Recognizing human actions from untrimmed videos is an important task in\nactivity understanding, and poses unique challenges in modeling long-range\ntemporal relations. Recent works adopt a predict-and-refine strategy which\nconverts an initial prediction to action segments for global context modeling.\nHowever, the generated segment representations are often noisy and exhibit\ninaccurate segment boundaries, over-segmentation and other problems. To deal\nwith these issues, we propose an attention based approach which we call\n\\textit{temporal segment transformer}, for joint segment relation modeling and\ndenoising. The main idea is to denoise segment representations using attention\nbetween segment and frame representations, and also use inter-segment attention\nto capture temporal correlations between segments. The refined segment\nrepresentations are used to predict action labels and adjust segment\nboundaries, and a final action segmentation is produced based on voting from\nsegment masks. We show that this novel architecture achieves state-of-the-art\naccuracy on the popular 50Salads, GTEA and Breakfast benchmarks. We also\nconduct extensive ablations to demonstrate the effectiveness of different\ncomponents of our design.\n","authors":["Zhichao Liu","Leshan Wang","Desen Zhou","Jian Wang","Songyang Zhang","Yang Bai","Errui Ding","Rui Fan"],"pdf_url":"https://arxiv.org/pdf/2302.13074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13069v1","updated":"2023-02-25T12:12:22Z","published":"2023-02-25T12:12:22Z","title":"Medical visual question answering using joint self-supervised learning","summary":"  Visual Question Answering (VQA) becomes one of the most active research\nproblems in the medical imaging domain. A well-known VQA challenge is the\nintrinsic diversity between the image and text modalities, and in the medical\nVQA task, there is another critical problem relying on the limited size of\nlabelled image-question-answer data. In this study we propose an\nencoder-decoder framework that leverages the image-text joint representation\nlearned from large-scaled medical image-caption data and adapted to the\nsmall-sized medical VQA task. The encoder embeds across the image-text dual\nmodalities with self-attention mechanism and is independently pre-trained on\nthe large-scaled medical image-caption dataset by multiple self-supervised\nlearning tasks. Then the decoder is connected to the top of the encoder and\nfine-tuned using the small-sized medical VQA dataset. The experiment results\npresent that our proposed method achieves better performance comparing with the\nbaseline and SOTA methods.\n","authors":["Yuan Zhou","Jing Mei","Yiqin Yu","Tanveer Syeda-Mahmood"],"pdf_url":"https://arxiv.org/pdf/2302.13069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15717v3","updated":"2023-02-25T11:59:26Z","published":"2022-11-28T19:03:01Z","title":"Learning deep abdominal CT registration through adaptive loss weighting\n  and synthetic data generation","summary":"  Purpose: This study aims to explore training strategies to improve\nconvolutional neural network-based image-to-image deformable registration for\nabdominal imaging. Methods: Different training strategies, loss functions, and\ntransfer learning schemes were considered. Furthermore, an augmentation layer\nwhich generates artificial training image pairs on-the-fly was proposed, in\naddition to a loss layer that enables dynamic loss weighting. Results: Guiding\nregistration using segmentations in the training step proved beneficial for\ndeep-learning-based image registration. Finetuning the pretrained model from\nthe brain MRI dataset to the abdominal CT dataset further improved performance\non the latter application, removing the need for a large dataset to yield\nsatisfactory performance. Dynamic loss weighting also marginally improved\nperformance, all without impacting inference runtime. Conclusion: Using simple\nconcepts, we improved the performance of a commonly used deep image\nregistration architecture, VoxelMorph. In future work, our framework, DDMR,\nshould be validated on different datasets to further assess its value.\n","authors":["Javier Pérez de Frutos","André Pedersen","Egidijus Pelanis","David Bouget","Shanmugapriya Survarachakan","Thomas Langø","Ole-Jakob Elle","Frank Lindseth"],"pdf_url":"https://arxiv.org/pdf/2211.15717v3.pdf","comment":"14 pages, 1 figure, 4 tables"},{"id":"http://arxiv.org/abs/2302.13057v1","updated":"2023-02-25T11:03:16Z","published":"2023-02-25T11:03:16Z","title":"DeepBrainPrint: A Novel Contrastive Framework for Brain MRI\n  Re-Identification","summary":"  Recent advances in MRI have led to the creation of large datasets. With the\nincrease in data volume, it has become difficult to locate previous scans of\nthe same patient within these datasets (a process known as re-identification).\nTo address this issue, we propose an AI-powered medical imaging retrieval\nframework called DeepBrainPrint, which is designed to retrieve brain MRI scans\nof the same patient. Our framework is a semi-self-supervised contrastive deep\nlearning approach with three main innovations. First, we use a combination of\nself-supervised and supervised paradigms to create an effective brain\nfingerprint from MRI scans that can be used for real-time image retrieval.\nSecond, we use a special weighting function to guide the training and improve\nmodel convergence. Third, we introduce new imaging transformations to improve\nretrieval robustness in the presence of intensity variations (i.e. different\nscan contrasts), and to account for age and disease progression in patients. We\ntested DeepBrainPrint on a large dataset of T1-weighted brain MRIs from the\nAlzheimer's Disease Neuroimaging Initiative (ADNI) and on a synthetic dataset\ndesigned to evaluate retrieval performance with different image modalities. Our\nresults show that DeepBrainPrint outperforms previous methods, including simple\nsimilarity metrics and more advanced contrastive deep learning frameworks.\n","authors":["Lemuel Puglisi","Frederik Barkhof","Daniel C. Alexander","Geoffrey JM Parker","Arman Eshaghi","Daniele Ravì"],"pdf_url":"https://arxiv.org/pdf/2302.13057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13056v1","updated":"2023-02-25T10:57:41Z","published":"2023-02-25T10:57:41Z","title":"SATBA: An Invisible Backdoor Attack Based On Spatial Attention","summary":"  As a new realm of AI security, backdoor attack has drew growing attention\nresearch in recent years. It is well known that backdoor can be injected in a\nDNN model through the process of model training with poisoned dataset which is\nconsist of poisoned sample. The injected model output correct prediction on\nbenign samples yet behave abnormally on poisoned samples included trigger\npattern. Most existing trigger of poisoned sample are visible and can be easily\nfound by human visual inspection, and the trigger injection process will cause\nthe feature loss of natural sample and trigger. To solve the above problems and\ninspire by spatial attention mechanism, we introduce a novel backdoor attack\nnamed SATBA, which is invisible and can minimize the loss of trigger to improve\nattack success rate and model accuracy. It extracts data features and generate\ntrigger pattern related to clean data through spatial attention, poisons clean\nimage by using a U-type models to plant a trigger into the original data. We\ndemonstrate the effectiveness of our attack against three popular image\nclassification DNNs on three standard datasets. Besides, we conduct extensive\nexperiments about image similarity to show that our proposed attack can provide\npractical stealthiness which is critical to resist to backdoor defense.\n","authors":["Huasong Zhou","Zhenyu Wang","Xiaowei Xu"],"pdf_url":"https://arxiv.org/pdf/2302.13056v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.13049v1","updated":"2023-02-25T10:26:34Z","published":"2023-02-25T10:26:34Z","title":"CASIA-Iris-Africa: A Large-scale African Iris Image Database","summary":"  Iris biometrics is a phenotypic biometric trait that has proven to be\nagnostic to human natural physiological changes. Research on iris biometrics\nhas progressed tremendously, partly due to publicly available iris databases.\nVarious databases have been available to researchers that address pressing iris\nbiometric challenges such as constraint, mobile, multispectral, synthetics,\nlong-distance, contact lenses, liveness detection, etc. However, these\ndatabases mostly contain subjects of Caucasian and Asian docents with very few\nAfricans. Despite many investigative studies on racial bias in face biometrics,\nvery few studies on iris biometrics have been published, mainly due to the lack\nof racially diverse large-scale databases containing sufficient iris samples of\nAfricans in the public domain. Furthermore, most of these databases contain a\nrelatively small number of subjects and labelled images. This paper proposes a\nlarge-scale African database named CASIA-Iris-Africa that can be used as a\ncomplementary database for the iris recognition community to mediate the effect\nof racial biases on Africans. The database contains 28,717 images of 1023\nAfrican subjects (2046 iris classes) with age, gender, and ethnicity attributes\nthat can be useful in demographically sensitive studies of Africans. Sets of\nspecific application protocols are incorporated with the database to ensure the\ndatabase's variability and scalability. Performance results of some open-source\nSOTA algorithms on the database are presented, which will serve as baseline\nperformances. The relatively poor performances of the baseline algorithms on\nthe proposed database despite better performance on other databases prove that\nracial biases exist in these iris recognition algorithms. The database will be\nmade available on our website: http://www.idealtest.org.\n","authors":["Jawad Muhammad","Yunlong Wang","Junxing Hu","Kunbo Zhang","Zhenan Sun"],"pdf_url":"https://arxiv.org/pdf/2302.13049v1.pdf","comment":"This paper has been accepted for publication in Machine Intelligence\n  Research Journal (MIR)"},{"id":"http://arxiv.org/abs/2111.06206v5","updated":"2023-02-25T09:37:35Z","published":"2021-11-11T13:48:20Z","title":"Towards Axiomatic, Hierarchical, and Symbolic Explanation for Deep\n  Models","summary":"  This paper aims to show that the inference logic of a deep model can be\nfaithfully approximated as a sparse, symbolic causal graph. Such a causal graph\npotentially bridges the gap between connectionism and symbolism. To this end,\nthe faithfulness of the causal graph is theoretically guaranteed, because we\nshow that the causal graph can well mimic the model's output on an exponential\nnumber of different masked samples. Besides, such a causal graph can be further\nsimplified and rewritten as an And-Or graph (AOG), which explains the logical\nrelationship between interactive concepts encoded by the deep model, without\nlosing much explanation accuracy.\n","authors":["Jie Ren","Mingjie Li","Qirui Chen","Huiqi Deng","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2111.06206v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13033v1","updated":"2023-02-25T09:11:09Z","published":"2023-02-25T09:11:09Z","title":"Speaker Recognition in Realistic Scenario Using Multimodal Data","summary":"  In recent years, an association is established between faces and voices of\ncelebrities leveraging large scale audio-visual information from YouTube. The\navailability of large scale audio-visual datasets is instrumental in developing\nspeaker recognition methods based on standard Convolutional Neural Networks.\nThus, the aim of this paper is to leverage large scale audio-visual information\nto improve speaker recognition task. To achieve this task, we proposed a\ntwo-branch network to learn joint representations of faces and voices in a\nmultimodal system. Afterwards, features are extracted from the two-branch\nnetwork to train a classifier for speaker recognition. We evaluated our\nproposed framework on a large scale audio-visual dataset named VoxCeleb$1$. Our\nresults show that addition of facial information improved the performance of\nspeaker recognition. Moreover, our results indicate that there is an overlap\nbetween face and voice.\n","authors":["Saqlain Hussain Shah","Muhammad Saad Saeed","Shah Nawaz","Muhammad Haroon Yousaf"],"pdf_url":"https://arxiv.org/pdf/2302.13033v1.pdf","comment":"Accepted at the International Conference on Artificial Intelligence\n  (ICAI'2023)"},{"id":"http://arxiv.org/abs/2302.13028v1","updated":"2023-02-25T09:02:01Z","published":"2023-02-25T09:02:01Z","title":"A Light-weight Deep Learning Model for Remote Sensing Image\n  Classification","summary":"  In this paper, we present a high-performance and light-weight deep learning\nmodel for Remote Sensing Image Classification (RSIC), the task of identifying\nthe aerial scene of a remote sensing image. To this end, we first valuate\nvarious benchmark convolutional neural network (CNN) architectures: MobileNet\nV1/V2, ResNet 50/151V2, InceptionV3/InceptionResNetV2, EfficientNet B0/B7,\nDenseNet 121/201, ConNeXt Tiny/Large. Then, the best performing models are\nselected to train a compact model in a teacher-student arrangement. The\nknowledge distillation from the teacher aims to achieve high performance with\nsignificantly reduced complexity. By conducting extensive experiments on the\nNWPU-RESISC45 benchmark, our proposed teacher-student models outperforms the\nstate-of-the-art systems, and has potential to be applied on a wide rage of\nedge devices.\n","authors":["Lam Pham","Cam Le","Dat Ngo","Anh Nguyen","Jasmin Lampert","Alexander Schindler","Ian McLoughlin"],"pdf_url":"https://arxiv.org/pdf/2302.13028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.00899v2","updated":"2023-02-25T08:27:17Z","published":"2022-11-02T05:49:19Z","title":"LightVessel: Exploring Lightweight Coronary Artery Vessel Segmentation\n  via Similarity Knowledge Distillation","summary":"  In recent years, deep convolution neural networks (DCNNs) have achieved great\nprospects in coronary artery vessel segmentation. However, it is difficult to\ndeploy complicated models in clinical scenarios since high-performance\napproaches have excessive parameters and high computation costs. To tackle this\nproblem, we propose \\textbf{LightVessel}, a Similarity Knowledge Distillation\nFramework, for lightweight coronary artery vessel segmentation. Primarily, we\npropose a Feature-wise Similarity Distillation (FSD) module for semantic-shift\nmodeling. Specifically, we calculate the feature similarity between the\nsymmetric layers from the encoder and decoder. Then the similarity is\ntransferred as knowledge from a cumbersome teacher network to a non-trained\nlightweight student network. Meanwhile, for encouraging the student model to\nlearn more pixel-wise semantic information, we introduce the Adversarial\nSimilarity Distillation (ASD) module. Concretely, the ASD module aims to\nconstruct the spatial adversarial correlation between the annotation and\nprediction from the teacher and student models, respectively. Through the ASD\nmodule, the student model obtains fined-grained subtle edge segmented results\nof the coronary artery vessel. Extensive experiments conducted on Clinical\nCoronary Artery Vessel Dataset demonstrate that LightVessel outperforms various\nknowledge distillation counterparts.\n","authors":["Hao Dang","Yuekai Zhang","Xingqun Qi","Wanting Zhou","Muyi Sun"],"pdf_url":"https://arxiv.org/pdf/2211.00899v2.pdf","comment":"5 pages, 7 figures, conference"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.13168v1","updated":"2023-02-25T21:32:16Z","published":"2023-02-25T21:32:16Z","title":"Random projection tree similarity metric for SpectralNet","summary":"  SpectralNet is a graph clustering method that uses neural network to find an\nembedding that separates the data. So far it was only used with $k$-nn graphs,\nwhich are usually constructed using a distance metric (e.g., Euclidean\ndistance). $k$-nn graphs restrict the points to have a fixed number of\nneighbors regardless of the local statistics around them. We proposed a new\nSpectralNet similarity metric based on random projection trees (rpTrees). Our\nexperiments revealed that SpectralNet produces better clustering accuracy using\nrpTree similarity metric compared to $k$-nn graph with a distance metric. Also,\nwe found out that rpTree parameters do not affect the clustering accuracy.\nThese parameters include the leaf size and the selection of projection\ndirection. It is computationally efficient to keep the leaf size in order of\n$\\log(n)$, and project the points onto a random direction instead of trying to\nfind the direction with the maximum dispersion.\n","authors":["Mashaan Alshammari","John Stavrakakis","Adel F. Ahmed","Masahiro Takatsuka"],"pdf_url":"https://arxiv.org/pdf/2302.13168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13165v1","updated":"2023-02-25T21:19:30Z","published":"2023-02-25T21:19:30Z","title":"A parameter-free graph reduction for spectral clustering and SpectralNet","summary":"  Graph-based clustering methods like spectral clustering and SpectralNet are\nvery efficient in detecting clusters of non-convex shapes. Unlike the popular\n$k$-means, graph-based clustering methods do not assume that each cluster has a\nsingle mean. However, these methods need a graph where vertices in the same\ncluster are connected by edges of large weights. To achieve this goal, many\nstudies have proposed graph reduction methods with parameters. Unfortunately,\nthese parameters have to be tuned for every dataset. We introduce a graph\nreduction method that does not require any parameters. First, the distances\nfrom every point $p$ to its neighbors are filtered using an adaptive threshold\nto only keep neighbors with similar surrounding density. Second, the\nsimilarities with close neighbors are computed and only high similarities are\nkept. The edges that survive these two filtering steps form the constructed\ngraph that was passed to spectral clustering and SpectralNet. The experiments\nshowed that our method provides a stable alternative, where other methods\nperformance fluctuated according to the setting of their parameters.\n","authors":["Mashaan Alshammari","John Stavrakakis","Masahiro Takatsuka"],"pdf_url":"https://arxiv.org/pdf/2302.13165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13160v1","updated":"2023-02-25T20:57:06Z","published":"2023-02-25T20:57:06Z","title":"The Effect of Points Dispersion on the $k$-nn Search in Random\n  Projection Forests","summary":"  Partitioning trees are efficient data structures for $k$-nearest neighbor\nsearch. Machine learning libraries commonly use a special type of partitioning\ntrees called $k$d-trees to perform $k$-nn search. Unfortunately, $k$d-trees can\nbe ineffective in high dimensions because they need more tree levels to\ndecrease the vector quantization (VQ) error. Random projection trees rpTrees\nsolve this scalability problem by using random directions to split the data. A\ncollection of rpTrees is called rpForest. $k$-nn search in an rpForest is\ninfluenced by two factors: 1) the dispersion of points along the random\ndirection and 2) the number of rpTrees in the rpForest. In this study, we\ninvestigate how these two factors affect the $k$-nn search with varying $k$\nvalues and different datasets. We found that with larger number of trees, the\ndispersion of points has a very limited effect on the $k$-nn search. One should\nuse the original rpTree algorithm by picking a random direction regardless of\nthe dispersion of points.\n","authors":["Mashaan Alshammari","John Stavrakakis","Adel F. Ahmed","Masahiro Takatsuka"],"pdf_url":"https://arxiv.org/pdf/2302.13160v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.12613v2","updated":"2023-02-25T14:12:52Z","published":"2021-09-26T14:09:25Z","title":"SimpleX: A Simple and Strong Baseline for Collaborative Filtering","summary":"  Collaborative filtering (CF) is a widely studied research topic in\nrecommender systems. The learning of a CF model generally depends on three\nmajor components, namely interaction encoder, loss function, and negative\nsampling. While many existing studies focus on the design of more powerful\ninteraction encoders, the impacts of loss functions and negative sampling\nratios have not yet been well explored. In this work, we show that the choice\nof loss function as well as negative sampling ratio is equivalently important.\nMore specifically, we propose the cosine contrastive loss (CCL) and further\nincorporate it to a simple unified CF model, dubbed SimpleX. Extensive\nexperiments have been conducted on 11 benchmark datasets and compared with 29\nexisting CF models in total. Surprisingly, the results show that, under our CCL\nloss and a large negative sampling ratio, SimpleX can surpass most\nsophisticated state-of-the-art models by a large margin (e.g., max 48.5%\nimprovement in NDCG@20 over LightGCN). We believe that SimpleX could not only\nserve as a simple strong baseline to foster future research on CF, but also\nshed light on the potential research direction towards improving loss function\nand negative sampling.\n","authors":["Kelong Mao","Jieming Zhu","Jinpeng Wang","Quanyu Dai","Zhenhua Dong","Xi Xiao","Xiuqiang He"],"pdf_url":"https://arxiv.org/pdf/2109.12613v2.pdf","comment":"Accepted by CIKM 2021. Code available at\n  https://github.com/xue-pai/SimpleX"},{"id":"http://arxiv.org/abs/2302.13053v1","updated":"2023-02-25T10:42:34Z","published":"2023-02-25T10:42:34Z","title":"RETEXO: Scalable Neural Network Training over Distributed Graphs","summary":"  Graph neural networks offer a promising approach to supervised learning over\ngraph data. Graph data, especially when it is privacy-sensitive or too large to\ntrain on centrally, is often stored partitioned across disparate processing\nunits (clients) which want to minimize the communication costs during\ncollaborative training. The fully-distributed setup takes such partitioning to\nits extreme, wherein features of only a single node and its adjacent edges are\nkept locally with one client processor. Existing GNNs are not architected for\ntraining in such setups and incur prohibitive costs therein. We propose RETEXO,\na novel transformation of existing GNNs that improves the communication\nefficiency during training in the fully-distributed setup. We experimentally\nconfirm that RETEXO offers up to 6 orders of magnitude better communication\nefficiency even when training shallow GNNs, with a minimal trade-off in\naccuracy for supervised node classification tasks.\n","authors":["Aashish Kolluri","Sarthak Choudhary","Bryan Hooi","Prateek Saxena"],"pdf_url":"https://arxiv.org/pdf/2302.13053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15214v5","updated":"2023-02-25T06:55:52Z","published":"2022-09-30T04:03:26Z","title":"Construction and Applications of Billion-Scale Pre-trained Multimodal\n  Business Knowledge Graph","summary":"  Business Knowledge Graphs (KGs) are important to many enterprises today,\nproviding factual knowledge and structured data that steer many products and\nmake them more intelligent. Despite their promising benefits, building business\nKG necessitates solving prohibitive issues of deficient structure and multiple\nmodalities. In this paper, we advance the understanding of the practical\nchallenges related to building KG in non-trivial real-world systems. We\nintroduce the process of building an open business knowledge graph (OpenBG)\nderived from a well-known enterprise, Alibaba Group. Specifically, we define a\ncore ontology to cover various abstract products and consumption demands, with\nfine-grained taxonomy and multimodal facts in deployed applications. OpenBG is\nan open business KG of unprecedented scale: 2.6 billion triples with more than\n88 million entities covering over 1 million core classes/concepts and 2,681\ntypes of relations. We release all the open resources (OpenBG benchmarks)\nderived from it for the community and report experimental results of KG-centric\ntasks. We also run up an online competition based on OpenBG benchmarks, and has\nattracted thousands of teams. We further pre-train OpenBG and apply it to many\nKG- enhanced downstream tasks in business scenarios, demonstrating the\neffectiveness of billion-scale multimodal knowledge for e-commerce. All the\nresources with codes have been released at\n\\url{https://github.com/OpenBGBenchmark/OpenBG}.\n","authors":["Shumin Deng","Chengming Wang","Zhoubo Li","Ningyu Zhang","Zelin Dai","Hehong Chen","Feiyu Xiong","Ming Yan","Qiang Chen","Mosha Chen","Jiaoyan Chen","Jeff Z. Pan","Bryan Hooi","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2209.15214v5.pdf","comment":"OpenBG. Accepted by ICDE 2023. The project is released at\n  \\url{https://github.com/OpenBGBenchmark/OpenBG}"},{"id":"http://arxiv.org/abs/2208.08063v4","updated":"2023-02-25T03:19:31Z","published":"2022-08-17T04:30:58Z","title":"NECE: Narrative Event Chain Extraction Toolkit","summary":"  To understand a narrative, it is essential to comprehend its main characters\nand the associated major events; however, this can be challenging with lengthy\nand unstructured narrative texts. To address this, we introduce NECE, an\nopen-access, document-level toolkit that automatically extracts and aligns\nnarrative events in the temporal order of their occurrence using sliding window\nmethod. Through extensive human evaluations, we have confirmed the high quality\nof the NECE toolkit, and external validation has demonstrated its potential for\napplication in downstream tasks such as question answering and bias analysis.\nThe NECE toolkit includes both a Python library and a user-friendly web\ninterface; the latter offers custom visualizations of event chains and easy\nnavigation between graphics and text to improve reading efficiency and\nexperience.\n","authors":["Guangxuan Xu","Paulina Toro Isaza","Moshi Li","Akintoye Oloko","Bingsheng Yao","Cassia Sanctos","Aminat Adebiyi","Yufang Hou","Nanyun Peng","Dakuo Wang"],"pdf_url":"https://arxiv.org/pdf/2208.08063v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.09912v2","updated":"2023-02-25T02:58:18Z","published":"2022-06-20T17:29:42Z","title":"A Dense Representation Framework for Lexical and Semantic Matching","summary":"  Lexical and semantic matching capture different successful approaches to text\nretrieval and the fusion of their results has proven to be more effective and\nrobust than either alone. Prior work performs hybrid retrieval by conducting\nlexical and semantic matching using different systems (e.g., Lucene and Faiss,\nrespectively) and then fusing their model outputs. In contrast, our work\nintegrates lexical representations with dense semantic representations by\ndensifying high-dimensional lexical representations into what we call\nlow-dimensional dense lexical representations (DLRs). Our experiments show that\nDLRs can effectively approximate the original lexical representations,\npreserving effectiveness while improving query latency. Furthermore, we can\ncombine dense lexical and semantic representations to generate dense hybrid\nrepresentations (DHRs) that are more flexible and yield faster retrieval\ncompared to existing hybrid techniques. In addition, we explore it jointly\ntraining lexical and semantic representations in a single model and empirically\nshow that the resulting DHRs are able to combine the advantages of the\nindividual components. Our best DHR model is competitive with state-of-the-art\nsingle-vector and multi-vector dense retrievers in both in-domain and zero-shot\nevaluation settings. Furthermore, our model is both faster and requires smaller\nindexes, making our dense representation framework an attractive approach to\ntext retrieval. Our code is available at https://github.com/castorini/dhr.\n","authors":["Sheng-Chieh Lin","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2206.09912v2.pdf","comment":"Published in ACM Transactions on Information Systems"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.13033v1","updated":"2023-02-25T09:11:09Z","published":"2023-02-25T09:11:09Z","title":"Speaker Recognition in Realistic Scenario Using Multimodal Data","summary":"  In recent years, an association is established between faces and voices of\ncelebrities leveraging large scale audio-visual information from YouTube. The\navailability of large scale audio-visual datasets is instrumental in developing\nspeaker recognition methods based on standard Convolutional Neural Networks.\nThus, the aim of this paper is to leverage large scale audio-visual information\nto improve speaker recognition task. To achieve this task, we proposed a\ntwo-branch network to learn joint representations of faces and voices in a\nmultimodal system. Afterwards, features are extracted from the two-branch\nnetwork to train a classifier for speaker recognition. We evaluated our\nproposed framework on a large scale audio-visual dataset named VoxCeleb$1$. Our\nresults show that addition of facial information improved the performance of\nspeaker recognition. Moreover, our results indicate that there is an overlap\nbetween face and voice.\n","authors":["Saqlain Hussain Shah","Muhammad Saad Saeed","Shah Nawaz","Muhammad Haroon Yousaf"],"pdf_url":"https://arxiv.org/pdf/2302.13033v1.pdf","comment":"Accepted at the International Conference on Artificial Intelligence\n  (ICAI'2023)"},{"id":"http://arxiv.org/abs/2302.12983v1","updated":"2023-02-25T04:34:14Z","published":"2023-02-25T04:34:14Z","title":"RipViz: Finding Rip Currents by Learning Pathline Behavior","summary":"  We present a hybrid machine learning and flow analysis feature detection\nmethod, RipViz, to extract rip currents from stationary videos. Rip currents\nare dangerous strong currents that can drag beachgoers out to sea. Most people\nare either unaware of them or do not know what they look like. In some\ninstances, even trained personnel such as lifeguards have difficulty\nidentifying them. RipViz produces a simple, easy to understand visualization of\nrip location overlaid on the source video. With RipViz, we first obtain an\nunsteady 2D vector field from the stationary video using optical flow. Movement\nat each pixel is analyzed over time. At each seed point, sequences of short\npathlines, rather a single long pathline, are traced across the frames of the\nvideo to better capture the quasi-periodic flow behavior of wave activity.\nBecause of the motion on the beach, the surf zone, and the surrounding areas,\nthese pathlines may still appear very cluttered and incomprehensible.\nFurthermore, lay audiences are not familiar with pathlines and may not know how\nto interpret them. To address this, we treat rip currents as a flow anomaly in\nan otherwise normal flow. To learn about the normal flow behavior, we train an\nLSTM autoencoder with pathline sequences from normal ocean, foreground, and\nbackground movements. During test time, we use the trained LSTM autoencoder to\ndetect anomalous pathlines (i.e., those in the rip zone). The origination\npoints of such anomalous pathlines, over the course of the video, are then\npresented as points within the rip zone. RipViz is fully automated and does not\nrequire user input. Feedback from domain expert suggests that RipViz has the\npotential for wider use.\n","authors":["Akila de Silva","Mona Zhao","Donald Stewart","Fahim Hasan Khan","Gregory Dusek","James Davis","Alex Pang"],"pdf_url":"https://arxiv.org/pdf/2302.12983v1.pdf","comment":"This is the author's version of the article published in IEEE\n  Transactions on Visualization and Computer Graphics, 2023"}]},"2023-02-28T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.14828v1","updated":"2023-02-28T18:23:17Z","published":"2023-02-28T18:23:17Z","title":"Automatic Scoring of Dream Reports' Emotional Content with Large\n  Language Models","summary":"  In the field of dream research, the study of dream content typically relies\non the analysis of verbal reports provided by dreamers upon awakening from\ntheir sleep. This task is classically performed through manual scoring provided\nby trained annotators, at a great time expense. While a consistent body of work\nsuggests that natural language processing (NLP) tools can support the automatic\nanalysis of dream reports, proposed methods lacked the ability to reason over a\nreport's full context and required extensive data pre-processing. Furthermore,\nin most cases, these methods were not validated against standard manual scoring\napproaches. In this work, we address these limitations by adopting large\nlanguage models (LLMs) to study and replicate the manual annotation of dream\nreports, using a mixture of off-the-shelf and bespoke approaches, with a focus\non references to reports' emotions. Our results show that the off-the-shelf\nmethod achieves a low performance probably in light of inherent linguistic\ndifferences between reports collected in different (groups of) individuals. On\nthe other hand, the proposed bespoke text classification method achieves a high\nperformance, which is robust against potential biases. Overall, these\nobservations indicate that our approach could find application in the analysis\nof large dream datasets and may favour reproducibility and comparability of\nresults across studies.\n","authors":["Lorenzo Bertolini","Valentina Elce","Adriana Michalak","Giulio Bernardi","Julie Weeds"],"pdf_url":"https://arxiv.org/pdf/2302.14828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12746v2","updated":"2023-02-28T17:54:00Z","published":"2023-02-24T16:59:54Z","title":"Spanish Built Factual Freectianary (Spanish-BFF): the first AI-generated\n  free dictionary","summary":"  Dictionaries are one of the oldest and most used linguistic resources.\nBuilding them is a complex task that, to the best of our knowledge, has yet to\nbe explored with generative Large Language Models (LLMs). We introduce the\n\"Spanish Built Factual Freectianary\" (Spanish-BFF) as the first Spanish\nAI-generated dictionary. This first-of-its-kind free dictionary uses GPT-3. We\nalso define future steps we aim to follow to improve this initial commitment to\nthe field, such as more additional languages.\n","authors":["Miguel Ortega-Martín","Óscar García-Sierra","Alfonso Ardoiz","Juan Carlos Armenteros","Jorge Álvarez","Adrián Alonso"],"pdf_url":"https://arxiv.org/pdf/2302.12746v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14785v1","updated":"2023-02-28T17:39:43Z","published":"2023-02-28T17:39:43Z","title":"Joint Representations of Text and Knowledge Graphs for Retrieval and\n  Evaluation","summary":"  A key feature of neural models is that they can produce semantic vector\nrepresentations of objects (texts, images, speech, etc.) ensuring that similar\nobjects are close to each other in the vector space. While much work has\nfocused on learning representations for other modalities, there are no aligned\ncross-modal representations for text and knowledge base (KB) elements. One\nchallenge for learning such representations is the lack of parallel data, which\nwe use contrastive training on heuristics-based datasets and data augmentation\nto overcome, training embedding models on (KB graph, text) pairs. On WebNLG, a\ncleaner manually crafted dataset, we show that they learn aligned\nrepresentations suitable for retrieval. We then fine-tune on annotated data to\ncreate EREDAT (Ensembled Representations for Evaluation of DAta-to-Text), a\nsimilarity metric between English text and KB graphs. EREDAT outperforms or\nmatches state-of-the-art metrics in terms of correlation with human judgments\non WebNLG even though, unlike them, it does not require a reference text to\ncompare against.\n","authors":["Teven Le Scao","Claire Gardent"],"pdf_url":"https://arxiv.org/pdf/2302.14785v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05131v3","updated":"2023-02-28T17:20:36Z","published":"2022-05-10T19:32:20Z","title":"UL2: Unifying Language Learning Paradigms","summary":"  Existing pre-trained models are generally geared towards a particular class\nof problems. To date, there seems to be still no consensus on what the right\narchitecture and pre-training setup should be. This paper presents a unified\nframework for pre-training models that are universally effective across\ndatasets and setups. We begin by disentangling architectural archetypes with\npre-training objectives -- two concepts that are commonly conflated. Next, we\npresent a generalized & unified perspective for self-supervision in NLP and\nshow how different pre-training objectives can be cast as one another and how\ninterpolating between different objectives can be effective. We then propose\nMixture-of-Denoisers (MoD), a pre-training objective that combines diverse\npre-training paradigms together. We furthermore introduce a notion of mode\nswitching, wherein downstream fine-tuning is associated with specific\npre-training schemes. We conduct extensive ablative experiments to compare\nmultiple pre-training objectives and find that our method pushes the\nPareto-frontier by outperforming T5 & GPT-like models across multiple diverse\nsetups. By scaling our model up to 20B parameters, we achieve SOTA performance\non 50 well-established supervised finetuning based NLP tasks. Our model also\nachieve strong results at in-context learning, outperforming 175B GPT-3 on\nzero-shot SuperGLUE and tripling the performance of T5-XXL on one-shot\nsummarization. On 0-shot MMLU, UL2 20B outperforms T0 and T5 models. UL2 20B\nalso works well with chain-of-thought prompting and reasoning, making it an\nappealing choice for research into reasoning at a small to medium scale of 20B\nparameters. Finally, we apply FLAN instruction tuning to the UL2 20B model,\nachieving MMLU and Big-Bench scores competitive to FLAN-PaLM 62B. We release\nFlax-based T5X checkpoints for the UL2 20B & Flan-UL2 20B.\n","authors":["Yi Tay","Mostafa Dehghani","Vinh Q. Tran","Xavier Garcia","Jason Wei","Xuezhi Wang","Hyung Won Chung","Siamak Shakeri","Dara Bahri","Tal Schuster","Huaixiu Steven Zheng","Denny Zhou","Neil Houlsby","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2205.05131v3.pdf","comment":"Updated Q1 2023 with Flan-UL2 20B release! :)"},{"id":"http://arxiv.org/abs/2302.14727v1","updated":"2023-02-28T16:34:55Z","published":"2023-02-28T16:34:55Z","title":"Automatically Classifying Emotions based on Text: A Comparative\n  Exploration of Different Datasets","summary":"  Emotion Classification based on text is a task with many applications which\nhas received growing interest in recent years. This paper presents a\npreliminary study with the goal to help researchers and practitioners gain\ninsight into relatively new datasets as well as emotion classification in\ngeneral. We focus on three datasets that were recently presented in the related\nliterature, and we explore the performance of traditional as well as\nstate-of-the-art deep learning models in the presence of different\ncharacteristics in the data. We also explore the use of data augmentation in\norder to improve performance. Our experimental work shows that state-of-the-art\nmodels such as RoBERTa perform the best for all cases. We also provide\nobservations and discussion that highlight the complexity of emotion\nclassification in these datasets and test out the applicability of the models\nto actual social media posts we collected and labeled.\n","authors":["Anna Koufakou","Jairo Garciga","Adam Paul","Joseph Morelli","Christopher Frank"],"pdf_url":"https://arxiv.org/pdf/2302.14727v1.pdf","comment":"Accepted at IEEE International Conference on Tools with Artificial\n  Intelligence (ICTAI 2022)"},{"id":"http://arxiv.org/abs/2302.14719v1","updated":"2023-02-28T16:31:17Z","published":"2023-02-28T16:31:17Z","title":"Self-training through Classifier Disagreement for Cross-Domain Opinion\n  Target Extraction","summary":"  Opinion target extraction (OTE) or aspect extraction (AE) is a fundamental\ntask in opinion mining that aims to extract the targets (or aspects) on which\nopinions have been expressed. Recent work focus on cross-domain OTE, which is\ntypically encountered in real-world scenarios, where the testing and training\ndistributions differ. Most methods use domain adversarial neural networks that\naim to reduce the domain gap between the labelled source and unlabelled target\ndomains to improve target domain performance. However, this approach only\naligns feature distributions and does not account for class-wise feature\nalignment, leading to suboptimal results. Semi-supervised learning (SSL) has\nbeen explored as a solution, but is limited by the quality of pseudo-labels\ngenerated by the model. Inspired by the theoretical foundations in domain\nadaptation [2], we propose a new SSL approach that opts for selecting target\nsamples whose model output from a domain-specific teacher and student network\ndisagree on the unlabelled target data, in an effort to boost the target domain\nperformance. Extensive experiments on benchmark cross-domain OTE datasets show\nthat this approach is effective and performs consistently well in settings with\nlarge domain shifts.\n","authors":["Kai Sun","Richong Zhang","Samuel Mensah","Nikolaos Aletras","Yongyi Mao","Xudong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.14719v1.pdf","comment":"Accepted at TheWebConf 2023"},{"id":"http://arxiv.org/abs/2302.14708v1","updated":"2023-02-28T16:19:24Z","published":"2023-02-28T16:19:24Z","title":"Is Japanese CCGBank empirically correct? A case study of passive and\n  causative constructions","summary":"  The Japanese CCGBank serves as training and evaluation data for developing\nJapanese CCG parsers. However, since it is automatically generated from the\nKyoto Corpus, a dependency treebank, its linguistic validity still needs to be\nsufficiently verified. In this paper, we focus on the analysis of\npassive/causative constructions in the Japanese CCGBank and show that, together\nwith the compositional semantics of ccg2lambda, a semantic parsing system, it\nyields empirically wrong predictions for the nested construction of passives\nand causatives.\n","authors":["Daisuke Bekki","Hitomi Yanaka"],"pdf_url":"https://arxiv.org/pdf/2302.14708v1.pdf","comment":"To appear in Proceedings of Treebanks and Linguistic Theories (TLT)\n  2023, the workshop in the Georgetown University Round Table on Linguistics\n  2023 (GURT2023)"},{"id":"http://arxiv.org/abs/2302.14691v1","updated":"2023-02-28T16:06:35Z","published":"2023-02-28T16:06:35Z","title":"In-Context Instruction Learning","summary":"  Instruction learning of Large Language Models (LLMs) has enabled zero-shot\ntask generalization. However, instruction learning has been predominantly\napproached as a fine-tuning problem, including instruction tuning and\nreinforcement learning from human feedback, where LLMs are multi-task\nfine-tuned on various tasks with instructions. In this paper, we present a\nsurprising finding that applying in-context learning to instruction learning,\nreferred to as In-Context Instruction Learning (ICIL), significantly improves\nthe zero-shot task generalization performance for both pretrained and\ninstruction-fine-tuned models. One of the core advantages of ICIL is that it\nuses a single fixed prompt to evaluate all tasks, which is a concatenation of\ncross-task demonstrations. In particular, we demonstrate that the most powerful\ninstruction-fine-tuned baseline (text-davinci-003) also benefits from ICIL by\n9.3%, indicating that the effect of ICIL is complementary to instruction-based\nfine-tuning.\n","authors":["Seonghyeon Ye","Hyeonbin Hwang","Sohee Yang","Hyeongu Yun","Yireun Kim","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2302.14691v1.pdf","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2302.14680v1","updated":"2023-02-28T15:45:20Z","published":"2023-02-28T15:45:20Z","title":"Which One Are You Referring To? Multimodal Object Identification in\n  Situated Dialogue","summary":"  The demand for multimodal dialogue systems has been rising in various\ndomains, emphasizing the importance of interpreting multimodal inputs from\nconversational and situational contexts. We explore three methods to tackle\nthis problem and evaluate them on the largest situated dialogue dataset, SIMMC\n2.1. Our best method, scene-dialogue alignment, improves the performance by\n~20% F1-score compared to the SIMMC 2.1 baselines. We provide analysis and\ndiscussion regarding the limitation of our methods and the potential directions\nfor future works. Our code is publicly available at\nhttps://github.com/holylovenia/multimodal-object-identification.\n","authors":["Holy Lovenia","Samuel Cahyawijaya","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2302.14680v1.pdf","comment":"Accepted at EACL SRW 2023"},{"id":"http://arxiv.org/abs/2302.04023v2","updated":"2023-02-28T15:20:21Z","published":"2023-02-08T12:35:34Z","title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on\n  Reasoning, Hallucination, and Interactivity","summary":"  This paper proposes a framework for quantitatively evaluating interactive\nLLMs such as ChatGPT using publicly available data sets. We carry out an\nextensive technical evaluation of ChatGPT using 23 data sets covering 8\ndifferent common NLP application tasks. We evaluate the multitask, multilingual\nand multi-modal aspects of ChatGPT based on these data sets and a newly\ndesigned multimodal dataset. We find that ChatGPT outperforms LLMs with\nzero-shot learning on most tasks and even outperforms fine-tuned models on some\ntasks. We find that it is better at understanding non-Latin script languages\nthan generating them. It is able to generate multimodal content from textual\nprompts, via an intermediate code generation step. Moreover, we find that\nChatGPT is 63.41% accurate on average in 10 different reasoning categories\nunder logical reasoning, non-textual reasoning, and commonsense reasoning,\nhence making it an unreliable reasoner. It is, for example, better at deductive\nthan inductive reasoning. ChatGPT suffers from hallucination problems like\nother LLMs and it generates more extrinsic hallucinations from its parametric\nmemory as it does not have access to an external knowledge base. Finally, the\ninteractive feature of ChatGPT enables human collaboration with the underlying\nLLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++\non machine translation, in a multi-turn \"prompt engineering\" fashion. We also\nrelease codebase for evaluation set extraction.\n","authors":["Yejin Bang","Samuel Cahyawijaya","Nayeon Lee","Wenliang Dai","Dan Su","Bryan Wilie","Holy Lovenia","Ziwei Ji","Tiezheng Yu","Willy Chung","Quyet V. Do","Yan Xu","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2302.04023v2.pdf","comment":"52 pages"},{"id":"http://arxiv.org/abs/2302.14635v1","updated":"2023-02-28T15:14:15Z","published":"2023-02-28T15:14:15Z","title":"H-AES: Towards Automated Essay Scoring for Hindi","summary":"  The use of Natural Language Processing (NLP) for Automated Essay Scoring\n(AES) has been well explored in the English language, with benchmark models\nexhibiting performance comparable to human scorers. However, AES in Hindi and\nother low-resource languages remains unexplored. In this study, we reproduce\nand compare state-of-the-art methods for AES in the Hindi domain. We employ\nclassical feature-based Machine Learning (ML) and advanced end-to-end models,\nincluding LSTM Networks and Fine-Tuned Transformer Architecture, in our\napproach and derive results comparable to those in the English language domain.\nHindi being a low-resource language, lacks a dedicated essay-scoring corpus. We\ntrain and evaluate our models using translated English essays and empirically\nmeasure their performance on our own small-scale, real-world Hindi corpus. We\nfollow this up with an in-depth analysis discussing prompt-specific behavior of\ndifferent language models implemented.\n","authors":["Shubhankar Singh","Anirudh Pupneja","Shivaansh Mital","Cheril Shah","Manish Bawkar","Lakshman Prasad Gupta","Ajit Kumar","Yaman Kumar","Rushali Gupta","Rajiv Ratn Shah"],"pdf_url":"https://arxiv.org/pdf/2302.14635v1.pdf","comment":"9 pages, 3 Tables, To be published as a part of Proceedings of the\n  37th AAAI Conference on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2302.14624v1","updated":"2023-02-28T15:05:33Z","published":"2023-02-28T15:05:33Z","title":"The 2022 NIST Language Recognition Evaluation","summary":"  In 2022, the U.S. National Institute of Standards and Technology (NIST)\nconducted the latest Language Recognition Evaluation (LRE) in an ongoing series\nadministered by NIST since 1996 to foster research in language recognition and\nto measure state-of-the-art technology. Similar to previous LREs, LRE22 focused\non conversational telephone speech (CTS) and broadcast narrowband speech (BNBS)\ndata. LRE22 also introduced new evaluation features, such as an emphasis on\nAfrican languages, including low resource languages, and a test set consisting\nof segments containing between 3s and 35s of speech randomly sampled and\nextracted from longer recordings. A total of 21 research organizations, forming\n16 teams, participated in this 3-month long evaluation and made a total of 65\nvalid system submissions to be evaluated. This paper presents an overview of\nLRE22 and an analysis of system performance over different evaluation\nconditions. The evaluation results suggest that Oromo and Tigrinya are easier\nto detect while Xhosa and Zulu are more challenging. A greater confusability is\nseen for some language pairs. When speech duration increased, system\nperformance significantly increased up to a certain duration, and then a\ndiminishing return on system performance is observed afterward.\n","authors":["Yooyoung Lee","Craig Greenberg","Eliot Godard","Asad A. Butt","Elliot Singer","Trang Nguyen","Lisa Mason","Douglas Reynolds"],"pdf_url":"https://arxiv.org/pdf/2302.14624v1.pdf","comment":"5 pages, 10 figures"},{"id":"http://arxiv.org/abs/2207.02098v3","updated":"2023-02-28T13:22:17Z","published":"2022-07-05T15:06:11Z","title":"Neural Networks and the Chomsky Hierarchy","summary":"  Reliable generalization lies at the heart of safe ML and AI. However,\nunderstanding when and how neural networks generalize remains one of the most\nimportant unsolved problems in the field. In this work, we conduct an extensive\nempirical study (20'910 models, 15 tasks) to investigate whether insights from\nthe theory of computation can predict the limits of neural network\ngeneralization in practice. We demonstrate that grouping tasks according to the\nChomsky hierarchy allows us to forecast whether certain architectures will be\nable to generalize to out-of-distribution inputs. This includes negative\nresults where even extensive amounts of data and training time never lead to\nany non-trivial generalization, despite models having sufficient capacity to\nfit the training data perfectly. Our results show that, for our subset of\ntasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can\nsolve regular and counter-language tasks, and only networks augmented with\nstructured memory (such as a stack or memory tape) can successfully generalize\non context-free and context-sensitive tasks.\n","authors":["Grégoire Delétang","Anian Ruoss","Jordi Grau-Moya","Tim Genewein","Li Kevin Wenliang","Elliot Catt","Chris Cundy","Marcus Hutter","Shane Legg","Joel Veness","Pedro A. Ortega"],"pdf_url":"https://arxiv.org/pdf/2207.02098v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14534v1","updated":"2023-02-28T12:44:10Z","published":"2023-02-28T12:44:10Z","title":"Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face","summary":"  We present Spacerini, a modular framework for seamless building and\ndeployment of interactive search applications, designed to facilitate the\nqualitative analysis of large scale research datasets. Spacerini integrates\nfeatures from both the Pyserini toolkit and the Hugging Face ecosystem to ease\nthe indexing text collections and deploy them as search engines for ad-hoc\nexploration and to make the retrieval of relevant data points quick and\nefficient. The user-friendly interface enables searching through massive\ndatasets in a no-code fashion, making Spacerini broadly accessible to anyone\nlooking to qualitatively audit their text collections. This is useful both to\nIR~researchers aiming to demonstrate the capabilities of their indexes in a\nsimple and interactive way, and to NLP~researchers looking to better understand\nand audit the failure modes of large language models. The framework is open\nsource and available on GitHub: https://github.com/castorini/hf-spacerini, and\nincludes utilities to load, pre-process, index, and deploy local and web search\napplications. A portfolio of applications created with Spacerini for a\nmultitude of use cases can be found by visiting https://hf.co/spacerini.\n","authors":["Christopher Akiki","Odunayo Ogundepo","Aleksandra Piktus","Xinyu Zhang","Akintunde Oladipo","Jimmy Lin","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2302.14534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14523v1","updated":"2023-02-28T12:33:12Z","published":"2023-02-28T12:33:12Z","title":"Automatic Heteronym Resolution Pipeline Using RAD-TTS Aligners","summary":"  Grapheme-to-phoneme (G2P) transduction is part of the standard text-to-speech\n(TTS) pipeline. However, G2P conversion is difficult for languages that contain\nheteronyms -- words that have one spelling but can be pronounced in multiple\nways. G2P datasets with annotated heteronyms are limited in size and expensive\nto create, as human labeling remains the primary method for heteronym\ndisambiguation. We propose a RAD-TTS Aligner-based pipeline to automatically\ndisambiguate heteronyms in datasets that contain both audio with text\ntranscripts. The best pronunciation can be chosen by generating all possible\ncandidates for each heteronym and scoring them with an Aligner model. The\nresulting labels can be used to create training datasets for use in both\nmulti-stage and end-to-end G2P systems.\n","authors":["Jocelyn Huang","Evelina Bakhturina","Oktai Tatanov"],"pdf_url":"https://arxiv.org/pdf/2302.14523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14520v1","updated":"2023-02-28T12:23:48Z","published":"2023-02-28T12:23:48Z","title":"Large Language Models Are State-of-the-Art Evaluators of Translation\n  Quality","summary":"  We describe GEMBA, a GPT-based metric for assessment of translation quality,\nwhich works both with a reference translation and without. In our evaluation,\nwe focus on zero-shot prompting, comparing four prompt variants in two modes,\nbased on the availability of the reference. We investigate seven versions of\nGPT models, including ChatGPT. We show that our method for translation quality\nassessment only works with GPT 3.5 and larger models. Comparing to results from\nWMT22's Metrics shared task, our method achieves state-of-the-art accuracy in\nboth modes when compared to MQM-based human labels. Our results are valid on\nthe system level for all three WMT22 Metrics shared task language pairs, namely\nEnglish into German, English into Russian, and Chinese into English. This\nprovides a first glimpse into the usefulness of pre-trained, generative large\nlanguage models for quality assessment of translations. We publicly release all\nour code and prompt templates used for the experiments described in this work,\nas well as all corresponding scoring results, to allow for external validation\nand reproducibility.\n","authors":["Tom Kocmi","Christian Federmann"],"pdf_url":"https://arxiv.org/pdf/2302.14520v1.pdf","comment":"10 pages, 8 tables, one figure"},{"id":"http://arxiv.org/abs/2210.12921v2","updated":"2023-02-28T11:56:22Z","published":"2022-10-24T02:18:03Z","title":"Investigating the effect of domain selection on automatic speech\n  recognition performance: a case study on Bangladeshi Bangla","summary":"  The performance of data-driven natural language processing systems is\ncontingent upon the quality of corpora. However, principal corpus design\ncriteria are often not identified and examined adequately, particularly in the\nspeech processing discipline. Speech corpora development requires additional\nattention with regard to clean/noisy, read/spontaneous, multi-talker speech,\naccents/dialects, etc. Domain selection is also a crucial decision point in\nspeech corpus development. In this study, we demonstrate the significance of\ndomain selection by assessing a state-of-the-art Bangla automatic speech\nrecognition (ASR) model on a novel multi-domain Bangladeshi Bangla ASR\nevaluation benchmark - BanSpeech, which contains 7.2 hours of speech and 9802\nutterances from 19 distinct domains. The ASR model has been trained with deep\nconvolutional neural network (CNN), layer normalization technique, and\nConnectionist Temporal Classification (CTC) loss criterion on SUBAK.KO, a\nmostly read speech corpus for the low-resource and morphologically rich\nlanguage Bangla. Experimental evaluation reveals the ASR model on SUBAK.KO\nfaces difficulty recognizing speech from domains with mostly spontaneous speech\nand has a high number of out-of-vocabulary (OOV) words. The same ASR model, on\nthe other hand, performs better in read speech domains and contains fewer OOV\nwords. In addition, we report the outcomes of our experiments with layer\nnormalization, input feature extraction, number of convolutional layers, etc.,\nand set a baseline on SUBAK.KO. The BanSpeech will be publicly available to\nmeet the need for a challenging evaluation benchmark for Bangla ASR.\n","authors":["Ahnaf Mozib Samin","M. Humayan Kobir","Md. Mushtaq Shahriyar Rafee","M. Firoz Ahmed","Mehedi Hasan","Partha Ghosh","Shafkat Kibria","M. Shahidur Rahman"],"pdf_url":"https://arxiv.org/pdf/2210.12921v2.pdf","comment":"To be submitted"},{"id":"http://arxiv.org/abs/2302.14502v1","updated":"2023-02-28T11:34:30Z","published":"2023-02-28T11:34:30Z","title":"A Survey on Long Text Modeling with Transformers","summary":"  Modeling long texts has been an essential technique in the field of natural\nlanguage processing (NLP). With the ever-growing number of long documents, it\nis important to develop effective modeling methods that can process and analyze\nsuch texts. However, long texts pose important research challenges for existing\ntext models, with more complex semantics and special characteristics. In this\npaper, we provide an overview of the recent advances on long texts modeling\nbased on Transformer models. Firstly, we introduce the formal definition of\nlong text modeling. Then, as the core content, we discuss how to process long\ninput to satisfy the length limitation and design improved Transformer\narchitectures to effectively extend the maximum context length. Following this,\nwe discuss how to adapt Transformer models to capture the special\ncharacteristics of long texts. Finally, we describe four typical applications\ninvolving long text modeling and conclude this paper with a discussion of\nfuture directions. Our survey intends to provide researchers with a synthesis\nand pointer to related work on long text modeling.\n","authors":["Zican Dong","Tianyi Tang","Lunyi Li","Wayne Xin Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.14502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05735v2","updated":"2023-02-28T11:26:32Z","published":"2023-02-11T16:04:38Z","title":"Divergence-Based Domain Transferability for Zero-Shot Classification","summary":"  Transferring learned patterns from pretrained neural language models has been\nshown to significantly improve effectiveness across a variety of language-based\ntasks, meanwhile further tuning on intermediate tasks has been demonstrated to\nprovide additional performance benefits, provided the intermediate task is\nsufficiently related to the target task. However, how to identify related tasks\nis an open problem, and brute-force searching effective task combinations is\nprohibitively expensive. Hence, the question arises, are we able to improve the\neffectiveness and efficiency of tasks with no training examples through\nselective fine-tuning? In this paper, we explore statistical measures that\napproximate the divergence between domain representations as a means to\nestimate whether tuning using one task pair will exhibit performance benefits\nover tuning another. This estimation can then be used to reduce the number of\ntask pairs that need to be tested by eliminating pairs that are unlikely to\nprovide benefits. Through experimentation over 58 tasks and over 6,600 task\npair combinations, we demonstrate that statistical measures can distinguish\neffective task pairs, and the resulting estimates can reduce end-to-end runtime\nby up to 40%.\n","authors":["Alexander Pugantsov","Richard McCreadie"],"pdf_url":"https://arxiv.org/pdf/2302.05735v2.pdf","comment":"Accepted at EACL 2023, Findings. Figure 1 caption corrected to\n  describe NDCG@K graph (Figure 1 caption was mistakenly describing Figure 2\n  before correction)"},{"id":"http://arxiv.org/abs/2302.14494v1","updated":"2023-02-28T11:21:24Z","published":"2023-02-28T11:21:24Z","title":"Text classification dataset and analysis for Uzbek language","summary":"  Text classification is an important task in Natural Language Processing\n(NLP), where the goal is to categorize text data into predefined classes. In\nthis study, we analyse the dataset creation steps and evaluation techniques of\nmulti-label news categorisation task as part of text classification. We first\npresent a newly obtained dataset for Uzbek text classification, which was\ncollected from 10 different news and press websites and covers 15 categories of\nnews, press and law texts. We also present a comprehensive evaluation of\ndifferent models, ranging from traditional bag-of-words models to deep learning\narchitectures, on this newly created dataset. Our experiments show that the\nRecurrent Neural Network (RNN) and Convolutional Neural Network (CNN) based\nmodels outperform the rule-based models. The best performance is achieved by\nthe BERTbek model, which is a transformer-based BERT model trained on the Uzbek\ncorpus. Our findings provide a good baseline for further research in Uzbek text\nclassification.\n","authors":["Elmurod Kuriyozov","Ulugbek Salaev","Sanatbek Matlatipov","Gayrat Matlatipov"],"pdf_url":"https://arxiv.org/pdf/2302.14494v1.pdf","comment":"Preprint of the paper accepted to The 10th Language & Technology\n  Conference: Human Language Technologies as a Challenge for Computer Science\n  and Linguistics. April 21-23, 2023, Poznan, Poland"},{"id":"http://arxiv.org/abs/2301.11596v2","updated":"2023-02-28T11:10:43Z","published":"2023-01-27T08:45:53Z","title":"ThoughtSource: A central hub for large language model reasoning data","summary":"  Large language models (LLMs) such as GPT-3 and ChatGPT have recently\ndemonstrated impressive results across a wide range of tasks. LLMs are still\nlimited, however, in that they frequently fail at complex reasoning, their\nreasoning processes are opaque, they are prone to 'hallucinate' facts, and\nthere are concerns about their underlying biases. Letting models verbalize\nreasoning steps as natural language, a technique known as chain-of-thought\nprompting, has recently been proposed as a way to address some of these issues.\nHere we present the first release of ThoughtSource, a meta-dataset and software\nlibrary for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to\nimprove future artificial intelligence systems by facilitating qualitative\nunderstanding of CoTs, enabling empirical evaluations, and providing training\ndata. This first release of ThoughtSource integrates six scientific/medical,\nthree general-domain and five math word question answering datasets.\n","authors":["Simon Ott","Konstantin Hebenstreit","Valentin Liévin","Christoffer Egeberg Hother","Milad Moradi","Maximilian Mayrhauser","Robert Praas","Ole Winther","Matthias Samwald"],"pdf_url":"https://arxiv.org/pdf/2301.11596v2.pdf","comment":"Revision adds information on further AI-generated data\n  ('ThoughtSource-100')"},{"id":"http://arxiv.org/abs/2203.07893v3","updated":"2023-02-28T10:50:17Z","published":"2022-03-15T13:40:22Z","title":"Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear\n  Guarded Attribute Information","summary":"  We describe a simple and effective method (Spectral Attribute removaL; SAL)\nto remove private or guarded information from neural representations. Our\nmethod uses matrix decomposition to project the input representations into\ndirections with reduced covariance with the guarded information rather than\nmaximal covariance as factorization methods normally use. We begin with linear\ninformation removal and proceed to generalize our algorithm to the case of\nnonlinear information removal using kernels. Our experiments demonstrate that\nour algorithm retains better main task performance after removing the guarded\ninformation compared to previous work. In addition, our experiments demonstrate\nthat we need a relatively small amount of guarded attribute data to remove\ninformation about these attributes, which lowers the exposure to sensitive data\nand is more suitable for low-resource scenarios. Code is available at\nhttps://github.com/jasonshaoshun/SAL.\n","authors":["Shun Shao","Yftah Ziser","Shay B. Cohen"],"pdf_url":"https://arxiv.org/pdf/2203.07893v3.pdf","comment":"Accepted to the Conference of the European Chapter of the Association\n  for Computational Linguistics (EACL), 2023; 12 pages"},{"id":"http://arxiv.org/abs/2302.13539v2","updated":"2023-02-28T10:45:04Z","published":"2023-02-27T06:32:45Z","title":"Finding Supporting Examples for In-Context Learning","summary":"  In-context learning is a new learning paradigm where a language model\nobserves a few examples and then straightly outputs the test input's\nprediction. Previous works have shown that in-context learning is sensitive to\nthe provided examples and randomly sampled examples show significantly unstable\nperformance. In this paper, we propose to find ``supporting examples'' for\nin-context learning: Given the training dataset, we need to select one\npermutation of a few examples, which are informative for the task's in-context\nlearning and lead to superior performance. Although in traditional\ngradient-based learning, e.g., fine-tuning, there are numerous methods to find\na ``coreset'' from the entire dataset, they are sub-optimal and not suitable\nfor this problem since in-context learning occurs in the language model's\ninference without gradients or parameter updates. Additionally, the strong\ndependence among in-context examples makes this problem an NP-hard\ncombinatorial optimization problem and enumerating all possible permutations is\ninfeasible. Hence we propose a two-stage method to tackle this challenge. First\nwe propose a novel metric to select informative examples based on the language\nmodel's feedback, with a progressive filtering strategy. And then we propose a\ndiversity-guided beam search method to refine and evaluate the selected\nexamples, iteratively. The experimental results show our method significantly\noutperforms a wide range of baselines, and further analyses show the\neffectiveness of our method and shed light on the properties of supporting\nexamples and in-context learning.\n","authors":["Xiaonan Li","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.13539v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14413v1","updated":"2023-02-28T08:47:20Z","published":"2023-02-28T08:47:20Z","title":"SMoA: Sparse Mixture of Adapters to Mitigate Multiple Dataset Biases","summary":"  Recent studies reveal that various biases exist in different NLP tasks, and\nover-reliance on biases results in models' poor generalization ability and low\nadversarial robustness. To mitigate datasets biases, previous works propose\nlots of debiasing techniques to tackle specific biases, which perform well on\nrespective adversarial sets but fail to mitigate other biases. In this paper,\nwe propose a new debiasing method Sparse Mixture-of-Adapters (SMoA), which can\nmitigate multiple dataset biases effectively and efficiently. Experiments on\nNatural Language Inference and Paraphrase Identification tasks demonstrate that\nSMoA outperforms full-finetuning, adapter tuning baselines, and prior strong\ndebiasing methods. Further analysis indicates the interpretability of SMoA that\nsub-adapter can capture specific pattern from the training data and specialize\nto handle specific bias.\n","authors":["Yanchen Liu","Jing Yan","Yan Chen","Jing Liu","Hua Wu"],"pdf_url":"https://arxiv.org/pdf/2302.14413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14406v1","updated":"2023-02-28T08:41:53Z","published":"2023-02-28T08:41:53Z","title":"Instruction Clarification Requests in Multimodal Collaborative Dialogue\n  Games: Tasks, and an Analysis of the CoDraw Dataset","summary":"  In visual instruction-following dialogue games, players can engage in repair\nmechanisms in face of an ambiguous or underspecified instruction that cannot be\nfully mapped to actions in the world. In this work, we annotate Instruction\nClarification Requests (iCRs) in CoDraw, an existing dataset of interactions in\na multimodal collaborative dialogue game. We show that it contains lexically\nand semantically diverse iCRs being produced self-motivatedly by players\ndeciding to clarify in order to solve the task successfully. With 8.8k iCRs\nfound in 9.9k dialogues, CoDraw-iCR (v1) is a large spontaneous iCR corpus,\nmaking it a valuable resource for data-driven research on clarification in\ndialogue. We then formalise and provide baseline models for two tasks:\nDetermining when to make an iCR and how to recognise them, in order to\ninvestigate to what extent these tasks are learnable from data.\n","authors":["Brielen Madureira","David Schlangen"],"pdf_url":"https://arxiv.org/pdf/2302.14406v1.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2302.14401v1","updated":"2023-02-28T08:35:28Z","published":"2023-02-28T08:35:28Z","title":"GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue\n  Generation","summary":"  We present GLM-Dialog, a large-scale language model (LLM) with 10B parameters\ncapable of knowledge-grounded conversation in Chinese using a search engine to\naccess the Internet knowledge. GLM-Dialog offers a series of applicable\ntechniques for exploiting various external knowledge including both helpful and\nnoisy knowledge, enabling the creation of robust knowledge-grounded dialogue\nLLMs with limited proper datasets. To evaluate the GLM-Dialog more fairly, we\nalso propose a novel evaluation method to allow humans to converse with\nmultiple deployed bots simultaneously and compare their performance implicitly\ninstead of explicitly rating using multidimensional metrics.Comprehensive\nevaluations from automatic to human perspective demonstrate the advantages of\nGLM-Dialog comparing with existing open source Chinese dialogue models. We\nrelease both the model checkpoint and source code, and also deploy it as a\nWeChat application to interact with users. We offer our evaluation platform\nonline in an effort to prompt the development of open source models and\nreliable dialogue evaluation systems. The additional easy-to-use toolkit that\nconsists of short text entity linking, query generation, and helpful knowledge\nclassification is also released to enable diverse applications. All the source\ncode is available on Github.\n","authors":["Jing Zhang","Xiaokang Zhang","Daniel Zhang-Li","Jifan Yu","Zijun Yao","Zeyao Ma","Yiqi Xu","Haohua Wang","Xiaohan Zhang","Nianyi Lin","Sunrui Lu","Juanzi Li","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2302.14401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13114v2","updated":"2023-02-28T08:31:33Z","published":"2023-02-25T16:33:53Z","title":"Sequential Query Encoding For Complex Query Answering on Knowledge\n  Graphs","summary":"  Complex Query Answering (CQA) is an important and fundamental task for\nknowledge graph (KG) reasoning. Query encoding (QE) is proposed as a fast and\nrobust solution to CQA. In the encoding process, most existing QE methods first\nparse the logical query into an executable computational direct-acyclic graph\n(DAG), then use neural networks to parameterize the operators, and finally,\nrecursively execute these neuralized operators. However, the\nparameterization-and-execution paradigm may be potentially over-complicated, as\nit can be structurally simplified by a single neural network encoder.\nMeanwhile, sequence encoders, like LSTM and Transformer, proved to be effective\nfor encoding semantic graphs in related tasks. Motivated by this, we propose\nsequential query encoding (SQE) as an alternative to encode queries for CQA.\nInstead of parameterizing and executing the computational graph, SQE first uses\na search-based algorithm to linearize the computational graph to a sequence of\ntokens and then uses a sequence encoder to compute its vector representation.\nThen this vector representation is used as a query embedding to retrieve\nanswers from the embedding space according to similarity scores. Despite its\nsimplicity, SQE demonstrates state-of-the-art neural query encoding performance\non FB15k, FB15k-237, and NELL on an extended benchmark including twenty-nine\ntypes of in-distribution queries. Further experiment shows that SQE also\ndemonstrates comparable knowledge inference capability on out-of-distribution\nqueries, whose query types are not observed during the training process.\n","authors":["Jiaxin Bai","Tianshi Zheng","Yangqiu Song"],"pdf_url":"https://arxiv.org/pdf/2302.13114v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2302.14389v1","updated":"2023-02-28T08:16:18Z","published":"2023-02-28T08:16:18Z","title":"Information-Restricted Neural Language Models Reveal Different Brain\n  Regions' Sensitivity to Semantics, Syntax and Context","summary":"  A fundamental question in neurolinguistics concerns the brain regions\ninvolved in syntactic and semantic processing during speech comprehension, both\nat the lexical (word processing) and supra-lexical levels (sentence and\ndiscourse processing). To what extent are these regions separated or\nintertwined? To address this question, we trained a lexical language model,\nGlove, and a supra-lexical language model, GPT-2, on a text corpus from which\nwe selectively removed either syntactic or semantic information. We then\nassessed to what extent these information-restricted models were able to\npredict the time-courses of fMRI signal of humans listening to naturalistic\ntext. We also manipulated the size of contextual information provided to GPT-2\nin order to determine the windows of integration of brain regions involved in\nsupra-lexical processing. Our analyses show that, while most brain regions\ninvolved in language are sensitive to both syntactic and semantic variables,\nthe relative magnitudes of these effects vary a lot across these regions.\nFurthermore, we found an asymmetry between the left and right hemispheres, with\nsemantic and syntactic processing being more dissociated in the left hemisphere\nthan in the right, and the left and right hemispheres showing respectively\ngreater sensitivity to short and long contexts. The use of\ninformation-restricted NLP models thus shed new light on the spatial\norganization of syntactic processing, semantic processing and compositionality.\n","authors":["Alexandre Pasquiou","Yair Lakretz","Bertrand Thirion","Christophe Pallier"],"pdf_url":"https://arxiv.org/pdf/2302.14389v1.pdf","comment":"19 pages, 8 figures, 10 pages of Appendix, 5 appendix figures"},{"id":"http://arxiv.org/abs/2302.14383v1","updated":"2023-02-28T08:11:56Z","published":"2023-02-28T08:11:56Z","title":"Linear Spaces of Meanings: the Compositional Language of VLMs","summary":"  We investigate compositional structures in vector data embeddings from\npre-trained vision-language models (VLMs). Traditionally, compositionality has\nbeen associated with algebraic operations on embeddings of words from a\npre-existing vocabulary. In contrast, we seek to approximate label\nrepresentations from a text encoder as combinations of a smaller set of vectors\nin the embedding space. These vectors can be seen as \"ideal words\" which can be\nused to generate new concepts in an efficient way. We present a theoretical\nframework for understanding linear compositionality, drawing connections with\nmathematical representation theory and previous definitions of disentanglement.\nWe provide theoretical and empirical evidence that ideal words provide good\ncompositional approximations of composite concepts and can be more effective\nthan token-based decompositions of the same concepts.\n","authors":["Matthew Trager","Pramuditha Perera","Luca Zancato","Alessandro Achille","Parminder Bhatia","Bing Xiang","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2302.14383v1.pdf","comment":"24 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2302.12578v2","updated":"2023-02-28T08:08:29Z","published":"2023-02-24T11:25:50Z","title":"Fairness in Language Models Beyond English: Gaps and Challenges","summary":"  With language models becoming increasingly ubiquitous, it has become\nessential to address their inequitable treatment of diverse demographic groups\nand factors. Most research on evaluating and mitigating fairness harms has been\nconcentrated on English, while multilingual models and non-English languages\nhave received comparatively little attention. This paper presents a survey of\nfairness in multilingual and non-English contexts, highlighting the\nshortcomings of current research and the difficulties faced by methods designed\nfor English. We contend that the multitude of diverse cultures and languages\nacross the world makes it infeasible to achieve comprehensive coverage in terms\nof constructing fairness datasets. Thus, the measurement and mitigation of\nbiases must evolve beyond the current dataset-driven practices that are\nnarrowly focused on specific dimensions and types of biases and, therefore,\nimpossible to scale across languages and cultures.\n","authors":["Krithika Ramesh","Sunayana Sitaram","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2302.12578v2.pdf","comment":"Accepted to EACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2302.05138v2","updated":"2023-02-28T07:20:06Z","published":"2023-02-10T09:43:15Z","title":"Plan-then-Seam: Towards Efficient Table-to-Text Generation","summary":"  Table-to-text generation aims at automatically generating text to help people\nconveniently obtain salient information in tables. Recent works explicitly\ndecompose the generation process into content planning and surface generation\nstages, employing two autoregressive networks for them respectively. However,\nthey are computationally expensive due to the non-parallelizable nature of\nautoregressive decoding and the redundant parameters of two networks. In this\npaper, we propose the first totally non-autoregressive table-to-text model\n(Plan-then-Seam, PTS) that produces its outputs in parallel with one single\nnetwork. PTS firstly writes and calibrates one plan of the content to be\ngenerated with a novel rethinking pointer predictor, and then takes the plan as\nthe context for seaming to decode the description. These two steps share\nparameters and perform iteratively to capture token inter-dependency while\nkeeping parallel decoding. Experiments on two public benchmarks show that PTS\nachieves 3.0~5.6 times speedup for inference time, reducing 50% parameters,\nwhile maintaining as least comparable performance against strong two-stage\ntable-to-text competitors.\n","authors":["Liang Li","Ruiying Geng","Chengyang Fang","Bing Li","Can Ma","Binhua Li","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2302.05138v2.pdf","comment":"Accepted to Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2302.13939v2","updated":"2023-02-28T06:28:43Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking neural networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the RWKV language model, we successfully\nimplement `SpikeGPT', a generative language model with pure binary,\nevent-driven spiking activation units. We train the proposed model on three\nmodel variants: 45M, 125M and 260M parameters. To the best of our knowledge,\nthis is 4x larger than any functional backprop-trained SNN to date. We achieve\nthis by modifying the transformer block to replace multi-head self attention to\nreduce quadratic computational complexity to linear with increasing sequence\nlength. Input tokens are instead streamed in sequentially to our attention\nmechanism (as with typical SNNs). Our preliminary experiments show that\nSpikeGPT remains competitive with non-spiking models on tested benchmarks,\nwhile maintaining 5x less energy consumption when processed on neuromorphic\nhardware that can leverage sparse, event-driven activations. Our code\nimplementation is available at https://github.com/ridgerchu/SpikeGPT.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.01306v2","updated":"2023-02-28T06:17:38Z","published":"2021-05-04T05:58:27Z","title":"Discourse Relation Embeddings: Representing the Relations between\n  Discourse Segments in Social Media","summary":"  Discourse relations are typically modeled as a discrete class that\ncharacterizes the relation between segments of text (e.g. causal explanations,\nexpansions). However, such predefined discrete classes limits the universe of\npotential relationships and their nuanced differences. Analogous to contextual\nword embeddings, we propose representing discourse relations as points in high\ndimensional continuous space. However, unlike words, discourse relations often\nhave no surface form (relations are between two segments, often with no word or\nphrase in that gap) which presents a challenge for existing embedding\ntechniques. We present a novel method for automatically creating discourse\nrelation embeddings (DiscRE), addressing the embedding challenge through a\nweakly supervised, multitask approach to learn diverse and nuanced relations\nbetween discourse segments in social media. Results show DiscRE can: (1) obtain\nthe best performance on Twitter discourse relation classification task (macro\nF1=0.76) (2) improve the state of the art in social media causality prediction\n(from F1=.79 to .81), (3) perform beyond modern sentence and contextual word\nembeddings at traditional discourse relation classification, and (4) capture\nnovel nuanced relations (e.g. relations semantically at the intersection of\ncausal explanations and counterfactuals).\n","authors":["Youngseo Son","Vasudha Varadarajan","H Andrew Schwartz"],"pdf_url":"https://arxiv.org/pdf/2105.01306v2.pdf","comment":"Published in EMNLP 2022 UM-IoS"},{"id":"http://arxiv.org/abs/2302.14337v1","updated":"2023-02-28T06:05:43Z","published":"2023-02-28T06:05:43Z","title":"UniFLG: Unified Facial Landmark Generator from Text or Speech","summary":"  Talking face generation has been extensively investigated owing to its wide\napplicability. The two primary frameworks used for talking face generation\ncomprise a text-driven framework, which generates synchronized speech and\ntalking faces from text, and a speech-driven framework, which generates talking\nfaces from speech. To integrate these frameworks, this paper proposes a unified\nfacial landmark generator (UniFLG). The proposed system exploits end-to-end\ntext-to-speech not only for synthesizing speech but also for extracting a\nseries of latent representations that are common to text and speech, and feeds\nit to a landmark decoder to generate facial landmarks. We demonstrate that our\nsystem achieves higher naturalness in both speech synthesis and facial landmark\ngeneration compared to the state-of-the-art text-driven method. We further\ndemonstrate that our system can generate facial landmarks from speech of\nspeakers without facial video data or even speech data.\n","authors":["Kentaro Mitsui","Yukiya Hono","Kei Sawada"],"pdf_url":"https://arxiv.org/pdf/2302.14337v1.pdf","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.14286v1","updated":"2023-02-28T03:38:26Z","published":"2023-02-28T03:38:26Z","title":"HugNLP: A Unified and Comprehensive Library for Natural Language\n  Processing","summary":"  In this paper, we introduce HugNLP, a unified and comprehensive library for\nnatural language processing (NLP) with the prevalent backend of HuggingFace\nTransformers, which is designed for NLP researchers to easily utilize\noff-the-shelf algorithms and develop novel methods with user-defined models and\ntasks in real-world scenarios. HugNLP consists of a hierarchical structure\nincluding models, processors and applications that unifies the learning process\nof pre-trained language models (PLMs) on different NLP tasks. Additionally, we\npresent some featured NLP applications to show the effectiveness of HugNLP,\nsuch as knowledge-enhanced PLMs, universal information extraction, low-resource\nmining, and code understanding and generation, etc. The source code will be\nreleased on GitHub (https://github.com/wjn1996/HugNLP).\n","authors":["Jianing Wang","Nuo Chen","Qiushi Sun","Wenkang Huang","Chengyu Wang","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2302.14286v1.pdf","comment":"8 Pages"},{"id":"http://arxiv.org/abs/2302.14261v1","updated":"2023-02-28T02:37:30Z","published":"2023-02-28T02:37:30Z","title":"Augmented Transformers with Adaptive n-grams Embedding for Multilingual\n  Scene Text Recognition","summary":"  While vision transformers have been highly successful in improving the\nperformance in image-based tasks, not much work has been reported on applying\ntransformers to multilingual scene text recognition due to the complexities in\nthe visual appearance of multilingual texts. To fill the gap, this paper\nproposes an augmented transformer architecture with n-grams embedding and\ncross-language rectification (TANGER). TANGER consists of a primary transformer\nwith single patch embeddings of visual images, and a supplementary transformer\nwith adaptive n-grams embeddings that aims to flexibly explore the potential\ncorrelations between neighbouring visual patches, which is essential for\nfeature extraction from multilingual scene texts. Cross-language rectification\nis achieved with a loss function that takes into account both language\nidentification and contextual coherence scoring. Extensive comparative studies\nare conducted on four widely used benchmark datasets as well as a new\nmultilingual scene text dataset containing Indonesian, English, and Chinese\ncollected from tourism scenes in Indonesia. Our experimental results\ndemonstrate that TANGER is considerably better compared to the\nstate-of-the-art, especially in handling complex multilingual scene texts.\n","authors":["Xueming Yan","Zhihang Fang","Yaochu Jin"],"pdf_url":"https://arxiv.org/pdf/2302.14261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12921v2","updated":"2023-02-28T02:28:41Z","published":"2023-02-24T22:38:54Z","title":"Pre-Finetuning for Few-Shot Emotional Speech Recognition","summary":"  Speech models have long been known to overfit individual speakers for many\nclassification tasks. This leads to poor generalization in settings where the\nspeakers are out-of-domain or out-of-distribution, as is common in production\nenvironments. We view speaker adaptation as a few-shot learning problem and\npropose investigating transfer learning approaches inspired by recent success\nwith pre-trained models in natural language tasks. We propose pre-finetuning\nspeech models on difficult tasks to distill knowledge into few-shot downstream\nclassification objectives. We pre-finetune Wav2Vec2.0 on every permutation of\nfour multiclass emotional speech recognition corpora and evaluate our\npre-finetuned models through 33,600 few-shot fine-tuning trials on the\nEmotional Speech Dataset.\n","authors":["Maximillian Chen","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2302.12921v2.pdf","comment":"5 pages, 4 figures. Code available at\n  https://github.com/maxlchen/Speech-PreFinetuning"},{"id":"http://arxiv.org/abs/2302.13814v2","updated":"2023-02-28T02:06:53Z","published":"2023-02-23T16:06:16Z","title":"An Independent Evaluation of ChatGPT on Mathematical Word Problems (MWP)","summary":"  We study the performance of a commercially available large language model\n(LLM) known as ChatGPT on math word problems (MWPs) from the dataset DRAW-1K.\nTo our knowledge, this is the first independent evaluation of ChatGPT. We found\nthat ChatGPT's performance changes dramatically based on the requirement to\nshow its work, failing 20% of the time when it provides work compared with 84%\nwhen it does not. Further several factors about MWPs relating to the number of\nunknowns and number of operations that lead to a higher probability of failure\nwhen compared with the prior, specifically noting (across all experiments) that\nthe probability of failure increases linearly with the number of addition and\nsubtraction operations. We also have released the dataset of ChatGPT's\nresponses to the MWPs to support further work on the characterization of LLM\nperformance and present baseline machine learning models to predict if ChatGPT\ncan correctly answer an MWP. We have released a dataset comprised of ChatGPT's\nresponses to support further research in this area.\n","authors":["Paulo Shakarian","Abhinav Koyyalamudi","Noel Ngu","Lakshmivihari Mareedu"],"pdf_url":"https://arxiv.org/pdf/2302.13814v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12542v3","updated":"2023-02-28T02:04:00Z","published":"2022-05-25T07:31:43Z","title":"ER-Test: Evaluating Explanation Regularization Methods for Language\n  Models","summary":"  By explaining how humans would solve a given task, human rationales can\nprovide strong learning signal for neural language models (LMs). Explanation\nregularization (ER) aims to improve LM generalization by pushing the LM's\nmachine rationales (Which input tokens did the LM focus on?) to align with\nhuman rationales (Which input tokens would humans focus on?). Though prior\nworks primarily study ER via in-distribution (ID) evaluation,\nout-of-distribution (OOD) generalization is often more critical in real-world\nscenarios, yet ER's effect on OOD generalization has been underexplored. In\nthis paper, we introduce ER-Test, a framework for evaluating ER models' OOD\ngeneralization along three dimensions: unseen dataset tests, contrast set\ntests, and functional tests. Using ER-Test, we extensively analyze how ER\nmodels' OOD generalization varies with different ER design choices. Across two\ntasks and six datasets, ER-Test shows that ER has little impact on ID\nperformance but can yield large OOD performance gains. Also, we find that ER\ncan improve OOD performance even with limited rationale supervision. ER-Test's\nresults help demonstrate ER's utility and establish best practices for using ER\neffectively.\n","authors":["Brihi Joshi","Aaron Chan","Ziyi Liu","Shaoliang Nie","Maziar Sanjabi","Hamed Firooz","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2205.12542v3.pdf","comment":"Findings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2302.13007v2","updated":"2023-02-28T01:53:14Z","published":"2023-02-25T06:58:16Z","title":"ChatAug: Leveraging ChatGPT for Text Data Augmentation","summary":"  Text data augmentation is an effective strategy for overcoming the challenge\nof limited sample sizes in many natural language processing (NLP) tasks. This\nchallenge is especially prominent in the few-shot learning scenario, where the\ndata in the target domain is generally much scarcer and of lowered quality. A\nnatural and widely-used strategy to mitigate such challenges is to perform data\naugmentation on the training data to better capture the data invariance and\nincrease the sample size. However, current text data augmentation methods\neither can not ensure the correct labeling of the generated data (lacking\nfaithfulness) or can not ensure sufficient diversity in the generated data\n(lacking completeness), or both. Inspired by the recent success of large\nlanguage models, especially the development of ChatGPT, which demonstrated\nimproved language comprehension abilities, in this work, we propose a text data\naugmentation approach based on ChatGPT (named ChatAug). ChatGPT is trained on\ndata with unparalleled linguistic richness and employs a reinforcement training\nprocess with large-scale human feedback, which endows the model with affinity\nto the naturalness of human language. Our text data augmentation approach\nChatAug rephrases each sentence in the training samples into multiple\nconceptually similar but semantically different samples. The augmented samples\ncan then be used in downstream model training. Experiment results on few-shot\nlearning text classification tasks show the superior performance of the\nproposed ChatAug approach over state-of-the-art text data augmentation methods\nin terms of testing accuracy and distribution of the augmented samples.\n","authors":["Haixing Dai","Zhengliang Liu","Wenxiong Liao","Xiaoke Huang","Zihao Wu","Lin Zhao","Wei Liu","Ninghao Liu","Sheng Li","Dajiang Zhu","Hongmin Cai","Quanzheng Li","Dinggang Shen","Tianming Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2302.13007v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14233v1","updated":"2023-02-28T01:32:32Z","published":"2023-02-28T01:32:32Z","title":"Goal Driven Discovery of Distributional Differences via Language\n  Descriptions","summary":"  Mining large corpora can generate useful discoveries but is time-consuming\nfor humans. We formulate a new task, D5, that automatically discovers\ndifferences between two large corpora in a goal-driven way. The task input is a\nproblem comprising a research goal \"$\\textit{comparing the side effects of drug\nA and drug B}$\" and a corpus pair (two large collections of patients'\nself-reported reactions after taking each drug). The output is a language\ndescription (discovery) of how these corpora differ (patients taking drug A\n\"$\\textit{mention feelings of paranoia}$\" more often). We build a D5 system,\nand to quantitatively measure its performance, we 1) contribute a meta-dataset,\nOpenD5, aggregating 675 open-ended problems ranging across business, social\nsciences, humanities, machine learning, and health, and 2) propose a set of\nunified evaluation metrics: validity, relevance, novelty, and significance.\nWith the dataset and the unified metrics, we confirm that language models can\nuse the goals to propose more relevant, novel, and significant candidate\ndiscoveries. Finally, our system produces discoveries previously unknown to the\nauthors on a wide range of applications in OpenD5, including temporal and\ndemographic differences in discussion topics, political stances and stereotypes\nin speech, insights in commercial reviews, and error patterns in NLP models.\n","authors":["Ruiqi Zhong","Peter Zhang","Steve Li","Jinwoo Ahn","Dan Klein","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2302.14233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14229v1","updated":"2023-02-28T01:27:37Z","published":"2023-02-28T01:27:37Z","title":"Cross-Lingual Summarization via ChatGPT","summary":"  Given a document in a source language, cross-lingual summarization (CLS) aims\nto generate a summary in a different target language. Recently, the emergence\nof ChatGPT has attracted wide attention from the computational linguistics\ncommunity. However, it is not yet known the performance of ChatGPT on CLS. In\nthis report, we empirically use various prompts to guide ChatGPT to perform\nzero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and\nprovide a preliminary evaluation on its generated summaries.We find that\nChatGPT originally prefers to produce lengthy summaries with more detailed\ninformation. But with the help of an interactive prompt, ChatGPT can balance\nbetween informativeness and conciseness, and significantly improve its CLS\nperformance. Experimental results on three widely-used CLS datasets show that\nChatGPT outperforms the advanced GPT 3.5 model (i.e., text-davinci-003). In\naddition, we provide qualitative case studies to show the superiority of\nChatGPT on CLS.\n","authors":["Jiaan Wang","Yunlong Liang","Fandong Meng","Zhixu Li","Jianfeng Qu","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.14229v1.pdf","comment":"Technical Report, 8 pages"},{"id":"http://arxiv.org/abs/2302.11752v3","updated":"2023-02-28T01:25:52Z","published":"2023-02-23T02:38:39Z","title":"VLSP2022-EVJVQA Challenge: Multilingual Visual Question Answering","summary":"  Visual Question Answering (VQA) is a challenging task of natural language\nprocessing (NLP) and computer vision (CV), attracting significant attention\nfrom researchers. English is a resource-rich language that has witnessed\nvarious developments in datasets and models for visual question answering.\nVisual question answering in other languages also would be developed for\nresources and models. In addition, there is no multilingual dataset targeting\nthe visual content of a particular country with its own objects and cultural\ncharacteristics. To address the weakness, we provide the research community\nwith a benchmark dataset named EVJVQA, including 33,000+ pairs of\nquestion-answer over three languages: Vietnamese, English, and Japanese, on\napproximately 5,000 images taken from Vietnam for evaluating multilingual VQA\nsystems or models. EVJVQA is used as a benchmark dataset for the challenge of\nmultilingual visual question answering at the 9th Workshop on Vietnamese\nLanguage and Speech Processing (VLSP 2022). This task attracted 62 participant\nteams from various universities and organizations. In this article, we present\ndetails of the organization of the challenge, an overview of the methods\nemployed by shared-task participants, and the results. The highest performances\nare 0.4392 in F1-score and 0.4009 in BLUE on the private test set. The\nmultilingual QA systems proposed by the top 2 teams use ViT for the pre-trained\nvision model and mT5 for the pre-trained language model, a powerful pre-trained\nlanguage model based on the transformer architecture. EVJVQA is a challenging\ndataset that motivates NLP and CV researchers to further explore the\nmultilingual models or systems for visual question answering systems.\n","authors":["Ngan Luu-Thuy Nguyen","Nghia Hieu Nguyen","Duong T. D Vo","Khanh Quoc Tran","Kiet Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.11752v3.pdf","comment":"VLSP2022 EVJVQA challenge"},{"id":"http://arxiv.org/abs/2203.03539v2","updated":"2023-02-28T01:24:30Z","published":"2022-02-02T06:20:59Z","title":"Understanding The Robustness of Self-supervised Learning Through Topic\n  Modeling","summary":"  Self-supervised learning has significantly improved the performance of many\nNLP tasks. However, how can self-supervised learning discover useful\nrepresentations, and why is it better than traditional approaches such as\nprobabilistic models are still largely unknown. In this paper, we focus on the\ncontext of topic modeling and highlight a key advantage of self-supervised\nlearning - when applied to data generated by topic models, self-supervised\nlearning can be oblivious to the specific model, and hence is less susceptible\nto model misspecification. In particular, we prove that commonly used\nself-supervised objectives based on reconstruction or contrastive samples can\nboth recover useful posterior information for general topic models.\nEmpirically, we show that the same objectives can perform on par with posterior\ninference using the correct model, while outperforming posterior inference\nusing misspecified models.\n","authors":["Zeping Luo","Shiyou Wu","Cindy Weng","Mo Zhou","Rong Ge"],"pdf_url":"https://arxiv.org/pdf/2203.03539v2.pdf","comment":"Accepted at ICLR 2023. Camera ready version"},{"id":"http://arxiv.org/abs/2302.14225v1","updated":"2023-02-28T01:07:39Z","published":"2023-02-28T01:07:39Z","title":"Weighted Sampling for Masked Language Modeling","summary":"  Masked Language Modeling (MLM) is widely used to pretrain language models.\nThe standard random masking strategy in MLM causes the pre-trained language\nmodels (PLMs) to be biased toward high-frequency tokens. Representation\nlearning of rare tokens is poor and PLMs have limited performance on downstream\ntasks. To alleviate this frequency bias issue, we propose two simple and\neffective Weighted Sampling strategies for masking tokens based on the token\nfrequency and training loss. We apply these two strategies to BERT and obtain\nWeighted-Sampled BERT (WSBERT). Experiments on the Semantic Textual Similarity\nbenchmark (STS) show that WSBERT significantly improves sentence embeddings\nover BERT. Combining WSBERT with calibration methods and prompt learning\nfurther improves sentence embeddings. We also investigate fine-tuning WSBERT on\nthe GLUE benchmark and show that Weighted Sampling also improves the transfer\nlearning capability of the backbone PLM. We further analyze and provide\ninsights into how WSBERT improves token embeddings.\n","authors":["Linhan Zhang","Qian Chen","Wen Wang","Chong Deng","Xin Cao","Kongzhang Hao","Yuxin Jiang","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14225v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2110.06651v3","updated":"2023-02-28T00:54:45Z","published":"2021-10-13T11:29:17Z","title":"MDERank: A Masked Document Embedding Rank Approach for Unsupervised\n  Keyphrase Extraction","summary":"  Keyphrase extraction (KPE) automatically extracts phrases in a document that\nprovide a concise summary of the core content, which benefits downstream\ninformation retrieval and NLP tasks. Previous state-of-the-art (SOTA) methods\nselect candidate keyphrases based on the similarity between learned\nrepresentations of the candidates and the document. They suffer performance\ndegradation on long documents due to discrepancy between sequence lengths which\ncauses mismatch between representations of keyphrase candidates and the\ndocument. In this work, we propose a novel unsupervised embedding-based KPE\napproach, Masked Document Embedding Rank (MDERank), to address this problem by\nleveraging a mask strategy and ranking candidates by the similarity between\nembeddings of the source document and the masked document. We further develop a\nKPE-oriented BERT (KPEBERT) model by proposing a novel self-supervised\ncontrastive learning method, which is more compatible to MDERank than vanilla\nBERT. Comprehensive evaluations on six KPE benchmarks demonstrate that the\nproposed MDERank outperforms state-of-the-art unsupervised KPE approach by\naverage 1.80 $F1@15$ improvement. MDERank further benefits from KPEBERT and\noverall achieves average 3.53 $F1@15$ improvement over the SOTA SIFRank. Our\ncode is available at \\url{https://github.com/LinhanZ/mderank}.\n","authors":["Linhan Zhang","Qian Chen","Wen Wang","Chong Deng","Shiliang Zhang","Bing Li","Wei Wang","Xin Cao"],"pdf_url":"https://arxiv.org/pdf/2110.06651v3.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.14220v1","updated":"2023-02-28T00:50:19Z","published":"2023-02-28T00:50:19Z","title":"Are Character-level Translations Worth the Wait? An Extensive Comparison\n  of Character- and Subword-level Models for Machine Translation","summary":"  Pretrained large character-level language models have been recently\nrevitalized and shown to be competitive with subword models across a range of\nNLP tasks. However, there has not been any research showing their effectiveness\nin neural machine translation (NMT). This work performs an extensive comparison\nacross multiple languages and experimental conditions of state-of-the-art\ncharacter- and subword-level pre-trained models (ByT5 and mT5, respectively) on\nNMT, and shows that the former not only are effective in translation, but\nfrequently outperform subword models, particularly in cases where training data\nis limited. The only drawback of character models appears to be their\ninefficiency (at least 4 times slower to train and for inference). Further\nanalysis indicates that character models are capable of implicitly translating\non the word or subword level, thereby nullifying a major potential weakness of\noperating on the character level.\n","authors":["Lukas Edman","Antonio Toral","Gertjan van Noord"],"pdf_url":"https://arxiv.org/pdf/2302.14220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05032v3","updated":"2023-02-28T23:46:24Z","published":"2022-12-09T18:30:24Z","title":"Training-Free Structured Diffusion Guidance for Compositional\n  Text-to-Image Synthesis","summary":"  Large-scale diffusion models have achieved state-of-the-art results on\ntext-to-image synthesis (T2I) tasks. Despite their ability to generate\nhigh-quality yet creative images, we observe that attribution-binding and\ncompositional capabilities are still considered major challenging issues,\nespecially when involving multiple objects. In this work, we improve the\ncompositional skills of T2I models, specifically more accurate attribute\nbinding and better image compositions. To do this, we incorporate linguistic\nstructures with the diffusion guidance process based on the controllable\nproperties of manipulating cross-attention layers in diffusion-based T2I\nmodels. We observe that keys and values in cross-attention layers have strong\nsemantic meanings associated with object layouts and content. Therefore, we can\nbetter preserve the compositional semantics in the generated image by\nmanipulating the cross-attention representations based on linguistic insights.\nBuilt upon Stable Diffusion, a SOTA T2I model, our structured cross-attention\ndesign is efficient that requires no additional training samples. We achieve\nbetter compositional skills in qualitative and quantitative results, leading to\na 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an\nin-depth analysis to reveal potential causes of incorrect image compositions\nand justify the properties of cross-attention layers in the generation process.\n","authors":["Weixi Feng","Xuehai He","Tsu-Jui Fu","Varun Jampani","Arjun Akula","Pradyumna Narayana","Sugato Basu","Xin Eric Wang","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.05032v3.pdf","comment":"ICLR 2023 Camera Ready version"},{"id":"http://arxiv.org/abs/2303.00135v1","updated":"2023-02-28T23:40:41Z","published":"2023-02-28T23:40:41Z","title":"Deep learning for COVID-19 topic modelling via Twitter: Alpha, Delta and\n  Omicron","summary":"  Topic modelling with innovative deep learning methods has gained interest for\na wide range of applications that includes COVID-19. Topic modelling can\nprovide, psychological, social and cultural insights for understanding human\nbehaviour in extreme events such as the COVID-19 pandemic. In this paper, we\nuse prominent deep learning-based language models for COVID-19 topic modelling\ntaking into account data from emergence (Alpha) to the Omicron variant. We\napply topic modeling to review the public behaviour across the first, second\nand third waves based on Twitter dataset from India. Our results show that the\ntopics extracted for the subsequent waves had certain overlapping themes such\nas covers governance, vaccination, and pandemic management while novel issues\naroused in political, social and economic situation during COVID-19 pandemic.\nWe also found a strong correlation of the major topics qualitatively to news\nmedia prevalent at the respective time period. Hence, our framework has the\npotential to capture major issues arising during different phases of the\nCOVID-19 pandemic which can be extended to other countries and regions.\n","authors":["Janhavi Lande","Arti Pillay","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2303.00135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01433v2","updated":"2023-02-28T23:06:09Z","published":"2022-12-02T20:30:59Z","title":"Avoiding spurious correlations via logit correction","summary":"  Empirical studies suggest that machine learning models trained with empirical\nrisk minimization (ERM) often rely on attributes that may be spuriously\ncorrelated with the class labels. Such models typically lead to poor\nperformance during inference for data lacking such correlations. In this work,\nwe explicitly consider a situation where potential spurious correlations are\npresent in the majority of training data. In contrast with existing approaches,\nwhich use the ERM model outputs to detect the samples without spurious\ncorrelations and either heuristically upweight or upsample those samples, we\npropose the logit correction (LC) loss, a simple yet effective improvement on\nthe softmax cross-entropy loss, to correct the sample logit. We demonstrate\nthat minimizing the LC loss is equivalent to maximizing the group-balanced\naccuracy, so the proposed LC could mitigate the negative impacts of spurious\ncorrelations. Our extensive experimental results further reveal that the\nproposed LC loss outperforms state-of-the-art solutions on multiple popular\nbenchmarks by a large margin, an average 5.5\\% absolute improvement, without\naccess to spurious attribute labels. LC is also competitive with oracle methods\nthat make use of the attribute labels. Code is available at\nhttps://github.com/shengliu66/LC.\n","authors":["Sheng Liu","Xu Zhang","Nitesh Sekhar","Yue Wu","Prateek Singhal","Carlos Fernandez-Granda"],"pdf_url":"https://arxiv.org/pdf/2212.01433v2.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2205.05656v4","updated":"2023-02-28T20:58:22Z","published":"2022-05-11T17:38:24Z","title":"Ontology-Driven and Weakly Supervised Rare Disease Identification from\n  Clinical Notes","summary":"  Computational text phenotyping is the practice of identifying patients with\ncertain disorders and traits from clinical notes. Rare diseases are challenging\nto be identified due to few cases available for machine learning and the need\nfor data annotation from domain experts. We propose a method using ontologies\nand weak supervision, with recent pre-trained contextual representations from\nBi-directional Transformers (e.g. BERT). The ontology-based framework includes\ntwo steps: (i) Text-to-UMLS, extracting phenotypes by contextually linking\nmentions to concepts in Unified Medical Language System (UMLS), with a Named\nEntity Recognition and Linking (NER+L) tool, SemEHR, and weak supervision with\ncustomised rules and contextual mention representation; (ii) UMLS-to-ORDO,\nmatching UMLS concepts to rare diseases in Orphanet Rare Disease Ontology\n(ORDO). The weakly supervised approach is proposed to learn a phenotype\nconfirmation model to improve Text-to-UMLS linking, without annotated data from\ndomain experts. We evaluated the approach on three clinical datasets, MIMIC-III\ndischarge summaries, MIMIC-III radiology reports, and NHS Tayside brain imaging\nreports from two institutions in the US and the UK, with annotations. The\nimprovements in the precision were pronounced (by over 30% to 50% absolute\nscore for Text-to-UMLS linking), with almost no loss of recall compared to the\nexisting NER+L tool, SemEHR. Results on radiology reports from MIMIC-III and\nNHS Tayside were consistent with the discharge summaries. The overall pipeline\nprocessing clinical notes can extract rare disease cases, mostly uncaptured in\nstructured data (manually assigned ICD codes). We discuss the usefulness of the\nweak supervision approach and propose directions for future studies.\n","authors":["Hang Dong","Víctor Suárez-Paniagua","Huayu Zhang","Minhong Wang","Arlene Casey","Emma Davidson","Jiaoyan Chen","Beatrice Alex","William Whiteley","Honghan Wu"],"pdf_url":"https://arxiv.org/pdf/2205.05656v4.pdf","comment":"Structured abstract in full text, 16 pages, 4 figures (and extra 6\n  pages, 1 figure in the supplementary material)"},{"id":"http://arxiv.org/abs/2303.00077v1","updated":"2023-02-28T20:49:38Z","published":"2023-02-28T20:49:38Z","title":"Beyond the limitations of any imaginable mechanism: large language\n  models and psycholinguistics","summary":"  Large language models are not detailed models of human linguistic processing.\nThey are, however, extremely successful at their primary task: providing a\nmodel for language. For this reason and because there are no animal models for\nlanguage, large language models are important in psycholinguistics: they are\nuseful as a practical tool, as an illustrative comparative, and\nphilosophically, as a basis for recasting the relationship between language and\nthought.\n","authors":["Conor Houghton","Nina Kazanina","Priyanka Sukumaran"],"pdf_url":"https://arxiv.org/pdf/2303.00077v1.pdf","comment":"This is a commentary on Bowers Et. Al. (2023)\n  doi:10.1017/S0140525X22002813"},{"id":"http://arxiv.org/abs/2301.08771v2","updated":"2023-02-28T20:24:00Z","published":"2023-01-20T19:13:09Z","title":"Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt\n  Learning for Automatic Scoring in Science Education","summary":"  Developing models to automatically score students' written responses to\nscience problems is critical for science education. However, collecting and\nlabeling sufficient student responses for training models is time and\ncost-consuming. Recent studies suggest that pre-trained language models (PLMs)\ncan be adapted to downstream tasks without fine-tuning with prompts. However,\nno research has employed such a prompt approach in science education. As\nstudent responses are presented with natural language, aligning the scoring\nprocedure as the next sentence prediction task using prompts can skip the\ncostly fine-tuning stage. In this study, we developed a zero-shot approach to\nautomatically score student responses via Matching Exemplars as Next Sentence\nPrediction (MeNSP). This approach employs no training samples. We first apply\nMeNSP in scoring three assessment tasks of scientific argumentation and found\nmachine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and\nF1 score ranges from 0.54 to 0.81. To improve the performance, we extend our\nresearch to the few-shots setting, either randomly selecting labeled student\nresponses or manually constructing responses to fine-tune the models. We find\nthat one task's performance is improved with more samples, Cohen's Kappa from\n0.30 to 0.38, and F1 score from 0.54 to 0.59; for the two others, scoring\nperformance is not improved. We also find that randomly selected few-shots\nperform better than the human expert-crafted approach. This study suggests that\nMeNSP can yield referable automatic scoring for student responses while\nsignificantly reducing the cost of model training. This method can benefit\nlow-stakes classroom assessment practices in science education. Future research\nshould further explore the applicability of the MeNSP in different types of\nassessment tasks in science education and improve the model performance.\n","authors":["Xuansheng Wu","Xinyu He","Tianming Li","Ninghao Liu","Xiaoming Zhai"],"pdf_url":"https://arxiv.org/pdf/2301.08771v2.pdf","comment":"10+3 pages"},{"id":"http://arxiv.org/abs/2303.00069v1","updated":"2023-02-28T20:18:59Z","published":"2023-02-28T20:18:59Z","title":"ClArTTS: An Open-Source Classical Arabic Text-to-Speech Corpus","summary":"  At present, Text-to-speech (TTS) systems that are trained with high-quality\ntranscribed speech data using end-to-end neural models can generate speech that\nis intelligible, natural, and closely resembles human speech. These models are\ntrained with relatively large single-speaker professionally recorded audio,\ntypically extracted from audiobooks. Meanwhile, due to the scarcity of freely\navailable speech corpora of this kind, a larger gap exists in Arabic TTS\nresearch and development. Most of the existing freely available Arabic speech\ncorpora are not suitable for TTS training as they contain multi-speaker casual\nspeech with variations in recording conditions and quality, whereas the corpus\ncurated for speech synthesis are generally small in size and not suitable for\ntraining state-of-the-art end-to-end models. In a move towards filling this gap\nin resources, we present a speech corpus for Classical Arabic Text-to-Speech\n(ClArTTS) to support the development of end-to-end TTS systems for Arabic. The\nspeech is extracted from a LibriVox audiobook, which is then processed,\nsegmented, and manually transcribed and annotated. The final ClArTTS corpus\ncontains about 12 hours of speech from a single male speaker sampled at 40100\nkHz. In this paper, we describe the process of corpus creation and provide\ndetails of corpus statistics and a comparison with existing resources.\nFurthermore, we develop two TTS systems based on Grad-TTS and Glow-TTS and\nillustrate the performance of the resulting systems via subjective and\nobjective evaluations. The corpus will be made publicly available at\nwww.clartts.com for research purposes, along with the baseline TTS systems\ndemo.\n","authors":["Ajinkya Kulkarni","Atharva Kulkarni","Sara Abedalmonem Mohammad Shatnawi","Hanan Aldarmaki"],"pdf_url":"https://arxiv.org/pdf/2303.00069v1.pdf","comment":"None"},{"id":"http://arxiv.org/abs/2302.14679v1","updated":"2023-02-28T15:42:30Z","published":"2023-02-28T15:42:30Z","title":"Synthesizing Mixed-type Electronic Health Records using Diffusion Models","summary":"  Electronic Health Records (EHRs) contain sensitive patient information, which\npresents privacy concerns when sharing such data. Synthetic data generation is\na promising solution to mitigate these risks, often relying on deep generative\nmodels such as Generative Adversarial Networks (GANs). However, recent studies\nhave shown that diffusion models offer several advantages over GANs, such as\ngeneration of more realistic synthetic data and stable training in generating\ndata modalities, including image, text, and sound. In this work, we investigate\nthe potential of diffusion models for generating realistic mixed-type tabular\nEHRs, comparing TabDDPM model with existing methods on four datasets in terms\nof data quality, utility, privacy, and augmentation. Our experiments\ndemonstrate that TabDDPM outperforms the state-of-the-art models across all\nevaluation metrics, except for privacy, which confirms the trade-off between\nprivacy and utility.\n","authors":["Taha Ceritli","Ghadeer O. Ghosheh","Vinod Kumar Chauhan","Tingting Zhu","Andrew P. Creagh","David A. Clifton"],"pdf_url":"https://arxiv.org/pdf/2302.14679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09217v3","updated":"2023-02-28T09:47:49Z","published":"2022-07-17T03:12:27Z","title":"Contextual Similarity is More Valuable than Character Similarity: An\n  Empirical Study for Chinese Spell Checking","summary":"  Chinese Spell Checking (CSC) task aims to detect and correct Chinese spelling\nerrors. Recently, related researches focus on introducing character similarity\nfrom confusion set to enhance the CSC models, ignoring the context of\ncharacters that contain richer information. To make better use of contextual\ninformation, we propose a simple yet effective Curriculum Learning (CL)\nframework for the CSC task. With the help of our model-agnostic CL framework,\nexisting CSC models will be trained from easy to difficult as humans learn\nChinese characters and achieve further performance improvements. Extensive\nexperiments and detailed analyses on widely used SIGHAN datasets show that our\nmethod outperforms previous state-of-the-art methods. More instructively, our\nstudy empirically suggests that contextual similarity is more valuable than\ncharacter similarity for the CSC task.\n","authors":["Ding Zhang","Yinghui Li","Qingyu Zhou","Shirong Ma","Yangning Li","Yunbo Cao","Hai-Tao Zheng"],"pdf_url":"https://arxiv.org/pdf/2207.09217v3.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2303.01241v1","updated":"2023-02-28T21:53:48Z","published":"2023-02-28T21:53:48Z","title":"PANACEA: An Automated Misinformation Detection System on COVID-19","summary":"  In this demo, we introduce a web-based misinformation detection system\nPANACEA on COVID-19 related claims, which has two modules, fact-checking and\nrumour detection. Our fact-checking module, which is supported by novel natural\nlanguage inference methods with a self-attention network, outperforms\nstate-of-the-art approaches. It is also able to give automated veracity\nassessment and ranked supporting evidence with the stance towards the claim to\nbe checked. In addition, PANACEA adapts the bi-directional graph convolutional\nnetworks model, which is able to detect rumours based on comment networks of\nrelated tweets, instead of relying on the knowledge base. This rumour detection\nmodule assists by warning the users in the early stages when a knowledge base\nmay not be available.\n","authors":["Runcong Zhao","Miguel Arana-Catania","Lixing Zhu","Elena Kochkina","Lin Gui","Arkaitz Zubiaga","Rob Procter","Maria Liakata","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2303.01241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01249v1","updated":"2023-02-28T14:43:49Z","published":"2023-02-28T14:43:49Z","title":"Language-Universal Adapter Learning with Knowledge Distillation for\n  End-to-End Multilingual Speech Recognition","summary":"  In this paper, we propose a language-universal adapter learning framework\nbased on a pre-trained model for end-to-end multilingual automatic speech\nrecognition (ASR). For acoustic modeling, the wav2vec 2.0 pre-trained model is\nfine-tuned by inserting language-specific and language-universal adapters. An\nonline knowledge distillation is then used to enable the language-universal\nadapters to learn both language-specific and universal features. The linguistic\ninformation confusion is also reduced by leveraging language identifiers\n(LIDs). With LIDs we perform a position-wise modification on the multi-head\nattention outputs. In the inference procedure, the language-specific adapters\nare removed while the language-universal adapters are kept activated. The\nproposed method improves the recognition accuracy and addresses the linear\nincrease of the number of adapters' parameters with the number of languages in\ncommon multilingual ASR systems. Experiments on the BABEL dataset confirm the\neffectiveness of the proposed framework. Compared to the conventional\nmultilingual model, a 3.3% absolute error rate reduction is achieved. The code\nis available at: https://github.com/shen9712/UniversalAdapterLearning.\n","authors":["Zhijie Shen","Wu Guo","Bin Gu"],"pdf_url":"https://arxiv.org/pdf/2303.01249v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.14859v1","updated":"2023-02-28T18:58:03Z","published":"2023-02-28T18:58:03Z","title":"BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis","summary":"  We present a method for reconstructing high-quality meshes of large unbounded\nreal-world scenes suitable for photorealistic novel view synthesis. We first\noptimize a hybrid neural volume-surface scene representation designed to have\nwell-behaved level sets that correspond to surfaces in the scene. We then bake\nthis representation into a high-quality triangle mesh, which we equip with a\nsimple and fast view-dependent appearance model based on spherical Gaussians.\nFinally, we optimize this baked representation to best reproduce the captured\nviewpoints, resulting in a model that can leverage accelerated polygon\nrasterization pipelines for real-time view synthesis on commodity hardware. Our\napproach outperforms previous scene representations for real-time rendering in\nterms of accuracy, speed, and power consumption, and produces high quality\nmeshes that enable applications such as appearance editing and physical\nsimulation.\n","authors":["Lior Yariv","Peter Hedman","Christian Reiser","Dor Verbin","Pratul P. Srinivasan","Richard Szeliski","Jonathan T. Barron","Ben Mildenhall"],"pdf_url":"https://arxiv.org/pdf/2302.14859v1.pdf","comment":"Video and interactive web demo available at\n  https://bakedsdf.github.io/"},{"id":"http://arxiv.org/abs/2210.06184v2","updated":"2023-02-28T18:40:52Z","published":"2022-10-07T17:27:50Z","title":"Images as Weight Matrices: Sequential Image Generation Through Synaptic\n  Learning Rules","summary":"  Work on fast weight programmers has demonstrated the effectiveness of\nkey/value outer product-based learning rules for sequentially generating a\nweight matrix (WM) of a neural net (NN) by another NN or itself. However, the\nweight generation steps are typically not visually interpretable by humans,\nbecause the contents stored in the WM of an NN are not. Here we apply the same\nprinciple to generate natural images. The resulting fast weight painters (FPAs)\nlearn to execute sequences of delta learning rules to sequentially generate\nimages as sums of outer products of self-invented keys and values, one rank at\na time, as if each image was a WM of an NN. We train our FPAs in the generative\nadversarial networks framework, and evaluate on various image datasets. We show\nhow these generic learning rules can generate images with respectable visual\nquality without any explicit inductive bias for images. While the performance\nlargely lags behind the one of specialised state-of-the-art image generators,\nour approach allows for visualising how synaptic learning rules iteratively\nproduce complex connection patterns, yielding human-interpretable meaningful\nimages. Finally, we also show that an additional convolutional U-Net (now\npopular in diffusion models) at the output of an FPA can learn one-step\n\"denoising\" of FPA-generated images to enhance their quality. Our code is\npublic.\n","authors":["Kazuki Irie","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2210.06184v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2210.09879v3","updated":"2023-02-28T18:35:23Z","published":"2022-10-18T14:13:20Z","title":"Unsupervised visualization of image datasets using contrastive learning","summary":"  Visualization methods based on the nearest neighbor graph, such as t-SNE or\nUMAP, are widely used for visualizing high-dimensional data. Yet, these\napproaches only produce meaningful results if the nearest neighbors themselves\nare meaningful. For images represented in pixel space this is not the case, as\ndistances in pixel space are often not capturing our sense of similarity and\ntherefore neighbors are not semantically close. This problem can be\ncircumvented by self-supervised approaches based on contrastive learning, such\nas SimCLR, relying on data augmentation to generate implicit neighbors, but\nthese methods do not produce two-dimensional embeddings suitable for\nvisualization. Here, we present a new method, called t-SimCNE, for unsupervised\nvisualization of image data. T-SimCNE combines ideas from contrastive learning\nand neighbor embeddings, and trains a parametric mapping from the\nhigh-dimensional pixel space into two dimensions. We show that the resulting 2D\nembeddings achieve classification accuracy comparable to the state-of-the-art\nhigh-dimensional SimCLR representations, thus faithfully capturing semantic\nrelationships. Using t-SimCNE, we obtain informative visualizations of the\nCIFAR-10 and CIFAR-100 datasets, showing rich cluster structure and\nhighlighting artifacts and outliers.\n","authors":["Jan Niklas Böhm","Philipp Berens","Dmitry Kobak"],"pdf_url":"https://arxiv.org/pdf/2210.09879v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.09956v2","updated":"2023-02-28T18:30:37Z","published":"2023-02-20T12:57:31Z","title":"Because Every Sensor Is Unique, so Is Every Pair: Handling Dynamicity in\n  Traffic Forecasting","summary":"  Traffic forecasting is a critical task to extract values from cyber-physical\ninfrastructures, which is the backbone of smart transportation. However owing\nto external contexts, the dynamics at each sensor are unique. For example, the\nafternoon peaks at sensors near schools are more likely to occur earlier than\nthose near residential areas. In this paper, we first analyze real-world\ntraffic data to show that each sensor has a unique dynamic. Further analysis\nalso shows that each pair of sensors also has a unique dynamic. Then, we\nexplore how node embedding learns the unique dynamics at every sensor location.\nNext, we propose a novel module called Spatial Graph Transformers (SGT) where\nwe use node embedding to leverage the self-attention mechanism to ensure that\nthe information flow between two sensors is adaptive with respect to the unique\ndynamic of each pair. Finally, we present Graph Self-attention WaveNet (G-SWaN)\nto address the complex, non-linear spatiotemporal traffic dynamics. Through\nempirical experiments on four real-world, open datasets, we show that the\nproposed method achieves superior performance on both traffic speed and flow\nforecasting. Code is available at: https://github.com/aprbw/G-SWaN\n","authors":["Arian Prabowo","Wei Shao","Hao Xue","Piotr Koniusz","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2302.09956v2.pdf","comment":"20 pages, IoTDI 2023; Correction on Fig. 4"},{"id":"http://arxiv.org/abs/2302.14831v1","updated":"2023-02-28T18:28:35Z","published":"2023-02-28T18:28:35Z","title":"FacEDiM: A Face Embedding Distribution Model for Few-Shot Biometric\n  Authentication of Cattle","summary":"  This work proposes to solve the problem of few-shot biometric authentication\nby computing the Mahalanobis distance between testing embeddings and a\nmultivariate Gaussian distribution of training embeddings obtained using\npre-trained CNNs. Experimental results show that models pre-trained on the\nImageNet dataset significantly outperform models pre-trained on human faces.\nWith a VGG16 model, we obtain a FRR of 1.18% for a FAR of 1.25% on a dataset of\n20 cattle identities.\n","authors":["Meshia Cédric Oveneke","Rucha Vaishampayan","Deogratias Lukamba Nsadisa","Jenny Ambukiyenyi Onya"],"pdf_url":"https://arxiv.org/pdf/2302.14831v1.pdf","comment":"4 pages, 1 figure, 1 table, paper accepted at Black In AI at the 36th\n  Conference on Neural Information Processing Systems (NeurIPS 2022), New\n  Orleans, USA"},{"id":"http://arxiv.org/abs/2302.14816v1","updated":"2023-02-28T18:08:21Z","published":"2023-02-28T18:08:21Z","title":"Monocular Depth Estimation using Diffusion Models","summary":"  We formulate monocular depth estimation using denoising diffusion models,\ninspired by their recent successes in high fidelity image generation. To that\nend, we introduce innovations to address problems arising due to noisy,\nincomplete depth maps in training data, including step-unrolled denoising\ndiffusion, an $L_1$ loss, and depth infilling during training. To cope with the\nlimited availability of data for supervised training, we leverage pre-training\non self-supervised image-to-image translation tasks. Despite the simplicity of\nthe approach, with a generic loss and architecture, our DepthGen model achieves\nSOTA performance on the indoor NYU dataset, and near SOTA results on the\noutdoor KITTI dataset. Further, with a multimodal posterior, DepthGen naturally\nrepresents depth ambiguity (e.g., from transparent surfaces), and its zero-shot\nperformance combined with depth imputation, enable a simple but effective\ntext-to-3D pipeline. Project page: https://depth-gen.github.io\n","authors":["Saurabh Saxena","Abhishek Kar","Mohammad Norouzi","David J. Fleet"],"pdf_url":"https://arxiv.org/pdf/2302.14816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14808v1","updated":"2023-02-28T17:58:54Z","published":"2023-02-28T17:58:54Z","title":"Opto-UNet: Optimized UNet for Segmentation of Varicose Veins in Optical\n  Coherence Tomography","summary":"  Human veins are important for carrying the blood from the body-parts to the\nheart. The improper functioning of the human veins may arise from several\nvenous diseases. Varicose vein is one such disease wherein back flow of blood\ncan occur, often resulting in increased venous pressure or restricted blood\nflow due to changes in the structure of vein. To examine the functional\ncharacteristics of the varicose vein, it is crucial to study the physical and\nbio mechanical properties of the vein. This work proposes a segmentation model\nOpto-UNet, for segmenting the venous wall structure. Optical Coherence\nTomography system is used to acquire images of varicose vein. As the extracted\nvein is not uniform in shape, hence adequate method of segmentation is required\nto segment the venous wall. Opto-UNet model is based on the U-Net architecture\nwherein a new block is integrated into the architecture, employing atrous and\nseparable convolution to extract spatially wide-range and separable features\nmaps for attaining advanced performance. Furthermore, the depth wise separable\nconvolution significantly reduces the complexity of the network by optimizing\nthe number of parameters. The model achieves accuracy of 0.9830, sensitivity of\n0.8425 and specificity of 0.9980 using 8.54 million number of parameters. These\nresults indicate that model is highly adequate in segmenting the varicose vein\nwall without deteriorating the segmentation quality along with reduced\ncomplexity\n","authors":["Maryam Viqar","Violeta Madjarova","Vipul Baghel","Elena Stoykova"],"pdf_url":"https://arxiv.org/pdf/2302.14808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14807v1","updated":"2023-02-28T17:57:06Z","published":"2023-02-28T17:57:06Z","title":"DFR-FastMOT: Detection Failure Resistant Tracker for Fast Multi-Object\n  Tracking Based on Sensor Fusion","summary":"  Persistent multi-object tracking (MOT) allows autonomous vehicles to navigate\nsafely in highly dynamic environments. One of the well-known challenges in MOT\nis object occlusion when an object becomes unobservant for subsequent frames.\nThe current MOT methods store objects information, like objects' trajectory, in\ninternal memory to recover the objects after occlusions. However, they retain\nshort-term memory to save computational time and avoid slowing down the MOT\nmethod. As a result, they lose track of objects in some occlusion scenarios,\nparticularly long ones. In this paper, we propose DFR-FastMOT, a light MOT\nmethod that uses data from a camera and LiDAR sensors and relies on an\nalgebraic formulation for object association and fusion. The formulation boosts\nthe computational time and permits long-term memory that tackles more occlusion\nscenarios. Our method shows outstanding tracking performance over recent\nlearning and non-learning benchmarks with about 3% and 4% margin in MOTA,\nrespectively. Also, we conduct extensive experiments that simulate occlusion\nphenomena by employing detectors with various distortion levels. The proposed\nsolution enables superior performance under various distortion levels in\ndetection over current state-of-art methods. Our framework processes about\n7,763 frames in 1.48 seconds, which is seven times faster than recent\nbenchmarks. The framework will be available at\nhttps://github.com/MohamedNagyMostafa/DFR-FastMOT.\n","authors":["Mohamed Nagy","Majid Khonji","Jorge Dias","Sajid Javed"],"pdf_url":"https://arxiv.org/pdf/2302.14807v1.pdf","comment":"\\c{opyright} 2023 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2302.14795v1","updated":"2023-02-28T17:46:25Z","published":"2023-02-28T17:46:25Z","title":"3D Coronary Vessel Reconstruction from Bi-Plane Angiography using Graph\n  Convolutional Networks","summary":"  X-ray coronary angiography (XCA) is used to assess coronary artery disease\nand provides valuable information on lesion morphology and severity. However,\nXCA images are 2D and therefore limit visualisation of the vessel. 3D\nreconstruction of coronary vessels is possible using multiple views, however\nlumen border detection in current software is performed manually resulting in\nlimited reproducibility and slow processing time. In this study we propose\n3DAngioNet, a novel deep learning (DL) system that enables rapid 3D vessel mesh\nreconstruction using 2D XCA images from two views. Our approach learns a coarse\nmesh template using an EfficientB3-UNet segmentation network and projection\ngeometries, and deforms it using a graph convolutional network. 3DAngioNet\noutperforms similar automated reconstruction methods, offers improved\nefficiency, and enables modelling of bifurcated vessels. The approach was\nvalidated using state-of-the-art software verified by skilled cardiologists.\n","authors":["Kit Mills Bransby","Vincenzo Tufaro","Murat Cap","Greg Slabaugh","Christos Bourantas","Qianni Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14795v1.pdf","comment":"Pre-print for IEEE International Symposium on Biomedical Imaging 2023\n  (ISBI)"},{"id":"http://arxiv.org/abs/2302.14794v1","updated":"2023-02-28T17:46:18Z","published":"2023-02-28T17:46:18Z","title":"Meta Learning to Bridge Vision and Language Models for Multimodal\n  Few-Shot Learning","summary":"  Multimodal few-shot learning is challenging due to the large domain gap\nbetween vision and language modalities. Existing methods are trying to\ncommunicate visual concepts as prompts to frozen language models, but rely on\nhand-engineered task induction to reduce the hypothesis space. To make the\nwhole process learnable, we introduce a multimodal meta-learning approach.\nSpecifically, our approach decomposes the training of the model into a set of\nrelated multimodal few-shot tasks. We define a meta-mapper network, acting as a\nmeta-learner, to efficiently bridge frozen large-scale vision and language\nmodels and leverage their already learned capacity. By updating the learnable\nparameters only of the meta-mapper, it learns to accrue shared meta-knowledge\namong these tasks. Thus, it can rapidly adapt to newly presented samples with\nonly a few gradient updates. Importantly, it induces the task in a completely\ndata-driven manner, with no need for a hand-engineered task induction. We\nevaluate our approach on recently proposed multimodal few-shot benchmarks,\nmeasuring how rapidly the model can bind novel visual concepts to words and\nanswer visual questions by observing only a limited set of labeled examples.\nThe experimental results show that our meta-learning approach outperforms the\nbaseline across multiple datasets and various training settings while being\ncomputationally more efficient.\n","authors":["Ivona Najdenkoska","Xiantong Zhen","Marcel Worring"],"pdf_url":"https://arxiv.org/pdf/2302.14794v1.pdf","comment":"International Conference on Learning Representations 2023"},{"id":"http://arxiv.org/abs/2106.13201v3","updated":"2023-02-28T17:36:38Z","published":"2021-06-24T17:27:32Z","title":"DROID: Driver-centric Risk Object Identification","summary":"  Identification of high-risk driving situations is generally approached\nthrough collision risk estimation or accident pattern recognition. In this\nwork, we approach the problem from the perspective of subjective risk. We\noperationalize subjective risk assessment by predicting driver behavior changes\nand identifying the cause of changes. To this end, we introduce a new task\ncalled driver-centric risk object identification (DROID), which uses egocentric\nvideo to identify object(s) influencing a driver's behavior, given only the\ndriver's response as the supervision signal. We formulate the task as a\ncause-effect problem and present a novel two-stage DROID framework, taking\ninspiration from models of situation awareness and causal inference. A subset\nof data constructed from the Honda Research Institute Driving Dataset (HDD) is\nused to evaluate DROID. We demonstrate state-of-the-art DROID performance, even\ncompared with strong baseline models using this dataset. Additionally, we\nconduct extensive ablative studies to justify our design choices. Moreover, we\ndemonstrate the applicability of DROID for risk assessment.\n","authors":["Chengxi Li","Stanley H. Chan","Yi-Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2106.13201v3.pdf","comment":"Submitted to TPAMI"},{"id":"http://arxiv.org/abs/2302.14777v1","updated":"2023-02-28T17:20:40Z","published":"2023-02-28T17:20:40Z","title":"VQA with Cascade of Self- and Co-Attention Blocks","summary":"  The use of complex attention modules has improved the performance of the\nVisual Question Answering (VQA) task. This work aims to learn an improved\nmulti-modal representation through dense interaction of visual and textual\nmodalities. The proposed model has an attention block containing both\nself-attention and co-attention on image and text. The self-attention modules\nprovide the contextual information of objects (for an image) and words (for a\nquestion) that are crucial for inferring an answer. On the other hand,\nco-attention aids the interaction of image and text. Further, fine-grained\ninformation is obtained from two modalities by using a Cascade of Self- and\nCo-Attention blocks (CSCA). This proposal is benchmarked on the widely used\nVQA2.0 and TDIUC datasets. The efficacy of key components of the model and\ncascading of attention modules are demonstrated by experiments involving\nablation analysis.\n","authors":["Aakansha Mishra","Ashish Anand","Prithwijit Guha"],"pdf_url":"https://arxiv.org/pdf/2302.14777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14772v1","updated":"2023-02-28T17:14:24Z","published":"2023-02-28T17:14:24Z","title":"PA&DA: Jointly Sampling PAth and DAta for Consistent NAS","summary":"  Based on the weight-sharing mechanism, one-shot NAS methods train a supernet\nand then inherit the pre-trained weights to evaluate sub-models, largely\nreducing the search cost. However, several works have pointed out that the\nshared weights suffer from different gradient descent directions during\ntraining. And we further find that large gradient variance occurs during\nsupernet training, which degrades the supernet ranking consistency. To mitigate\nthis issue, we propose to explicitly minimize the gradient variance of the\nsupernet training by jointly optimizing the sampling distributions of PAth and\nDAta (PA&DA). We theoretically derive the relationship between the gradient\nvariance and the sampling distributions, and reveal that the optimal sampling\nprobability is proportional to the normalized gradient norm of path and\ntraining data. Hence, we use the normalized gradient norm as the importance\nindicator for path and training data, and adopt an importance sampling strategy\nfor the supernet training. Our method only requires negligible computation cost\nfor optimizing the sampling distributions of path and data, but achieves lower\ngradient variance during supernet training and better generalization\nperformance for the supernet, resulting in a more consistent NAS. We conduct\ncomprehensive comparisons with other improved approaches in various search\nspaces. Results show that our method surpasses others with more reliable\nranking performance and higher accuracy of searched architectures, showing the\neffectiveness of our method. Code is available at\nhttps://github.com/ShunLu91/PA-DA.\n","authors":["Shun Lu","Yu Hu","Longxing Yang","Zihao Sun","Jilin Mei","Jianchao Tan","Chengru Song"],"pdf_url":"https://arxiv.org/pdf/2302.14772v1.pdf","comment":"To appear in CVPR 2023; we will update the camera-ready version soon"},{"id":"http://arxiv.org/abs/2302.14771v1","updated":"2023-02-28T17:13:14Z","published":"2023-02-28T17:13:14Z","title":"Generic-to-Specific Distillation of Masked Autoencoders","summary":"  Large vision Transformers (ViTs) driven by self-supervised pre-training\nmechanisms achieved unprecedented progress. Lightweight ViT models limited by\nthe model capacity, however, benefit little from those pre-training mechanisms.\nKnowledge distillation defines a paradigm to transfer representations from\nlarge (teacher) models to small (student) ones. However, the conventional\nsingle-stage distillation easily gets stuck on task-specific transfer, failing\nto retain the task-agnostic knowledge crucial for model generalization. In this\nstudy, we propose generic-to-specific distillation (G2SD), to tap the potential\nof small ViT models under the supervision of large models pre-trained by masked\nautoencoders. In generic distillation, decoder of the small model is encouraged\nto align feature predictions with hidden representations of the large model, so\nthat task-agnostic knowledge can be transferred. In specific distillation,\npredictions of the small model are constrained to be consistent with those of\nthe large model, to transfer task-specific features which guarantee task\nperformance. With G2SD, the vanilla ViT-Small model respectively achieves\n98.7%, 98.1% and 99.3% the performance of its teacher (ViT-Base) for image\nclassification, object detection, and semantic segmentation, setting a solid\nbaseline for two-stage vision distillation. Code will be available at\nhttps://github.com/pengzhiliang/G2SD.\n","authors":["Wei Huang","Zhiliang Peng","Li Dong","Furu Wei","Jianbin Jiao","Qixiang Ye"],"pdf_url":"https://arxiv.org/pdf/2302.14771v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2204.05235v2","updated":"2023-02-28T17:12:35Z","published":"2022-04-11T16:32:25Z","title":"Data Splits and Metrics for Method Benchmarking on Surgical Action\n  Triplet Datasets","summary":"  In addition to generating data and annotations, devising sensible data\nsplitting strategies and evaluation metrics is essential for the creation of a\nbenchmark dataset. This practice ensures consensus on the usage of the data,\nhomogeneous assessment, and uniform comparison of research methods on the\ndataset. This study focuses on CholecT50, which is a 50 video surgical dataset\nthat formalizes surgical activities as triplets of <instrument, verb, target>.\nIn this paper, we introduce the standard splits for the CholecT50 and CholecT45\ndatasets and show how they compare with existing use of the dataset. CholecT45\nis the first public release of 45 videos of CholecT50 dataset. We also develop\na metrics library, ivtmetrics, for model evaluation on surgical triplets.\nFurthermore, we conduct a benchmark study by reproducing baseline methods in\nthe most predominantly used deep learning frameworks (PyTorch and TensorFlow)\nto evaluate them using the proposed data splits and metrics and release them\npublicly to support future research. The proposed data splits and evaluation\nmetrics will enable global tracking of research progress on the dataset and\nfacilitate optimal model selection for further deployment.\n","authors":["Chinedu Innocent Nwoye","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2204.05235v2.pdf","comment":"Official splits for the CholecT50 and CholecT45 datasets, 13 pages, 2\n  figures, 12 tables"},{"id":"http://arxiv.org/abs/2302.14769v1","updated":"2023-02-28T17:10:32Z","published":"2023-02-28T17:10:32Z","title":"Membership Inference Attack for Beluga Whales Discrimination","summary":"  To efficiently monitor the growth and evolution of a particular wildlife\npopulation, one of the main fundamental challenges to address in animal ecology\nis the re-identification of individuals that have been previously encountered\nbut also the discrimination between known and unknown individuals (the\nso-called \"open-set problem\"), which is the first step to realize before\nre-identification. In particular, in this work, we are interested in the\ndiscrimination within digital photos of beluga whales, which are known to be\namong the most challenging marine species to discriminate due to their lack of\ndistinctive features. To tackle this problem, we propose a novel approach based\non the use of Membership Inference Attacks (MIAs), which are normally used to\nassess the privacy risks associated with releasing a particular machine\nlearning model. More precisely, we demonstrate that the problem of\ndiscriminating between known and unknown individuals can be solved efficiently\nusing state-of-the-art approaches for MIAs. Extensive experiments on three\nbenchmark datasets related to whales, two different neural network\narchitectures, and three MIA clearly demonstrate the performance of the\napproach. In addition, we have also designed a novel MIA strategy that we\ncoined as ensemble MIA, which combines the outputs of different MIAs to\nincrease the attack accuracy while diminishing the false positive rate.\nOverall, one of our main objectives is also to show that the research on\nprivacy attacks can also be leveraged \"for good\" by helping to address\npractical challenges encountered in animal ecology.\n","authors":["Voncarlos Marcelo Araújo","Sébastien Gambs","Clément Chion","Robert Michaud","Léo Schneider","Hadrien Lautraite"],"pdf_url":"https://arxiv.org/pdf/2302.14769v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2302.14762v1","updated":"2023-02-28T17:02:35Z","published":"2023-02-28T17:02:35Z","title":"Kartezio: Evolutionary Design of Explainable Pipelines for Biomedical\n  Image Analysis","summary":"  An unresolved issue in contemporary biomedicine is the overwhelming number\nand diversity of complex images that require annotation, analysis and\ninterpretation. Recent advances in Deep Learning have revolutionized the field\nof computer vision, creating algorithms that compete with human experts in\nimage segmentation tasks. Crucially however, these frameworks require large\nhuman-annotated datasets for training and the resulting models are difficult to\ninterpret. In this study, we introduce Kartezio, a modular Cartesian Genetic\nProgramming based computational strategy that generates transparent and easily\ninterpretable image processing pipelines by iteratively assembling and\nparameterizing computer vision functions. The pipelines thus generated exhibit\ncomparable precision to state-of-the-art Deep Learning approaches on instance\nsegmentation tasks, while requiring drastically smaller training datasets, a\nfeature which confers tremendous flexibility, speed, and functionality to this\napproach. We also deployed Kartezio to solve semantic and instance segmentation\nproblems in four real-world Use Cases, and showcase its utility in imaging\ncontexts ranging from high-resolution microscopy to clinical pathology. By\nsuccessfully implementing Kartezio on a portfolio of images ranging from\nsubcellular structures to tumoral tissue, we demonstrated the flexibility,\nrobustness and practical utility of this fully explicable evolutionary designer\nfor semantic and instance segmentation.\n","authors":["Kévin Cortacero","Brienne McKenzie","Sabina Müller","Roxana Khazen","Fanny Lafouresse","Gaëlle Corsaut","Nathalie Van Acker","François-Xavier Frenois","Laurence Lamant","Nicolas Meyer","Béatrice Vergier","Dennis G. Wilson","Hervé Luga","Oskar Staufer","Michael L. Dustin","Salvatore Valitutti","Sylvain Cussat-Blanc"],"pdf_url":"https://arxiv.org/pdf/2302.14762v1.pdf","comment":"42 pages, 6 main Figures, 3 Extended Data Figures, 5 Extended Data\n  Tables, 1 Extended Data Movie. The Extended Data Movie is available at the\n  following link:\n  https://drive.google.com/file/d/1eNGhFC8gyu5xjVOhIZve894g3bBKXEgs/view?usp=sharing"},{"id":"http://arxiv.org/abs/2210.10947v2","updated":"2023-02-28T16:54:02Z","published":"2022-10-20T01:32:41Z","title":"Does Learning from Decentralized Non-IID Unlabeled Data Benefit from\n  Self Supervision?","summary":"  Decentralized learning has been advocated and widely deployed to make\nefficient use of distributed datasets, with an extensive focus on supervised\nlearning (SL) problems. Unfortunately, the majority of real-world data are\nunlabeled and can be highly heterogeneous across sources. In this work, we\ncarefully study decentralized learning with unlabeled data through the lens of\nself-supervised learning (SSL), specifically contrastive visual representation\nlearning. We study the effectiveness of a range of contrastive learning\nalgorithms under decentralized learning settings, on relatively large-scale\ndatasets including ImageNet-100, MS-COCO, and a new real-world robotic\nwarehouse dataset. Our experiments show that the decentralized SSL (Dec-SSL)\napproach is robust to the heterogeneity of decentralized datasets, and learns\nuseful representation for object classification, detection, and segmentation\ntasks. This robustness makes it possible to significantly reduce communication\nand reduce the participation ratio of data sources with only minimal drops in\nperformance. Interestingly, using the same amount of data, the representation\nlearned by Dec-SSL can not only perform on par with that learned by centralized\nSSL which requires communication and excessive data storage costs, but also\nsometimes outperform representations extracted from decentralized SL which\nrequires extra knowledge about the data labels. Finally, we provide theoretical\ninsights into understanding why data heterogeneity is less of a concern for\nDec-SSL objectives, and introduce feature alignment and clustering techniques\nto develop a new Dec-SSL algorithm that further improves the performance, in\nthe face of highly non-IID data. Our study presents positive evidence to\nembrace unlabeled data in decentralized learning, and we hope to provide new\ninsights into whether and why decentralized SSL is effective.\n","authors":["Lirui Wang","Kaiqing Zhang","Yunzhu Li","Yonglong Tian","Russ Tedrake"],"pdf_url":"https://arxiv.org/pdf/2210.10947v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14746v1","updated":"2023-02-28T16:45:21Z","published":"2023-02-28T16:45:21Z","title":"Mask3D: Pre-training 2D Vision Transformers by Learning Masked 3D Priors","summary":"  Current popular backbones in computer vision, such as Vision Transformers\n(ViT) and ResNets are trained to perceive the world from 2D images. However, to\nmore effectively understand 3D structural priors in 2D backbones, we propose\nMask3D to leverage existing large-scale RGB-D data in a self-supervised\npre-training to embed these 3D priors into 2D learned feature representations.\nIn contrast to traditional 3D contrastive learning paradigms requiring 3D\nreconstructions or multi-view correspondences, our approach is simple: we\nformulate a pre-text reconstruction task by masking RGB and depth patches in\nindividual RGB-D frames. We demonstrate the Mask3D is particularly effective in\nembedding 3D priors into the powerful 2D ViT backbone, enabling improved\nrepresentation learning for various scene understanding tasks, such as semantic\nsegmentation, instance segmentation and object detection. Experiments show that\nMask3D notably outperforms existing self-supervised 3D pre-training approaches\non ScanNet, NYUv2, and Cityscapes image understanding tasks, with an\nimprovement of +6.5% mIoU against the state-of-the-art Pri3D on ScanNet image\nsemantic segmentation.\n","authors":["Ji Hou","Xiaoliang Dai","Zijian He","Angela Dai","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2302.14746v1.pdf","comment":"accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2302.14736v1","updated":"2023-02-28T16:39:36Z","published":"2023-02-28T16:39:36Z","title":"TextIR: A Simple Framework for Text-based Editable Image Restoration","summary":"  Most existing image restoration methods use neural networks to learn strong\nimage-level priors from huge data to estimate the lost information. However,\nthese works still struggle in cases when images have severe information\ndeficits. Introducing external priors or using reference images to provide\ninformation also have limitations in the application domain. In contrast, text\ninput is more readily available and provides information with higher\nflexibility. In this work, we design an effective framework that allows the\nuser to control the restoration process of degraded images with text\ndescriptions. We use the text-image feature compatibility of the CLIP to\nalleviate the difficulty of fusing text and image features. Our framework can\nbe used for various image restoration tasks, including image inpainting, image\nsuper-resolution, and image colorization. Extensive experiments demonstrate the\neffectiveness of our method.\n","authors":["Yunpeng Bai","Cairong Wang","Shuzhao Xie","Chao Dong","Chun Yuan","Zhi Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14736v1.pdf","comment":"9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.14728v1","updated":"2023-02-28T16:34:55Z","published":"2023-02-28T16:34:55Z","title":"Global Context-Aware Person Image Generation","summary":"  We propose a data-driven approach for context-aware person image generation.\nSpecifically, we attempt to generate a person image such that the synthesized\ninstance can blend into a complex scene. In our method, the position, scale,\nand appearance of the generated person are semantically conditioned on the\nexisting persons in the scene. The proposed technique is divided into three\nsequential steps. At first, we employ a Pix2PixHD model to infer a coarse\nsemantic mask that represents the new person's spatial location, scale, and\npotential pose. Next, we use a data-centric approach to select the closest\nrepresentation from a precomputed cluster of fine semantic masks. Finally, we\nadopt a multi-scale, attention-guided architecture to transfer the appearance\nattributes from an exemplar image. The proposed strategy enables us to\nsynthesize semantically coherent realistic persons that can blend into an\nexisting scene without altering the global context. We conclude our findings\nwith relevant qualitative and quantitative evaluations.\n","authors":["Prasun Roy","Saumik Bhattacharya","Subhankar Ghosh","Umapada Pal","Michael Blumenstein"],"pdf_url":"https://arxiv.org/pdf/2302.14728v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2112.04720v2","updated":"2023-02-28T16:21:41Z","published":"2021-12-09T06:16:08Z","title":"Amicable Aid: Perturbing Images to Improve Classification Performance","summary":"  While adversarial perturbation of images to attack deep image classification\nmodels pose serious security concerns in practice, this paper suggests a novel\nparadigm where the concept of image perturbation can benefit classification\nperformance, which we call amicable aid. We show that by taking the opposite\nsearch direction of perturbation, an image can be modified to yield higher\nclassification confidence and even a misclassified image can be made correctly\nclassified. This can be also achieved with a large amount of perturbation by\nwhich the image is made unrecognizable by human eyes. The mechanism of the\namicable aid is explained in the viewpoint of the underlying natural image\nmanifold. Furthermore, we investigate the universal amicable aid, i.e., a fixed\nperturbation can be applied to multiple images to improve their classification\nresults. While it is challenging to find such perturbations, we show that\nmaking the decision boundary as perpendicular to the image manifold as possible\nvia training with modified data is effective to obtain a model for which\nuniversal amicable perturbations are more easily found.\n","authors":["Juyeop Kim","Jun-Ho Choi","Soobeom Jang","Jong-Seok Lee"],"pdf_url":"https://arxiv.org/pdf/2112.04720v2.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2302.14696v1","updated":"2023-02-28T16:09:06Z","published":"2023-02-28T16:09:06Z","title":"Dissolving Is Amplifying: Towards Fine-Grained Anomaly Detection","summary":"  Medical anomalous data normally contains fine-grained instance-wise additive\nfeature patterns (e.g. tumor, hemorrhage), that are oftenly critical but\ninsignificant. Interestingly, apart from the remarkable image generation\nabilities of diffusion models, we observed that diffusion models can dissolve\nimage details for a given image, resulting in generalized feature\nrepresentations. We hereby propose DIA, dissolving is amplifying, that\namplifies fine-grained image features by contrasting an image against its\nfeature dissolved counterpart. In particular, we show that diffusion models can\nserve as semantic preserving feature dissolvers that help learning fine-grained\nanomalous patterns for anomaly detection tasks, especially for medical domains\nwith fine-grained feature differences. As a result, our method yields a novel\nfine-grained anomaly detection method, aims at amplifying instance-level\nfeature patterns, that significantly improves medical anomaly detection\naccuracy in a large margin without any prior knowledge of explicit fine-grained\nanomalous feature patterns.\n","authors":["Jian Shi","Pengyi Zhang","Ni Zhang","Hakim Ghazzai","Yehia Massoud"],"pdf_url":"https://arxiv.org/pdf/2302.14696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06958v2","updated":"2023-02-28T15:59:30Z","published":"2023-01-17T15:32:59Z","title":"RILS: Masked Visual Reconstruction in Language Semantic Space","summary":"  Both masked image modeling (MIM) and natural language supervision have\nfacilitated the progress of transferable visual pre-training. In this work, we\nseek the synergy between two paradigms and study the emerging properties when\nMIM meets natural language supervision. To this end, we present a novel masked\nvisual Reconstruction In Language semantic Space (RILS) pre-training framework,\nin which sentence representations, encoded by the text encoder, serve as\nprototypes to transform the vision-only signals into patch-sentence\nprobabilities as semantically meaningful MIM reconstruction targets. The vision\nmodels can therefore capture useful components with structured information by\npredicting proper semantic of masked tokens. Better visual representations\ncould, in turn, improve the text encoder via the image-text alignment\nobjective, which is essential for the effective MIM target transformation.\nExtensive experimental results demonstrate that our method not only enjoys the\nbest of previous MIM and CLIP but also achieves further improvements on various\ntasks due to their mutual benefits. RILS exhibits advanced transferability on\ndownstream classification, detection, and segmentation, especially for low-shot\nregimes. Code will be made available at https://github.com/hustvl/RILS.\n","authors":["Shusheng Yang","Yixiao Ge","Kun Yi","Dian Li","Ying Shan","Xiaohu Qie","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2301.06958v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14685v1","updated":"2023-02-28T15:54:47Z","published":"2023-02-28T15:54:47Z","title":"DART: Diversify-Aggregate-Repeat Training Improves Generalization of\n  Neural Networks","summary":"  Generalization of neural networks is crucial for deploying them safely in the\nreal world. Common training strategies to improve generalization involve the\nuse of data augmentations, ensembling and model averaging. In this work, we\nfirst establish a surprisingly simple but strong benchmark for generalization\nwhich utilizes diverse augmentations within a training minibatch, and show that\nthis can learn a more balanced distribution of features. Further, we propose\nDiversify-Aggregate-Repeat Training (DART) strategy that first trains diverse\nmodels using different augmentations (or domains) to explore the loss basin,\nand further Aggregates their weights to combine their expertise and obtain\nimproved generalization. We find that Repeating the step of Aggregation\nthroughout training improves the overall optimization trajectory and also\nensures that the individual models have a sufficiently low loss barrier to\nobtain improved generalization on combining them. We shed light on our approach\nby casting it in the framework proposed by Shen et al. and theoretically show\nthat it indeed generalizes better. In addition to improvements in In- Domain\ngeneralization, we demonstrate SOTA performance on the Domain Generalization\nbenchmarks in the popular DomainBed framework as well. Our method is generic\nand can easily be integrated with several base training algorithms to achieve\nperformance gains.\n","authors":["Samyak Jain","Sravanti Addepalli","Pawan Sahu","Priyam Dey","R. Venkatesh Babu"],"pdf_url":"https://arxiv.org/pdf/2302.14685v1.pdf","comment":"Accepted at CVPR 2023. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2302.14683v1","updated":"2023-02-28T15:51:19Z","published":"2023-02-28T15:51:19Z","title":"IntrinsicNGP: Intrinsic Coordinate based Hash Encoding for Human NeRF","summary":"  Recently, many works have been proposed to utilize the neural radiance field\nfor novel view synthesis of human performers. However, most of these methods\nrequire hours of training, making them difficult for practical use. To address\nthis challenging problem, we propose IntrinsicNGP, which can train from scratch\nand achieve high-fidelity results in few minutes with videos of a human\nperformer. To achieve this target, we introduce a continuous and optimizable\nintrinsic coordinate rather than the original explicit Euclidean coordinate in\nthe hash encoding module of instant-NGP. With this novel intrinsic coordinate,\nIntrinsicNGP can aggregate inter-frame information for dynamic objects with the\nhelp of proxy geometry shapes. Moreover, the results trained with the given\nrough geometry shapes can be further refined with an optimizable offset field\nbased on the intrinsic coordinate.Extensive experimental results on several\ndatasets demonstrate the effectiveness and efficiency of IntrinsicNGP. We also\nillustrate our approach's ability to edit the shape of reconstructed subjects.\n","authors":["Bo Peng","Jun Hu","Jingtao Zhou","Xuan Gao","Juyong Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14683v1.pdf","comment":"Project page:https://ustc3dv.github.io/IntrinsicNGP/. arXiv admin\n  note: substantial text overlap with arXiv:2210.01651"},{"id":"http://arxiv.org/abs/2107.09559v4","updated":"2023-02-28T15:46:52Z","published":"2021-07-20T15:22:16Z","title":"SynthSeg: Segmentation of brain MRI scans of any contrast and resolution\n  without retraining","summary":"  Despite advances in data augmentation and transfer learning, convolutional\nneural networks (CNNs) difficultly generalise to unseen domains. When\nsegmenting brain scans, CNNs are highly sensitive to changes in resolution and\ncontrast: even within the same MRI modality, performance can decrease across\ndatasets. Here we introduce SynthSeg, the first segmentation CNN robust against\nchanges in contrast and resolution. SynthSeg is trained with synthetic data\nsampled from a generative model conditioned on segmentations. Crucially, we\nadopt a domain randomisation strategy where we fully randomise the contrast and\nresolution of the synthetic training data. Consequently, SynthSeg can segment\nreal scans from a wide range of target domains without retraining or\nfine-tuning, which enables straightforward analysis of huge amounts of\nheterogeneous clinical data. Because SynthSeg only requires segmentations to be\ntrained (no images), it can learn from labels obtained by automated methods on\ndiverse populations (e.g., ageing and diseased), thus achieving robustness to a\nwide range of morphological variability. We demonstrate SynthSeg on 5,000 scans\nof six modalities (including CT) and ten resolutions, where it exhibits\nunparalleled generalisation compared with supervised CNNs, state-of-the-art\ndomain adaptation, and Bayesian segmentation. Finally, we demonstrate the\ngeneralisability of SynthSeg by applying it to cardiac MRI and CT scans.\n","authors":["Benjamin Billot","Douglas N. Greve","Oula Puonti","Axel Thielscher","Koen Van Leemput","Bruce Fischl","Adrian V. Dalca","Juan Eugenio Iglesias"],"pdf_url":"https://arxiv.org/pdf/2107.09559v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14680v1","updated":"2023-02-28T15:45:20Z","published":"2023-02-28T15:45:20Z","title":"Which One Are You Referring To? Multimodal Object Identification in\n  Situated Dialogue","summary":"  The demand for multimodal dialogue systems has been rising in various\ndomains, emphasizing the importance of interpreting multimodal inputs from\nconversational and situational contexts. We explore three methods to tackle\nthis problem and evaluate them on the largest situated dialogue dataset, SIMMC\n2.1. Our best method, scene-dialogue alignment, improves the performance by\n~20% F1-score compared to the SIMMC 2.1 baselines. We provide analysis and\ndiscussion regarding the limitation of our methods and the potential directions\nfor future works. Our code is publicly available at\nhttps://github.com/holylovenia/multimodal-object-identification.\n","authors":["Holy Lovenia","Samuel Cahyawijaya","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2302.14680v1.pdf","comment":"Accepted at EACL SRW 2023"},{"id":"http://arxiv.org/abs/2302.14677v1","updated":"2023-02-28T15:39:31Z","published":"2023-02-28T15:39:31Z","title":"Backdoor Attacks Against Deep Image Compression via Adaptive Frequency\n  Trigger","summary":"  Recent deep-learning-based compression methods have achieved superior\nperformance compared with traditional approaches. However, deep learning models\nhave proven to be vulnerable to backdoor attacks, where some specific trigger\npatterns added to the input can lead to malicious behavior of the models. In\nthis paper, we present a novel backdoor attack with multiple triggers against\nlearned image compression models. Motivated by the widely used discrete cosine\ntransform (DCT) in existing compression systems and standards, we propose a\nfrequency-based trigger injection model that adds triggers in the DCT domain.\nIn particular, we design several attack objectives for various attacking\nscenarios, including: 1) attacking compression quality in terms of bit-rate and\nreconstruction quality; 2) attacking task-driven measures, such as down-stream\nface recognition and semantic segmentation. Moreover, a novel simple dynamic\nloss is designed to balance the influence of different loss terms adaptively,\nwhich helps achieve more efficient training. Extensive experiments show that\nwith our trained trigger injection models and simple modification of encoder\nparameters (of the compression model), the proposed attack can successfully\ninject several backdoors with corresponding triggers in a single image\ncompression model.\n","authors":["Yi Yu","Yufei Wang","Wenhan Yang","Shijian Lu","Yap-peng Tan","Alex C. Kot"],"pdf_url":"https://arxiv.org/pdf/2302.14677v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.14673v1","updated":"2023-02-28T15:36:17Z","published":"2023-02-28T15:36:17Z","title":"Attention-based Point Cloud Edge Sampling","summary":"  Point cloud sampling is a less explored research topic for this data\nrepresentation. The most common sampling methods nowadays are still classical\nrandom sampling and farthest point sampling. With the development of neural\nnetworks, various methods have been proposed to sample point clouds in a\ntask-based learning manner. However, these methods are mostly generative-based,\nother than selecting points directly with mathematical statistics. Inspired by\nthe Canny edge detection algorithm for images and with the help of the\nattention mechanism, this paper proposes a non-generative Attention-based Point\ncloud Edge Sampling method (APES), which can capture the outline of input point\nclouds. Experimental results show that better performances are achieved with\nour sampling method due to the important outline information it learned.\n","authors":["Chengzhi Wu","Junwei Zheng","Julius Pfrommer","Jürgen Beyerer"],"pdf_url":"https://arxiv.org/pdf/2302.14673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14670v1","updated":"2023-02-28T15:34:01Z","published":"2023-02-28T15:34:01Z","title":"Double Dynamic Sparse Training for GANs","summary":"  The past decade has witnessed a drastic increase in modern deep neural\nnetworks (DNNs) size, especially for generative adversarial networks (GANs).\nSince GANs usually suffer from high computational complexity, researchers have\nshown an increased interest in applying pruning methods to reduce the training\nand inference costs of GANs. Among different pruning methods invented for\nsupervised learning, dynamic sparse training (DST) has gained increasing\nattention recently as it enjoys excellent training efficiency with comparable\nperformance to post-hoc pruning. Hence, applying DST on GANs, where we train a\nsparse GAN with a fixed parameter count throughout training, seems to be a good\ncandidate for reducing GAN training costs. However, a few challenges, including\nthe degrading training instability, emerge due to the adversarial nature of\nGANs. Hence, we introduce a quantity called balance ratio (BR) to quantify the\nbalance of the generator and the discriminator. We conduct a series of\nexperiments to show the importance of BR in understanding sparse GAN training.\nBuilding upon single dynamic sparse training (SDST), where only the generator\nis adjusted during training, we propose double dynamic sparse training (DDST)\nto control the BR during GAN training. Empirically, DDST automatically\ndetermines the density of the discriminator and greatly boosts the performance\nof sparse GANs on multiple datasets.\n","authors":["Yite Wang","Jing Wu","Naira Hovakimyan","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2302.14670v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.14665v1","updated":"2023-02-28T15:31:23Z","published":"2023-02-28T15:31:23Z","title":"Parametrizing Product Shape Manifolds by Composite Networks","summary":"  Parametrizations of data manifolds in shape spaces can be computed using the\nrich toolbox of Riemannian geometry. This, however, often comes with high\ncomputational costs, which raises the question if one can learn an efficient\nneural network approximation. We show that this is indeed possible for shape\nspaces with a special product structure, namely those smoothly approximable by\na direct sum of low-dimensional manifolds. Our proposed architecture leverages\nthis structure by separately learning approximations for the low-dimensional\nfactors and a subsequent combination. After developing the approach as a\ngeneral framework, we apply it to a shape space of triangular surfaces. Here,\ntypical examples of data manifolds are given through datasets of articulated\nmodels and can be factorized, for example, by a Sparse Principal Geodesic\nAnalysis (SPGA). We demonstrate the effectiveness of our proposed approach with\nexperiments on synthetic data as well as manifolds extracted from data via\nSPGA.\n","authors":["Josua Sassen","Klaus Hildebrandt","Martin Rumpf","Benedikt Wirth"],"pdf_url":"https://arxiv.org/pdf/2302.14665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03022v2","updated":"2023-02-28T15:09:40Z","published":"2023-02-06T18:57:30Z","title":"SurgT challenge: Benchmark of Soft-Tissue Trackers for Robotic Surgery","summary":"  This paper introduces the \"SurgT: Surgical Tracking\" challenge which was\norganised in conjunction with the 25th International Conference on Medical\nImage Computing and Computer-Assisted Intervention (MICCAI 2022). There were\ntwo purposes for the creation of this challenge: (1) the establishment of the\nfirst standardised benchmark for the research community to assess soft-tissue\ntrackers; and (2) to encourage the development of unsupervised deep learning\nmethods, given the lack of annotated data in surgery. A dataset of 157 stereo\nendoscopic videos from 20 clinical cases, along with stereo camera calibration\nparameters, have been provided. The participants were tasked with the\ndevelopment of algorithms to track a bounding box on stereo endoscopic videos.\nAt the end of the challenge, the developed methods were assessed on a\npreviously hidden test subset. This assessment uses benchmarking metrics that\nwere purposely developed for this challenge and are now available online. The\nteams were ranked according to their Expected Average Overlap (EAO) score,\nwhich is a weighted average of the Intersection over Union (IoU) scores. The\nperformance evaluation study verifies the efficacy of unsupervised deep\nlearning algorithms in tracking soft-tissue. The best-performing method\nachieved an EAO score of 0.583 in the test subset. The dataset and benchmarking\ntool created for this challenge have been made publicly available. This\nchallenge is expected to contribute to the development of autonomous robotic\nsurgery and other digital surgical technologies.\n","authors":["Joao Cartucho","Alistair Weld","Samyakh Tukra","Haozheng Xu","Hiroki Matsuzaki","Taiyo Ishikawa","Minjun Kwon","Yong Eun Jang","Kwang-Ju Kim","Gwang Lee","Bizhe Bai","Lueder Kahrs","Lars Boecking","Simeon Allmendinger","Leopold Muller","Yitong Zhang","Yueming Jin","Bano Sophia","Francisco Vasconcelos","Wolfgang Reiter","Jonas Hajek","Bruno Silva","Lukas R. Buschle","Estevao Lima","Joao L. Vilaca","Sandro Queiros","Stamatia Giannarou"],"pdf_url":"https://arxiv.org/pdf/2302.03022v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14623v1","updated":"2023-02-28T15:03:18Z","published":"2023-02-28T15:03:18Z","title":"Fast as CHITA: Neural Network Pruning with Combinatorial Optimization","summary":"  The sheer size of modern neural networks makes model serving a serious\ncomputational challenge. A popular class of compression techniques overcomes\nthis challenge by pruning or sparsifying the weights of pretrained networks.\nWhile useful, these techniques often face serious tradeoffs between\ncomputational requirements and compression quality. In this work, we propose a\nnovel optimization-based pruning framework that considers the combined effect\nof pruning (and updating) multiple weights subject to a sparsity constraint.\nOur approach, CHITA, extends the classical Optimal Brain Surgeon framework and\nresults in significant improvements in speed, memory, and performance over\nexisting optimization-based approaches for network pruning. CHITA's main\nworkhorse performs combinatorial optimization updates on a memory-friendly\nrepresentation of local quadratic approximation(s) of the loss function. On a\nstandard benchmark of pretrained models and datasets, CHITA leads to\nsignificantly better sparsity-accuracy tradeoffs than competing methods. For\nexample, for MLPNet with only 2% of the weights retained, our approach improves\nthe accuracy by 63% relative to the state of the art. Furthermore, when used in\nconjunction with fine-tuning SGD steps, our method achieves significant\naccuracy gains over the state-of-the-art approaches.\n","authors":["Riade Benbaki","Wenyu Chen","Xiang Meng","Hussein Hazimeh","Natalia Ponomareva","Zhe Zhao","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2302.14623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14595v1","updated":"2023-02-28T14:29:22Z","published":"2023-02-28T14:29:22Z","title":"MateRobot: Material Recognition in Wearable Robotics for People with\n  Visual Impairments","summary":"  Wearable robotics can improve the lives of People with Visual Impairments\n(PVI) by providing additional sensory information. Blind people typically\nrecognize objects through haptic perception. However, knowing materials before\ntouching is under-explored in the field of assistive technology. To fill this\ngap, in this work, a wearable robotic system, MateRobot, is established for PVI\nto recognize materials before hand. Specially, the human-centric system can\nperform pixel-wise semantic segmentation of objects and materials. Considering\nboth general object segmentation and material segmentation, an efficient\nMateViT architecture with Learnable Importance Sampling (LIS) and Multi-gate\nMixture-of-Experts (MMoE) is proposed to wearable robots to achieve\ncomplementary gains from different target domains. Our methods achieve\nrespective 40.2% and 51.1% of mIoU on COCOStuff and DMS datasets, surpassing\nprevious method with +5.7% and +7.0% gains. Moreover, on the field test with\nparticipants, our wearable system obtains a score of 28 in NASA-Task Load\nIndex, indicating low cognitive demands and ease of use. Our MateRobot\ndemonstrates the feasibility of recognizing material properties through visual\ncues, and offers a promising step towards improving the functionality of\nwearable robots for PVI. Code will be available at:\nhttps://github.com/JunweiZheng93/MATERobot.\n","authors":["Junwei Zheng","Jiaming Zhang","Kailun Yang","Kunyu Peng","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2302.14595v1.pdf","comment":"Code will be available at: https://github.com/JunweiZheng93/MATERobot"},{"id":"http://arxiv.org/abs/2302.14589v1","updated":"2023-02-28T14:16:32Z","published":"2023-02-28T14:16:32Z","title":"Focus On Details: Online Multi-object Tracking with Diverse Fine-grained\n  Representation","summary":"  Discriminative representation is essential to keep a unique identifier for\neach target in Multiple object tracking (MOT). Some recent MOT methods extract\nfeatures of the bounding box region or the center point as identity embeddings.\nHowever, when targets are occluded, these coarse-grained global representations\nbecome unreliable. To this end, we propose exploring diverse fine-grained\nrepresentation, which describes appearance comprehensively from global and\nlocal perspectives. This fine-grained representation requires high feature\nresolution and precise semantic information. To effectively alleviate the\nsemantic misalignment caused by indiscriminate contextual information\naggregation, Flow Alignment FPN (FAFPN) is proposed for multi-scale feature\nalignment aggregation. It generates semantic flow among feature maps from\ndifferent resolutions to transform their pixel positions. Furthermore, we\npresent a Multi-head Part Mask Generator (MPMG) to extract fine-grained\nrepresentation based on the aligned feature maps. Multiple parallel branches of\nMPMG allow it to focus on different parts of targets to generate local masks\nwithout label supervision. The diverse details in target masks facilitate\nfine-grained representation. Eventually, benefiting from a Shuffle-Group\nSampling (SGS) training strategy with positive and negative samples balanced,\nwe achieve state-of-the-art performance on MOT17 and MOT20 test sets. Even on\nDanceTrack, where the appearance of targets is extremely similar, our method\nsignificantly outperforms ByteTrack by 5.0% on HOTA and 5.6% on IDF1. Extensive\nexperiments have proved that diverse fine-grained representation makes Re-ID\ngreat again in MOT.\n","authors":["Hao Ren","Shoudong Han","Huilin Ding","Ziwen Zhang","Hongwei Wang","Faquan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14581v1","updated":"2023-02-28T14:03:40Z","published":"2023-02-28T14:03:40Z","title":"HopFIR: Hop-wise GraphFormer with Intragroup Joint Refinement for 3D\n  Human Pose Estimation","summary":"  2D-to-3D human pose lifting is fundamental for 3D human pose estimation\n(HPE). Graph Convolutional Network (GCN) has been proven inherently suitable to\nmodel the human skeletal topology. However, current GCN-based 3D HPE methods\nupdate the node features by aggregating their neighbors' information without\nconsidering the interaction of joints in different motion patterns. Although\nsome studies import limb information to learn the movement patterns, the latent\nsynergies among joints, such as maintaining balance in the motion are seldom\ninvestigated. We propose a hop-wise GraphFormer with intragroup joint\nrefinement (HopFIR) to tackle the 3D HPE problem. The HopFIR mainly consists of\na novel Hop-wise GraphFormer(HGF) module and an Intragroup Joint\nRefinement(IJR) module which leverages the prior limb information for\nperipheral joints refinement. The HGF module groups the joints by $k$-hop\nneighbors and utilizes a hop-wise transformer-like attention mechanism among\nthese groups to discover latent joint synergy. Extensive experimental results\nshow that HopFIR outperforms the SOTA methods with a large margin (on the\nHuman3.6M dataset, the mean per joint position error (MPJPE) is 32.67mm).\nFurthermore, it is also demonstrated that previous SOTA GCN-based methods can\nbenefit from the proposed hop-wise attention mechanism efficiently with\nsignificant performance promotion, such as SemGCN and MGCN are improved by 8.9%\nand 4.5%, respectively.\n","authors":["Kai Zhai","Qiang Nie","Bo Ouyang","Xiang Li","ShanLin Yang"],"pdf_url":"https://arxiv.org/pdf/2302.14581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14578v1","updated":"2023-02-28T14:01:01Z","published":"2023-02-28T14:01:01Z","title":"Interactive Segmentation as Gaussian Process Classification","summary":"  Click-based interactive segmentation (IS) aims to extract the target objects\nunder user interaction. For this task, most of the current deep learning\n(DL)-based methods mainly follow the general pipelines of semantic\nsegmentation. Albeit achieving promising performance, they do not fully and\nexplicitly utilize and propagate the click information, inevitably leading to\nunsatisfactory segmentation results, even at clicked points. Against this\nissue, in this paper, we propose to formulate the IS task as a Gaussian process\n(GP)-based pixel-wise binary classification model on each image. To solve this\nmodel, we utilize amortized variational inference to approximate the\nintractable GP posterior in a data-driven manner and then decouple the\napproximated GP posterior into double space forms for efficient sampling with\nlinear complexity. Then, we correspondingly construct a GP classification\nframework, named GPCIS, which is integrated with the deep kernel learning\nmechanism for more flexibility. The main specificities of the proposed GPCIS\nlie in: 1) Under the explicit guidance of the derived GP posterior, the\ninformation contained in clicks can be finely propagated to the entire image\nand then boost the segmentation; 2) The accuracy of predictions at clicks has\ngood theoretical support. These merits of GPCIS as well as its good generality\nand high efficiency are substantiated by comprehensive experiments on several\nbenchmarks, as compared with representative methods both quantitatively and\nqualitatively.\n","authors":["Minghao Zhou","Hong Wang","Qian Zhao","Yuexiang Li","Yawen Huang","Deyu Meng","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.14578v1.pdf","comment":"To appear in CVPR2023"},{"id":"http://arxiv.org/abs/2211.16761v2","updated":"2023-02-28T13:57:43Z","published":"2022-11-30T05:59:23Z","title":"Improving Cross-Modal Retrieval with Set of Diverse Embeddings","summary":"  Cross-modal retrieval across image and text modalities is a challenging task\ndue to its inherent ambiguity: An image often exhibits various situations, and\na caption can be coupled with diverse images. Set-based embedding has been\nstudied as a solution to this problem. It seeks to encode a sample into a set\nof different embedding vectors that capture different semantics of the sample.\nIn this paper, we present a novel set-based embedding method, which is distinct\nfrom previous work in two aspects. First, we present a new similarity function\ncalled smooth-Chamfer similarity, which is designed to alleviate the side\neffects of existing similarity functions for set-based embedding. Second, we\npropose a novel set prediction module to produce a set of embedding vectors\nthat effectively captures diverse semantics of input by the slot attention\nmechanism. Our method is evaluated on the COCO and Flickr30K datasets across\ndifferent visual backbones, where it outperforms existing methods including\nones that demand substantially larger computation at inference.\n","authors":["Dongwon Kim","Namyup Kim","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2211.16761v2.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2302.14574v1","updated":"2023-02-28T13:54:31Z","published":"2023-02-28T13:54:31Z","title":"A Little Bit Attention Is All You Need for Person Re-Identification","summary":"  Person re-identification plays a key role in applications where a mobile\nrobot needs to track its users over a long period of time, even if they are\npartially unobserved for some time, in order to follow them or be available on\ndemand. In this context, deep-learning based real-time feature extraction on a\nmobile robot is often performed on special-purpose devices whose computational\nresources are shared for multiple tasks. Therefore, the inference speed has to\nbe taken into account. In contrast, person re-identification is often improved\nby architectural changes that come at the cost of significantly slowing down\ninference. Attention blocks are one such example. We will show that some\nwell-performing attention blocks used in the state of the art are subject to\ninference costs that are far too high to justify their use for mobile robotic\napplications. As a consequence, we propose an attention block that only\nslightly affects the inference speed while keeping up with much deeper networks\nor more complex attention blocks in terms of re-identification accuracy. We\nperform extensive neural architecture search to derive rules at which locations\nthis attention block should be integrated into the architecture in order to\nachieve the best trade-off between speed and accuracy. Finally, we confirm that\nthe best performing configuration on a re-identification benchmark also\nperforms well on an indoor robotic dataset.\n","authors":["Markus Eisenbach","Jannik Lübberstedt","Dustin Aganian","Horst-Michael Gross"],"pdf_url":"https://arxiv.org/pdf/2302.14574v1.pdf","comment":"IEEE International Conference on Robotics and Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2301.07668v2","updated":"2023-02-28T13:53:42Z","published":"2023-01-18T17:24:01Z","title":"Behind the Scenes: Density Fields for Single View Reconstruction","summary":"  Inferring a meaningful geometric scene representation from a single image is\na fundamental problem in computer vision. Approaches based on traditional depth\nmap prediction can only reason about areas that are visible in the image.\nCurrently, neural radiance fields (NeRFs) can capture true 3D including color\nbut are too complex to be generated from a single image. As an alternative, we\nintroduce a neural network that predicts an implicit density field from a\nsingle image. It maps every location in the frustum of the image to volumetric\ndensity. Our network can be trained through self-supervision from only video\ndata. By not storing color in the implicit volume, but directly sampling color\nfrom the available views during training, our scene representation becomes\nsignificantly less complex compared to NeRFs, and we can train neural networks\nto predict it. Thus, we can apply volume rendering to perform both depth\nprediction and novel view synthesis. In our experiments, we show that our\nmethod is able to predict meaningful geometry for regions that are occluded in\nthe input image. Additionally, we demonstrate the potential of our approach on\nthree datasets for depth prediction and novel-view synthesis.\n","authors":["Felix Wimbauer","Nan Yang","Christian Rupprecht","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2301.07668v2.pdf","comment":"Project Page: https://fwmb.github.io/bts/"},{"id":"http://arxiv.org/abs/2206.04656v5","updated":"2023-02-28T13:48:48Z","published":"2022-06-09T17:55:51Z","title":"Simple Cues Lead to a Strong Multi-Object Tracker","summary":"  For a long time, the most common paradigm in Multi-Object Tracking was\ntracking-by-detection (TbD), where objects are first detected and then\nassociated over video frames. For association, most models resourced to motion\nand appearance cues, e.g., re-identification networks. Recent approaches based\non attention propose to learn the cues in a data-driven manner, showing\nimpressive results. In this paper, we ask ourselves whether simple good old TbD\nmethods are also capable of achieving the performance of end-to-end models. To\nthis end, we propose two key ingredients that allow a standard\nre-identification network to excel at appearance-based tracking. We extensively\nanalyse its failure cases, and show that a combination of our appearance\nfeatures with a simple motion model leads to strong tracking results. Our\ntracker generalizes to four public datasets, namely MOT17, MOT20, BDD100k, and\nDanceTrack, achieving state-of-the-art performance. We will release the code\nand models\n","authors":["Jenny Seidenschwarz","Guillem Brasó","Victor Castro Serrano","Ismail Elezi","Laura Leal-Taixé"],"pdf_url":"https://arxiv.org/pdf/2206.04656v5.pdf","comment":"Accepted to CVPR2023!"},{"id":"http://arxiv.org/abs/2302.14557v1","updated":"2023-02-28T13:26:24Z","published":"2023-02-28T13:26:24Z","title":"GRAN: Ghost Residual Attention Network for Single Image Super Resolution","summary":"  Recently, many works have designed wider and deeper networks to achieve\nhigher image super-resolution performance. Despite their outstanding\nperformance, they still suffer from high computational resources, preventing\nthem from directly applying to embedded devices. To reduce the computation\nresources and maintain performance, we propose a novel Ghost Residual Attention\nNetwork (GRAN) for efficient super-resolution. This paper introduces Ghost\nResidual Attention Block (GRAB) groups to overcome the drawbacks of the\nstandard convolutional operation, i.e., redundancy of the intermediate feature.\nGRAB consists of the Ghost Module and Channel and Spatial Attention Module\n(CSAM) to alleviate the generation of redundant features. Specifically, Ghost\nModule can reveal information underlying intrinsic features by employing linear\noperations to replace the standard convolutions. Reducing redundant features by\nthe Ghost Module, our model decreases memory and computing resource\nrequirements in the network. The CSAM pays more comprehensive attention to\nwhere and what the feature extraction is, which is critical to recovering the\nimage details. Experiments conducted on the benchmark datasets demonstrate the\nsuperior performance of our method in both qualitative and quantitative.\nCompared to the baseline models, we achieve higher performance with lower\ncomputational resources, whose parameters and FLOPs have decreased by more than\nten times.\n","authors":["Axi Niu","Pei Wang","Yu Zhu","Jinqiu Sun","Qingsen Yan","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14554v1","updated":"2023-02-28T13:19:11Z","published":"2023-02-28T13:19:11Z","title":"FPCD: An Open Aerial VHR Dataset for Farm Pond Change Detection","summary":"  Change detection for aerial imagery involves locating and identifying changes\nassociated with the areas of interest between co-registered bi-temporal or\nmulti-temporal images of a geographical location. Farm ponds are man-made\nstructures belonging to the category of minor irrigation structures used to\ncollect surface run-off water for future irrigation purposes. Detection of farm\nponds from aerial imagery and their evolution over time helps in land surveying\nto analyze the agricultural shifts, policy implementation, seasonal effects and\nclimate changes. In this paper, we introduce a publicly available object\ndetection and instance segmentation (OD/IS) dataset for localizing farm ponds\nfrom aerial imagery. We also collected and annotated the bi-temporal data over\na time-span of 14 years across 17 villages, resulting in a binary change\ndetection dataset called \\textbf{F}arm \\textbf{P}ond \\textbf{C}hange\n\\textbf{D}etection Dataset (\\textbf{FPCD}). We have benchmarked and analyzed\nthe performance of various object detection and instance segmentation methods\non our OD/IS dataset and the change detection methods over the FPCD dataset.\nThe datasets are publicly accessible at this page:\n\\textit{\\url{https://huggingface.co/datasets/ctundia/FPCD}}\n","authors":["Chintan Tundia","Rajiv Kumar","Om Damani","G. Sivakumar"],"pdf_url":"https://arxiv.org/pdf/2302.14554v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.06931v4","updated":"2023-02-28T13:09:19Z","published":"2022-01-18T12:49:59Z","title":"Deep Equilibrium Models for Video Snapshot Compressive Imaging","summary":"  The ability of snapshot compressive imaging (SCI) systems to efficiently\ncapture high-dimensional (HD) data has led to an inverse problem, which\nconsists of recovering the HD signal from the compressed and noisy measurement.\nWhile reconstruction algorithms grow fast to solve it with the recent advances\nof deep learning, the fundamental issue of accurate and stable recovery\nremains. To this end, we propose deep equilibrium models (DEQ) for video SCI,\nfusing data-driven regularization and stable convergence in a theoretically\nsound manner. Each equilibrium model implicitly learns a nonexpansive operator\nand analytically computes the fixed point, thus enabling unlimited iterative\nsteps and infinite network depth with only a constant memory requirement in\ntraining and testing. Specifically, we demonstrate how DEQ can be applied to\ntwo existing models for video SCI reconstruction: recurrent neural networks\n(RNN) and Plug-and-Play (PnP) algorithms. On a variety of datasets and real\ndata, both quantitative and qualitative evaluations of our results demonstrate\nthe effectiveness and stability of our proposed method. The code and models are\navailable at: https://github.com/IndigoPurple/DEQSCI .\n","authors":["Yaping Zhao","Siming Zheng","Xin Yuan"],"pdf_url":"https://arxiv.org/pdf/2201.06931v4.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.14533v1","updated":"2023-02-28T12:43:52Z","published":"2023-02-28T12:43:52Z","title":"DEff-GAN: Diverse Attribute Transfer for Few-Shot Image Synthesis","summary":"  Requirements of large amounts of data is a difficulty in training many GANs.\nData efficient GANs involve fitting a generators continuous target distribution\nwith a limited discrete set of data samples, which is a difficult task. Single\nimage methods have focused on modeling the internal distribution of a single\nimage and generating its samples. While single image methods can synthesize\nimage samples with diversity, they do not model multiple images or capture the\ninherent relationship possible between two images. Given only a handful of\nimages, we are interested in generating samples and exploiting the\ncommonalities in the input images. In this work, we extend the single-image GAN\nmethod to model multiple images for sample synthesis. We modify the\ndiscriminator with an auxiliary classifier branch, which helps to generate a\nwide variety of samples and to classify the input labels. Our Data-Efficient\nGAN (DEff-GAN) generates excellent results when similarities and\ncorrespondences can be drawn between the input images or classes.\n","authors":["Rajiv Kumar","G. Sivakumar"],"pdf_url":"https://arxiv.org/pdf/2302.14533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14522v1","updated":"2023-02-28T12:31:31Z","published":"2023-02-28T12:31:31Z","title":"AdaptiveShape: Solving Shape Variability for 3D Object Detection with\n  Geometry Aware Anchor Distributions","summary":"  3D object detection with point clouds and images plays an important role in\nperception tasks such as autonomous driving. Current methods show great\nperformance on detection and pose estimation of standard-shaped vehicles but\nlack behind on more complex shapes as e.g. semi-trailer truck combinations.\nDetermining the shape and motion of those special vehicles accurately is\ncrucial in yard operation and maneuvering and industrial automation\napplications. This work introduces several new methods to improve and measure\nthe performance for such classes. State-of-the-art methods are based on\npredefined anchor grids or heatmaps for ground truth targets. However, the\nunderlying representations do not take the shape of different sized objects\ninto account. Our main contribution, AdaptiveShape, uses shape aware anchor\ndistributions and heatmaps to improve the detection capabilities. For large\nvehicles we achieve +10.9% AP in comparison to current shape agnostic methods.\nFurthermore we introduce a new fast LiDAR-camera fusion. It is based on 2D\nbounding box camera detections which are available in many processing\npipelines. This fusion method does not rely on perfectly calibrated or\ntemporally synchronized systems and is therefore applicable to a broad range of\nrobotic applications. We extend a standard point pillar network to account for\ntemporal data and improve learning of complex object movements. In addition we\nextended a ground truth augmentation to use grouped object pairs to further\nimprove truck AP by +2.2% compared to conventional augmentation.\n","authors":["Benjamin Sick","Michael Walter","Jochen Abhau"],"pdf_url":"https://arxiv.org/pdf/2302.14522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09489v5","updated":"2023-02-28T12:15:46Z","published":"2022-09-20T06:02:57Z","title":"Perceptual Quality Assessment for Digital Human Heads","summary":"  Digital humans are attracting more and more research interest during the last\ndecade, the generation, representation, rendering, and animation of which have\nbeen put into large amounts of effort. However, the quality assessment of\ndigital humans has fallen behind. Therefore, to tackle the challenge of digital\nhuman quality assessment issues, we propose the first large-scale quality\nassessment database for three-dimensional (3D) scanned digital human heads\n(DHHs). The constructed database consists of 55 reference DHHs and 1,540\ndistorted DHHs along with the subjective perceptual ratings. Then, a simple yet\neffective full-reference (FR) projection-based method is proposed to evaluate\nthe visual quality of DHHs. The pretrained Swin Transformer tiny is employed\nfor hierarchical feature extraction and the multi-head attention module is\nutilized for feature fusion. The experimental results reveal that the proposed\nmethod exhibits state-of-the-art performance among the mainstream FR metrics.\nThe database is released at https://github.com/zzc-1998/DHHQA.\n","authors":["Zicheng Zhang","Yingjie Zhou","Wei Sun","Xiongkuo Min","Yuzhe Wu","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2209.09489v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14511v1","updated":"2023-02-28T12:01:16Z","published":"2023-02-28T12:01:16Z","title":"A Unified BEV Model for Joint Learning of 3D Local Features and Overlap\n  Estimation","summary":"  Pairwise point cloud registration is a critical task for many applications,\nwhich heavily depends on finding the right correspondences from the two point\nclouds. However, the low overlap between the input point clouds makes the\nregistration prone to fail, leading to mistaken overlapping and mismatched\ncorrespondences, especially in scenes where non-overlapping regions contain\nsimilar structures. In this paper, we present a unified bird's-eye view (BEV)\nmodel for jointly learning of 3D local features and overlap estimation to\nfulfill the pairwise registration and loop closure. Feature description based\non BEV representation is performed by a sparse UNet-like network, and the 3D\nkeypoints are extracted by a detection head for 2D locations and a regression\nhead for heights, respectively. For overlap detection, a cross-attention module\nis applied for interacting contextual information of the input point clouds,\nfollowed by a classification head to estimate the overlapping region. We\nevaluate our unified model extensively on the KITTI dataset and Apollo-SouthBay\ndataset. The experiments demonstrate that our method significantly outperforms\nexisting methods on overlap prediction, especially in scenes with small\noverlaps. The registration precision also achieves top performance on both\ndatasets in terms of translation and rotation errors. Source codes will be\navailable soon.\n","authors":["Lin Li","Wendong Ding","Yongkun Wen","Yufei Liang","Yong Liu","Guowei Wan"],"pdf_url":"https://arxiv.org/pdf/2302.14511v1.pdf","comment":"8 pages. Accepted by ICRA-2023"},{"id":"http://arxiv.org/abs/2302.14503v1","updated":"2023-02-28T11:34:55Z","published":"2023-02-28T11:34:55Z","title":"Can We Use Diffusion Probabilistic Models for 3D Motion Prediction?","summary":"  After many researchers observed fruitfulness from the recent diffusion\nprobabilistic model, its effectiveness in image generation is actively studied\nthese days. In this paper, our objective is to evaluate the potential of\ndiffusion probabilistic models for 3D human motion-related tasks. To this end,\nthis paper presents a study of employing diffusion probabilistic models to\npredict future 3D human motion(s) from the previously observed motion. Based on\nthe Human 3.6M and HumanEva-I datasets, our results show that diffusion\nprobabilistic models are competitive for both single (deterministic) and\nmultiple (stochastic) 3D motion prediction tasks, after finishing a single\ntraining process. In addition, we find out that diffusion probabilistic models\ncan offer an attractive compromise, since they can strike the right balance\nbetween the likelihood and diversity of the predicted future motions. Our code\nis publicly available on the project website:\nhttps://sites.google.com/view/diffusion-motion-prediction.\n","authors":["Hyemin Ahn","Esteve Valls Mascaro","Dongheui Lee"],"pdf_url":"https://arxiv.org/pdf/2302.14503v1.pdf","comment":"7 pages, 3 figures, ICRA 2023"},{"id":"http://arxiv.org/abs/2112.02500v4","updated":"2023-02-28T11:19:31Z","published":"2021-12-05T07:38:53Z","title":"MovieNet-PS: A Large-Scale Person Search Dataset in the Wild","summary":"  Person search aims to jointly localize and identify a query person from\nnatural, uncropped images, which has been actively studied over the past few\nyears. In this paper, we delve into the rich context information globally and\nlocally surrounding the target person, which we refer to as scene and group\ncontext, respectively. Unlike previous works that treat the two types of\ncontext individually, we exploit them in a unified global-local context network\n(GLCNet) with the intuitive aim of feature enhancement. Specifically, re-ID\nembeddings and context features are simultaneously learned in a multi-stage\nfashion, ultimately leading to enhanced, discriminative features for person\nsearch. We conduct the experiments on two person search benchmarks (i.e.,\nCUHK-SYSU and PRW) as well as extend our approach to a more challenging setting\n(i.e., character search on MovieNet). Extensive experimental results\ndemonstrate the consistent improvement of the proposed GLCNet over the\nstate-of-the-art methods on all three datasets. Our source codes, pre-trained\nmodels, and the new dataset are publicly available at:\nhttps://github.com/ZhengPeng7/GLCNet.\n","authors":["Jie Qin","Peng Zheng","Yichao Yan","Rong Quan","Xiaogang Cheng","Bingbing Ni"],"pdf_url":"https://arxiv.org/pdf/2112.02500v4.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.14490v1","updated":"2023-02-28T11:03:08Z","published":"2023-02-28T11:03:08Z","title":"Estimating Head Motion from MR-Images","summary":"  Head motion is an omnipresent confounder of magnetic resonance image (MRI)\nanalyses as it systematically affects morphometric measurements, even when\nvisual quality control is performed. In order to estimate subtle head motion,\nthat remains undetected by experts, we introduce a deep learning method to\npredict in-scanner head motion directly from T1-weighted (T1w), T2-weighted\n(T2w) and fluid-attenuated inversion recovery (FLAIR) images using motion\nestimates from an in-scanner depth camera as ground truth. Since we work with\ndata from compliant healthy participants of the Rhineland Study, head motion\nand resulting imaging artifacts are less prevalent than in most clinical\ncohorts and more difficult to detect. Our method demonstrates improved\nperformance compared to state-of-the-art motion estimation methods and can\nquantify drift and respiration movement independently. Finally, on unseen data,\nour predictions preserve the known, significant correlation with age.\n","authors":["Clemens Pollak","David Kügler","Martin Reuter"],"pdf_url":"https://arxiv.org/pdf/2302.14490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14487v1","updated":"2023-02-28T11:00:55Z","published":"2023-02-28T11:00:55Z","title":"Enhancing Classification with Hierarchical Scalable Query on Fusion\n  Transformer","summary":"  Real-world vision based applications require fine-grained classification for\nvarious area of interest like e-commerce, mobile applications, warehouse\nmanagement, etc. where reducing the severity of mistakes and improving the\nclassification accuracy is of utmost importance. This paper proposes a method\nto boost fine-grained classification through a hierarchical approach via\nlearnable independent query embeddings. This is achieved through a\nclassification network that uses coarse class predictions to improve the fine\nclass accuracy in a stage-wise sequential manner. We exploit the idea of\nhierarchy to learn query embeddings that are scalable across all levels, thus\nmaking this a relevant approach even for extreme classification where we have a\nlarge number of classes. The query is initialized with a weighted Eigen image\ncalculated from training samples to best represent and capture the variance of\nthe object. We introduce transformer blocks to fuse intermediate layers at\nwhich query attention happens to enhance the spatial representation of feature\nmaps at different scales. This multi-scale fusion helps improve the accuracy of\nsmall-size objects. We propose a two-fold approach for the unique\nrepresentation of learnable queries. First, at each hierarchical level, we\nleverage cluster based loss that ensures maximum separation between inter-class\nquery embeddings and helps learn a better (query) representation in higher\ndimensional spaces. Second, we fuse coarse level queries with finer level\nqueries weighted by a learned scale factor. We additionally introduce a novel\nblock called Cross Attention on Multi-level queries with Prior (CAMP) Block\nthat helps reduce error propagation from coarse level to finer level, which is\na common problem in all hierarchical classifiers. Our method is able to\noutperform the existing methods with an improvement of ~11% at the fine-grained\nclassification.\n","authors":["Sudeep Kumar Sahoo","Sathish Chalasani","Abhishek Joshi","Kiran Nanjunda Iyer"],"pdf_url":"https://arxiv.org/pdf/2302.14487v1.pdf","comment":"6 pages, 7 figures Published in IEEE ICCE 2023"},{"id":"http://arxiv.org/abs/2302.14486v1","updated":"2023-02-28T11:00:13Z","published":"2023-02-28T11:00:13Z","title":"TrainSim: A Railway Simulation Framework for LiDAR and Camera Dataset\n  Generation","summary":"  The railway industry is searching for new ways to automate a number of\ncomplex train functions, such as object detection, track discrimination, and\naccurate train positioning, which require the artificial perception of the\nrailway environment through different types of sensors, including cameras,\nLiDARs, wheel encoders, and inertial measurement units. A promising approach\nfor processing such sensory data is the use of deep learning models, which\nproved to achieve excellent performance in other application domains, as\nrobotics and self-driving cars. However, testing new algorithms and solutions\nrequires the availability of a large amount of labeled data, acquired in\ndifferent scenarios and operating conditions, which are difficult to obtain in\na real railway setting due to strict regulations and practical constraints in\naccessing the trackside infrastructure and equipping a train with the required\nsensors. To address such difficulties, this paper presents a visual simulation\nframework able to generate realistic railway scenarios in a virtual environment\nand automatically produce inertial data and labeled datasets from emulated\nLiDARs and cameras useful for training deep neural networks or testing\ninnovative algorithms. A set of experimental results are reported to show the\neffectiveness of the proposed approach.\n","authors":["Gianluca D'Amico","Mauro Marinoni","Federico Nesti","Giulio Rossolini","Giorgio Buttazzo","Salvatore Sabina","Gianluigi Lauro"],"pdf_url":"https://arxiv.org/pdf/2302.14486v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.14485v1","updated":"2023-02-28T10:58:01Z","published":"2023-02-28T10:58:01Z","title":"Memory-aided Contrastive Consensus Learning for Co-salient Object\n  Detection","summary":"  Co-Salient Object Detection (CoSOD) aims at detecting common salient objects\nwithin a group of relevant source images. Most of the latest works employ the\nattention mechanism for finding common objects. To achieve accurate CoSOD\nresults with high-quality maps and high efficiency, we propose a novel\nMemory-aided Contrastive Consensus Learning (MCCL) framework, which is capable\nof effectively detecting co-salient objects in real time (~110 fps). To learn\nbetter group consensus, we propose the Group Consensus Aggregation Module\n(GCAM) to abstract the common features of each image group; meanwhile, to make\nthe consensus representation more discriminative, we introduce the Memory-based\nContrastive Module (MCM), which saves and updates the consensus of images from\ndifferent groups in a queue of memories. Finally, to improve the quality and\nintegrity of the predicted maps, we develop an Adversarial Integrity Learning\n(AIL) strategy to make the segmented regions more likely composed of complete\nobjects with less surrounding noise. Extensive experiments on all the latest\nCoSOD benchmarks demonstrate that our lite MCCL outperforms 13 cutting-edge\nmodels, achieving the new state of the art (~5.9% and ~6.2% improvement in\nS-measure on CoSOD3k and CoSal2015, respectively). Our source codes, saliency\nmaps, and online demos are publicly available at\nhttps://github.com/ZhengPeng7/MCCL.\n","authors":["Peng Zheng","Jie Qin","Shuo Wang","Tian-Zhu Xiang","Huan Xiong"],"pdf_url":"https://arxiv.org/pdf/2302.14485v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2302.14483v1","updated":"2023-02-28T10:54:36Z","published":"2023-02-28T10:54:36Z","title":"RoPAWS: Robust Semi-supervised Representation Learning from Uncurated\n  Data","summary":"  Semi-supervised learning aims to train a model using limited labels.\nState-of-the-art semi-supervised methods for image classification such as PAWS\nrely on self-supervised representations learned with large-scale unlabeled but\ncurated data. However, PAWS is often less effective when using real-world\nunlabeled data that is uncurated, e.g., contains out-of-class data. We propose\nRoPAWS, a robust extension of PAWS that can work with real-world unlabeled\ndata. We first reinterpret PAWS as a generative classifier that models\ndensities using kernel density estimation. From this probabilistic perspective,\nwe calibrate its prediction based on the densities of labeled and unlabeled\ndata, which leads to a simple closed-form solution from the Bayes' rule. We\ndemonstrate that RoPAWS significantly improves PAWS for uncurated Semi-iNat by\n+5.3% and curated ImageNet by +0.4%.\n","authors":["Sangwoo Mo","Jong-Chyi Su","Chih-Yao Ma","Mido Assran","Ishan Misra","Licheng Yu","Sean Bell"],"pdf_url":"https://arxiv.org/pdf/2302.14483v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2209.07734v2","updated":"2023-02-28T10:44:34Z","published":"2022-09-16T06:15:26Z","title":"CenterLineDet: CenterLine Graph Detection for Road Lanes with\n  Vehicle-mounted Sensors by Transformer for HD Map Generation","summary":"  With the fast development of autonomous driving technologies, there is an\nincreasing demand for high-definition (HD) maps, which provide reliable and\nrobust prior information about the static part of the traffic environments. As\none of the important elements in HD maps, road lane centerline is critical for\ndownstream tasks, such as prediction and planning. Manually annotating\ncenterlines for road lanes in HD maps is labor-intensive, expensive and\ninefficient, severely restricting the wide applications of autonomous driving\nsystems. Previous work seldom explores the lane centerline detection problem\ndue to the complicated topology and severe overlapping issues of lane\ncenterlines. In this paper, we propose a novel method named CenterLineDet to\ndetect lane centerlines for automatic HD map generation. Our CenterLineDet is\ntrained by imitation learning and can effectively detect the graph of\ncenterlines with vehicle-mounted sensors (i.e., six cameras and one LiDAR)\nthrough iterations. Due to the use of the DETR-like transformer network,\nCenterLineDet can handle complicated graph topology, such as lane\nintersections. The proposed approach is evaluated on the large-scale public\ndataset NuScenes. The superiority of our CenterLineDet is demonstrated by the\ncomparative results. Our code, supplementary materials, and video\ndemonstrations are available at\n\\href{https://tonyxuqaq.github.io/projects/CenterLineDet/}{https://tonyxuqaq.github.io/projects/CenterLineDet/}.\n","authors":["Zhenhua Xu","Yuxuan Liu","Yuxiang Sun","Ming Liu","Lujia Wang"],"pdf_url":"https://arxiv.org/pdf/2209.07734v2.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2302.14475v1","updated":"2023-02-28T10:34:44Z","published":"2023-02-28T10:34:44Z","title":"Benchmarking Deepart Detection","summary":"  Deepfake technologies have been blurring the boundaries between the real and\nunreal, likely resulting in malicious events. By leveraging newly emerged\ndeepfake technologies, deepfake researchers have been making a great upending\nto create deepfake artworks (deeparts), which are further closing the gap\nbetween reality and fantasy. To address potentially appeared ethics questions,\nthis paper establishes a deepart detection database (DDDB) that consists of a\nset of high-quality conventional art images (conarts) and five sets of deepart\nimages generated by five state-of-the-art deepfake models. This database\nenables us to explore once-for-all deepart detection and continual deepart\ndetection. For the two new problems, we suggest four benchmark evaluations and\nfour families of solutions on the constructed DDDB. The comprehensive study\ndemonstrates the effectiveness of the proposed solutions on the established\nbenchmark dataset, which is capable of paving a way to more interesting\ndirections of deepart detection. The constructed benchmark dataset and the\nsource code will be made publicly available.\n","authors":["Yabin Wang","Zhiwu Huang","Xiaopeng Hong"],"pdf_url":"https://arxiv.org/pdf/2302.14475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14470v1","updated":"2023-02-28T10:26:02Z","published":"2023-02-28T10:26:02Z","title":"Learning to Estimate Single-View Volumetric Flow Motions without 3D\n  Supervision","summary":"  We address the challenging problem of jointly inferring the 3D flow and\nvolumetric densities moving in a fluid from a monocular input video with a deep\nneural network. Despite the complexity of this task, we show that it is\npossible to train the corresponding networks without requiring any 3D ground\ntruth for training. In the absence of ground truth data we can train our model\nwith observations from real-world capture setups instead of relying on\nsynthetic reconstructions. We make this unsupervised training approach possible\nby first generating an initial prototype volume which is then moved and\ntransported over time without the need for volumetric supervision. Our approach\nrelies purely on image-based losses, an adversarial discriminator network, and\nregularization. Our method can estimate long-term sequences in a stable manner,\nwhile achieving closely matching targets for inputs such as rising smoke\nplumes.\n","authors":["Erik Franz","Barbara Solenthaler","Nils Thuerey"],"pdf_url":"https://arxiv.org/pdf/2302.14470v1.pdf","comment":"ICLR 2023 poster, source code:\n  https://github.com/tum-pbs/Neural-Global-Transport"},{"id":"http://arxiv.org/abs/2302.14460v1","updated":"2023-02-28T10:08:11Z","published":"2023-02-28T10:08:11Z","title":"Interpretable and Intervenable Ultrasonography-based Machine Learning\n  Models for Pediatric Appendicitis","summary":"  Appendicitis is among the most frequent reasons for pediatric abdominal\nsurgeries. With recent advances in machine learning, data-driven decision\nsupport could help clinicians diagnose and manage patients while reducing the\nnumber of non-critical surgeries. Previous decision support systems for\nappendicitis focused on clinical, laboratory, scoring and computed tomography\ndata, mainly ignoring abdominal ultrasound, a noninvasive and readily available\ndiagnostic modality. To this end, we developed and validated interpretable\nmachine learning models for predicting the diagnosis, management and severity\nof suspected appendicitis using ultrasound images. Our models were trained on a\ndataset comprising 579 pediatric patients with 1709 ultrasound images\naccompanied by clinical and laboratory data. Our methodological contribution is\nthe generalization of concept bottleneck models to prediction problems with\nmultiple views and incomplete concept sets. Notably, such models lend\nthemselves to interpretation and interaction via high-level concepts\nunderstandable to clinicians without sacrificing performance or requiring\ntime-consuming image annotation when deployed.\n","authors":["Ričards Marcinkevičs","Patricia Reis Wolfertstetter","Ugne Klimiene","Ece Ozkan","Kieran Chin-Cheong","Alyssia Paschke","Julia Zerres","Markus Denzinger","David Niederberger","Sven Wellmann","Christian Knorr","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2302.14460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14452v1","updated":"2023-02-28T09:56:45Z","published":"2023-02-28T09:56:45Z","title":"An Effective Crop-Paste Pipeline for Few-shot Object Detection","summary":"  Few-shot object detection (FSOD) aims to expand an object detector for novel\ncategories given only a few instances for training. However, detecting novel\ncategories with only a few samples usually leads to the problem of\nmisclassification. In FSOD, we notice the false positive (FP) of novel\ncategories is prominent, in which the base categories are often recognized as\nnovel ones. To address this issue, a novel data augmentation pipeline that\nCrops the Novel instances and Pastes them on the selected Base images, called\nCNPB, is proposed. There are two key questions to be answered: (1) How to\nselect useful base images? and (2) How to combine novel and base data? We\ndesign a multi-step selection strategy to find useful base data. Specifically,\nwe first discover the base images which contain the FP of novel categories and\nselect a certain amount of samples from them for the base and novel categories\nbalance. Then the bad cases, such as the base images that have unlabeled ground\ntruth or easily confused base instances, are removed by using CLIP. Finally,\nthe same category strategy is adopted, in which a novel instance with category\nn is pasted on the base image with the FP of n. During combination, a novel\ninstance is cropped and randomly down-sized, and thus pasted at the assigned\noptimal location from the randomly generated candidates in a selected base\nimage. Our method is simple yet effective and can be easy to plug into existing\nFSOD methods, demonstrating significant potential for use. Extensive\nexperiments on PASCAL VOC and MS COCO validate the effectiveness of our method.\n","authors":["Shaobo Lin","Kun Wang","Xingyu Zeng","Rui Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.14452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.05278v3","updated":"2023-02-28T09:56:20Z","published":"2022-04-11T17:29:36Z","title":"Negligible effect of brain MRI data preprocessing for tumor segmentation","summary":"  Magnetic resonance imaging (MRI) data is heterogeneous due to differences in\ndevice manufacturers, scanning protocols, and inter-subject variability. A\nconventional way to mitigate MR image heterogeneity is to apply preprocessing\ntransformations such as anatomy alignment, voxel resampling, signal intensity\nequalization, image denoising, and localization of regions of interest.\nAlthough a preprocessing pipeline standardizes image appearance, its influence\non the quality of image segmentation and on other downstream tasks in deep\nneural networks has never been rigorously studied.\n  We conduct experiments on three publicly available datasets and evaluate the\neffect of different preprocessing steps in intra- and inter-dataset training\nscenarios. Our results demonstrate that most popular standardization steps add\nno value to the network performance; moreover, preprocessing can hamper model\nperformance. We suggest that image intensity normalization approaches do not\ncontribute to model accuracy because of the reduction of signal variance with\nimage standardization. Finally, we show that the contribution of\nskull-stripping in data preprocessing is almost negligible if measured in terms\nof estimated tumor volume.\n  We show that the only essential transformation for accurate deep learning\nanalysis is the unification of voxel spacing across the dataset. In contrast,\ninter-subjects anatomy alignment in the form of non-rigid atlas registration is\nnot necessary and intensity equalization steps (denoising, bias-field\ncorrection and histogram matching) do not improve models' performance. The\nstudy code is accessible online\n\\footnote{https://github.com/MedImAIR/brain-mri-processing-pipeline}.\n","authors":["Ekaterina Kondrateva","Polina Druzhinina","Alexandra Dalechina","Svetlana Zolotova","Andrey Golanov","Boris Shirokikh","Mikhail Belyaev","Anvar Kurmukov"],"pdf_url":"https://arxiv.org/pdf/2204.05278v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14450v1","updated":"2023-02-28T09:54:53Z","published":"2023-02-28T09:54:53Z","title":"Swin Deformable Attention Hybrid U-Net for Medical Image Segmentation","summary":"  How to harmonize convolution and multi-head self-attention mechanisms has\nrecently emerged as a significant area of research in the field of medical\nimage segmentation. Various combination methods have been proposed. However,\nthere is a common flaw in these works: failed to provide a direct explanation\nfor their hybrid model, which is crucial in clinical scenarios. Deformable\nAttention can improve the segmentation performance and provide an explanation\nbased on the deformation field. Incorporating Deformable Attention into a\nhybrid model could result in a synergistic effect to boost segmentation\nperformance while enhancing the explainability. In this study, we propose the\nincorporation of Swin Deformable Attention with hybrid architecture to improve\nthe segmentation performance while establishing explainability. In the\nexperiment section, our proposed Swin Deformable Attention Hybrid UNet\n(SDAH-UNet) demonstrates state-of-the-art performance on both anatomical and\nlesion segmentation tasks.\n","authors":["Lichao Wang","Jiahao Huang","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2302.14450v1.pdf","comment":"10 pages, 5 figures, conference"},{"id":"http://arxiv.org/abs/2302.14444v1","updated":"2023-02-28T09:42:39Z","published":"2023-02-28T09:42:39Z","title":"Learning to Estimate Two Dense Depths from LiDAR and Event Data","summary":"  Event cameras do not produce images, but rather a continuous flow of events,\nwhich encode changes of illumination for each pixel independently and\nasynchronously. While they output temporally rich information, they lack any\ndepth information which could facilitate their use with other sensors. LiDARs\ncan provide this depth information, but are by nature very sparse, which makes\nthe depth-to-event association more complex. Furthermore, as events represent\nchanges of illumination, they might also represent changes of depth;\nassociating them with a single depth is therefore inadequate. In this work, we\npropose to address these issues by fusing information from an event camera and\na LiDAR using a learning-based approach to estimate accurate dense depth maps.\nTo solve the \"potential change of depth\" problem, we propose here to estimate\ntwo depth maps at each step: one \"before\" the events happen, and one \"after\"\nthe events happen. We further propose to use this pair of depths to compute a\ndepth difference for each event, to give them more context. We train and\nevaluate our network, ALED, on both synthetic and real driving sequences, and\nshow that it is able to predict dense depths with an error reduction of up to\n61% compared to the current state of the art. We also demonstrate the quality\nof our 2-depths-to-event association, and the usefulness of the depth\ndifference information. Finally, we release SLED, a novel synthetic dataset\ncomprising events, LiDAR point clouds, RGB images, and dense depth maps.\n","authors":["Vincent Brebion","Julien Moreau","Franck Davoine"],"pdf_url":"https://arxiv.org/pdf/2302.14444v1.pdf","comment":"Accepted for SCIA 2023. For the project page, see\n  https://vbrebion.github.io/ALED/"},{"id":"http://arxiv.org/abs/2104.12623v2","updated":"2023-02-28T09:37:59Z","published":"2021-04-26T14:50:59Z","title":"Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against\n  Image Translation Models","summary":"  Machine learning models are typically made available to potential client\nusers via inference APIs. Model extraction attacks occur when a malicious\nclient uses information gleaned from queries to the inference API of a victim\nmodel $F_V$ to build a surrogate model $F_A$ with comparable functionality.\nRecent research has shown successful model extraction of image classification,\nand natural language processing models. In this paper, we show the first model\nextraction attack against real-world generative adversarial network (GAN) image\ntranslation models. We present a framework for conducting such attacks, and\nshow that an adversary can successfully extract functional surrogate models by\nquerying $F_V$ using data from the same domain as the training data for $F_V$.\nThe adversary need not know $F_V$'s architecture or any other information about\nit beyond its intended task. We evaluate the effectiveness of our attacks using\nthree different instances of two popular categories of image translation: (1)\nSelfie-to-Anime and (2) Monet-to-Photo (image style transfer), and (3)\nSuper-Resolution (super resolution). Using standard performance metrics for\nGANs, we show that our attacks are effective. Furthermore, we conducted a large\nscale (125 participants) user study on Selfie-to-Anime and Monet-to-Photo to\nshow that human perception of the images produced by $F_V$ and $F_A$ can be\nconsidered equivalent, within an equivalence bound of Cohen's d = 0.3. Finally,\nwe show that existing defenses against model extraction attacks (watermarking,\nadversarial examples, poisoning) do not extend to image translation models.\n","authors":["Sebastian Szyller","Vasisht Duddu","Tommi Gröndahl","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2104.12623v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2302.14435v1","updated":"2023-02-28T09:25:37Z","published":"2023-02-28T09:25:37Z","title":"ProxyFormer: Proxy Alignment Assisted Point Cloud Completion with\n  Missing Part Sensitive Transformer","summary":"  Problems such as equipment defects or limited viewpoints will lead the\ncaptured point clouds to be incomplete. Therefore, recovering the complete\npoint clouds from the partial ones plays an vital role in many practical tasks,\nand one of the keys lies in the prediction of the missing part. In this paper,\nwe propose a novel point cloud completion approach namely ProxyFormer that\ndivides point clouds into existing (input) and missing (to be predicted) parts\nand each part communicates information through its proxies. Specifically, we\nfuse information into point proxy via feature and position extractor, and\ngenerate features for missing point proxies from the features of existing point\nproxies. Then, in order to better perceive the position of missing points, we\ndesign a missing part sensitive transformer, which converts random normal\ndistribution into reasonable position information, and uses proxy alignment to\nrefine the missing proxies. It makes the predicted point proxies more sensitive\nto the features and positions of the missing part, and thus make these proxies\nmore suitable for subsequent coarse-to-fine processes. Experimental results\nshow that our method outperforms state-of-the-art completion networks on\nseveral benchmark datasets and has the fastest inference speed. Code is\navailable at https://github.com/I2-Multimedia-Lab/ProxyFormer.\n","authors":["Shanshan Li","Pan Gao","Xiaoyang Tan","Mingqiang Wei"],"pdf_url":"https://arxiv.org/pdf/2302.14435v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2302.14434v1","updated":"2023-02-28T09:24:36Z","published":"2023-02-28T09:24:36Z","title":"A Hierarchical Representation Network for Accurate and Detailed Face\n  Reconstruction from In-The-Wild Images","summary":"  Limited by the nature of the low-dimensional representational capacity of\n3DMM, most of the 3DMM-based face reconstruction (FR) methods fail to recover\nhigh-frequency facial details, such as wrinkles, dimples, etc. Some attempt to\nsolve the problem by introducing detail maps or non-linear operations, however,\nthe results are still not vivid. To this end, we in this paper present a novel\nhierarchical representation network (HRN) to achieve accurate and detailed face\nreconstruction from a single image. Specifically, we implement the geometry\ndisentanglement and introduce the hierarchical representation to fulfill\ndetailed face modeling. Meanwhile, 3D priors of facial details are incorporated\nto enhance the accuracy and authenticity of the reconstruction results. We also\npropose a de-retouching module to achieve better decoupling of the geometry and\nappearance. It is noteworthy that our framework can be extended to a multi-view\nfashion by considering detail consistency of different views. Extensive\nexperiments on two single-view and two multi-view FR benchmarks demonstrate\nthat our method outperforms the existing methods in both reconstruction\naccuracy and visual effects. Finally, we introduce a high-quality 3D face\ndataset FaceHD-100 to boost the research of high-fidelity face reconstruction.\n","authors":["Biwen Lei","Jianqiang Ren","Mengyang Feng","Miaomiao Cui","Xuansong Xie"],"pdf_url":"https://arxiv.org/pdf/2302.14434v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2302.14431v1","updated":"2023-02-28T09:21:12Z","published":"2023-02-28T09:21:12Z","title":"Efficient Masked Autoencoders with Self-Consistency","summary":"  Inspired by masked language modeling (MLM) in natural language processing,\nmasked image modeling (MIM) has been recognized as a strong and popular\nself-supervised pre-training method in computer vision. However, its high\nrandom mask ratio would result in two serious problems: 1) the data are not\nefficiently exploited, which brings inefficient pre-training (\\eg, 1600 epochs\nfor MAE $vs.$ 300 epochs for the supervised), and 2) the high uncertainty and\ninconsistency of the pre-trained model, \\ie, the prediction of the same patch\nmay be inconsistent under different mask rounds. To tackle these problems, we\npropose efficient masked autoencoders with self-consistency (EMAE), to improve\nthe pre-training efficiency and increase the consistency of MIM. In particular,\nwe progressively divide the image into K non-overlapping parts, each of which\nis generated by a random mask and has the same mask ratio. Then the MIM task is\nconducted parallelly on all parts in an iteration and generates predictions.\nBesides, we design a self-consistency module to further maintain the\nconsistency of predictions of overlapping masked patches among parts. Overall,\nthe proposed method is able to exploit the data more efficiently and obtains\nreliable representations. Experiments on ImageNet show that EMAE achieves even\nhigher results with only 300 pre-training epochs under ViT-Base than MAE (1600\nepochs). EMAE also consistently obtains state-of-the-art transfer performance\non various downstream tasks, like object detection, and semantic segmentation.\n","authors":["Zhaowen Li","Yousong Zhu","Zhiyang Chen","Wei Li","Chaoyang Zhao","Liwei Wu","Rui Zhao","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14430v1","updated":"2023-02-28T09:18:48Z","published":"2023-02-28T09:18:48Z","title":"Tracking Fast by Learning Slow: An Event-based Speed Adaptive Hand\n  Tracker Leveraging Knowledge in RGB Domain","summary":"  3D hand tracking methods based on monocular RGB videos are easily affected by\nmotion blur, while event camera, a sensor with high temporal resolution and\ndynamic range, is naturally suitable for this task with sparse output and low\npower consumption. However, obtaining 3D annotations of fast-moving hands is\ndifficult for constructing event-based hand-tracking datasets. In this paper,\nwe provided an event-based speed adaptive hand tracker (ESAHT) to solve the\nhand tracking problem based on event camera. We enabled a CNN model trained on\na hand tracking dataset with slow motion, which enabled the model to leverage\nthe knowledge of RGB-based hand tracking solutions, to work on fast hand\ntracking tasks. To realize our solution, we constructed the first 3D hand\ntracking dataset captured by an event camera in a real-world environment,\nfigured out two data augment methods to narrow the domain gap between slow and\nfast motion data, developed a speed adaptive event stream segmentation method\nto handle hand movements in different moving speeds, and introduced a new\nevent-to-frame representation method adaptive to event streams with different\nlengths. Experiments showed that our solution outperformed RGB-based as well as\nprevious event-based solutions in fast hand tracking tasks, and our codes and\ndataset will be publicly available.\n","authors":["Chuanlin Lan","Ziyuan Yin","Arindam Basu","Rosa H. M. Chan"],"pdf_url":"https://arxiv.org/pdf/2302.14430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08377v2","updated":"2023-02-28T09:00:33Z","published":"2022-12-16T10:05:31Z","title":"PointAvatar: Deformable Point-based Head Avatars from Videos","summary":"  The ability to create realistic, animatable and relightable head avatars from\ncasual video sequences would open up wide ranging applications in communication\nand entertainment. Current methods either build on explicit 3D morphable meshes\n(3DMM) or exploit neural implicit representations. The former are limited by\nfixed topology, while the latter are non-trivial to deform and inefficient to\nrender. Furthermore, existing approaches entangle lighting in the color\nestimation, thus they are limited in re-rendering the avatar in new\nenvironments. In contrast, we propose PointAvatar, a deformable point-based\nrepresentation that disentangles the source color into intrinsic albedo and\nnormal-dependent shading. We demonstrate that PointAvatar bridges the gap\nbetween existing mesh- and implicit representations, combining high-quality\ngeometry and appearance with topological flexibility, ease of deformation and\nrendering efficiency. We show that our method is able to generate animatable 3D\navatars using monocular videos from multiple sources including hand-held\nsmartphones, laptop webcams and internet videos, achieving state-of-the-art\nquality in challenging cases where previous methods fail, e.g., thin hair\nstrands, while being significantly more efficient in training than competing\nmethods.\n","authors":["Yufeng Zheng","Wang Yifan","Gordon Wetzstein","Michael J. Black","Otmar Hilliges"],"pdf_url":"https://arxiv.org/pdf/2212.08377v2.pdf","comment":"Project page: https://zhengyuf.github.io/PointAvatar/ Code base:\n  https://github.com/zhengyuf/pointavatar"},{"id":"http://arxiv.org/abs/2211.15166v2","updated":"2023-02-28T08:57:52Z","published":"2022-11-28T09:21:47Z","title":"Toward Global Sensing Quality Maximization: A Configuration Optimization\n  Scheme for Camera Networks","summary":"  The performance of a camera network monitoring a set of targets depends\ncrucially on the configuration of the cameras. In this paper, we investigate\nthe reconfiguration strategy for the parameterized camera network model, with\nwhich the sensing qualities of the multiple targets can be optimized globally\nand simultaneously. We first propose to use the number of pixels occupied by a\nunit-length object in image as a metric of the sensing quality of the object,\nwhich is determined by the parameters of the camera, such as intrinsic,\nextrinsic, and distortional coefficients. Then, we form a single quantity that\nmeasures the sensing quality of the targets by the camera network. This\nquantity further serves as the objective function of our optimization problem\nto obtain the optimal camera configuration. We verify the effectiveness of our\napproach through extensive simulations and experiments, and the results reveal\nits improved performance on the AprilTag detection tasks. Codes and related\nutilities for this work are open-sourced and available at\nhttps://github.com/sszxc/MultiCam-Simulation.\n","authors":["Xuechao Zhang","Xuda Ding","Yi Ren","Yu Zheng","Chongrong Fang","Jianping He"],"pdf_url":"https://arxiv.org/pdf/2211.15166v2.pdf","comment":"The 2022 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2022)"},{"id":"http://arxiv.org/abs/2302.14418v1","updated":"2023-02-28T08:50:17Z","published":"2023-02-28T08:50:17Z","title":"PCR-CG: Point Cloud Registration via Deep Color and Geometry","summary":"  In this paper, we introduce PCR-CG: a novel 3D point cloud registration\nmodule explicitly embedding the color signals into the geometry representation.\nDifferent from previous methods that only use geometry representation, our\nmodule is specifically designed to effectively correlate color into geometry\nfor the point cloud registration task. Our key contribution is a 2D-3D\ncross-modality learning algorithm that embeds the deep features learned from\ncolor signals to the geometry representation. With our designed 2D-3D\nprojection module, the pixel features in a square region centered at\ncorrespondences perceived from images are effectively correlated with point\nclouds. In this way, the overlapped regions can be inferred not only from point\ncloud but also from the texture appearances. Adding color is non-trivial. We\ncompare against a variety of baselines designed for adding color to 3D, such as\nexhaustively adding per-pixel features or RGB values in an implicit manner. We\nleverage Predator [25] as the baseline method and incorporate our proposed\nmodule onto it. To validate the effectiveness of 2D features, we ablate\ndifferent 2D pre-trained networks and show a positive correlation between the\npre-trained weights and the task performance. Our experimental results indicate\na significant improvement of 6.5% registration recall over the baseline method\non the 3DLoMatch benchmark. We additionally evaluate our approach on SOTA\nmethods and observe consistent improvements, such as an improvement of 2.4%\nregistration recall over GeoTransformer as well as 3.5% over CoFiNet. Our study\nreveals a significant advantages of correlating explicit deep color features to\nthe point cloud in the registration task.\n","authors":["Yu Zhang","Junle Yu","Xiaolin Huang","Wenhui Zhou","Ji Hou"],"pdf_url":"https://arxiv.org/pdf/2302.14418v1.pdf","comment":"accepted to ECCV2022; code at https://github.com/Gardlin/PCR-CG"},{"id":"http://arxiv.org/abs/2302.14416v1","updated":"2023-02-28T08:48:45Z","published":"2023-02-28T08:48:45Z","title":"DREAM: Efficient Dataset Distillation by Representative Matching","summary":"  Dataset distillation aims to generate small datasets with little information\nloss as large-scale datasets for reducing storage and training costs. Recent\nstate-of-the-art methods mainly constrain the sample generation process by\nmatching synthetic images and the original ones regarding gradients, embedding\ndistributions, or training trajectories. Although there are various matching\nobjectives, currently the method for selecting original images is limited to\nnaive random sampling. We argue that random sampling inevitably involves\nsamples near the decision boundaries, which may provide large or noisy matching\ntargets. Besides, random sampling cannot guarantee the evenness and diversity\nof the sample distribution. These factors together lead to large optimization\noscillations and degrade the matching efficiency. Accordingly, we propose a\nnovel matching strategy named as \\textbf{D}ataset distillation by\n\\textbf{RE}present\\textbf{A}tive \\textbf{M}atching (DREAM), where only\nrepresentative original images are selected for matching. DREAM is able to be\neasily plugged into popular dataset distillation frameworks and reduce the\nmatching iterations by 10 times without performance drop. Given sufficient\ntraining time, DREAM further provides significant improvements and achieves\nstate-of-the-art performances.\n","authors":["Yanqing Liu","Jianyang Gu","Kai Wang","Zheng Zhu","Wei Jiang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2302.14416v1.pdf","comment":"Efficient matching for dataset distillation"},{"id":"http://arxiv.org/abs/2302.14415v1","updated":"2023-02-28T08:47:53Z","published":"2023-02-28T08:47:53Z","title":"Mesh-SORT: Simple and effective of location-wise tracker","summary":"  Multi-object tracking (MOT) raised much attention in recent years because of\nits wide prospect on traffic and person. We found that in most tracking\nscenarios without camera motion, objects move and lost with a certain location\nspecificity. In this paper simple and effective location-wise method is\nproposed for tracking by detection scheme, the experiment shows its potential\nand improvement on the baseline.\n","authors":["ZongTan Li"],"pdf_url":"https://arxiv.org/pdf/2302.14415v1.pdf","comment":"10 pages 16 figs"},{"id":"http://arxiv.org/abs/2302.14409v1","updated":"2023-02-28T08:44:00Z","published":"2023-02-28T08:44:00Z","title":"An Adaptive Method for Camera Attribution under Complex Radial\n  Distortion Corrections","summary":"  Radial correction distortion, applied by in-camera or out-camera\nsoftware/firmware alters the supporting grid of the image so as to hamper\nPRNU-based camera attribution. Existing solutions to deal with this problem try\nto invert/estimate the correction using radial transformations parameterized\nwith few variables in order to restrain the computational load; however, with\never more prevalent complex distortion corrections their performance is\nunsatisfactory. In this paper we propose an adaptive algorithm that by dividing\nthe image into concentric annuli is able to deal with sophisticated corrections\nlike those applied out-camera by third party software like Adobe Lightroom,\nPhotoshop, Gimp and PT-Lens. We also introduce a statistic called cumulative\npeak of correlation energy (CPCE) that allows for an efficient early stopping\nstrategy. Experiments on a large dataset of in-camera and out-camera radially\ncorrected images show that our solution improves the state of the art in terms\nof both accuracy and computational cost.\n","authors":["Andrea Montibeller","Fernando Pérez-González"],"pdf_url":"https://arxiv.org/pdf/2302.14409v1.pdf","comment":"This paper was submitted to IEEE Transactions on Information\n  Forensics & Security the July 28, 2022"},{"id":"http://arxiv.org/abs/2302.14402v1","updated":"2023-02-28T08:35:50Z","published":"2023-02-28T08:35:50Z","title":"Neural Video Compression with Diverse Contexts","summary":"  For any video codecs, the coding efficiency highly relies on whether the\ncurrent signal to be encoded can find the relevant contexts from the previous\nreconstructed signals. Traditional codec has verified more contexts bring\nsubstantial coding gain, but in a time-consuming manner. However, for the\nemerging neural video codec (NVC), its contexts are still limited, leading to\nlow compression ratio. To boost NVC, this paper proposes increasing the context\ndiversity in both temporal and spatial dimensions. First, we guide the model to\nlearn hierarchical quality patterns across frames, which enriches long-term and\nyet high-quality temporal contexts. Furthermore, to tap the potential of\noptical flow-based coding framework, we introduce a group-based offset\ndiversity where the cross-group interaction is proposed for better context\nmining. In addition, this paper also adopts a quadtree-based partition to\nincrease spatial context diversity when encoding the latent representation in\nparallel. Experiments show that our codec obtains 23.5% bitrate saving over\nprevious SOTA NVC. Better yet, our codec has surpassed the under-developing\nnext generation traditional codec/ECM in both RGB and YUV420 colorspaces, in\nterms of PSNR. The codes are at https://github.com/microsoft/DCVC.\n","authors":["Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2302.14402v1.pdf","comment":"Accepted by CVPR 2023. Codes are at https://github.com/microsoft/DCVC"},{"id":"http://arxiv.org/abs/2302.14390v1","updated":"2023-02-28T08:17:50Z","published":"2023-02-28T08:17:50Z","title":"Your time series is worth a binary image: machine vision assisted deep\n  framework for time series forecasting","summary":"  Time series forecasting (TSF) has been a challenging research area, and\nvarious models have been developed to address this task. However, almost all\nthese models are trained with numerical time series data, which is not as\neffectively processed by the neural system as visual information. To address\nthis challenge, this paper proposes a novel machine vision assisted deep time\nseries analysis (MV-DTSA) framework. The MV-DTSA framework operates by\nanalyzing time series data in a novel binary machine vision time series metric\nspace, which includes a mapping and an inverse mapping function from the\nnumerical time series space to the binary machine vision space, and a deep\nmachine vision model designed to address the TSF task in the binary space. A\ncomprehensive computational analysis demonstrates that the proposed MV-DTSA\nframework outperforms state-of-the-art deep TSF models, without requiring\nsophisticated data decomposition or model customization. The code for our\nframework is accessible at https://github.com/IkeYang/\nmachine-vision-assisted-deep-time-series-analysis-MV-DTSA-.\n","authors":["Luoxiao Yang","Xinqi Fan","Zijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14383v1","updated":"2023-02-28T08:11:56Z","published":"2023-02-28T08:11:56Z","title":"Linear Spaces of Meanings: the Compositional Language of VLMs","summary":"  We investigate compositional structures in vector data embeddings from\npre-trained vision-language models (VLMs). Traditionally, compositionality has\nbeen associated with algebraic operations on embeddings of words from a\npre-existing vocabulary. In contrast, we seek to approximate label\nrepresentations from a text encoder as combinations of a smaller set of vectors\nin the embedding space. These vectors can be seen as \"ideal words\" which can be\nused to generate new concepts in an efficient way. We present a theoretical\nframework for understanding linear compositionality, drawing connections with\nmathematical representation theory and previous definitions of disentanglement.\nWe provide theoretical and empirical evidence that ideal words provide good\ncompositional approximations of composite concepts and can be more effective\nthan token-based decompositions of the same concepts.\n","authors":["Matthew Trager","Pramuditha Perera","Luca Zancato","Alessandro Achille","Parminder Bhatia","Bing Xiang","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2302.14383v1.pdf","comment":"24 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2301.08915v3","updated":"2023-02-28T07:54:36Z","published":"2023-01-21T08:30:15Z","title":"Improving Deep Regression with Ordinal Entropy","summary":"  In computer vision, it is often observed that formulating regression problems\nas a classification task often yields better performance. We investigate this\ncurious phenomenon and provide a derivation to show that classification, with\nthe cross-entropy loss, outperforms regression with a mean squared error loss\nin its ability to learn high-entropy feature representations. Based on the\nanalysis, we propose an ordinal entropy loss to encourage higher-entropy\nfeature spaces while maintaining ordinal relationships to improve the\nperformance of regression tasks. Experiments on synthetic and real-world\nregression tasks demonstrate the importance and benefits of increasing entropy\nfor regression.\n","authors":["Shihao Zhang","Linlin Yang","Michael Bi Mi","Xiaoxu Zheng","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2301.08915v3.pdf","comment":"Accepted to ICLR 2023. Project page:\n  https://github.com/needylove/OrdinalEntropy"},{"id":"http://arxiv.org/abs/2302.14368v1","updated":"2023-02-28T07:43:00Z","published":"2023-02-28T07:43:00Z","title":"Towards Enhanced Controllability of Diffusion Models","summary":"  Denoising Diffusion models have shown remarkable capabilities in generating\nrealistic, high-quality and diverse images. However, the extent of\ncontrollability and editability with diffusion models is underexplored relative\nto GANs. Inspired by techniques based on the latent space of GAN models for\nimage manipulation, we propose to train a diffusion model conditioned on two\nlatent codes, a spatial content mask and a flattened style embedding. We rely\non the inductive bias of the progressive denoising process of diffusion models\nto encode pose/layout information in the spatial structure mask and\nsemantic/style information in the style code. We extend the sampling technique\nfrom composable diffusion models to allow for some dependence between\nconditional inputs. This improves the quality of the generations significantly\nwhile also providing control over the amount of guidance from each latent code\nseparately as well as from their joint distribution. To further enhance\ncontrollability, we vary the level of guidance for structure and style latents\nbased on the denoising timestep. We observe more controllability compared to\nexisting methods and show that without explicit training objectives, diffusion\nmodels can be leveraged for effective image manipulation, reference based image\ntranslation and style transfer.\n","authors":["Wonwoong Cho","Hareesh Ravi","Midhun Harikumar","Vinh Khuc","Krishna Kumar Singh","Jingwan Lu","David I. Inouye","Ajinkya Kale"],"pdf_url":"https://arxiv.org/pdf/2302.14368v1.pdf","comment":"28 pages, 26 figures"},{"id":"http://arxiv.org/abs/2302.14365v1","updated":"2023-02-28T07:37:53Z","published":"2023-02-28T07:37:53Z","title":"RemoteTouch: Enhancing Immersive 3D Video Communication with Hand Touch","summary":"  Recent research advance has significantly improved the visual realism of\nimmersive 3D video communication. In this work we present a method to further\nenhance this immersive experience by adding the hand touch capability (\"remote\nhand clapping\"). In our system, each meeting participant sits in front of a\nlarge screen with haptic feedback. The local participant can reach his hand out\nto the screen and perform hand clapping with the remote participant as if the\ntwo participants were only separated by a virtual glass. A key challenge in\nemulating the remote hand touch is the realistic rendering of the participant's\nhand and arm as the hand touches the screen. When the hand is very close to the\nscreen, the RGBD data required for realistic rendering is no longer available.\nTo tackle this challenge, we present a dual representation of the user's hand.\nOur dual representation not only preserves the high-quality rendering usually\nfound in recent image-based rendering systems but also allows the hand to reach\nthe screen. This is possible because the dual representation includes both an\nimage-based model and a 3D geometry-based model, with the latter driven by a\nhand skeleton tracked by a side view camera. In addition, the dual\nrepresentation provides a distance-based fusion of the image-based and 3D\ngeometry-based models as the hand moves closer to the screen. The result is\nthat the image-based and 3D geometry-based models mutually enhance each other,\nleading to realistic and seamless rendering. Our experiments demonstrate that\nour method provides consistent hand contact experience between remote users and\nimproves the immersive experience of 3D video communication.\n","authors":["Yizhong Zhang","Zhiqi Li","Sicheng Xu","Chong Li","Jiaolong Yang","Xin Tong","Baining Guo"],"pdf_url":"https://arxiv.org/pdf/2302.14365v1.pdf","comment":"IEEE VR 2023"},{"id":"http://arxiv.org/abs/2302.14363v1","updated":"2023-02-28T07:31:48Z","published":"2023-02-28T07:31:48Z","title":"Efficient Implicit Neural Reconstruction Using LiDAR","summary":"  Modeling scene geometry using implicit neural representation has revealed its\nadvantages in accuracy, flexibility, and low memory usage. Previous approaches\nhave demonstrated impressive results using color or depth images but still have\ndifficulty handling poor light conditions and large-scale scenes. Methods\ntaking global point cloud as input require accurate registration and ground\ntruth coordinate labels, which limits their application scenarios. In this\npaper, we propose a new method that uses sparse LiDAR point clouds and rough\nodometry to reconstruct fine-grained implicit occupancy field efficiently\nwithin a few minutes. We introduce a new loss function that supervises directly\nin 3D space without 2D rendering, avoiding information loss. We also manage to\nrefine poses of input frames in an end-to-end manner, creating consistent\ngeometry without global point cloud registration. As far as we know, our method\nis the first to reconstruct implicit scene representation from LiDAR-only\ninput. Experiments on synthetic and real-world datasets, including indoor and\noutdoor scenes, prove that our method is effective, efficient, and accurate,\nobtaining comparable results with existing methods using dense input.\n","authors":["Dongyu Yan","Xiaoyang Lyu","Jieqi Shi","Yi Lin"],"pdf_url":"https://arxiv.org/pdf/2302.14363v1.pdf","comment":"6+2 pages, 8 figures, Accepted for publication at IEEE International\n  Conference on Robotics and Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2302.14362v1","updated":"2023-02-28T07:30:36Z","published":"2023-02-28T07:30:36Z","title":"One-Shot Video Inpainting","summary":"  Recently, removing objects from videos and filling in the erased regions\nusing deep video inpainting (VI) algorithms has attracted considerable\nattention. Usually, a video sequence and object segmentation masks for all\nframes are required as the input for this task. However, in real-world\napplications, providing segmentation masks for all frames is quite difficult\nand inefficient. Therefore, we deal with VI in a one-shot manner, which only\ntakes the initial frame's object mask as its input. Although we can achieve\nthat using naive combinations of video object segmentation (VOS) and VI\nmethods, they are sub-optimal and generally cause critical errors. To address\nthat, we propose a unified pipeline for one-shot video inpainting (OSVI). By\njointly learning mask prediction and video completion in an end-to-end manner,\nthe results can be optimal for the entire task instead of each separate module.\nAdditionally, unlike the two stage methods that use the predicted masks as\nground truth cues, our method is more reliable because the predicted masks can\nbe used as the network's internal guidance. On the synthesized datasets for\nOSVI, our proposed method outperforms all others both quantitatively and\nqualitatively.\n","authors":["Sangjin Lee","Suhwan Cho","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2302.14362v1.pdf","comment":"AAAI2023 submitted"},{"id":"http://arxiv.org/abs/2210.00939v4","updated":"2023-02-28T07:22:39Z","published":"2022-10-03T13:50:58Z","title":"Improving Sample Quality of Diffusion Models Using Self-Attention\n  Guidance","summary":"  Denoising diffusion models (DDMs) have attracted attention due to their\nexceptional sample quality and diversity. This success is largely attributed to\nthe use of class- or text-conditional diffusion guidance methods. In this\npaper, we propose a more comprehensive approach that expands beyond traditional\nguidance methods. By adopting this generalized perspective, we introduce two\nnovel condition-free strategies to enhance the quality of generated images:\nblur guidance and advanced Self-Attention Guidance (SAG). Employing benign\nproperties of Gaussian blur, blur guidance enhances the suitability of\nintermediate samples for fine-scale information and generates higher quality\nsamples with a moderate guidance scale. Improving upon this, SAG utilizes\nintermediate self-attention maps to enhance the stability and efficacy.\nSpecifically, SAG leverages intermediate attention maps of diffusion models at\neach iteration to capture essential information for the generative process and\nguide it accordingly. Our experimental results demonstrate that our zero-shot\nmethod enhances the performance of various diffusion models, including ADM,\nIDDPM, and Stable Diffusion. Furthermore, combining SAG with conventional\nguidance methods, such as classifier-free guidance, results in further\nimprovement.\n","authors":["Susung Hong","Gyuseong Lee","Wooseok Jang","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2210.00939v4.pdf","comment":"Project page: https://ku-cvlab.github.io/Self-Attention-Guidance"},{"id":"http://arxiv.org/abs/2302.14354v1","updated":"2023-02-28T07:14:15Z","published":"2023-02-28T07:14:15Z","title":"Deep Learning for Identifying Iran's Cultural Heritage Buildings in Need\n  of Conservation Using Image Classification and Grad-CAM","summary":"  The cultural heritage buildings (CHB), which are part of mankind's history\nand identity, are in constant danger of damage or in extreme situations total\ndestruction. That being said, it's of utmost importance to preserve them by\nidentifying the existent, or presumptive, defects using novel methods so that\nrenovation processes can be done in a timely manner and with higher accuracy.\nThe main goal of this research is to use new deep learning (DL) methods in the\nprocess of preserving CHBs (situated in Iran); a goal that has been neglected\nespecially in developing countries such as Iran, as these countries still\npreserve their CHBs using manual, and even archaic, methods that need direct\nhuman supervision. Having proven their effectiveness and performance when it\ncomes to processing images, the convolutional neural networks (CNN) are a\nstaple in computer vision (CV) literacy and this paper is not exempt. When\nlacking enough CHB images, training a CNN from scratch would be very difficult\nand prone to overfitting; that's why we opted to use a technique called\ntransfer learning (TL) in which we used pre-trained ResNet, MobileNet, and\nInception networks, for classification. Even more, the Grad-CAM was utilized to\nlocalize the defects to some extent. The final results were very favorable\nbased on those of similar research. The final proposed model can pave the way\nfor moving from manual to unmanned CHB conservation, hence an increase in\naccuracy and a decrease in human-induced errors.\n","authors":["Mahdi Bahrami","Amir Albadvi"],"pdf_url":"https://arxiv.org/pdf/2302.14354v1.pdf","comment":"16 pages, 4745 words, 11 figures, and 5 tables"},{"id":"http://arxiv.org/abs/2107.02450v3","updated":"2023-02-28T06:59:49Z","published":"2021-07-06T07:58:07Z","title":"End-To-End Data-Dependent Routing in Multi-Path Neural Networks","summary":"  Neural networks are known to give better performance with increased depth due\nto their ability to learn more abstract features. Although the deepening of\nnetworks has been well established, there is still room for efficient feature\nextraction within a layer which would reduce the need for mere parameter\nincrement. The conventional widening of networks by having more filters in each\nlayer introduces a quadratic increment of parameters. Having multiple parallel\nconvolutional/dense operations in each layer solves this problem, but without\nany context-dependent allocation of resources among these operations: the\nparallel computations tend to learn similar features making the widening\nprocess less effective. Therefore, we propose the use of multi-path neural\nnetworks with data-dependent resource allocation among parallel computations\nwithin layers, which also lets an input to be routed end-to-end through these\nparallel paths. To do this, we first introduce a cross-prediction based\nalgorithm between parallel tensors of subsequent layers. Second, we further\nreduce the routing overhead by introducing feature-dependent cross-connections\nbetween parallel tensors of successive layers. Our multi-path networks show\nsuperior performance to existing widening and adaptive feature extraction, and\neven ensembles, and deeper networks at similar complexity in the image\nrecognition task.\n","authors":["Dumindu Tissera","Rukshan Wijessinghe","Kasun Vithanage","Alex Xavier","Subha Fernando","Ranga Rodrigo"],"pdf_url":"https://arxiv.org/pdf/2107.02450v3.pdf","comment":"Neural Computing and Applications 2023"},{"id":"http://arxiv.org/abs/2302.14350v1","updated":"2023-02-28T06:59:05Z","published":"2023-02-28T06:59:05Z","title":"Knowledge Augmented Relation Inference for Group Activity Recognition","summary":"  Most existing group activity recognition methods construct spatial-temporal\nrelations merely based on visual representation. Some methods introduce extra\nknowledge, such as action labels, to build semantic relations and use them to\nrefine the visual presentation. However, the knowledge they explored just stay\nat the semantic-level, which is insufficient for pursing notable accuracy. In\nthis paper, we propose to exploit knowledge concretization for the group\nactivity recognition, and develop a novel Knowledge Augmented Relation\nInference framework that can effectively use the concretized knowledge to\nimprove the individual representations. Specifically, the framework consists of\na Visual Representation Module to extract individual appearance features, a\nKnowledge Augmented Semantic Relation Module explore semantic representations\nof individual actions, and a Knowledge-Semantic-Visual Interaction Module aims\nto integrate visual and semantic information by the knowledge. Benefiting from\nthese modules, the proposed framework can utilize knowledge to enhance the\nrelation inference process and the individual representations, thus improving\nthe performance of group activity recognition. Experimental results on two\npublic datasets show that the proposed framework achieves competitive\nperformance compared with state-of-the-art methods.\n","authors":["Xianglong Lang","Zhuming Wang","Zun Li","Meng Tian","Ge Shi","Lifang Wu"],"pdf_url":"https://arxiv.org/pdf/2302.14350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14348v1","updated":"2023-02-28T06:38:25Z","published":"2023-02-28T06:38:25Z","title":"Im2Hands: Learning Attentive Implicit Representation of Interacting\n  Two-Hand Shapes","summary":"  We present Implicit Two Hands (Im2Hands), the first neural implicit\nrepresentation of two interacting hands. Unlike existing methods on two-hand\nreconstruction that rely on a parametric hand model and/or low-resolution\nmeshes, Im2Hands can produce fine-grained geometry of two hands with high\nhand-to-hand and hand-to-image coherency. To handle the shape complexity and\ninteraction context between two hands, Im2Hands models the occupancy volume of\ntwo hands - conditioned on an RGB image and coarse 3D keypoints - by two novel\nattention-based modules responsible for (1) initial occupancy estimation and\n(2) context-aware occupancy refinement, respectively. Im2Hands first learns\nper-hand neural articulated occupancy in the canonical space designed for each\nhand using query-image attention. It then refines the initial two-hand\noccupancy in the posed space to enhance the coherency between the two hand\nshapes using query-anchor attention. In addition, we introduce an optional\nkeypoint refinement module to enable robust two-hand shape estimation from\npredicted hand keypoints in a single-image reconstruction scenario. We\nexperimentally demonstrate the effectiveness of Im2Hands on two-hand\nreconstruction in comparison to related methods, where ours achieves\nstate-of-the-art results. Our code is publicly available at\nhttps://github.com/jyunlee/Im2Hands.\n","authors":["Jihyun Lee","Minhyuk Sung","Honggyu Choi","Tae-Kyun Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14348v1.pdf","comment":"6 figures, 14 pages, accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2302.03985v5","updated":"2023-02-28T06:31:09Z","published":"2023-02-08T10:50:01Z","title":"Cross-Layer Retrospective Retrieving via Layer Attention","summary":"  More and more evidence has shown that strengthening layer interactions can\nenhance the representation power of a deep neural network, while self-attention\nexcels at learning interdependencies by retrieving query-activated information.\nMotivated by this, we devise a cross-layer attention mechanism, called\nmulti-head recurrent layer attention (MRLA), that sends a query representation\nof the current layer to all previous layers to retrieve query-related\ninformation from different levels of receptive fields. A light-weighted version\nof MRLA is also proposed to reduce the quadratic computation cost. The proposed\nlayer attention mechanism can enrich the representation power of many\nstate-of-the-art vision networks, including CNNs and vision transformers. Its\neffectiveness has been extensively evaluated in image classification, object\ndetection and instance segmentation tasks, where improvements can be\nconsistently observed. For example, our MRLA can improve 1.6% Top-1 accuracy on\nResNet-50, while only introducing 0.16M parameters and 0.07B FLOPs.\nSurprisingly, it can boost the performances by a large margin of 3-4% box AP\nand mask AP in dense prediction tasks. Our code is available at\nhttps://github.com/joyfang1106/MRLA.\n","authors":["Yanwen Fang","Yuxi Cai","Jintai Chen","Jingyu Zhao","Guangjian Tian","Guodong Li"],"pdf_url":"https://arxiv.org/pdf/2302.03985v5.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14340v1","updated":"2023-02-28T06:20:07Z","published":"2023-02-28T06:20:07Z","title":"HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of\n  Indoor Scenes with Iterative Intertwined Regularization","summary":"  Recovery of an underlying scene geometry from multiview images stands as a\nlong-time challenge in computer vision research. The recent promise leverages\nneural implicit surface learning and differentiable volume rendering, and\nachieves both the recovery of scene geometry and synthesis of novel views,\nwhere deep priors of neural models are used as an inductive smoothness bias.\nWhile promising for object-level surfaces, these methods suffer when coping\nwith complex scene surfaces. In the meanwhile, traditional multi-view stereo\ncan recover the geometry of scenes with rich textures, by globally optimizing\nthe local, pixel-wise correspondences across multiple views. We are thus\nmotivated to make use of the complementary benefits from the two strategies,\nand propose a method termed Helix-shaped neural implicit Surface learning or\nHelixSurf; HelixSurf uses the intermediate prediction from one strategy as the\nguidance to regularize the learning of the other one, and conducts such\nintertwined regularization iteratively during the learning process. We also\npropose an efficient scheme for differentiable volume rendering in HelixSurf.\nExperiments on surface reconstruction of indoor scenes show that our method\ncompares favorably with existing methods and is orders of magnitude faster,\neven when some of existing methods are assisted with auxiliary training data.\nThe source code is available at https://github.com/Gorilla-Lab-SCUT/HelixSurf.\n","authors":["Zhihao Liang","Zhangjin Huang","Changxing Ding","Kui Jia"],"pdf_url":"https://arxiv.org/pdf/2302.14340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08270v2","updated":"2023-02-28T06:17:36Z","published":"2022-08-17T13:02:17Z","title":"On the Privacy Effect of Data Enhancement via the Lens of Memorization","summary":"  Machine learning poses severe privacy concerns as it has been shown that the\nlearned models can reveal sensitive information about their training data. Many\nworks have investigated the effect of widely-adopted data augmentation (DA) and\nadversarial training (AT) techniques, termed data enhancement in the paper, on\nthe privacy leakage of machine learning models. Such privacy effects are often\nmeasured by membership inference attacks (MIAs), which aim to identify whether\na particular example belongs to the training set or not. We propose to\ninvestigate privacy from a new perspective called memorization. Through the\nlens of memorization, we find that previously deployed MIAs produce misleading\nresults as they are less likely to identify samples with higher privacy risks\nas members compared to samples with low privacy risks. To solve this problem,\nwe deploy a recent attack that can capture individual samples' memorization\ndegrees for evaluation. Through extensive experiments, we unveil non-trivial\nfindings about the connections between three essential properties of machine\nlearning models, including privacy, generalization gap, and adversarial\nrobustness. We demonstrate that, unlike existing results, the generalization\ngap is shown not highly correlated with privacy leakage. Moreover, stronger\nadversarial robustness does not necessarily imply that the model is more\nsusceptible to privacy attacks.\n","authors":["Xiao Li","Qiongxiu Li","Zhanhao Hu","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2208.08270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14338v1","updated":"2023-02-28T06:06:12Z","published":"2023-02-28T06:06:12Z","title":"Turning a CLIP Model into a Scene Text Detector","summary":"  The recent large-scale Contrastive Language-Image Pretraining (CLIP) model\nhas shown great potential in various downstream tasks via leveraging the\npretrained vision and language knowledge. Scene text, which contains rich\ntextual and visual information, has an inherent connection with a model like\nCLIP. Recently, pretraining approaches based on vision language models have\nmade effective progresses in the field of text detection. In contrast to these\nworks, this paper proposes a new method, termed TCM, focusing on Turning the\nCLIP Model directly for text detection without pretraining process. We\ndemonstrate the advantages of the proposed TCM as follows: (1) The underlying\nprinciple of our framework can be applied to improve existing scene text\ndetector. (2) It facilitates the few-shot training capability of existing\nmethods, e.g., by using 10% of labeled data, we significantly improve the\nperformance of the baseline method with an average of 22% in terms of the\nF-measure on 4 benchmarks. (3) By turning the CLIP model into existing scene\ntext detection methods, we further achieve promising domain adaptation ability.\nThe code will be publicly released.\n","authors":["Wenwen Yu","Yuliang Liu","Wei Hua","Deqiang Jiang","Bo Ren","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2302.14338v1.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2302.14337v1","updated":"2023-02-28T06:05:43Z","published":"2023-02-28T06:05:43Z","title":"UniFLG: Unified Facial Landmark Generator from Text or Speech","summary":"  Talking face generation has been extensively investigated owing to its wide\napplicability. The two primary frameworks used for talking face generation\ncomprise a text-driven framework, which generates synchronized speech and\ntalking faces from text, and a speech-driven framework, which generates talking\nfaces from speech. To integrate these frameworks, this paper proposes a unified\nfacial landmark generator (UniFLG). The proposed system exploits end-to-end\ntext-to-speech not only for synthesizing speech but also for extracting a\nseries of latent representations that are common to text and speech, and feeds\nit to a landmark decoder to generate facial landmarks. We demonstrate that our\nsystem achieves higher naturalness in both speech synthesis and facial landmark\ngeneration compared to the state-of-the-art text-driven method. We further\ndemonstrate that our system can generate facial landmarks from speech of\nspeakers without facial video data or even speech data.\n","authors":["Kentaro Mitsui","Yukiya Hono","Kei Sawada"],"pdf_url":"https://arxiv.org/pdf/2302.14337v1.pdf","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.14335v1","updated":"2023-02-28T06:03:42Z","published":"2023-02-28T06:03:42Z","title":"DC-Former: Diverse and Compact Transformer for Person Re-Identification","summary":"  In person re-identification (re-ID) task, it is still challenging to learn\ndiscriminative representation by deep learning, due to limited data. Generally\nspeaking, the model will get better performance when increasing the amount of\ndata. The addition of similar classes strengthens the ability of the classifier\nto identify similar identities, thereby improving the discrimination of\nrepresentation. In this paper, we propose a Diverse and Compact Transformer\n(DC-Former) that can achieve a similar effect by splitting embedding space into\nmultiple diverse and compact subspaces. Compact embedding subspace helps model\nlearn more robust and discriminative embedding to identify similar classes. And\nthe fusion of these diverse embeddings containing more fine-grained information\ncan further improve the effect of re-ID. Specifically, multiple class tokens\nare used in vision transformer to represent multiple embedding spaces. Then, a\nself-diverse constraint (SDC) is applied to these spaces to push them away from\neach other, which makes each embedding space diverse and compact. Further, a\ndynamic weight controller(DWC) is further designed for balancing the relative\nimportance among them during training. The experimental results of our method\nare promising, which surpass previous state-of-the-art methods on several\ncommonly used person re-ID benchmarks.\n","authors":["Wen Li","Cheng Zou","Meng Wang","Furong Xu","Jianan Zhao","Ruobing Zheng","Yuan Cheng","Wei Chu"],"pdf_url":"https://arxiv.org/pdf/2302.14335v1.pdf","comment":"Accepted by AAAI23"},{"id":"http://arxiv.org/abs/2302.14332v1","updated":"2023-02-28T05:55:42Z","published":"2023-02-28T05:55:42Z","title":"Markerless Camera-to-Robot Pose Estimation via Self-supervised\n  Sim-to-Real Transfer","summary":"  Solving the camera-to-robot pose is a fundamental requirement for\nvision-based robot control, and is a process that takes considerable effort and\ncares to make accurate. Traditional approaches require modification of the\nrobot via markers, and subsequent deep learning approaches enabled markerless\nfeature extraction. Mainstream deep learning methods only use synthetic data\nand rely on Domain Randomization to fill the sim-to-real gap, because acquiring\nthe 3D annotation is labor-intensive. In this work, we go beyond the limitation\nof 3D annotations for real-world data. We propose an end-to-end pose estimation\nframework that is capable of online camera-to-robot calibration and a\nself-supervised training method to scale the training to unlabeled real-world\ndata. Our framework combines deep learning and geometric vision for solving the\nrobot pose, and the pipeline is fully differentiable. To train the\nCamera-to-Robot Pose Estimation Network (CtRNet), we leverage foreground\nsegmentation and differentiable rendering for image-level self-supervision. The\npose prediction is visualized through a renderer and the image loss with the\ninput image is back-propagated to train the neural network. Our experimental\nresults on two public real datasets confirm the effectiveness of our approach\nover existing works. We also integrate our framework into a visual servoing\nsystem to demonstrate the promise of real-time precise robot pose estimation\nfor automation tasks.\n","authors":["Jingpei Lu","Florian Richter","Michael C. Yip"],"pdf_url":"https://arxiv.org/pdf/2302.14332v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.14325v1","updated":"2023-02-28T05:37:45Z","published":"2023-02-28T05:37:45Z","title":"BEVPlace: Learning LiDAR-based Place Recognition using Bird's Eye View\n  Images","summary":"  Place recognition is a key module for long-term SLAM systems. Current\nLiDAR-based place recognition methods are usually based on representations of\npoint clouds such as unordered points or range images. These methods achieve\nhigh recall rates of retrieval, but their performance may degrade in the case\nof view variation or scene changes. In this work, we explore the potential of a\ndifferent representation in place recognition, i.e. bird's eye view (BEV)\nimages. We observe that the structural contents of BEV images are less\ninfluenced by rotations and translations of point clouds. We validate that,\nwithout any delicate design, a simple VGGNet trained on BEV images achieves\ncomparable performance with the state-of-the-art place recognition methods in\nscenes of slight viewpoint changes. For more robust place recognition, we\ndesign a rotation-invariant network called BEVPlace. We use group convolution\nto extract rotation-equivariant local features from the images and NetVLAD for\nglobal feature aggregation. In addition, we observe that the distance between\nBEV features is correlated with the geometry distance of point clouds. Based on\nthe observation, we develop a method to estimate the position of the query\ncloud, extending the usage of place recognition. The experiments conducted on\nlarge-scale public datasets show that our method 1) achieves state-of-the-art\nperformance in terms of recall rates, 2) is robust to view changes, 3) shows\nstrong generalization ability, and 4) can estimate the positions of query point\nclouds. Source code will be made publicly available at\nhttps://github.com/zjuluolun/BEVPlace.\n","authors":["Lun Luo","Shuhang Zheng","Yixuan Li","Yongzhi Fan","Beinan Yu","Siyuan Cao","Huiliang Shen"],"pdf_url":"https://arxiv.org/pdf/2302.14325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14323v1","updated":"2023-02-28T05:37:04Z","published":"2023-02-28T05:37:04Z","title":"Read Pointer Meters in complex environments based on a Human-like\n  Alignment and Recognition Algorithm","summary":"  Recently, developing an automatic reading system for analog measuring\ninstruments has gained increased attention, as it enables the collection of\nnumerous state of equipment. Nonetheless, two major obstacles still obstruct\nits deployment to real-world applications. The first issue is that they rarely\ntake the entire pipeline's speed into account. The second is that they are\nincapable of dealing with some low-quality images (i.e., meter breakage, blur,\nand uneven scale). In this paper, we propose a human-like alignment and\nrecognition algorithm to overcome these problems. More specifically, a Spatial\nTransformed Module(STM) is proposed to obtain the front view of images in a\nself-autonomous way based on an improved Spatial Transformer Networks(STN).\nMeanwhile, a Value Acquisition Module(VAM) is proposed to infer accurate meter\nvalues by an end-to-end trained framework. In contrast to previous research,\nour model aligns and recognizes meters totally implemented by learnable\nprocessing, which mimics human's behaviours and thus achieves higher\nperformances. Extensive results verify the good robustness of the proposed\nmodel in terms of the accuracy and efficiency.\n","authors":["Yan Shu","Shaohui Liu","Honglei Xu","Feng Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.14323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06052v3","updated":"2023-02-28T05:23:51Z","published":"2023-01-15T09:34:42Z","title":"T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete\n  Representations","summary":"  In this work, we investigate a simple and must-known conditional generative\nframework based on Vector Quantised-Variational AutoEncoder (VQ-VAE) and\nGenerative Pre-trained Transformer (GPT) for human motion generation from\ntextural descriptions. We show that a simple CNN-based VQ-VAE with commonly\nused training recipes (EMA and Code Reset) allows us to obtain high-quality\ndiscrete representations. For GPT, we incorporate a simple corruption strategy\nduring the training to alleviate training-testing discrepancy. Despite its\nsimplicity, our T2M-GPT shows better performance than competitive approaches,\nincluding recent diffusion-based approaches. For example, on HumanML3D, which\nis currently the largest dataset, we achieve comparable performance on the\nconsistency between text and generated motion (R-Precision), but with FID 0.116\nlargely outperforming MotionDiffuse of 0.630. Additionally, we conduct analyses\non HumanML3D and observe that the dataset size is a limitation of our approach.\nOur work suggests that VQ-VAE still remains a competitive approach for human\nmotion generation.\n","authors":["Jianrong Zhang","Yangsong Zhang","Xiaodong Cun","Shaoli Huang","Yong Zhang","Hongwei Zhao","Hongtao Lu","Xi Shen"],"pdf_url":"https://arxiv.org/pdf/2301.06052v3.pdf","comment":"Accepted to CVPR 2023. Project page:\n  https://mael-zys.github.io/T2M-GPT/"},{"id":"http://arxiv.org/abs/2209.08772v2","updated":"2023-02-28T05:22:09Z","published":"2022-09-19T05:54:26Z","title":"TANDEM3D: Active Tactile Exploration for 3D Object Recognition","summary":"  Tactile recognition of 3D objects remains a challenging task. Compared to 2D\nshapes, the complex geometry of 3D surfaces requires richer tactile signals,\nmore dexterous actions, and more advanced encoding techniques. In this work, we\npropose TANDEM3D, a method that applies a co-training framework for exploration\nand decision making to 3D object recognition with tactile signals. Starting\nwith our previous work, which introduced a co-training paradigm for 2D\nrecognition problems, we introduce a number of advances that enable us to scale\nup to 3D. TANDEM3D is based on a novel encoder that builds 3D object\nrepresentation from contact positions and normals using PointNet++.\nFurthermore, by enabling 6DOF movement, TANDEM3D explores and collects\ndiscriminative touch information with high efficiency. Our method is trained\nentirely in simulation and validated with real-world experiments. Compared to\nstate-of-the-art baselines, TANDEM3D achieves higher accuracy and a lower\nnumber of actions in recognizing 3D objects and is also shown to be more robust\nto different types and amounts of sensor noise. Video is available at\nhttps://jxu.ai/tandem3d.\n","authors":["Jingxi Xu","Han Lin","Shuran Song","Matei Ciocarlie"],"pdf_url":"https://arxiv.org/pdf/2209.08772v2.pdf","comment":"7 pages. Accepted to International Conference on Robotics and\n  Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2205.10706v2","updated":"2023-02-28T05:17:43Z","published":"2022-05-22T02:00:09Z","title":"GL-RG: Global-Local Representation Granularity for Video Captioning","summary":"  Video captioning is a challenging task as it needs to accurately transform\nvisual understanding into natural language description. To date,\nstate-of-the-art methods inadequately model global-local representation across\nvideo frames for caption generation, leaving plenty of room for improvement. In\nthis work, we approach the video captioning task from a new perspective and\npropose a GL-RG framework for video captioning, namely a\n\\textbf{G}lobal-\\textbf{L}ocal \\textbf{R}epresentation \\textbf{G}ranularity.\nOur GL-RG demonstrates three advantages over the prior efforts: 1) we\nexplicitly exploit extensive visual representations from different video ranges\nto improve linguistic expression; 2) we devise a novel global-local encoder to\nproduce rich semantic vocabulary to obtain a descriptive granularity of video\ncontents across frames; 3) we develop an incremental training strategy which\norganizes model learning in an incremental fashion to incur an optimal\ncaptioning behavior. Experimental results on the challenging MSR-VTT and MSVD\ndatasets show that our DL-RG outperforms recent state-of-the-art methods by a\nsignificant margin. Code is available at \\url{https://github.com/ylqi/GL-RG}.\n","authors":["Liqi Yan","Qifan Wang","Yiming Cui","Fuli Feng","Xiaojun Quan","Xiangyu Zhang","Dongfang Liu"],"pdf_url":"https://arxiv.org/pdf/2205.10706v2.pdf","comment":"Accepted to IJCAI 2022"},{"id":"http://arxiv.org/abs/2302.14309v1","updated":"2023-02-28T04:59:23Z","published":"2023-02-28T04:59:23Z","title":"Temporal Coherent Test-Time Optimization for Robust Video Classification","summary":"  Deep neural networks are likely to fail when the test data is corrupted in\nreal-world deployment (e.g., blur, weather, etc.). Test-time optimization is an\neffective way that adapts models to generalize to corrupted data during\ntesting, which has been shown in the image domain. However, the techniques for\nimproving video classification corruption robustness remain few. In this work,\nwe propose a Temporal Coherent Test-time Optimization framework (TeCo) to\nutilize spatio-temporal information in test-time optimization for robust video\nclassification. To exploit information in video with self-supervised learning,\nTeCo uses global content from video clips and optimizes models for entropy\nminimization. TeCo minimizes the entropy of the prediction based on the global\ncontent from video clips. Meanwhile, it also feeds local content to regularize\nthe temporal coherence at the feature level. TeCo retains the generalization\nability of various video classification models and achieves significant\nimprovements in corruption robustness across Mini Kinetics-C and Mini SSV2-C.\nFurthermore, TeCo sets a new baseline in video classification corruption\nrobustness via test-time optimization.\n","authors":["Chenyu Yi","Siyuan Yang","Yufei Wang","Haoliang Li","Yap-Peng Tan","Alex C. Kot"],"pdf_url":"https://arxiv.org/pdf/2302.14309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12102v4","updated":"2023-02-28T04:56:21Z","published":"2020-12-07T18:16:59Z","title":"Using Persistent Homology Topological Features to Characterize Medical\n  Images: Case Studies on Lung and Brain Cancers","summary":"  Tumor shape is a key factor that affects tumor growth and metastasis. This\npaper proposes a topological feature computed by persistent homology to\ncharacterize tumor progression from digital pathology and radiology images and\nexamines its effect on the time-to-event data. The proposed topological\nfeatures are invariant to scale-preserving transformation and can summarize\nvarious tumor shape patterns. The topological features are represented in\nfunctional space and used as functional predictors in a functional Cox\nproportional hazards model. The proposed model enables interpretable inference\nabout the association between topological shape features and survival risks.\nTwo case studies are conducted using consecutive 133 lung cancer and 77 brain\ntumor patients. The results of both studies show that the topological features\npredict survival prognosis after adjusting clinical variables, and the\npredicted high-risk groups have worse survival outcomes than the low-risk\ngroups. Also, the topological shape features found to be positively associated\nwith survival hazards are irregular and heterogeneous shape patterns, which are\nknown to be related to tumor progression.\n","authors":["Chul Moon","Qiwei Li","Guanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2012.12102v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14307v1","updated":"2023-02-28T04:45:31Z","published":"2023-02-28T04:45:31Z","title":"GradMA: A Gradient-Memory-based Accelerated Federated Learning with\n  Alleviated Catastrophic Forgetting","summary":"  Federated Learning (FL) has emerged as a de facto machine learning area and\nreceived rapid increasing research interests from the community. However,\ncatastrophic forgetting caused by data heterogeneity and partial participation\nposes distinctive challenges for FL, which are detrimental to the performance.\nTo tackle the problems, we propose a new FL approach (namely GradMA), which\ntakes inspiration from continual learning to simultaneously correct the\nserver-side and worker-side update directions as well as take full advantage of\nserver's rich computing and memory resources. Furthermore, we elaborate a\nmemory reduction strategy to enable GradMA to accommodate FL with a large scale\nof workers. We then analyze convergence of GradMA theoretically under the\nsmooth non-convex setting and show that its convergence rate achieves a linear\nspeed up w.r.t the increasing number of sampled active workers. At last, our\nextensive experiments on various image classification tasks show that GradMA\nachieves significant performance gains in accuracy and communication efficiency\ncompared to SOTA baselines.\n","authors":["Kangyang Luo","Xiang Li","Yunshi Lan","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2302.14307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14306v1","updated":"2023-02-28T04:38:52Z","published":"2023-02-28T04:38:52Z","title":"CLR-GAM: Contrastive Point Cloud Learning with Guided Augmentation and\n  Feature Mapping","summary":"  Point cloud data plays an essential role in robotics and self-driving\napplications. Yet, annotating point cloud data is time-consuming and nontrivial\nwhile they enable learning discriminative 3D representations that empower\ndownstream tasks, such as classification and segmentation. Recently,\ncontrastive learning-based frameworks have shown promising results for learning\n3D representations in a self-supervised manner. However, existing contrastive\nlearning methods cannot precisely encode and associate structural features and\nsearch the higher dimensional augmentation space efficiently. In this paper, we\npresent CLR-GAM, a novel contrastive learning-based framework with Guided\nAugmentation (GA) for efficient dynamic exploration strategy and Guided Feature\nMapping (GFM) for similar structural feature association between augmented\npoint clouds. We empirically demonstrate that the proposed approach achieves\nstate-of-the-art performance on both simulated and real-world 3D point cloud\ndatasets for three different downstream tasks, i.e., 3D point cloud\nclassification, few-shot learning, and object part segmentation.\n","authors":["Srikanth Malla","Yi-Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2302.14306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14302v1","updated":"2023-02-28T04:31:09Z","published":"2023-02-28T04:31:09Z","title":"Improving Model Generalization by On-manifold Adversarial Augmentation\n  in the Frequency Domain","summary":"  Deep neural networks (DNNs) may suffer from significantly degenerated\nperformance when the training and test data are of different underlying\ndistributions. Despite the importance of model generalization to\nout-of-distribution (OOD) data, the accuracy of state-of-the-art (SOTA) models\non OOD data can plummet. Recent work has demonstrated that regular or\noff-manifold adversarial examples, as a special case of data augmentation, can\nbe used to improve OOD generalization. Inspired by this, we theoretically prove\nthat on-manifold adversarial examples can better benefit OOD generalization.\nNevertheless, it is nontrivial to generate on-manifold adversarial examples\nbecause the real manifold is generally complex. To address this issue, we\nproposed a novel method of Augmenting data with Adversarial examples via a\nWavelet module (AdvWavAug), an on-manifold adversarial data augmentation\ntechnique that is simple to implement. In particular, we project a benign image\ninto a wavelet domain. With the assistance of the sparsity characteristic of\nwavelet transformation, we can modify an image on the estimated data manifold.\nWe conduct adversarial augmentation based on AdvProp training framework.\nExtensive experiments on different models and different datasets, including\nImageNet and its distorted versions, demonstrate that our method can improve\nmodel generalization, especially on OOD data. By integrating AdvWavAug into the\ntraining process, we have achieved SOTA results on some recent\ntransformer-based models.\n","authors":["Chang Liu","Wenzhao Xiang","Yuan He","Hui Xue","Shibao Zheng","Hang Su"],"pdf_url":"https://arxiv.org/pdf/2302.14302v1.pdf","comment":"International Journal of Computer Vision (IJCV) [under review]"},{"id":"http://arxiv.org/abs/2302.07116v3","updated":"2023-02-28T04:28:12Z","published":"2023-02-14T15:21:53Z","title":"Team DETR: Guide Queries as a Professional Team in Detection\n  Transformers","summary":"  Recent proposed DETR variants have made tremendous progress in various\nscenarios due to their streamlined processes and remarkable performance.\nHowever, the learned queries usually explore the global context to generate the\nfinal set prediction, resulting in redundant burdens and unfaithful results.\nMore specifically, a query is commonly responsible for objects of different\nscales and positions, which is a challenge for the query itself, and will cause\nspatial resource competition among queries. To alleviate this issue, we propose\nTeam DETR, which leverages query collaboration and position constraints to\nembrace objects of interest more precisely. We also dynamically cater to each\nquery member's prediction preference, offering the query better scale and\nspatial priors. In addition, the proposed Team DETR is flexible enough to be\nadapted to other existing DETR variants without increasing parameters and\ncalculations. Extensive experiments on the COCO dataset show that Team DETR\nachieves remarkable gains, especially for small and large objects. Code is\navailable at \\url{https://github.com/horrible-dong/TeamDETR}.\n","authors":["Tian Qiu","Linyun Zhou","Wenxiang Xu","Lechao Cheng","Zunlei Feng","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2302.07116v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14301v1","updated":"2023-02-28T04:26:20Z","published":"2023-02-28T04:26:20Z","title":"A Comprehensive Study on Robustness of Image Classification Models:\n  Benchmarking and Rethinking","summary":"  The robustness of deep neural networks is usually lacking under adversarial\nexamples, common corruptions, and distribution shifts, which becomes an\nimportant research problem in the development of deep learning. Although new\ndeep learning methods and robustness improvement techniques have been\nconstantly proposed, the robustness evaluations of existing methods are often\ninadequate due to their rapid development, diverse noise patterns, and simple\nevaluation metrics. Without thorough robustness evaluations, it is hard to\nunderstand the advances in the field and identify the effective methods. In\nthis paper, we establish a comprehensive robustness benchmark called\n\\textbf{ARES-Bench} on the image classification task. In our benchmark, we\nevaluate the robustness of 55 typical deep learning models on ImageNet with\ndiverse architectures (e.g., CNNs, Transformers) and learning algorithms (e.g.,\nnormal supervised training, pre-training, adversarial training) under numerous\nadversarial attacks and out-of-distribution (OOD) datasets. Using robustness\ncurves as the major evaluation criteria, we conduct large-scale experiments and\ndraw several important findings, including: 1) there is an inherent trade-off\nbetween adversarial and natural robustness for the same model architecture; 2)\nadversarial training effectively improves adversarial robustness, especially\nwhen performed on Transformer architectures; 3) pre-training significantly\nimproves natural robustness based on more training data or self-supervised\nlearning. Based on ARES-Bench, we further analyze the training tricks in\nlarge-scale adversarial training on ImageNet. By designing the training\nsettings accordingly, we achieve the new state-of-the-art adversarial\nrobustness. We have made the benchmarking results and code platform publicly\navailable.\n","authors":["Chang Liu","Yinpeng Dong","Wenzhao Xiang","Xiao Yang","Hang Su","Jun Zhu","Yuefeng Chen","Yuan He","Hui Xue","Shibao Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.14301v1.pdf","comment":"International Journal of Computer Vision (IJCV) [under review]"},{"id":"http://arxiv.org/abs/2206.04797v4","updated":"2023-02-28T04:18:22Z","published":"2022-06-06T21:56:11Z","title":"Memory-efficient model-based deep learning with convergence and\n  robustness guarantees","summary":"  Computational imaging has been revolutionized by compressed sensing\nalgorithms, which offer guaranteed uniqueness, convergence, and stability\nproperties. Model-based deep learning methods that combine imaging physics with\nlearned regularization priors have emerged as more powerful alternatives for\nimage recovery. The main focus of this paper is to introduce a memory efficient\nmodel-based algorithm with similar theoretical guarantees as CS methods. The\nproposed iterative algorithm alternates between a gradient descent involving\nthe score function and a conjugate gradient algorithm to encourage data\nconsistency. The score function is modeled as a monotone convolutional neural\nnetwork. Our analysis shows that the monotone constraint is necessary and\nsufficient to enforce the uniqueness of the fixed point in arbitrary inverse\nproblems. In addition, it also guarantees the convergence to a fixed point,\nwhich is robust to input perturbations. We introduce two implementations of the\nproposed MOL framework, which differ in the way the monotone property is\nimposed. The first approach enforces a strict monotone constraint, while the\nsecond one relies on an approximation. The guarantees are not valid for the\nsecond approach in the strict sense. However, our empirical studies show that\nthe convergence and robustness of both approaches are comparable, while the\nless constrained approximate implementation offers better performance. The\nproposed deep equilibrium formulation is significantly more memory efficient\nthan unrolled methods, which allows us to apply it to 3D or 2D+time problems\nthat current unrolled algorithms cannot handle.\n","authors":["Aniket Pramanik","M. Bridget Zimmerman","Mathews Jacob"],"pdf_url":"https://arxiv.org/pdf/2206.04797v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12366v2","updated":"2023-02-28T04:16:53Z","published":"2023-02-23T23:48:20Z","title":"Less is More: Data Pruning for Faster Adversarial Training","summary":"  Deep neural networks (DNNs) are sensitive to adversarial examples, resulting\nin fragile and unreliable performance in the real world. Although adversarial\ntraining (AT) is currently one of the most effective methodologies to robustify\nDNNs, it is computationally very expensive (e.g., 5-10X costlier than standard\ntraining). To address this challenge, existing approaches focus on single-step\nAT, referred to as Fast AT, reducing the overhead of adversarial example\ngeneration. Unfortunately, these approaches are known to fail against stronger\nadversaries. To make AT computationally efficient without compromising\nrobustness, this paper takes a different view of the efficient AT problem.\nSpecifically, we propose to minimize redundancies at the data level by\nleveraging data pruning. Extensive experiments demonstrate that the data\npruning based AT can achieve similar or superior robust (and clean) accuracy as\nits unpruned counterparts while being significantly faster. For instance,\nproposed strategies accelerate CIFAR-10 training up to 3.44X and CIFAR-100\ntraining to 2.02X. Additionally, the data pruning methods can readily be\nreconciled with existing adversarial acceleration tricks to obtain the striking\nspeed-ups of 5.66X and 5.12X on CIFAR-10, 3.67X and 3.07X on CIFAR-100 with\nTRADES and MART, respectively.\n","authors":["Yize Li","Pu Zhao","Xue Lin","Bhavya Kailkhura","Ryan Goldhahn"],"pdf_url":"https://arxiv.org/pdf/2302.12366v2.pdf","comment":"The AAAI-23 Workshop on Artificial Intelligence Safety (SafeAI 2023)"},{"id":"http://arxiv.org/abs/2302.14290v1","updated":"2023-02-28T03:50:56Z","published":"2023-02-28T03:50:56Z","title":"Learning to Retain while Acquiring: Combating Distribution-Shift in\n  Adversarial Data-Free Knowledge Distillation","summary":"  Data-free Knowledge Distillation (DFKD) has gained popularity recently, with\nthe fundamental idea of carrying out knowledge transfer from a Teacher neural\nnetwork to a Student neural network in the absence of training data. However,\nin the Adversarial DFKD framework, the student network's accuracy, suffers due\nto the non-stationary distribution of the pseudo-samples under multiple\ngenerator updates. To this end, at every generator update, we aim to maintain\nthe student's performance on previously encountered examples while acquiring\nknowledge from samples of the current distribution. Thus, we propose a\nmeta-learning inspired framework by treating the task of Knowledge-Acquisition\n(learning from newly generated samples) and Knowledge-Retention (retaining\nknowledge on previously met samples) as meta-train and meta-test, respectively.\nHence, we dub our method as Learning to Retain while Acquiring. Moreover, we\nidentify an implicit aligning factor between the Knowledge-Retention and\nKnowledge-Acquisition tasks indicating that the proposed student update\nstrategy enforces a common gradient direction for both tasks, alleviating\ninterference between the two objectives. Finally, we support our hypothesis by\nexhibiting extensive evaluation and comparison of our method with prior arts on\nmultiple datasets.\n","authors":["Gaurav Patel","Konda Reddy Mopuri","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.14290v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2302.12995v2","updated":"2023-02-28T03:48:03Z","published":"2023-02-25T05:29:45Z","title":"Raw Image Reconstruction with Learned Compact Metadata","summary":"  While raw images exhibit advantages over sRGB images (e.g., linearity and\nfine-grained quantization level), they are not widely used by common users due\nto the large storage requirements. Very recent works propose to compress raw\nimages by designing the sampling masks in the raw image pixel space, leading to\nsuboptimal image representations and redundant metadata. In this paper, we\npropose a novel framework to learn a compact representation in the latent space\nserving as the metadata in an end-to-end manner. Furthermore, we propose a\nnovel sRGB-guided context model with improved entropy estimation strategies,\nwhich leads to better reconstruction quality, smaller size of metadata, and\nfaster speed. We illustrate how the proposed raw image compression scheme can\nadaptively allocate more bits to image regions that are important from a global\nperspective. The experimental results show that the proposed method can achieve\nsuperior raw image reconstruction results using a smaller size of the metadata\non both uncompressed sRGB images and JPEG images.\n","authors":["Yufei Wang","Yi Yu","Wenhan Yang","Lanqing Guo","Lap-Pui Chau","Alex Kot","Bihan Wen"],"pdf_url":"https://arxiv.org/pdf/2302.12995v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.14284v1","updated":"2023-02-28T03:36:48Z","published":"2023-02-28T03:36:48Z","title":"Rethink Long-tailed Recognition with Vision Transforms","summary":"  In the real world, data tends to follow long-tailed distributions w.r.t.\nclass or attribution, motivating the challenging Long-Tailed Recognition (LTR)\nproblem. In this paper, we revisit recent LTR methods with promising Vision\nTransformers (ViT). We figure out that 1) ViT is hard to train with long-tailed\ndata. 2) ViT learns generalized features in an unsupervised manner, like mask\ngenerative training, either on long-tailed or balanced datasets. Hence, we\npropose to adopt unsupervised learning to utilize long-tailed data.\nFurthermore, we propose the Predictive Distribution Calibration (PDC) as a\nnovel metric for LTR, where the model tends to simply classify inputs into\ncommon classes. Our PDC can measure the model calibration of predictive\npreferences quantitatively. On this basis, we find many LTR approaches\nalleviate it slightly, despite the accuracy improvement. Extensive experiments\non benchmark datasets validate that PDC reflects the model's predictive\npreference precisely, which is consistent with the visualization.\n","authors":["Zhengzhuo Xu","Shuo Yang","Xingjun Wang","Chun Yuan"],"pdf_url":"https://arxiv.org/pdf/2302.14284v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.14277v1","updated":"2023-02-28T03:23:36Z","published":"2023-02-28T03:23:36Z","title":"DECOR-NET: A COVID-19 Lung Infection Segmentation Network Improved by\n  Emphasizing Low-level Features and Decorrelating Features","summary":"  Since 2019, coronavirus Disease 2019 (COVID-19) has been widely spread and\nposed a serious threat to public health. Chest Computed Tomography (CT) holds\ngreat potential for screening and diagnosis of this disease. The segmentation\nof COVID-19 CT imaging can achieves quantitative evaluation of infections and\ntracks disease progression. COVID-19 infections are characterized by high\nheterogeneity and unclear boundaries, so capturing low-level features such as\ntexture and intensity is critical for segmentation. However, segmentation\nnetworks that emphasize low-level features are still lacking. In this work, we\npropose a DECOR-Net capable of capturing more decorrelated low-level features.\nThe channel re-weighting strategy is applied to obtain plenty of low-level\nfeatures and the dependencies between channels are reduced by proposed\ndecorrelation loss. Experiments show that DECOR-Net outperforms other\ncutting-edge methods and surpasses the baseline by 5.1% and 4.9% in terms of\nDice coefficient and intersection over union. Moreover, the proposed\ndecorrelation loss can improve the performance constantly under different\nsettings. The Code is available at https://github.com/jiesihu/DECOR-Net.git.\n","authors":["Jiesi Hu","Yanwu Yang","Xutao Guo","Ting Ma"],"pdf_url":"https://arxiv.org/pdf/2302.14277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10792v2","updated":"2023-02-28T03:21:35Z","published":"2022-07-08T05:02:15Z","title":"Test-Time Adaptation via Self-Training with Nearest Neighbor Information","summary":"  Test-time adaptation (TTA) aims to adapt a trained classifier using online\nunlabeled test data only, without any information related to the training\nprocedure. Most existing TTA methods adapt the trained classifier using the\nclassifier's prediction on the test data as pseudo-label. However, under\ntest-time domain shift, accuracy of the pseudo labels cannot be guaranteed, and\nthus the TTA methods often encounter performance degradation at the adapted\nclassifier. To overcome this limitation, we propose a novel test-time\nadaptation method, called Test-time Adaptation via Self-Training with nearest\nneighbor information (TAST), which is composed of the following procedures: (1)\nadds trainable adaptation modules on top of the trained feature extractor; (2)\nnewly defines a pseudo-label distribution for the test data by using the\nnearest neighbor information; (3) trains these modules only a few times during\ntest time to match the nearest neighbor-based pseudo label distribution and a\nprototype-based class distribution for the test data; and (4) predicts the\nlabel of test data using the average predicted class distribution from these\nmodules. The pseudo-label generation is based on the basic intuition that a\ntest data and its nearest neighbor in the embedding space are likely to share\nthe same label under the domain shift. By utilizing multiple randomly\ninitialized adaptation modules, TAST extracts useful information for the\nclassification of the test data under the domain shift, using the nearest\nneighbor information. TAST showed better performance than the state-of-the-art\nTTA methods on two standard benchmark tasks, domain generalization, namely\nVLCS, PACS, OfficeHome, and TerraIncognita, and image corruption, particularly\nCIFAR-10/100C.\n","authors":["Minguk Jang","Sae-Young Chung","Hye Won Chung"],"pdf_url":"https://arxiv.org/pdf/2207.10792v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06185v2","updated":"2023-02-28T03:19:18Z","published":"2023-02-13T08:42:41Z","title":"PUPS: Point Cloud Unified Panoptic Segmentation","summary":"  Point cloud panoptic segmentation is a challenging task that seeks a holistic\nsolution for both semantic and instance segmentation to predict groupings of\ncoherent points. Previous approaches treat semantic and instance segmentation\nas surrogate tasks, and they either use clustering methods or bounding boxes to\ngather instance groupings with costly computation and hand-crafted designs in\nthe instance segmentation task. In this paper, we propose a simple but\neffective point cloud unified panoptic segmentation (PUPS) framework, which use\na set of point-level classifiers to directly predict semantic and instance\ngroupings in an end-to-end manner. To realize PUPS, we introduce bipartite\nmatching to our training pipeline so that our classifiers are able to\nexclusively predict groupings of instances, getting rid of hand-crafted\ndesigns, e.g. anchors and Non-Maximum Suppression (NMS). In order to achieve\nbetter grouping results, we utilize a transformer decoder to iteratively refine\nthe point classifiers and develop a context-aware CutMix augmentation to\novercome the class imbalance problem. As a result, PUPS achieves 1st place on\nthe leader board of SemanticKITTI panoptic segmentation task and\nstate-of-the-art results on nuScenes.\n","authors":["Shihao Su","Jianyun Xu","Huanyu Wang","Zhenwei Miao","Xin Zhan","Dayang Hao","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2302.06185v2.pdf","comment":"accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.14268v1","updated":"2023-02-28T03:02:11Z","published":"2023-02-28T03:02:11Z","title":"Self-Supervised Category-Level Articulated Object Pose Estimation with\n  Part-Level SE(3) Equivariance","summary":"  Category-level articulated object pose estimation aims to estimate a\nhierarchy of articulation-aware object poses of an unseen articulated object\nfrom a known category. To reduce the heavy annotations needed for supervised\nlearning methods, we present a novel self-supervised strategy that solves this\nproblem without any human labels. Our key idea is to factorize canonical shapes\nand articulated object poses from input articulated shapes through part-level\nequivariant shape analysis. Specifically, we first introduce the concept of\npart-level SE(3) equivariance and devise a network to learn features of such\nproperty. Then, through a carefully designed fine-grained pose-shape\ndisentanglement strategy, we expect that canonical spaces to support pose\nestimation could be induced automatically. Thus, we could further predict\narticulated object poses as per-part rigid transformations describing how parts\ntransform from their canonical part spaces to the camera space. Extensive\nexperiments demonstrate the effectiveness of our method on both complete and\npartial point clouds from synthetic and real articulated object datasets.\n","authors":["Xueyi Liu","Ji Zhang","Ruizhen Hu","Haibin Huang","He Wang","Li Yi"],"pdf_url":"https://arxiv.org/pdf/2302.14268v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2206.05751v2","updated":"2023-02-28T03:02:02Z","published":"2022-06-12T14:45:11Z","title":"Consistent Attack: Universal Adversarial Perturbation on Embodied Vision\n  Navigation","summary":"  Embodied agents in vision navigation coupled with deep neural networks have\nattracted increasing attention. However, deep neural networks are vulnerable to\nmalicious adversarial noises, which may potentially cause catastrophic failures\nin Embodied Vision Navigation. Among these adversarial noises, universal\nadversarial perturbations (UAP), i.e., the image-agnostic perturbation applied\non each frame received by the agent, are more critical for Embodied Vision\nNavigation since they are computation-efficient and application-practical\nduring the attack. However, existing UAP methods do not consider the system\ndynamics of Embodied Vision Navigation. For extending UAP in the sequential\ndecision setting, we formulate the disturbed environment under the universal\nnoise $\\delta$, as a $\\delta$-disturbed Markov Decision Process ($\\delta$-MDP).\nBased on the formulation, we analyze the properties of $\\delta$-MDP and propose\ntwo novel Consistent Attack methods for attacking Embodied agents, which first\nconsider the dynamic of the MDP by estimating the disturbed Q function and the\ndisturbed distribution. In spite of victim models, our Consistent Attack can\ncause a significant drop in the performance for the Goalpoint task in habitat.\nExtensive experimental results indicate that there exist potential risks for\napplying Embodied Vision Navigation methods to the real world.\n","authors":["Chengyang Ying","You Qiaoben","Xinning Zhou","Hang Su","Jun Zhu","Bo Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.05751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14267v1","updated":"2023-02-28T03:01:58Z","published":"2023-02-28T03:01:58Z","title":"Adversarial Attack with Raindrops","summary":"  Deep neural networks (DNNs) are known to be vulnerable to adversarial\nexamples, which are usually designed artificially to fool DNNs, but rarely\nexist in real-world scenarios. In this paper, we study the adversarial examples\ncaused by raindrops, to demonstrate that there exist plenty of natural\nphenomena being able to work as adversarial attackers to DNNs. Moreover, we\npresent a new approach to generate adversarial raindrops, denoted as AdvRD,\nusing the generative adversarial network (GAN) technique to simulate natural\nraindrops. The images crafted by our AdvRD look very similar to the real-world\nraindrop images, statistically close to the distribution of true raindrop\nimages, and more importantly, can perform strong adversarial attack to the\nstate-of-the-art DNN models. On the other side, we show that the adversarial\ntraining using our AdvRD images can significantly improve the robustness of\nDNNs to the real-world raindrop attacks. Extensive experiments are carried out\nto demonstrate that the images crafted by AdvRD are visually and statistically\nclose to the natural raindrop images, can work as strong attackers to DNN\nmodels, and also help improve the robustness of DNNs to raindrop attacks.\n","authors":["Jiyuan Liu","Bingyi Lu","Mingkang Xiong","Tao Zhang","Huilin Xiong"],"pdf_url":"https://arxiv.org/pdf/2302.14267v1.pdf","comment":"10 pages, 7 figures, cvpr2023"},{"id":"http://arxiv.org/abs/2212.02770v2","updated":"2023-02-28T02:49:07Z","published":"2022-12-06T05:44:21Z","title":"CSQ: Growing Mixed-Precision Quantization Scheme with Bi-level\n  Continuous Sparsification","summary":"  Mixed-precision quantization has been widely applied on deep neural networks\n(DNNs) as it leads to significantly better efficiency-accuracy tradeoffs\ncompared to uniform quantization. Meanwhile, determining the exact precision of\neach layer remains challenging. Previous attempts on bit-level regularization\nand pruning-based dynamic precision adjustment during training suffer from\nnoisy gradients and unstable convergence. In this work, we propose Continuous\nSparsification Quantization (CSQ), a bit-level training method to search for\nmixed-precision quantization schemes with improved stability. CSQ stabilizes\nthe bit-level mixed-precision training process with a bi-level gradual\ncontinuous sparsification on both the bit values of the quantized weights and\nthe bit selection in determining the quantization precision of each layer. The\ncontinuous sparsification scheme enables fully-differentiable training without\ngradient approximation while achieving an exact quantized model in the end.A\nbudget-aware regularization of total model size enables the dynamic growth and\npruning of each layer's precision towards a mixed-precision quantization scheme\nof the desired size. Extensive experiments show CSQ achieves better\nefficiency-accuracy tradeoff than previous methods on multiple models and\ndatasets.\n","authors":["Lirui Xiao","Huanrui Yang","Zhen Dong","Kurt Keutzer","Li Du","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.02770v2.pdf","comment":"Published as a conference paper at DAC 2023"},{"id":"http://arxiv.org/abs/2204.10972v2","updated":"2023-02-28T02:46:40Z","published":"2022-04-23T01:40:06Z","title":"GRM: Gradient Rectification Module for Visual Place Retrieval","summary":"  Visual place retrieval aims to search images in the database that depict\nsimilar places as the query image. However, global descriptors encoded by the\nnetwork usually fall into a low dimensional principal space, which is harmful\nto the retrieval performance. We first analyze the cause of this phenomenon,\npointing out that it is due to degraded distribution of the gradients of\ndescriptors. Then, we propose Gradient Rectification Module(GRM) to alleviate\nthis issue. GRM is appended after the final pooling layer and can rectify\ngradients to the complementary space of the principal space. With GRM, the\nnetwork is encouraged to generate descriptors more uniformly in the whole\nspace. At last, we conduct experiments on multiple datasets and generalize our\nmethod to classification task under prototype learning framework.\n","authors":["Boshu Lei","Wenjie Ding","Limeng Qiao","Xi Qiu"],"pdf_url":"https://arxiv.org/pdf/2204.10972v2.pdf","comment":"Accepted to the 2023 International Conference on Robotics and\n  Automation (ICRA 2023)"},{"id":"http://arxiv.org/abs/2302.14264v1","updated":"2023-02-28T02:41:27Z","published":"2023-02-28T02:41:27Z","title":"RGB-D Grasp Detection via Depth Guided Learning with Cross-modal\n  Attention","summary":"  Planar grasp detection is one of the most fundamental tasks to robotic\nmanipulation, and the recent progress of consumer-grade RGB-D sensors enables\ndelivering more comprehensive features from both the texture and shape\nmodalities. However, depth maps are generally of a relatively lower quality\nwith much stronger noise compared to RGB images, making it challenging to\nacquire grasp depth and fuse multi-modal clues. To address the two issues, this\npaper proposes a novel learning based approach to RGB-D grasp detection, namely\nDepth Guided Cross-modal Attention Network (DGCAN). To better leverage the\ngeometry information recorded in the depth channel, a complete 6-dimensional\nrectangle representation is adopted with the grasp depth dedicatedly considered\nin addition to those defined in the common 5-dimensional one. The prediction of\nthe extra grasp depth substantially strengthens feature learning, thereby\nleading to more accurate results. Moreover, to reduce the negative impact\ncaused by the discrepancy of data quality in two modalities, a Local\nCross-modal Attention (LCA) module is designed, where the depth features are\nrefined according to cross-modal relations and concatenated to the RGB ones for\nmore sufficient fusion. Extensive simulation and physical evaluations are\nconducted and the experimental results highlight the superiority of the\nproposed approach.\n","authors":["Ran Qin","Haoxiang Ma","Boyang Gao","Di Huang"],"pdf_url":"https://arxiv.org/pdf/2302.14264v1.pdf","comment":"Accepted at ICRA 2023"},{"id":"http://arxiv.org/abs/2212.08846v3","updated":"2023-02-28T02:30:31Z","published":"2022-12-17T11:00:34Z","title":"Painterly Image Harmonization in Dual Domains","summary":"  Image harmonization aims to produce visually harmonious composite images by\nadjusting the foreground appearance to be compatible with the background. When\nthe composite image has photographic foreground and painterly background, the\ntask is called painterly image harmonization. There are only few works on this\ntask, which are either time-consuming or weak in generating well-harmonized\nresults. In this work, we propose a novel painterly harmonization network\nconsisting of a dual-domain generator and a dual-domain discriminator, which\nharmonizes the composite image in both spatial domain and frequency domain. The\ndual-domain generator performs harmonization by using AdaIN modules in the\nspatial domain and our proposed ResFFT modules in the frequency domain. The\ndual-domain discriminator attempts to distinguish the inharmonious patches\nbased on the spatial feature and frequency feature of each patch, which can\nenhance the ability of generator in an adversarial manner. Extensive\nexperiments on the benchmark dataset show the effectiveness of our method. Our\ncode and model are available at\nhttps://github.com/bcmi/PHDNet-Painterly-Image-Harmonization.\n","authors":["Junyan Cao","Yan Hong","Li Niu"],"pdf_url":"https://arxiv.org/pdf/2212.08846v3.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.14256v1","updated":"2023-02-28T02:27:36Z","published":"2023-02-28T02:27:36Z","title":"Remote Sensing Scene Classification with Masked Image Modeling (MIM)","summary":"  Remote sensing scene classification has been extensively studied for its\ncritical roles in geological survey, oil exploration, traffic management,\nearthquake prediction, wildfire monitoring, and intelligence monitoring. In the\npast, the Machine Learning (ML) methods for performing the task mainly used the\nbackbones pretrained in the manner of supervised learning (SL). As Masked Image\nModeling (MIM), a self-supervised learning (SSL) technique, has been shown as a\nbetter way for learning visual feature representation, it presents a new\nopportunity for improving ML performance on the scene classification task. This\nresearch aims to explore the potential of MIM pretrained backbones on four\nwell-known classification datasets: Merced, AID, NWPU-RESISC45, and Optimal-31.\nCompared to the published benchmarks, we show that the MIM pretrained Vision\nTransformer (ViTs) backbones outperform other alternatives (up to 18% on top 1\naccuracy) and that the MIM technique can learn better feature representation\nthan the supervised learning counterparts (up to 5% on top 1 accuracy).\nMoreover, we show that the general-purpose MIM-pretrained ViTs can achieve\ncompetitive performance as the specially designed yet complicated Transformer\nfor Remote Sensing (TRS) framework. Our experiment results also provide a\nperformance baseline for future studies.\n","authors":["Liya Wang","Alex Tien"],"pdf_url":"https://arxiv.org/pdf/2302.14256v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2301.12058"},{"id":"http://arxiv.org/abs/2302.14250v1","updated":"2023-02-28T02:21:42Z","published":"2023-02-28T02:21:42Z","title":"Foundation Model Drives Weakly Incremental Learning for Semantic\n  Segmentation","summary":"  Modern incremental learning for semantic segmentation methods usually learn\nnew categories based on dense annotations. Although achieve promising results,\npixel-by-pixel labeling is costly and time-consuming. Weakly incremental\nlearning for semantic segmentation (WILSS) is a novel and attractive task,\nwhich aims at learning to segment new classes from cheap and widely available\nimage-level labels. Despite the comparable results, the image-level labels can\nnot provide details to locate each segment, which limits the performance of\nWILSS. This inspires us to think how to improve and effectively utilize the\nsupervision of new classes given image-level labels while avoiding forgetting\nold ones. In this work, we propose a novel and data-efficient framework for\nWILSS, named FMWISS. Specifically, we propose pre-training based\nco-segmentation to distill the knowledge of complementary foundation models for\ngenerating dense pseudo labels. We further optimize the noisy pseudo masks with\na teacher-student architecture, where a plug-in teacher is optimized with a\nproposed dense contrastive loss. Moreover, we introduce memory-based copy-paste\naugmentation to improve the catastrophic forgetting problem of old classes.\nExtensive experiments on Pascal VOC and COCO datasets demonstrate the superior\nperformance of our framework, e.g., FMWISS achieves 70.7% and 73.3% in the 15-5\nVOC setting, outperforming the state-of-the-art method by 3.4% and 6.1%,\nrespectively.\n","authors":["Chaohui Yu","Qiang Zhou","Jingliang Li","Jianlong Yuan","Zhibin Wang","Fan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14250v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2204.05859v2","updated":"2023-02-28T01:46:21Z","published":"2022-04-12T14:59:48Z","title":"DCMS: Motion Forecasting with Dual Consistency and Multi-Pseudo-Target\n  Supervision","summary":"  We present a novel framework for motion forecasting with Dual Consistency\nConstraints and Multi-Pseudo-Target supervision. The motion forecasting task\npredicts future trajectories of vehicles by incorporating spatial and temporal\ninformation from the past. A key design of DCMS is the proposed Dual\nConsistency Constraints that regularize the predicted trajectories under\nspatial and temporal perturbation during the training stage. In addition, we\ndesign a novel self-ensembling scheme to obtain accurate pseudo targets to\nmodel the multi-modality in motion forecasting through supervision with\nmultiple targets explicitly, namely Multi-Pseudo-Target supervision. Our\nexperimental results on the Argoverse motion forecasting benchmark show that\nDCMS significantly outperforms the state-of-the-art methods, achieving 1st\nplace on the leaderboard. We also demonstrate that our proposed strategies can\nbe incorporated into other motion forecasting approaches as general training\nschemes.\n","authors":["Maosheng Ye","Jiamiao Xu","Xunnong Xu","Tengfei Wang","Tongyi Cao","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2204.05859v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14239v1","updated":"2023-02-28T01:44:55Z","published":"2023-02-28T01:44:55Z","title":"Nonlinear Intensity, Scale and Rotation Invariant Matching for\n  Multimodal Images","summary":"  We present an effective method for the matching of multimodal images.\nAccurate image matching is the basis of various applications, such as image\nregistration and structure from motion. Conventional matching methods fail when\nhandling noisy multimodal image pairs with severe scale change, rotation, and\nnonlinear intensity distortion (NID). Toward this need, we introduce an image\npyramid strategy to tackle scale change. We put forward an accurate primary\norientation estimation approach to reduce the effect of image rotation at any\nangle. We utilize multi-scale and multi-orientation image filtering results and\na feature-to-template matching scheme to ensure effective and accurate matching\nunder large NID. Integrating these improvements significantly increases noise,\nscale, rotation, and NID invariant capability. Our experimental results confirm\nthe excellent ability to achieve high-quality matches across various multimodal\nimages. The proposed method outperforms the mainstream multimodal image\nmatching methods in qualitative and quantitative evaluations. Our\nimplementation is available at https://github.com/Zhongli-Fan/NISR.\n","authors":["Zhongli Fan","Li Zhang","Yuxuan Liu"],"pdf_url":"https://arxiv.org/pdf/2302.14239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14237v1","updated":"2023-02-28T01:39:36Z","published":"2023-02-28T01:39:36Z","title":"Towards Surgical Context Inference and Translation to Gestures","summary":"  Manual labeling of gestures in robot-assisted surgery is labor intensive,\nprone to errors, and requires expertise or training. We propose a method for\nautomated and explainable generation of gesture transcripts that leverages the\nabundance of data for image segmentation to train a surgical scene segmentation\nmodel that provides surgical tool and object masks. Surgical context is\ndetected using segmentation masks by examining the distances and intersections\nbetween the tools and objects. Next, context labels are translated into gesture\ntranscripts using knowledge-based Finite State Machine (FSM) and data-driven\nLong Short Term Memory (LSTM) models. We evaluate the performance of each stage\nof our method by comparing the results with the ground truth segmentation\nmasks, the consensus context labels, and the gesture labels in the JIGSAWS\ndataset. Our results show that our segmentation models achieve state-of-the-art\nperformance in recognizing needle and thread in Suturing and we can\nautomatically detect important surgical states with high agreement with\ncrowd-sourced labels (e.g., contact between graspers and objects in Suturing).\nWe also find that the FSM models are more robust to poor segmentation and\nlabeling performance than LSTMs. Our proposed method can significantly shorten\nthe gesture labeling process (~2.8 times).\n","authors":["Kay Hutchinson","Zongyu Li","Ian Reyes","Homa Alemzadeh"],"pdf_url":"https://arxiv.org/pdf/2302.14237v1.pdf","comment":"accepted for the 2023 International Conference on Robotics and\n  Automation (ICRA)"},{"id":"http://arxiv.org/abs/2205.09949v4","updated":"2023-02-28T01:23:20Z","published":"2022-05-20T03:53:56Z","title":"HCFormer: Unified Image Segmentation with Hierarchical Clustering","summary":"  Hierarchical clustering is an effective and efficient approach widely used\nfor classical image segmentation methods. However, many existing methods using\nneural networks generate segmentation masks directly from per-pixel features,\ncomplicating the architecture design and degrading the interpretability. In\nthis work, we propose a simpler, more interpretable architecture, called\nHCFormer. HCFormer accomplishes image segmentation by bottom-up hierarchical\nclustering and allows us to interpret, visualize, and evaluate the intermediate\nresults as hierarchical clustering results. HCFormer can address semantic,\ninstance, and panoptic segmentation with the same architecture because the\npixel clustering is a common approach for various image segmentation tasks. In\nexperiments, HCFormer achieves comparable or superior segmentation accuracy\ncompared to baseline methods on semantic segmentation (55.5 mIoU on ADE20K),\ninstance segmentation (47.1 AP on COCO), and panoptic segmentation (55.7 PQ on\nCOCO).\n","authors":["Teppei Suzuki"],"pdf_url":"https://arxiv.org/pdf/2205.09949v4.pdf","comment":"Code: https://github.com/DensoITLab/HCFormer"},{"id":"http://arxiv.org/abs/2302.14217v1","updated":"2023-02-28T00:43:13Z","published":"2023-02-28T00:43:13Z","title":"Global Proxy-based Hard Mining for Visual Place Recognition","summary":"  Learning deep representations for visual place recognition is commonly\nperformed using pairwise or triple loss functions that highly depend on the\nhardness of the examples sampled at each training iteration. Existing\ntechniques address this by using computationally and memory expensive offline\nhard mining, which consists of identifying, at each iteration, the hardest\nsamples from the training set. In this paper we introduce a new technique that\nperforms global hard mini-batch sampling based on proxies. To do so, we add a\nnew end-to-end trainable branch to the network, which generates efficient place\ndescriptors (one proxy for each place). These proxy representations are thus\nused to construct a global index that encompasses the similarities between all\nplaces in the dataset, allowing for highly informative mini-batch sampling at\neach training iteration. Our method can be used in combination with all\nexisting pairwise and triplet loss functions with negligible additional memory\nand computation cost. We run extensive ablation studies and show that our\ntechnique brings new state-of-the-art performance on multiple large-scale\nbenchmarks such as Pittsburgh, Mapillary-SLS and SPED. In particular, our\nmethod provides more than 100% relative improvement on the challenging Nordland\ndataset. Our code is available at https://github.com/amaralibey/GPM\n","authors":["Amar Ali-bey","Brahim Chaib-draa","Philippe Giguère"],"pdf_url":"https://arxiv.org/pdf/2302.14217v1.pdf","comment":"Accepted at BMVC 2022"},{"id":"http://arxiv.org/abs/2303.00138v1","updated":"2023-02-28T23:56:31Z","published":"2023-02-28T23:56:31Z","title":"Video Pose Track with Graph-Guided Sparse Motion Estimation","summary":"  In this paper, we propose a novel framework for multi-person pose estimation\nand tracking under occlusions and motion blurs. Specifically, the consistency\nin graph structures from consecutive frames is improved by concentrating on\nvisible body joints and estimating the motion vectors of sparse key-points\nsurrounding visible joints. The proposed framework involves three components:\n(i) A Sparse Key-point Flow Estimating Module (SKFEM) for sampling key-points\nfrom around body joints and estimating the motion vectors of key-points which\ncontribute to the refinement of body joint locations and fine-tuning of pose\nestimators; (ii) A Hierarchical Graph Distance Minimizing Module (HGMM) for\nevaluating the visibility scores of nodes from hierarchical graphs with the\nvisibility score of a node determining the number of samples around that node;\nand (iii) The combination of multiple historical frames for matching\nidentities. Graph matching with HGMM facilitates more accurate tracking even\nunder partial occlusions. The proposed approach not only achieves\nstate-of-the-art performance on the PoseTrack dataset but also contributes to\nsignificant improvements in human-related anomaly detection. Besides a higher\naccuracy, the proposed SKFEM also shows a much higher efficiency than dense\noptical flow estimation.\n","authors":["Yalong Jiang","Wenrui Ding","Hongguang Li","Zheru Chi"],"pdf_url":"https://arxiv.org/pdf/2303.00138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00137v1","updated":"2023-02-28T23:52:01Z","published":"2023-02-28T23:52:01Z","title":"PixHt-Lab: Pixel Height Based Light Effect Generation for Image\n  Compositing","summary":"  Lighting effects such as shadows or reflections are key in making synthetic\nimages realistic and visually appealing. To generate such effects, traditional\ncomputer graphics uses a physically-based renderer along with 3D geometry. To\ncompensate for the lack of geometry in 2D Image compositing, recent deep\nlearning-based approaches introduced a pixel height representation to generate\nsoft shadows and reflections. However, the lack of geometry limits the quality\nof the generated soft shadows and constrain reflections to pure specular ones.\nWe introduce PixHt-Lab, a system leveraging an explicit mapping from pixel\nheight representation to 3D space. Using this mapping, PixHt-Lab reconstructs\nboth the cutout and background geometry and renders realistic, diverse,\nlighting effects for image compositing. Given a surface with physically-based\nmaterials, we can render reflections with varying glossiness. To generate more\nrealistic soft shadows, we further propose to use 3D-aware buffer channels to\nguide a neural renderer. Both quantitative and qualitative evaluations\ndemonstrate that PixHt-Lab significantly improves soft shadow generation.\n","authors":["Yichen Sheng","Jianming Zhang","Julien Philip","Yannick Hold-Geoffroy","Xin Sun","HE Zhang","Lu Ling","Bedrich Benes"],"pdf_url":"https://arxiv.org/pdf/2303.00137v1.pdf","comment":"11 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.05032v3","updated":"2023-02-28T23:46:24Z","published":"2022-12-09T18:30:24Z","title":"Training-Free Structured Diffusion Guidance for Compositional\n  Text-to-Image Synthesis","summary":"  Large-scale diffusion models have achieved state-of-the-art results on\ntext-to-image synthesis (T2I) tasks. Despite their ability to generate\nhigh-quality yet creative images, we observe that attribution-binding and\ncompositional capabilities are still considered major challenging issues,\nespecially when involving multiple objects. In this work, we improve the\ncompositional skills of T2I models, specifically more accurate attribute\nbinding and better image compositions. To do this, we incorporate linguistic\nstructures with the diffusion guidance process based on the controllable\nproperties of manipulating cross-attention layers in diffusion-based T2I\nmodels. We observe that keys and values in cross-attention layers have strong\nsemantic meanings associated with object layouts and content. Therefore, we can\nbetter preserve the compositional semantics in the generated image by\nmanipulating the cross-attention representations based on linguistic insights.\nBuilt upon Stable Diffusion, a SOTA T2I model, our structured cross-attention\ndesign is efficient that requires no additional training samples. We achieve\nbetter compositional skills in qualitative and quantitative results, leading to\na 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an\nin-depth analysis to reveal potential causes of incorrect image compositions\nand justify the properties of cross-attention layers in the generation process.\n","authors":["Weixi Feng","Xuehai He","Tsu-Jui Fu","Varun Jampani","Arjun Akula","Pradyumna Narayana","Sugato Basu","Xin Eric Wang","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.05032v3.pdf","comment":"ICLR 2023 Camera Ready version"},{"id":"http://arxiv.org/abs/2203.12023v5","updated":"2023-02-28T23:25:05Z","published":"2022-03-22T20:24:21Z","title":"Generative Modeling Helps Weak Supervision (and Vice Versa)","summary":"  Many promising applications of supervised machine learning face hurdles in\nthe acquisition of labeled data in sufficient quantity and quality, creating an\nexpensive bottleneck. To overcome such limitations, techniques that do not\ndepend on ground truth labels have been studied, including weak supervision and\ngenerative modeling. While these techniques would seem to be usable in concert,\nimproving one another, how to build an interface between them is not\nwell-understood. In this work, we propose a model fusing programmatic weak\nsupervision and generative adversarial networks and provide theoretical\njustification motivating this fusion. The proposed approach captures discrete\nlatent variables in the data alongside the weak supervision derived label\nestimate. Alignment of the two allows for better modeling of sample-dependent\naccuracies of the weak supervision sources, improving the estimate of\nunobserved labels. It is the first approach to enable data augmentation through\nweakly supervised synthetic images and pseudolabels. Additionally, its learned\nlatent variables can be inspected qualitatively. The model outperforms baseline\nweak supervision label models on a number of multiclass image classification\ndatasets, improves the quality of generated images, and further improves\nend-model performance through data augmentation with synthetic samples.\n","authors":["Benedikt Boecking","Nicholas Roberts","Willie Neiswanger","Stefano Ermon","Frederic Sala","Artur Dubrawski"],"pdf_url":"https://arxiv.org/pdf/2203.12023v5.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.01433v2","updated":"2023-02-28T23:06:09Z","published":"2022-12-02T20:30:59Z","title":"Avoiding spurious correlations via logit correction","summary":"  Empirical studies suggest that machine learning models trained with empirical\nrisk minimization (ERM) often rely on attributes that may be spuriously\ncorrelated with the class labels. Such models typically lead to poor\nperformance during inference for data lacking such correlations. In this work,\nwe explicitly consider a situation where potential spurious correlations are\npresent in the majority of training data. In contrast with existing approaches,\nwhich use the ERM model outputs to detect the samples without spurious\ncorrelations and either heuristically upweight or upsample those samples, we\npropose the logit correction (LC) loss, a simple yet effective improvement on\nthe softmax cross-entropy loss, to correct the sample logit. We demonstrate\nthat minimizing the LC loss is equivalent to maximizing the group-balanced\naccuracy, so the proposed LC could mitigate the negative impacts of spurious\ncorrelations. Our extensive experimental results further reveal that the\nproposed LC loss outperforms state-of-the-art solutions on multiple popular\nbenchmarks by a large margin, an average 5.5\\% absolute improvement, without\naccess to spurious attribute labels. LC is also competitive with oracle methods\nthat make use of the attribute labels. Code is available at\nhttps://github.com/shengliu66/LC.\n","authors":["Sheng Liu","Xu Zhang","Nitesh Sekhar","Yue Wu","Prateek Singhal","Carlos Fernandez-Granda"],"pdf_url":"https://arxiv.org/pdf/2212.01433v2.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.00111v1","updated":"2023-02-28T22:26:18Z","published":"2023-02-28T22:26:18Z","title":"PixCUE -- Joint Uncertainty Estimation and Image Reconstruction in MRI\n  using Deep Pixel Classification","summary":"  Deep learning (DL) models are capable of successfully exploiting latent\nrepresentations in MR data and have become state-of-the-art for accelerated MRI\nreconstruction. However, undersampling the measurements in k-space as well as\nthe over- or under-parameterized and non-transparent nature of DL make these\nmodels exposed to uncertainty. Consequently, uncertainty estimation has become\na major issue in DL MRI reconstruction. To estimate uncertainty, Monte Carlo\n(MC) inference techniques have become a common practice where multiple\nreconstructions are utilized to compute the variance in reconstruction as a\nmeasurement of uncertainty. However, these methods demand high computational\ncosts as they require multiple inferences through the DL model. To this end, we\nintroduce a method to estimate uncertainty during MRI reconstruction using a\npixel classification framework. The proposed method, PixCUE (stands for Pixel\nClassification Uncertainty Estimation) produces the reconstructed image along\nwith an uncertainty map during a single forward pass through the DL model. We\ndemonstrate that this approach generates uncertainty maps that highly correlate\nwith the reconstruction errors with respect to various MR imaging sequences and\nunder numerous adversarial conditions. We also show that the estimated\nuncertainties are correlated to that of the conventional MC method. We further\nprovide an empirical relationship between the uncertainty estimations using\nPixCUE and well-established reconstruction metrics such as NMSE, PSNR, and\nSSIM. We conclude that PixCUE is capable of reliably estimating the uncertainty\nin MRI reconstruction with a minimum additional computational cost.\n","authors":["Mevan Ekanayake","Kamlesh Pawar","Gary Egan","Zhaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00111v1.pdf","comment":"19 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2209.07896v2","updated":"2023-02-28T21:57:49Z","published":"2022-09-16T12:41:43Z","title":"3D VSG: Long-term Semantic Scene Change Prediction through 3D Variable\n  Scene Graphs","summary":"  Numerous applications require robots to operate in environments shared with\nother agents, such as humans or other robots. However, such shared scenes are\ntypically subject to different kinds of long-term semantic scene changes. The\nability to model and predict such changes is thus crucial for robot autonomy.\nIn this work, we formalize the task of semantic scene variability estimation\nand identify three main varieties of semantic scene change: changes in the\nposition of an object, its semantic state, or the composition of a scene as a\nwhole. To represent this variability, we propose the Variable Scene Graph\n(VSG), which augments existing 3D Scene Graph (SG) representations with the\nvariability attribute, representing the likelihood of discrete long-term change\nevents. We present a novel method, DeltaVSG, to estimate the variability of\nVSGs in a supervised fashion. We evaluate our method on the 3RScan long-term\ndataset, showing notable improvements in this novel task over existing\napproaches. Our method DeltaVSG achieves an accuracy of 77.1% and a recall of\n72.3%, often mimicking human intuition about how indoor scenes change over\ntime. We further show the utility of VSG prediction in the task of active\nrobotic change detection, speeding up task completion by 66.0% compared to a\nscene-change-unaware planner. We make our code available as open-source.\n","authors":["Samuel Looper","Javier Rodriguez-Puigvert","Roland Siegwart","Cesar Cadena","Lukas Schmid"],"pdf_url":"https://arxiv.org/pdf/2209.07896v2.pdf","comment":"Accepted for IEEE International Conference on Robotics and Automation\n  (ICRA) 2023. 8 pages, 4 figures, code released at\n  https://github.com/ethz-asl/3d_vsg"},{"id":"http://arxiv.org/abs/2303.00092v1","updated":"2023-02-28T21:32:49Z","published":"2023-02-28T21:32:49Z","title":"A study on the use of perceptual hashing to detect manipulation of\n  embedded messages in images","summary":"  Typically, metadata of images are stored in a specific data segment of the\nimage file. However, to securely detect changes, data can also be embedded\nwithin images. This follows the goal to invisibly and robustly embed as much\ninformation as possible to, ideally, even survive compression.\n  This work searches for embedding principles which allow to distinguish\nbetween unintended changes by lossy image compression and malicious\nmanipulation of the embedded message based on the change of its perceptual or\nrobust hash. Different embedding and compression algorithms are compared.\n  The study shows that embedding a message via integer wavelet transform and\ncompression with Karhunen-Loeve-transform yields the best results. However, it\nwas not possible to distinguish between manipulation and compression in all\ncases.\n","authors":["Sven-Jannik Wöhnert","Kai Hendrik Wöhnert","Eldar Almamedov","Carsten Frank","Volker Skwarek"],"pdf_url":"https://arxiv.org/pdf/2303.00092v1.pdf","comment":"12 pages, 3 figures submitted, accepted and presented at IPCV 2022,\n  subconference of CSCE, https://american-cse.org/csce2022/conferences-IPCV as\n  the publication of the proceedings is delayed, the permission for a\n  (pre-)publication on arxiv was granted\n  https://american-cse.org/csce2022/publisher"},{"id":"http://arxiv.org/abs/2209.08196v2","updated":"2023-02-28T21:30:32Z","published":"2022-09-16T23:29:48Z","title":"Lossless SIMD Compression of LiDAR Range and Attribute Scan Sequences","summary":"  As LiDAR sensors have become ubiquitous, the need for an efficient LiDAR data\ncompression algorithm has increased. Modern LiDARs produce gigabytes of scan\ndata per hour and are often used in applications with limited compute,\nbandwidth, and storage resources.\n  We present a fast, lossless compression algorithm for LiDAR range and\nattribute scan sequences including multiple-return range, signal, reflectivity,\nand ambient infrared. Our algorithm -- dubbed \"Jiffy\" -- achieves substantial\ncompression by exploiting spatiotemporal redundancy and sparsity. Speed is\naccomplished by maximizing use of single-instruction-multiple-data (SIMD)\ninstructions. In autonomous driving, infrastructure monitoring, drone\ninspection, and handheld mapping benchmarks, the Jiffy algorithm consistently\noutcompresses competing lossless codecs while operating at speeds in excess of\n65M points/sec on a single core. In a typical autonomous vehicle use case,\nsingle-threaded Jiffy achieves 6x compression of centimeter-precision range\nscans at 500+ scans per second. To ensure reproducibility and enable adoption,\nthe software is freely available as an open source library.\n","authors":["Jeff Ford","Jordan Ford"],"pdf_url":"https://arxiv.org/pdf/2209.08196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00086v1","updated":"2023-02-28T21:06:36Z","published":"2023-02-28T21:06:36Z","title":"Applying Plain Transformers to Real-World Point Clouds","summary":"  Due to the lack of inductive bias, transformer-based models usually require a\nlarge amount of training data. The problem is especially concerning in 3D\nvision, as 3D data are harder to acquire and annotate. To overcome this\nproblem, previous works modify the architecture of transformers to incorporate\ninductive biases by applying, e.g., local attention and down-sampling. Although\nthey have achieved promising results, earlier works on transformers for point\nclouds have two issues. First, the power of plain transformers is still\nunder-explored. Second, they focus on simple and small point clouds instead of\ncomplex real-world ones. This work revisits the plain transformers in\nreal-world point cloud understanding. We first take a closer look at some\nfundamental components of plain transformers, e.g., patchifier and positional\nembedding, for both efficiency and performance. To close the performance gap\ndue to the lack of inductive bias and annotated data, we investigate\nself-supervised pre-training with masked autoencoder (MAE). Specifically, we\npropose drop patch, which prevents information leakage and significantly\nimproves the effectiveness of MAE. Our models achieve SOTA results in semantic\nsegmentation on the S3DIS dataset and object detection on the ScanNet dataset\nwith lower computational costs. Our work provides a new baseline for future\nresearch on transformers for point clouds.\n","authors":["Lanxiao Li","Michael Heizmann"],"pdf_url":"https://arxiv.org/pdf/2303.00086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10859v2","updated":"2023-02-28T20:33:45Z","published":"2023-02-21T18:16:20Z","title":"SF2Former: Amyotrophic Lateral Sclerosis Identification From\n  Multi-center MRI Data Using Spatial and Frequency Fusion Transformer","summary":"  Amyotrophic Lateral Sclerosis (ALS) is a complex neurodegenerative disorder\ninvolving motor neuron degeneration. Significant research has begun to\nestablish brain magnetic resonance imaging (MRI) as a potential biomarker to\ndiagnose and monitor the state of the disease. Deep learning has turned into a\nprominent class of machine learning programs in computer vision and has been\nsuccessfully employed to solve diverse medical image analysis tasks. However,\ndeep learning-based methods applied to neuroimaging have not achieved superior\nperformance in ALS patients classification from healthy controls due to having\ninsignificant structural changes correlated with pathological features.\nTherefore, the critical challenge in deep models is to determine useful\ndiscriminative features with limited training data. By exploiting the\nlong-range relationship of image features, this study introduces a framework\nnamed SF2Former that leverages vision transformer architecture's power to\ndistinguish the ALS subjects from the control group. To further improve the\nnetwork's performance, spatial and frequency domain information are combined\nbecause MRI scans are captured in the frequency domain before being converted\nto the spatial domain. The proposed framework is trained with a set of\nconsecutive coronal 2D slices, which uses the pre-trained weights on ImageNet\nby leveraging transfer learning. Finally, a majority voting scheme has been\nemployed to those coronal slices of a particular subject to produce the final\nclassification decision. Our proposed architecture has been thoroughly assessed\nwith multi-modal neuroimaging data using two well-organized versions of the\nCanadian ALS Neuroimaging Consortium (CALSNIC) multi-center datasets. The\nexperimental results demonstrate the superiority of our proposed strategy in\nterms of classification accuracy compared with several popular deep\nlearning-based techniques.\n","authors":["Rafsanjany Kushol","Collin C. Luk","Avyarthana Dey","Michael Benatar","Hannah Briemberg","Annie Dionne","Nicolas Dupré","Richard Frayne","Angela Genge","Summer Gibson","Simon J. Graham","Lawrence Korngut","Peter Seres","Robert C. Welsh","Alan Wilman","Lorne Zinman","Sanjay Kalra","Yee-Hong Yang"],"pdf_url":"https://arxiv.org/pdf/2302.10859v2.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2203.04450v2","updated":"2023-02-28T20:21:57Z","published":"2022-03-08T23:44:01Z","title":"How to exploit hyperspherical embeddings for out-of-distribution\n  detection?","summary":"  Out-of-distribution (OOD) detection is a critical task for reliable machine\nlearning. Recent advances in representation learning give rise to\ndistance-based OOD detection, where testing samples are detected as OOD if they\nare relatively far away from the centroids or prototypes of in-distribution\n(ID) classes. However, prior methods directly take off-the-shelf contrastive\nlosses that suffice for classifying ID samples, but are not optimally designed\nwhen test inputs contain OOD samples. In this work, we propose CIDER, a novel\nrepresentation learning framework that exploits hyperspherical embeddings for\nOOD detection. CIDER jointly optimizes two losses to promote strong ID-OOD\nseparability: a dispersion loss that promotes large angular distances among\ndifferent class prototypes, and a compactness loss that encourages samples to\nbe close to their class prototypes. We analyze and establish the unexplored\nrelationship between OOD detection performance and the embedding properties in\nthe hyperspherical space, and demonstrate the importance of dispersion and\ncompactness. CIDER establishes superior performance, outperforming the latest\nrival by 19.36% in FPR95. Code is available at\nhttps://github.com/deeplearning-wisc/cider.\n","authors":["Yifei Ming","Yiyou Sun","Ousmane Dia","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2203.04450v2.pdf","comment":"Published at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.03516v2","updated":"2023-02-28T19:56:16Z","published":"2022-12-07T08:46:04Z","title":"Site Assessment and Layout Optimization for Rooftop Solar Energy\n  Generation in Worldview-3 Imagery","summary":"  With the growth of residential rooftop PV adoption in recent decades, the\nproblem of effective layout design has become increasingly important in recent\nyears. Although a number of automated methods have been introduced, these tend\nto rely on simplifying assumptions and heuristics to improve computational\ntractability. We demonstrate a fully automated layout design pipeline that\nattempts to solve a more general formulation with greater geometric flexibility\nthat accounts for shading losses. Our approach generates rooftop areas from\nsatellite imagery and uses MINLP optimization to select panel positions,\nazimuth angles and tilt angles on an individual basis rather than imposing any\npredefined layouts. Our results demonstrate that shading plays a critical role\nin automated rooftop PV optimization and significantly changes the resulting\nlayouts. Additionally, they suggest that, although several common heuristics\nare often effective, they may not be universally suitable due to complications\nresulting from geometric restrictions and shading losses. Finally, we evaluate\na few specific heuristics from the literature and propose a potential new rule\nof thumb that may help improve rooftop solar energy potential when shading\neffects are considered.\n","authors":["Zeyad Awwad","Abdulaziz Alharbi","Abdulelah H. Habib","Olivier L. de Weck"],"pdf_url":"https://arxiv.org/pdf/2212.03516v2.pdf","comment":"Final draft"},{"id":"http://arxiv.org/abs/2303.00050v1","updated":"2023-02-28T19:47:30Z","published":"2023-02-28T19:47:30Z","title":"Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface","summary":"  Reconstructing general dynamic scenes is important for many computer vision\nand graphics applications. Recent works represent the dynamic scene with neural\nradiance fields for photorealistic view synthesis, while their surface geometry\nis under-constrained and noisy. Other works introduce surface constraints to\nthe implicit neural representation to disentangle the ambiguity of geometry and\nappearance field for static scene reconstruction. To bridge the gap between\nrendering dynamic scenes and recovering static surface geometry, we propose a\ntemplate-free method to reconstruct surface geometry and appearance using\nneural implicit representations from multi-view videos. We leverage\ntopology-aware deformation and the signed distance field to learn complex\ndynamic surfaces via differentiable volume rendering without scene-specific\nprior knowledge like template models. Furthermore, we propose a novel\nmask-based ray selection strategy to significantly boost the optimization on\nchallenging time-varying regions. Experiments on different multi-view video\ndatasets demonstrate that our method achieves high-fidelity surface\nreconstruction as well as photorealistic novel view synthesis.\n","authors":["Decai Chen","Haofei Lu","Ingo Feldmann","Oliver Schreer","Peter Eisert"],"pdf_url":"https://arxiv.org/pdf/2303.00050v1.pdf","comment":"5 pages, accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00040v1","updated":"2023-02-28T19:29:05Z","published":"2023-02-28T19:29:05Z","title":"Towards Generalisable Video Moment Retrieval: Visual-Dynamic Injection\n  to Image-Text Pre-Training","summary":"  The correlation between the vision and text is essential for video moment\nretrieval (VMR), however, existing methods heavily rely on separate\npre-training feature extractors for visual and textual understanding. Without\nsufficient temporal boundary annotations, it is non-trivial to learn universal\nvideo-text alignments. In this work, we explore multi-modal correlations\nderived from large-scale image-text data to facilitate generalisable VMR. To\naddress the limitations of image-text pre-training models on capturing the\nvideo changes, we propose a generic method, referred to as Visual-Dynamic\nInjection (VDI), to empower the model's understanding of video moments. Whilst\nexisting VMR methods are focusing on building temporal-aware video features,\nbeing aware of the text descriptions about the temporal changes is also\ncritical but originally overlooked in pre-training by matching static images\nwith sentences. Therefore, we extract visual context and spatial dynamic\ninformation from video frames and explicitly enforce their alignments with the\nphrases describing video changes (e.g. verb). By doing so, the potentially\nrelevant visual and motion patterns in videos are encoded in the corresponding\ntext embeddings (injected) so to enable more accurate video-text alignments. We\nconduct extensive experiments on two VMR benchmark datasets (Charades-STA and\nActivityNet-Captions) and achieve state-of-the-art performances. Especially,\nVDI yields notable advantages when being tested on the out-of-distribution\nsplits where the testing samples involve novel scenes and vocabulary.\n","authors":["Dezhao Luo","Jiabo Huang","Shaogang Gong","Hailin Jin","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2303.00040v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2302.14835v1","updated":"2023-02-28T18:32:16Z","published":"2023-02-28T18:32:16Z","title":"Novel Machine Learning Approach for Predicting Poverty using Temperature\n  and Remote Sensing Data in Ethiopia","summary":"  In many developing nations, a lack of poverty data prevents critical\nhumanitarian organizations from responding to large-scale crises. Currently,\nsocioeconomic surveys are the only method implemented on a large scale for\norganizations and researchers to measure and track poverty. However, the\ninability to collect survey data efficiently and inexpensively leads to\nsignificant temporal gaps in poverty data; these gaps severely limit the\nability of organizational entities to address poverty at its root cause. We\npropose a transfer learning model based on surface temperature change and\nremote sensing data to extract features useful for predicting poverty rates.\nMachine learning, supported by data sources of poverty indicators, has the\npotential to estimate poverty rates accurately and within strict time\nconstraints. Higher temperatures, as a result of climate change, have caused\nnumerous agricultural obstacles, socioeconomic issues, and environmental\ndisruptions, trapping families in developing countries in cycles of poverty. To\nfind patterns of poverty relating to temperature that have the highest\ninfluence on spatial poverty rates, we use remote sensing data. The two-step\ntransfer model predicts the temperature delta from high resolution satellite\nimagery and then extracts image features useful for predicting poverty. The\nresulting model achieved 80% accuracy on temperature prediction. This method\ntakes advantage of abundant satellite and temperature data to measure poverty\nin a manner comparable to the existing survey methods and exceeds similar\nmodels of poverty prediction.\n","authors":["Om Shah","Krti Tallam"],"pdf_url":"https://arxiv.org/pdf/2302.14835v1.pdf","comment":"12 pages, 3 figures, title page included"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.03561v2","updated":"2023-02-28T16:41:22Z","published":"2023-02-07T16:17:25Z","title":"Optimizing Audio Recommendations for the Long-Term: A Reinforcement\n  Learning Perspective","summary":"  We study the problem of optimizing a recommender system for outcomes that\noccur over several weeks or months. We begin by drawing on reinforcement\nlearning to formulate a comprehensive model of users' recurring relationships\nwith a recommender system. Measurement, attribution, and coordination\nchallenges complicate algorithm design. We describe careful modeling --\nincluding a new representation of user state and key conditional independence\nassumptions -- which overcomes these challenges and leads to simple, testable\nrecommender system prototypes. We apply our approach to a podcast recommender\nsystem that makes personalized recommendations to hundreds of millions of\nlisteners. A/B tests demonstrate that purposefully optimizing for long-term\noutcomes leads to large performance gains over conventional approaches that\noptimize for short-term proxies.\n","authors":["Lucas Maystre","Daniel Russo","Yu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.03561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14723v1","updated":"2023-02-28T16:32:38Z","published":"2023-02-28T16:32:38Z","title":"Extending English IR methods to multi-lingual IR","summary":"  This paper describes our participation in the 2023 WSDM CUP - MIRACL\nchallenge. Via a combination of i) document translation; ii) multilingual\nSPLADE and Contriever; and iii) multilingual RankT5 and many other models, we\nwere able to get first place in both the known and surprise languages tracks.\nOur strategy mostly revolved around getting the most diverse runs for the first\nstage and then throwing all possible reranking techniques. While this was not a\nfirst for many techniques, we had some things that we believe were never tried\nbefore, for example, we train the first SPLADE model that is effectively\ncapable of working in more than 10 languages. However, a more careful study of\nthe results is needed in order to verify if we were able to get first place\njust due to brute force or if the hybrids we developed really brought\nimprovements over the other team's solutions.\n","authors":["Carlos Lassance"],"pdf_url":"https://arxiv.org/pdf/2302.14723v1.pdf","comment":"Description of the runs that got 1st place on both tasks at WSDM CUP\n  2023 - MIRACL"},{"id":"http://arxiv.org/abs/2302.14640v1","updated":"2023-02-28T15:18:42Z","published":"2023-02-28T15:18:42Z","title":"Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start\n  Recommendation","summary":"  Sequential recommenders have made great strides in capturing a user's\npreferences. Nevertheless, the cold-start recommendation remains a fundamental\nchallenge in which only a few user-item interactions are available for\npersonalization. Gradient-based meta-learning approaches have recently emerged\nin the sequential recommendation field due to their fast adaptation and\neasy-to-integrate abilities. The meta-learning algorithms formulate the\ncold-start recommendation as a few-shot learning problem, where each user is\nrepresented as a task to be adapted. However, while meta-learning algorithms\ngenerally assume that task-wise samples are evenly distributed over classes or\nvalues, user-item interactions are not that way in real-world applications\n(e.g., watching favorite videos multiple times, leaving only good ratings and\nno bad ones). As a result, in the real-world, imbalanced user feedback that\naccounts for most task training data may dominate the user adaptation and\nprevent meta-learning algorithms from learning meaningful meta-knowledge for\npersonalized recommendations. To alleviate this limitation, we propose a novel\nsequential recommendation framework based on gradient-based meta-learning that\ncaptures the imbalance of each user's rating distribution and accordingly\ncomputes adaptive loss for user-specific learning. It is the first work to\ntackle the impact of imbalanced ratings in cold-start sequential recommendation\nscenarios. We design adaptive weighted loss and improve the existing\nmeta-learning algorithms for state-of-the-art sequential recommendation\nmethods. Extensive experiments conducted on real-world datasets demonstrate the\neffectiveness of our framework.\n","authors":["Minchang Kim","Yongjin Yang","Jung Hyun Ryu","Taesup Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14534v1","updated":"2023-02-28T12:44:10Z","published":"2023-02-28T12:44:10Z","title":"Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face","summary":"  We present Spacerini, a modular framework for seamless building and\ndeployment of interactive search applications, designed to facilitate the\nqualitative analysis of large scale research datasets. Spacerini integrates\nfeatures from both the Pyserini toolkit and the Hugging Face ecosystem to ease\nthe indexing text collections and deploy them as search engines for ad-hoc\nexploration and to make the retrieval of relevant data points quick and\nefficient. The user-friendly interface enables searching through massive\ndatasets in a no-code fashion, making Spacerini broadly accessible to anyone\nlooking to qualitatively audit their text collections. This is useful both to\nIR~researchers aiming to demonstrate the capabilities of their indexes in a\nsimple and interactive way, and to NLP~researchers looking to better understand\nand audit the failure modes of large language models. The framework is open\nsource and available on GitHub: https://github.com/castorini/hf-spacerini, and\nincludes utilities to load, pre-process, index, and deploy local and web search\napplications. A portfolio of applications created with Spacerini for a\nmultitude of use cases can be found by visiting https://hf.co/spacerini.\n","authors":["Christopher Akiki","Odunayo Ogundepo","Aleksandra Piktus","Xinyu Zhang","Akintunde Oladipo","Jimmy Lin","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2302.14534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14532v1","updated":"2023-02-28T12:43:17Z","published":"2023-02-28T12:43:17Z","title":"Rethinking Multi-Interest Learning for Candidate Matching in Recommender\n  Systems","summary":"  Existing research efforts for multi-interest candidate matching in\nrecommender systems mainly focus on improving model architecture or\nincorporating additional information, neglecting the importance of training\nschemes. This work revisits the training framework and uncovers two major\nproblems hindering the expressiveness of learned multi-interest\nrepresentations. First, the current training objective (i.e., uniformly sampled\nsoftmax) fails to effectively train discriminative representations in a\nmulti-interest learning scenario due to the severe increase in easy negative\nsamples. Second, a routing collapse problem is observed where each learned\ninterest may collapse to express information only from a single item, resulting\nin information loss. To address these issues, we propose the REMI framework,\nconsisting of an Interest-aware Hard Negative mining strategy (IHN) and a\nRouting Regularization (RR) method. IHN emphasizes interest-aware hard\nnegatives by proposing an ideal sampling distribution and developing a\nMonte-Carlo strategy for efficient approximation. RR prevents routing collapse\nby introducing a novel regularization term on the item-to-interest routing\nmatrices. These two components enhance the learned multi-interest\nrepresentations from both the optimization objective and the composition\ninformation. REMI is a general framework that can be readily applied to various\nexisting multi-interest candidate matching methods. Experiments on three\nreal-world datasets show our method can significantly improve state-of-the-art\nmethods with easy implementation and negligible computational overhead. The\nsource code will be released.\n","authors":["Yueqi Xie","Jingqi Gao","Peilin Zhou","Qichen Ye","Yining Hua","Jaeboum Kim","Fangzhao Wu","Sunghun Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10632v3","updated":"2023-02-28T12:13:25Z","published":"2023-02-21T12:44:17Z","title":"Multi-Modal Self-Supervised Learning for Recommendation","summary":"  The online emergence of multi-modal sharing platforms (eg, TikTok, Youtube)\nis powering personalized recommender systems to incorporate various modalities\n(eg, visual, textual and acoustic) into the latent user representations. While\nexisting works on multi-modal recommendation exploit multimedia content\nfeatures in enhancing item embeddings, their model representation capability is\nlimited by heavy label reliance and weak robustness on sparse user behavior\ndata. Inspired by the recent progress of self-supervised learning in\nalleviating label scarcity issue, we explore deriving self-supervision signals\nwith effectively learning of modality-aware user preference and cross-modal\ndependencies. To this end, we propose a new Multi-Modal Self-Supervised\nLearning (MMSSL) method which tackles two key challenges. Specifically, to\ncharacterize the inter-dependency between the user-item collaborative view and\nitem multi-modal semantic view, we design a modality-aware interactive\nstructure learning paradigm via adversarial perturbations for data\naugmentation. In addition, to capture the effects that user's modality-aware\ninteraction pattern would interweave with each other, a cross-modal contrastive\nlearning approach is introduced to jointly preserve the inter-modal semantic\ncommonality and user preference diversity. Experiments on real-world datasets\nverify the superiority of our method in offering great potential for multimedia\nrecommendation over various state-of-the-art baselines. The implementation is\nreleased at: https://github.com/HKUDS/MMSSL.\n","authors":["Wei Wei","Chao Huang","Lianghao Xia","Chuxu Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.10632v3.pdf","comment":"This paper has been published as a full paper at WWW 2023"},{"id":"http://arxiv.org/abs/2210.09957v2","updated":"2023-02-28T10:26:48Z","published":"2022-10-18T16:11:55Z","title":"Contextual bandits with concave rewards, and an application to fair\n  ranking","summary":"  We consider Contextual Bandits with Concave Rewards (CBCR), a multi-objective\nbandit problem where the desired trade-off between the rewards is defined by a\nknown concave objective function, and the reward vector depends on an observed\nstochastic context. We present the first algorithm with provably vanishing\nregret for CBCR without restrictions on the policy space, whereas prior works\nwere restricted to finite policy spaces or tabular representations. Our\nsolution is based on a geometric interpretation of CBCR algorithms as\noptimization algorithms over the convex set of expected rewards spanned by all\nstochastic policies. Building on Frank-Wolfe analyses in constrained convex\noptimization, we derive a novel reduction from the CBCR regret to the regret of\na scalar-reward bandit problem. We illustrate how to apply the reduction\noff-the-shelf to obtain algorithms for CBCR with both linear and general reward\nfunctions, in the case of non-combinatorial actions. Motivated by fairness in\nrecommendation, we describe a special case of CBCR with rankings and\nfairness-aware objectives, leading to the first algorithm with regret\nguarantees for contextual combinatorial bandits with fairness of exposure.\n","authors":["Virginie Do","Elvis Dohmatob","Matteo Pirotta","Alessandro Lazaric","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2210.09957v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14438v1","updated":"2023-02-28T09:30:24Z","published":"2023-02-28T09:30:24Z","title":"Self-Supervised Interest Transfer Network via Prototypical Contrastive\n  Learning for Recommendation","summary":"  Cross-domain recommendation has attracted increasing attention from industry\nand academia recently. However, most existing methods do not exploit the\ninterest invariance between domains, which would yield sub-optimal solutions.\nIn this paper, we propose a cross-domain recommendation method: Self-supervised\nInterest Transfer Network (SITN), which can effectively transfer invariant\nknowledge between domains via prototypical contrastive learning. Specifically,\nwe perform two levels of cross-domain contrastive learning: 1)\ninstance-to-instance contrastive learning, 2) instance-to-cluster contrastive\nlearning. Not only that, we also take into account users' multi-granularity and\nmulti-view interests. With this paradigm, SITN can explicitly learn the\ninvariant knowledge of interest clusters between domains and accurately capture\nusers' intents and preferences. We conducted extensive experiments on a public\ndataset and a large-scale industrial dataset collected from one of the world's\nleading e-commerce corporations. The experimental results indicate that SITN\nachieves significant improvements over state-of-the-art recommendation methods.\nAdditionally, SITN has been deployed on a micro-video recommendation platform,\nand the online A/B testing results further demonstrate its practical value.\nSupplement is available at: https://github.com/fanqieCoffee/SITN-Supplement.\n","authors":["Guoqiang Sun","Yibin Shen","Sijin Zhou","Xiang Chen","Hongyan Liu","Chunming Wu","Chenyi Lei","Xianhui Wei","Fei Fang"],"pdf_url":"https://arxiv.org/pdf/2302.14438v1.pdf","comment":"9 pages, 3 figures, accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.14395v1","updated":"2023-02-28T08:23:15Z","published":"2023-02-28T08:23:15Z","title":"Item Cold Start Recommendation via Adversarial Variational Auto-encoder\n  Warm-up","summary":"  The gap between the randomly initialized item ID embedding and the\nwell-trained warm item ID embedding makes the cold items hard to suit the\nrecommendation system, which is trained on the data of historical warm items.\nTo alleviate the performance decline of new items recommendation, the\ndistribution of the new item ID embedding should be close to that of the\nhistorical warm items. To achieve this goal, we propose an Adversarial\nVariational Auto-encoder Warm-up model (AVAEW) to generate warm-up item ID\nembedding for cold items. Specifically, we develop a conditional variational\nauto-encoder model to leverage the side information of items for generating the\nwarm-up item ID embedding. Particularly, we introduce an adversarial module to\nenforce the alignment between warm-up item ID embedding distribution and\nhistorical item ID embedding distribution. We demonstrate the effectiveness and\ncompatibility of the proposed method by extensive offline experiments on public\ndatasets and online A/B tests on a real-world large-scale news recommendation\nplatform.\n","authors":["Shenzheng Zhang","Qi Tan","Xinzhi Zheng","Yi Ren","Xu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.14395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09000v2","updated":"2023-02-28T04:18:29Z","published":"2022-09-19T13:25:38Z","title":"Reweighting Clicks with Dwell Time in Recommendation","summary":"  The click behavior is the most widely-used user positive feedback in\nrecommendation. However, simply considering each click equally in training may\nsuffer from clickbaits and title-content mismatching, and thus fail to\nprecisely capture users' real satisfaction on items. Dwell time could be viewed\nas a high-quality quantitative indicator of user preferences on each click,\nwhile existing recommendation models do not fully explore the modeling of dwell\ntime. In this work, we focus on reweighting clicks with dwell time in\nrecommendation. Precisely, we first define a new behavior named valid read,\nwhich helps to select high-quality click instances for different users and\nitems via dwell time. Next, we propose a normalized dwell time function to\nreweight click signals in training for recommendation. The Click reweighting\nmodel achieves significant improvements on both offline and online evaluations\nin real-world systems.\n","authors":["Ruobing Xie","Lin Ma","Shaoliang Zhang","Feng Xia","Leyu Lin"],"pdf_url":"https://arxiv.org/pdf/2209.09000v2.pdf","comment":"5 pages, accepted by WWW-2023 Companion"},{"id":"http://arxiv.org/abs/2303.00135v1","updated":"2023-02-28T23:40:41Z","published":"2023-02-28T23:40:41Z","title":"Deep learning for COVID-19 topic modelling via Twitter: Alpha, Delta and\n  Omicron","summary":"  Topic modelling with innovative deep learning methods has gained interest for\na wide range of applications that includes COVID-19. Topic modelling can\nprovide, psychological, social and cultural insights for understanding human\nbehaviour in extreme events such as the COVID-19 pandemic. In this paper, we\nuse prominent deep learning-based language models for COVID-19 topic modelling\ntaking into account data from emergence (Alpha) to the Omicron variant. We\napply topic modeling to review the public behaviour across the first, second\nand third waves based on Twitter dataset from India. Our results show that the\ntopics extracted for the subsequent waves had certain overlapping themes such\nas covers governance, vaccination, and pandemic management while novel issues\naroused in political, social and economic situation during COVID-19 pandemic.\nWe also found a strong correlation of the major topics qualitatively to news\nmedia prevalent at the respective time period. Hence, our framework has the\npotential to capture major issues arising during different phases of the\nCOVID-19 pandemic which can be extended to other countries and regions.\n","authors":["Janhavi Lande","Arti Pillay","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2303.00135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14757v1","updated":"2023-02-28T16:59:13Z","published":"2023-02-28T16:59:13Z","title":"Audio Retrieval for Multimodal Design Documents: A New Dataset and\n  Algorithms","summary":"  We consider and propose a new problem of retrieving audio files relevant to\nmultimodal design document inputs comprising both textual elements and visual\nimagery, e.g., birthday/greeting cards. In addition to enhancing user\nexperience, integrating audio that matches the theme/style of these inputs also\nhelps improve the accessibility of these documents (e.g., visually impaired\npeople can listen to the audio instead). While recent work in audio retrieval\nexists, these methods and datasets are targeted explicitly towards natural\nimages. However, our problem considers multimodal design documents (created by\nusers using creative software) substantially different from a naturally clicked\nphotograph. To this end, our first contribution is collecting and curating a\nnew large-scale dataset called Melodic-Design (or MELON), comprising design\ndocuments representing various styles, themes, templates, illustrations, etc.,\npaired with music audio. Given our paired image-text-audio dataset, our next\ncontribution is a novel multimodal cross-attention audio retrieval (MMCAR)\nalgorithm that enables training neural networks to learn a common shared\nfeature space across image, text, and audio dimensions. We use these learned\nfeatures to demonstrate that our method outperforms existing state-of-the-art\nmethods and produce a new reference benchmark for the research community on our\nnew dataset.\n","authors":["Prachi Singh","Srikrishna Karanam","Sumit Shekhar"],"pdf_url":"https://arxiv.org/pdf/2302.14757v1.pdf","comment":"5 pages including references"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.14853v1","updated":"2023-02-28T18:51:55Z","published":"2023-02-28T18:51:55Z","title":"An Efficient Tester-Learner for Halfspaces","summary":"  We give the first efficient algorithm for learning halfspaces in the testable\nlearning model recently defined by Rubinfeld and Vasilyan (2023). In this\nmodel, a learner certifies that the accuracy of its output hypothesis is near\noptimal whenever the training set passes an associated test, and training sets\ndrawn from some target distribution -- e.g., the Gaussian -- must pass the\ntest. This model is more challenging than distribution-specific agnostic or\nMassart noise models where the learner is allowed to fail arbitrarily if the\ndistributional assumption does not hold.\n  We consider the setting where the target distribution is Gaussian (or more\ngenerally any strongly log-concave distribution) in $d$ dimensions and the\nnoise model is either Massart or adversarial (agnostic). For Massart noise our\ntester-learner runs in polynomial time and outputs a hypothesis with error\n$\\mathsf{opt} + \\epsilon$, which is information-theoretically optimal. For\nadversarial noise our tester-learner has error $\\tilde{O}(\\mathsf{opt}) +\n\\epsilon$ and runs in quasipolynomial time.\n  Prior work on testable learning ignores the labels in the training set and\nchecks that the empirical moments of the covariates are close to the moments of\nthe base distribution. Here we develop new tests of independent interest that\nmake critical use of the labels and combine them with the moment-matching\napproach of Gollakota et al. (2023). This enables us to simulate a variant of\nthe algorithm of Diakonikolas et al. (2020) for learning noisy halfspaces using\nnonconvex SGD but in the testable learning setting.\n","authors":["Aravind Gollakota","Adam R. Klivans","Konstantinos Stavropoulos","Arsen Vasilyan"],"pdf_url":"https://arxiv.org/pdf/2302.14853v1.pdf","comment":"23 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.10261v2","updated":"2023-02-28T18:50:45Z","published":"2023-02-20T19:47:25Z","title":"Deep Reinforcement Learning for Cost-Effective Medical Diagnosis","summary":"  Dynamic diagnosis is desirable when medical tests are costly or\ntime-consuming. In this work, we use reinforcement learning (RL) to find a\ndynamic policy that selects lab test panels sequentially based on previous\nobservations, ensuring accurate testing at a low cost. Clinical diagnostic data\nare often highly imbalanced; therefore, we aim to maximize the $F_1$ score\ninstead of the error rate. However, optimizing the non-concave $F_1$ score is\nnot a classic RL problem, thus invalidates standard RL methods. To remedy this\nissue, we develop a reward shaping approach, leveraging properties of the $F_1$\nscore and duality of policy optimization, to provably find the set of all\nPareto-optimal policies for budget-constrained $F_1$ score maximization. To\nhandle the combinatorially complex state space, we propose a Semi-Model-based\nDeep Diagnosis Policy Optimization (SM-DDPO) framework that is compatible with\nend-to-end training and online learning. SM-DDPO is tested on diverse clinical\ntasks: ferritin abnormality detection, sepsis mortality prediction, and acute\nkidney injury diagnosis. Experiments with real-world data validate that SM-DDPO\ntrains efficiently and identifies all Pareto-front solutions. Across all tasks,\nSM-DDPO is able to achieve state-of-the-art diagnosis accuracy (in some cases\nhigher than conventional methods) with up to $85\\%$ reduction in testing cost.\nThe code is available at\n[https://github.com/Zheng321/Deep-Reinforcement-Learning-for-Cost-Effective-Medical-Diagnosis].\n","authors":["Zheng Yu","Yikuan Li","Joseph Kim","Kaixuan Huang","Yuan Luo","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2302.10261v2.pdf","comment":"Accepted to ICRL 2023"},{"id":"http://arxiv.org/abs/2302.14843v1","updated":"2023-02-28T18:42:11Z","published":"2023-02-28T18:42:11Z","title":"High Probability Convergence of Stochastic Gradient Methods","summary":"  In this work, we describe a generic approach to show convergence with high\nprobability for both stochastic convex and non-convex optimization with\nsub-Gaussian noise. In previous works for convex optimization, either the\nconvergence is only in expectation or the bound depends on the diameter of the\ndomain. Instead, we show high probability convergence with bounds depending on\nthe initial distance to the optimal solution. The algorithms use step sizes\nanalogous to the standard settings and are universal to Lipschitz functions,\nsmooth functions, and their linear combinations. This method can be applied to\nthe non-convex case. We demonstrate an\n$O((1+\\sigma^{2}\\log(1/\\delta))/T+\\sigma/\\sqrt{T})$ convergence rate when the\nnumber of iterations $T$ is known and an\n$O((1+\\sigma^{2}\\log(T/\\delta))/\\sqrt{T})$ convergence rate when $T$ is unknown\nfor SGD, where $1-\\delta$ is the desired success probability. These bounds\nimprove over existing bounds in the literature. Additionally, we demonstrate\nthat our techniques can be used to obtain high probability bound for\nAdaGrad-Norm (Ward et al., 2019) that removes the bounded gradients assumption\nfrom previous works. Furthermore, our technique for AdaGrad-Norm extends to the\nstandard per-coordinate AdaGrad algorithm (Duchi et al., 2011), providing the\nfirst noise-adapted high probability convergence for AdaGrad.\n","authors":["Zijian Liu","Ta Duy Nguyen","Thien Hang Nguyen","Alina Ene","Huy Lê Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.14843v1.pdf","comment":"This paper subsumes arXiv paper arxiv:2210.00679"},{"id":"http://arxiv.org/abs/2210.06184v2","updated":"2023-02-28T18:40:52Z","published":"2022-10-07T17:27:50Z","title":"Images as Weight Matrices: Sequential Image Generation Through Synaptic\n  Learning Rules","summary":"  Work on fast weight programmers has demonstrated the effectiveness of\nkey/value outer product-based learning rules for sequentially generating a\nweight matrix (WM) of a neural net (NN) by another NN or itself. However, the\nweight generation steps are typically not visually interpretable by humans,\nbecause the contents stored in the WM of an NN are not. Here we apply the same\nprinciple to generate natural images. The resulting fast weight painters (FPAs)\nlearn to execute sequences of delta learning rules to sequentially generate\nimages as sums of outer products of self-invented keys and values, one rank at\na time, as if each image was a WM of an NN. We train our FPAs in the generative\nadversarial networks framework, and evaluate on various image datasets. We show\nhow these generic learning rules can generate images with respectable visual\nquality without any explicit inductive bias for images. While the performance\nlargely lags behind the one of specialised state-of-the-art image generators,\nour approach allows for visualising how synaptic learning rules iteratively\nproduce complex connection patterns, yielding human-interpretable meaningful\nimages. Finally, we also show that an additional convolutional U-Net (now\npopular in diffusion models) at the output of an FPA can learn one-step\n\"denoising\" of FPA-generated images to enhance their quality. Our code is\npublic.\n","authors":["Kazuki Irie","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2210.06184v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2210.09879v3","updated":"2023-02-28T18:35:23Z","published":"2022-10-18T14:13:20Z","title":"Unsupervised visualization of image datasets using contrastive learning","summary":"  Visualization methods based on the nearest neighbor graph, such as t-SNE or\nUMAP, are widely used for visualizing high-dimensional data. Yet, these\napproaches only produce meaningful results if the nearest neighbors themselves\nare meaningful. For images represented in pixel space this is not the case, as\ndistances in pixel space are often not capturing our sense of similarity and\ntherefore neighbors are not semantically close. This problem can be\ncircumvented by self-supervised approaches based on contrastive learning, such\nas SimCLR, relying on data augmentation to generate implicit neighbors, but\nthese methods do not produce two-dimensional embeddings suitable for\nvisualization. Here, we present a new method, called t-SimCNE, for unsupervised\nvisualization of image data. T-SimCNE combines ideas from contrastive learning\nand neighbor embeddings, and trains a parametric mapping from the\nhigh-dimensional pixel space into two dimensions. We show that the resulting 2D\nembeddings achieve classification accuracy comparable to the state-of-the-art\nhigh-dimensional SimCLR representations, thus faithfully capturing semantic\nrelationships. Using t-SimCNE, we obtain informative visualizations of the\nCIFAR-10 and CIFAR-100 datasets, showing rich cluster structure and\nhighlighting artifacts and outliers.\n","authors":["Jan Niklas Böhm","Philipp Berens","Dmitry Kobak"],"pdf_url":"https://arxiv.org/pdf/2210.09879v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2205.00511v2","updated":"2023-02-28T18:33:27Z","published":"2022-05-01T16:42:05Z","title":"An Early Fault Detection Method of Rotating Machines Based on Multiple\n  Feature Fusion with Stacking Architecture","summary":"  Early fault detection (EFD) of rotating machines is important to decrease the\nmaintenance cost and improve the mechanical system stability. One of the key\npoints of EFD is developing a generic model to extract robust and\ndiscriminative features from different equipment for early fault detection.\nMost existing EFD methods focus on learning fault representation by one type of\nfeature. However, a combination of multiple features can capture a more\ncomprehensive representation of system state. In this paper, we propose an EFD\nmethod based on multiple feature fusion with stacking architecture (M2FSA). The\nproposed method can extract generic and discriminiative features to detect\nearly faults by combining time domain (TD), frequency domain (FD), and\ntime-frequency domain (TFD) features. In order to unify the dimensions of the\ndifferent domain features, Stacked Denoising Autoencoder (SDAE) is utilized to\nlearn deep features in three domains. The architecture of the proposed M2FSA\nconsists of two layers. The first layer contains three base models, whose\ncorresponding inputs are different deep features. The outputs of the first\nlayer are concatenated to generate the input to the second layer, which\nconsists of a meta model. The proposed method is tested on three bearing\ndatasets. The results demonstrate that the proposed method is better than\nexisting methods both in sensibility and reliability.\n","authors":["Wenbin Song","Di Wu","Weiming Shen","Benoit Boulet"],"pdf_url":"https://arxiv.org/pdf/2205.00511v2.pdf","comment":"The results require to be updated"},{"id":"http://arxiv.org/abs/2302.14835v1","updated":"2023-02-28T18:32:16Z","published":"2023-02-28T18:32:16Z","title":"Novel Machine Learning Approach for Predicting Poverty using Temperature\n  and Remote Sensing Data in Ethiopia","summary":"  In many developing nations, a lack of poverty data prevents critical\nhumanitarian organizations from responding to large-scale crises. Currently,\nsocioeconomic surveys are the only method implemented on a large scale for\norganizations and researchers to measure and track poverty. However, the\ninability to collect survey data efficiently and inexpensively leads to\nsignificant temporal gaps in poverty data; these gaps severely limit the\nability of organizational entities to address poverty at its root cause. We\npropose a transfer learning model based on surface temperature change and\nremote sensing data to extract features useful for predicting poverty rates.\nMachine learning, supported by data sources of poverty indicators, has the\npotential to estimate poverty rates accurately and within strict time\nconstraints. Higher temperatures, as a result of climate change, have caused\nnumerous agricultural obstacles, socioeconomic issues, and environmental\ndisruptions, trapping families in developing countries in cycles of poverty. To\nfind patterns of poverty relating to temperature that have the highest\ninfluence on spatial poverty rates, we use remote sensing data. The two-step\ntransfer model predicts the temperature delta from high resolution satellite\nimagery and then extracts image features useful for predicting poverty. The\nresulting model achieved 80% accuracy on temperature prediction. This method\ntakes advantage of abundant satellite and temperature data to measure poverty\nin a manner comparable to the existing survey methods and exceeds similar\nmodels of poverty prediction.\n","authors":["Om Shah","Krti Tallam"],"pdf_url":"https://arxiv.org/pdf/2302.14835v1.pdf","comment":"12 pages, 3 figures, title page included"},{"id":"http://arxiv.org/abs/2302.14833v1","updated":"2023-02-28T18:31:07Z","published":"2023-02-28T18:31:07Z","title":"Learning to Control Autonomous Fleets from Observation via Offline\n  Reinforcement Learning","summary":"  Autonomous Mobility-on-Demand (AMoD) systems are a rapidly evolving mode of\ntransportation in which a centrally coordinated fleet of self-driving vehicles\ndynamically serves travel requests. The control of these systems is typically\nformulated as a large network optimization problem, and reinforcement learning\n(RL) has recently emerged as a promising approach to solve the open challenges\nin this space. However, current RL-based approaches exclusively focus on\nlearning from online data, fundamentally ignoring the per-sample-cost of\ninteractions within real-world transportation systems. To address these\nlimitations, we propose to formalize the control of AMoD systems through the\nlens of offline reinforcement learning and learn effective control strategies\nvia solely offline data, thus readily available to current mobility operators.\nWe further investigate design decisions and provide experiments on real-world\nmobility systems showing how offline learning allows to recover AMoD control\npolicies that (i) exhibit performance on par with online methods, (ii)\ndrastically improve data efficiency, and (iii) completely eliminate the need\nfor complex simulated environments. Crucially, this paper demonstrates that\noffline reinforcement learning is a promising paradigm for the application of\nRL-based solutions within economically-critical systems, such as mobility\nsystems.\n","authors":["Carolin Schmidt","Daniele Gammelli","Francisco Camara Pereira","Filipe Rodrigues"],"pdf_url":"https://arxiv.org/pdf/2302.14833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.00112v2","updated":"2023-02-28T18:30:57Z","published":"2022-10-31T19:35:15Z","title":"Indexability is Not Enough for Whittle: Improved, Near-Optimal\n  Algorithms for Restless Bandits","summary":"  We study the problem of planning restless multi-armed bandits (RMABs) with\nmultiple actions. This is a popular model for multi-agent systems with\napplications like multi-channel communication, monitoring and machine\nmaintenance tasks, and healthcare. Whittle index policies, which are based on\nLagrangian relaxations, are widely used in these settings due to their\nsimplicity and near-optimality under certain conditions. In this work, we first\nshow that Whittle index policies can fail in simple and practically relevant\nRMAB settings, even when the RMABs are indexable. We discuss why the optimality\nguarantees fail and why asymptotic optimality may not translate well to\npractically relevant planning horizons.\n  We then propose an alternate planning algorithm based on the mean-field\nmethod, which can provably and efficiently obtain near-optimal policies with a\nlarge number of arms, without the stringent structural assumptions required by\nthe Whittle index policies. This borrows ideas from existing research with some\nimprovements: our approach is hyper-parameter free, and we provide an improved\nnon-asymptotic analysis which has: (a) no requirement for exogenous\nhyper-parameters and tighter polynomial dependence on known problem parameters;\n(b) high probability bounds which show that the reward of the policy is\nreliable; and (c) matching sub-optimality lower bounds for this algorithm with\nrespect to the number of arms, thus demonstrating the tightness of our bounds.\nOur extensive experimental analysis shows that the mean-field approach matches\nor outperforms other baselines.\n","authors":["Abheek Ghosh","Dheeraj Nagaraj","Manish Jain","Milind Tambe"],"pdf_url":"https://arxiv.org/pdf/2211.00112v2.pdf","comment":"21 pages; AAMAS'23 version with appendix"},{"id":"http://arxiv.org/abs/2302.09956v2","updated":"2023-02-28T18:30:37Z","published":"2023-02-20T12:57:31Z","title":"Because Every Sensor Is Unique, so Is Every Pair: Handling Dynamicity in\n  Traffic Forecasting","summary":"  Traffic forecasting is a critical task to extract values from cyber-physical\ninfrastructures, which is the backbone of smart transportation. However owing\nto external contexts, the dynamics at each sensor are unique. For example, the\nafternoon peaks at sensors near schools are more likely to occur earlier than\nthose near residential areas. In this paper, we first analyze real-world\ntraffic data to show that each sensor has a unique dynamic. Further analysis\nalso shows that each pair of sensors also has a unique dynamic. Then, we\nexplore how node embedding learns the unique dynamics at every sensor location.\nNext, we propose a novel module called Spatial Graph Transformers (SGT) where\nwe use node embedding to leverage the self-attention mechanism to ensure that\nthe information flow between two sensors is adaptive with respect to the unique\ndynamic of each pair. Finally, we present Graph Self-attention WaveNet (G-SWaN)\nto address the complex, non-linear spatiotemporal traffic dynamics. Through\nempirical experiments on four real-world, open datasets, we show that the\nproposed method achieves superior performance on both traffic speed and flow\nforecasting. Code is available at: https://github.com/aprbw/G-SWaN\n","authors":["Arian Prabowo","Wei Shao","Hao Xue","Piotr Koniusz","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2302.09956v2.pdf","comment":"20 pages, IoTDI 2023; Correction on Fig. 4"},{"id":"http://arxiv.org/abs/2302.14831v1","updated":"2023-02-28T18:28:35Z","published":"2023-02-28T18:28:35Z","title":"FacEDiM: A Face Embedding Distribution Model for Few-Shot Biometric\n  Authentication of Cattle","summary":"  This work proposes to solve the problem of few-shot biometric authentication\nby computing the Mahalanobis distance between testing embeddings and a\nmultivariate Gaussian distribution of training embeddings obtained using\npre-trained CNNs. Experimental results show that models pre-trained on the\nImageNet dataset significantly outperform models pre-trained on human faces.\nWith a VGG16 model, we obtain a FRR of 1.18% for a FAR of 1.25% on a dataset of\n20 cattle identities.\n","authors":["Meshia Cédric Oveneke","Rucha Vaishampayan","Deogratias Lukamba Nsadisa","Jenny Ambukiyenyi Onya"],"pdf_url":"https://arxiv.org/pdf/2302.14831v1.pdf","comment":"4 pages, 1 figure, 1 table, paper accepted at Black In AI at the 36th\n  Conference on Neural Information Processing Systems (NeurIPS 2022), New\n  Orleans, USA"},{"id":"http://arxiv.org/abs/2106.11943v2","updated":"2023-02-28T18:24:25Z","published":"2021-06-22T17:29:24Z","title":"Reusing Combinatorial Structure: Faster Iterative Projections over\n  Submodular Base Polytopes","summary":"  Optimization algorithms such as projected Newton's method, FISTA, mirror\ndescent, and its variants enjoy near-optimal regret bounds and convergence\nrates, but suffer from a computational bottleneck of computing ``projections''\nin potentially each iteration (e.g., $O(T^{1/2})$ regret of online mirror\ndescent). On the other hand, conditional gradient variants solve a linear\noptimization in each iteration, but result in suboptimal rates (e.g.,\n$O(T^{3/4})$ regret of online Frank-Wolfe). Motivated by this trade-off in\nruntime v/s convergence rates, we consider iterative projections of close-by\npoints over widely-prevalent submodular base polytopes $B(f)$. We first give\nnecessary and sufficient conditions for when two close points project to the\nsame face of a polytope, and then show that points far away from the polytope\nproject onto its vertices with high probability. We next use this theory and\ndevelop a toolkit to speed up the computation of iterative projections over\nsubmodular polytopes using both discrete and continuous perspectives. We\nsubsequently adapt the away-step Frank-Wolfe algorithm to use this information\nand enable early termination. For the special case of cardinality-based\nsubmodular polytopes, we improve the runtime of computing certain Bregman\nprojections by a factor of $\\Omega(n/\\log(n))$. Our theoretical results show\norders of magnitude reduction in runtime in preliminary computational\nexperiments.\n","authors":["Jai Moondra","Hassan Mortagy","Swati Gupta"],"pdf_url":"https://arxiv.org/pdf/2106.11943v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09801v2","updated":"2023-02-28T18:00:06Z","published":"2022-11-17T18:59:03Z","title":"Machine Learned Calabi-Yau Metrics and Curvature","summary":"  Finding Ricci-flat (Calabi-Yau) metrics is a long standing problem in\ngeometry with deep implications for string theory and phenomenology. A new\nattack on this problem uses neural networks to engineer approximations to the\nCalabi-Yau metric within a given K\\\"ahler class. In this paper we investigate\nnumerical Ricci-flat metrics over smooth and singular K3 surfaces and\nCalabi-Yau threefolds. Using these Ricci-flat metric approximations for the\nCefal\\'u family of quartic twofolds and the Dwork family of quintic threefolds,\nwe study characteristic forms on these geometries. We observe that the\nnumerical stability of the numerically computed topological characteristic is\nheavily influenced by the choice of the neural network model, in particular, we\nbriefly discuss a different neural network model, namely Spectral networks,\nwhich correctly approximate the topological characteristic of a Calabi-Yau.\nUsing persistent homology, we show that high curvature regions of the manifolds\nform clusters near the singular points. For our neural network approximations,\nwe observe a Bogomolov--Yau type inequality $3c_2 \\geq c_1^2$ and observe an\nidentity when our geometries have isolated $A_1$ type singularities. We sketch\na proof that $\\chi(X~\\smallsetminus~\\mathrm{Sing}\\,{X}) +\n2~|\\mathrm{Sing}\\,{X}| = 24$ also holds for our numerical approximations.\n","authors":["Per Berglund","Giorgi Butbaia","Tristan Hübsch","Vishnu Jejjala","Damián Mayorga Peña","Challenger Mishra","Justin Tan"],"pdf_url":"https://arxiv.org/pdf/2211.09801v2.pdf","comment":"46 pages, 31 figures, 7 tables, 3 appendices: substantially updated\n  with more detailed and improved numerical computations; additional references\n  and discussion"},{"id":"http://arxiv.org/abs/2302.14808v1","updated":"2023-02-28T17:58:54Z","published":"2023-02-28T17:58:54Z","title":"Opto-UNet: Optimized UNet for Segmentation of Varicose Veins in Optical\n  Coherence Tomography","summary":"  Human veins are important for carrying the blood from the body-parts to the\nheart. The improper functioning of the human veins may arise from several\nvenous diseases. Varicose vein is one such disease wherein back flow of blood\ncan occur, often resulting in increased venous pressure or restricted blood\nflow due to changes in the structure of vein. To examine the functional\ncharacteristics of the varicose vein, it is crucial to study the physical and\nbio mechanical properties of the vein. This work proposes a segmentation model\nOpto-UNet, for segmenting the venous wall structure. Optical Coherence\nTomography system is used to acquire images of varicose vein. As the extracted\nvein is not uniform in shape, hence adequate method of segmentation is required\nto segment the venous wall. Opto-UNet model is based on the U-Net architecture\nwherein a new block is integrated into the architecture, employing atrous and\nseparable convolution to extract spatially wide-range and separable features\nmaps for attaining advanced performance. Furthermore, the depth wise separable\nconvolution significantly reduces the complexity of the network by optimizing\nthe number of parameters. The model achieves accuracy of 0.9830, sensitivity of\n0.8425 and specificity of 0.9980 using 8.54 million number of parameters. These\nresults indicate that model is highly adequate in segmenting the varicose vein\nwall without deteriorating the segmentation quality along with reduced\ncomplexity\n","authors":["Maryam Viqar","Violeta Madjarova","Vipul Baghel","Elena Stoykova"],"pdf_url":"https://arxiv.org/pdf/2302.14808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.03675v3","updated":"2023-02-28T17:56:32Z","published":"2022-10-07T16:33:50Z","title":"Koopman Neural Forecaster for Time Series with Temporal Distribution\n  Shifts","summary":"  Temporal distributional shifts, with underlying dynamics changing over time,\nfrequently occur in real-world time series and pose a fundamental challenge for\ndeep neural networks (DNNs). In this paper, we propose a novel deep sequence\nmodel based on the Koopman theory for time series forecasting: Koopman Neural\nForecaster (KNF) which leverages DNNs to learn the linear Koopman space and the\ncoefficients of chosen measurement functions. KNF imposes appropriate inductive\nbiases for improved robustness against distributional shifts, employing both a\nglobal operator to learn shared characteristics and a local operator to capture\nchanging dynamics, as well as a specially-designed feedback loop to\ncontinuously update the learned operators over time for rapidly varying\nbehaviors. We demonstrate that \\ours{} achieves superior performance compared\nto the alternatives, on multiple time series datasets that are shown to suffer\nfrom distribution shifts.\n","authors":["Rui Wang","Yihe Dong","Sercan Ö. Arik","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2210.03675v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14806v1","updated":"2023-02-28T17:56:19Z","published":"2023-02-28T17:56:19Z","title":"Framelet Message Passing","summary":"  Graph neural networks (GNNs) have achieved champion in wide applications.\nNeural message passing is a typical key module for feature propagation by\naggregating neighboring features. In this work, we propose a new message\npassing based on multiscale framelet transforms, called Framelet Message\nPassing. Different from traditional spatial methods, it integrates framelet\nrepresentation of neighbor nodes from multiple hops away in node message\nupdate. We also propose a continuous message passing using neural ODE solvers.\nIt turns both discrete and continuous cases can provably achieve network\nstability and limit oversmoothing due to the multiscale property of framelets.\nNumerical experiments on real graph datasets show that the continuous version\nof the framelet message passing significantly outperforms existing methods when\nlearning heterogeneous graphs and achieves state-of-the-art performance on\nclassic node classification tasks with low computational costs.\n","authors":["Xinliang Liu","Bingxin Zhou","Chutian Zhang","Yu Guang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15434v3","updated":"2023-02-28T17:53:00Z","published":"2022-05-30T21:20:30Z","title":"A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems","summary":"  In order for agents in multi-agent systems (MAS) to be safe, they need to\ntake into account the risks posed by the actions of other agents. However, the\ndominant paradigm in game theory (GT) assumes that agents are not affected by\nrisk from other agents and only strive to maximise their expected utility. For\nexample, in hybrid human-AI driving systems, it is necessary to limit large\ndeviations in reward resulting from car crashes. Although there are equilibrium\nconcepts in game theory that take into account risk aversion, they either\nassume that agents are risk-neutral with respect to the uncertainty caused by\nthe actions of other agents, or they are not guaranteed to exist. We introduce\na new GT-based Risk-Averse Equilibrium (RAE) that always produces a solution\nthat minimises the potential variance in reward accounting for the strategy of\nother agents. Theoretically and empirically, we show RAE shares many properties\nwith a Nash Equilibrium (NE), establishing convergence properties and\ngeneralising to risk-dominant NE in certain cases. To tackle large-scale\nproblems, we extend RAE to the PSRO multi-agent reinforcement learning (MARL)\nframework. We empirically demonstrate the minimum reward variance benefits of\nRAE in matrix games with high-risk outcomes. Results on MARL experiments show\nRAE generalises to risk-dominant NE in a trust dilemma game and that it reduces\ninstances of crashing by 7x in an autonomous driving setting versus the best\nperforming baseline.\n","authors":["Oliver Slumbers","David Henry Mguni","Stephen Marcus McAleer","Stefano B. Blumberg","Jun Wang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2205.15434v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10445v2","updated":"2023-02-28T17:52:10Z","published":"2022-11-18T14:59:42Z","title":"Building a Subspace of Policies for Scalable Continual Learning","summary":"  The ability to continuously acquire new knowledge and skills is crucial for\nautonomous agents. Existing methods are typically based on either fixed-size\nmodels that struggle to learn a large number of diverse behaviors, or\ngrowing-size models that scale poorly with the number of tasks. In this work,\nwe aim to strike a better balance between an agent's size and performance by\ndesigning a method that grows adaptively depending on the task sequence. We\nintroduce Continual Subspace of Policies (CSP), a new approach that\nincrementally builds a subspace of policies for training a reinforcement\nlearning agent on a sequence of tasks. The subspace's high expressivity allows\nCSP to perform well for many different tasks while growing sublinearly with the\nnumber of tasks. Our method does not suffer from forgetting and displays\npositive transfer to new tasks. CSP outperforms a number of popular baselines\non a wide range of scenarios from two challenging domains, Brax (locomotion)\nand Continual World (manipulation).\n","authors":["Jean-Baptiste Gaya","Thang Doan","Lucas Caccia","Laure Soulier","Ludovic Denoyer","Roberta Raileanu"],"pdf_url":"https://arxiv.org/pdf/2211.10445v2.pdf","comment":"Accepted at ICLR2023 (notable-top-25%)"},{"id":"http://arxiv.org/abs/2302.14803v1","updated":"2023-02-28T17:51:43Z","published":"2023-02-28T17:51:43Z","title":"Learned Risk Metric Maps for Kinodynamic Systems","summary":"  We present Learned Risk Metric Maps (LRMM) for real-time estimation of\ncoherent risk metrics of high dimensional dynamical systems operating in\nunstructured, partially observed environments. LRMM models are simple to design\nand train -- requiring only procedural generation of obstacle sets, state and\ncontrol sampling, and supervised training of a function approximator -- which\nmakes them broadly applicable to arbitrary system dynamics and obstacle sets.\nIn a parallel autonomy setting, we demonstrate the model's ability to rapidly\ninfer collision probabilities of a fast-moving car-like robot driving\nrecklessly in an obstructed environment; allowing the LRMM agent to intervene,\ntake control of the vehicle, and avoid collisions. In this time-critical\nscenario, we show that LRMMs can evaluate risk metrics 20-100x times faster\nthan alternative safety algorithms based on control barrier functions (CBFs)\nand Hamilton-Jacobi reachability (HJ-reach), leading to 5-15\\% fewer obstacle\ncollisions by the LRMM agent than CBFs and HJ-reach. This performance\nimprovement comes in spite of the fact that the LRMM model only has access to\nlocal/partial observation of obstacles, whereas the CBF and HJ-reach agents are\ngranted privileged/global information. We also show that our model can be\nequally well trained on a 12-dimensional quadrotor system operating in an\nobstructed indoor environment. The LRMM codebase is provided at\nhttps://github.com/mit-drl/pyrmm.\n","authors":["Ross Allen","Wei Xiao","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2302.14803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14796v1","updated":"2023-02-28T17:46:32Z","published":"2023-02-28T17:46:32Z","title":"Particle-based Online Bayesian Sampling","summary":"  Online optimization has gained increasing interest due to its capability of\ntracking real-world streaming data. Although online optimization methods have\nbeen widely studied in the setting of frequentist statistics, few works have\nconsidered online optimization with the Bayesian sampling problem. In this\npaper, we study an Online Particle-based Variational Inference (OPVI) algorithm\nthat uses a set of particles to represent the approximating distribution. To\nreduce the gradient error caused by the use of stochastic approximation, we\ninclude a sublinear increasing batch-size method to reduce the variance. To\ntrack the performance of the OPVI algorithm with respect to a sequence of\ndynamically changing target posterior, we provide a detailed theoretical\nanalysis from the perspective of Wasserstein gradient flow with a dynamic\nregret. Synthetic and Bayesian Neural Network experiments show that the\nproposed algorithm achieves better results than naively applying existing\nBayesian sampling methods in the online setting.\n","authors":["Yifan Yang","Chang Liu","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03439v3","updated":"2023-02-28T17:33:36Z","published":"2023-02-07T12:51:20Z","title":"Ensemble Value Functions for Efficient Exploration in Multi-Agent\n  Reinforcement Learning","summary":"  Cooperative multi-agent reinforcement learning (MARL) requires agents to\nexplore to learn to cooperate. Existing value-based MARL algorithms commonly\nrely on random exploration, such as $\\epsilon$-greedy, which is inefficient in\ndiscovering multi-agent cooperation. Additionally, the environment in MARL\nappears non-stationary to any individual agent due to the simultaneous training\nof other agents, leading to highly variant and thus unstable optimisation\nsignals. In this work, we propose ensemble value functions for multi-agent\nexploration (EMAX), a general framework to extend any value-based MARL\nalgorithm. EMAX trains ensembles of value functions for each agent to address\nthe key challenges of exploration and non-stationarity: (1) The uncertainty of\nvalue estimates across the ensemble is used in a UCB policy to guide the\nexploration of agents to parts of the environment which require cooperation.\n(2) Average value estimates across the ensemble serve as target values. These\ntargets exhibit lower variance compared to commonly applied target networks and\nwe show that they lead to more stable gradients during the optimisation. We\ninstantiate three value-based MARL algorithms with EMAX, independent DQN, VDN\nand QMIX, and evaluate them in 21 tasks across four environments. Using\nensembles of five value functions, EMAX improves sample efficiency and final\nevaluation returns of these algorithms by 54%, 55%, and 844%, respectively,\naveraged all 21 tasks.\n","authors":["Lukas Schäfer","Oliver Slumbers","Stephen McAleer","Yali Du","Stefano V. Albrecht","David Mguni"],"pdf_url":"https://arxiv.org/pdf/2302.03439v3.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2206.01816v2","updated":"2023-02-28T17:32:58Z","published":"2022-06-03T20:50:54Z","title":"From $t$-SNE to UMAP with contrastive learning","summary":"  Neighbor embedding methods $t$-SNE and UMAP are the de facto standard for\nvisualizing high-dimensional datasets. Motivated from entirely different\nviewpoints, their loss functions appear to be unrelated. In practice, they\nyield strongly differing embeddings and can suggest conflicting interpretations\nof the same data. The fundamental reasons for this and, more generally, the\nexact relationship between $t$-SNE and UMAP have remained unclear. In this\nwork, we uncover their conceptual connection via a new insight into contrastive\nlearning methods. Noise-contrastive estimation can be used to optimize $t$-SNE,\nwhile UMAP relies on negative sampling, another contrastive method. We find the\nprecise relationship between these two contrastive methods and provide a\nmathematical characterization of the distortion introduced by negative\nsampling. Visually, this distortion results in UMAP generating more compact\nembeddings with tighter clusters compared to $t$-SNE. We exploit this new\nconceptual connection to propose and implement a generalization of negative\nsampling, allowing us to interpolate between (and even extrapolate beyond)\n$t$-SNE and UMAP and their respective embeddings. Moving along this spectrum of\nembeddings leads to a trade-off between discrete / local and continuous /\nglobal structures, mitigating the risk of over-interpreting ostensible features\nof any single embedding. We provide a PyTorch implementation.\n","authors":["Sebastian Damrich","Jan Niklas Böhm","Fred A. Hamprecht","Dmitry Kobak"],"pdf_url":"https://arxiv.org/pdf/2206.01816v2.pdf","comment":"ICLR 2023. 44 pages, 19 figures. Code at\n  https://github.com/hci-unihd/cl-tsne-umap and\n  https://github.com/berenslab/contrastive-ne"},{"id":"http://arxiv.org/abs/2205.13710v2","updated":"2023-02-28T17:32:27Z","published":"2022-05-27T02:09:55Z","title":"Privacy of Noisy Stochastic Gradient Descent: More Iterations without\n  More Privacy Loss","summary":"  A central issue in machine learning is how to train models on sensitive user\ndata. Industry has widely adopted a simple algorithm: Stochastic Gradient\nDescent with noise (a.k.a. Stochastic Gradient Langevin Dynamics). However,\nfoundational theoretical questions about this algorithm's privacy loss remain\nopen -- even in the seemingly simple setting of smooth convex losses over a\nbounded domain. Our main result resolves these questions: for a large range of\nparameters, we characterize the differential privacy up to a constant factor.\nThis result reveals that all previous analyses for this setting have the wrong\nqualitative behavior. Specifically, while previous privacy analyses increase ad\ninfinitum in the number of iterations, we show that after a small burn-in\nperiod, running SGD longer leaks no further privacy.\n  Our analysis departs from previous approaches based on fast mixing, instead\nusing techniques based on optimal transport (namely, Privacy Amplification by\nIteration) and the Sampled Gaussian Mechanism (namely, Privacy Amplification by\nSampling). Our techniques readily extend to other settings, e.g., strongly\nconvex losses, non-uniform stepsizes, arbitrary batch sizes, and random or\ncyclic choice of batches.\n","authors":["Jason M. Altschuler","Kunal Talwar"],"pdf_url":"https://arxiv.org/pdf/2205.13710v2.pdf","comment":"v2: improved exposition, slightly simplified proofs, all results\n  unchanged"},{"id":"http://arxiv.org/abs/2209.15408v2","updated":"2023-02-28T17:30:11Z","published":"2022-09-30T12:10:15Z","title":"Equivariant Energy-Guided SDE for Inverse Molecular Design","summary":"  Inverse molecular design is critical in material science and drug discovery,\nwhere the generated molecules should satisfy certain desirable properties. In\nthis paper, we propose equivariant energy-guided stochastic differential\nequations (EEGSDE), a flexible framework for controllable 3D molecule\ngeneration under the guidance of an energy function in diffusion models.\nFormally, we show that EEGSDE naturally exploits the geometric symmetry in 3D\nmolecular conformation, as long as the energy function is invariant to\northogonal transformations. Empirically, under the guidance of designed energy\nfunctions, EEGSDE significantly improves the baseline on QM9, in inverse\nmolecular design targeted to quantum properties and molecular structures.\nFurthermore, EEGSDE is able to generate molecules with multiple target\nproperties by combining the corresponding energy functions linearly.\n","authors":["Fan Bao","Min Zhao","Zhongkai Hao","Peiyao Li","Chongxuan Li","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.15408v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14781v1","updated":"2023-02-28T17:26:27Z","published":"2023-02-28T17:26:27Z","title":"Time Series Anomaly Detection in Smart Homes: A Deep Learning Approach","summary":"  Fixing energy leakage caused by different anomalies can result in significant\nenergy savings and extended appliance life. Further, it assists grid operators\nin scheduling their resources to meet the actual needs of end users, while\nhelping end users reduce their energy costs. In this paper, we analyze the\npatterns pertaining to the power consumption of dishwashers used in two houses\nof the REFIT dataset. Then two autoencoder (AEs) with 1D-CNN and TCN as\nbackbones are trained to differentiate the normal patterns from the abnormal\nones. Our results indicate that TCN outperforms CNN1D in detecting anomalies in\nenergy consumption. Finally, the data from the Fridge_Freezer and the Freezer\nof house No. 3 in REFIT is also used to evaluate our approach.\n","authors":["Somayeh Zamani","Hamed Talebi","Gunnar Stevens"],"pdf_url":"https://arxiv.org/pdf/2302.14781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14772v1","updated":"2023-02-28T17:14:24Z","published":"2023-02-28T17:14:24Z","title":"PA&DA: Jointly Sampling PAth and DAta for Consistent NAS","summary":"  Based on the weight-sharing mechanism, one-shot NAS methods train a supernet\nand then inherit the pre-trained weights to evaluate sub-models, largely\nreducing the search cost. However, several works have pointed out that the\nshared weights suffer from different gradient descent directions during\ntraining. And we further find that large gradient variance occurs during\nsupernet training, which degrades the supernet ranking consistency. To mitigate\nthis issue, we propose to explicitly minimize the gradient variance of the\nsupernet training by jointly optimizing the sampling distributions of PAth and\nDAta (PA&DA). We theoretically derive the relationship between the gradient\nvariance and the sampling distributions, and reveal that the optimal sampling\nprobability is proportional to the normalized gradient norm of path and\ntraining data. Hence, we use the normalized gradient norm as the importance\nindicator for path and training data, and adopt an importance sampling strategy\nfor the supernet training. Our method only requires negligible computation cost\nfor optimizing the sampling distributions of path and data, but achieves lower\ngradient variance during supernet training and better generalization\nperformance for the supernet, resulting in a more consistent NAS. We conduct\ncomprehensive comparisons with other improved approaches in various search\nspaces. Results show that our method surpasses others with more reliable\nranking performance and higher accuracy of searched architectures, showing the\neffectiveness of our method. Code is available at\nhttps://github.com/ShunLu91/PA-DA.\n","authors":["Shun Lu","Yu Hu","Longxing Yang","Zihao Sun","Jilin Mei","Jianchao Tan","Chengru Song"],"pdf_url":"https://arxiv.org/pdf/2302.14772v1.pdf","comment":"To appear in CVPR 2023; we will update the camera-ready version soon"},{"id":"http://arxiv.org/abs/2302.14770v1","updated":"2023-02-28T17:11:42Z","published":"2023-02-28T17:11:42Z","title":"Completeness of Atomic Structure Representations","summary":"  Achieving a complete and symmetric description of a group of point particles,\nsuch as atoms in a molecule, is a common problem in physics and theoretical\nchemistry. The introduction of machine learning to science has made this issue\neven more critical, as it underpins the ability of a model to reproduce\narbitrary physical relationships, and to do so while being consistent with\nbasic symmetries and conservation laws. However, the descriptors that are\ncommonly used to represent point clouds -- most notably those adopted to\ndescribe matter at the atomic scale -- are unable to distinguish between\nspecial arrangements of particles. This makes it impossible to machine learn\ntheir properties. Frameworks that are provably complete exist, but are only so\nin the limit in which they simultaneously describe the mutual relationship\nbetween all atoms, which is impractical. We introduce, and demonstrate on a\nparticularly insidious class of atomic arrangements, a strategy to build\ndescriptors that rely solely on information on the relative arrangement of\ntriplets of particles, but can be used to construct symmetry-adapted models\nthat have universal approximation power.\n","authors":["Jigyasa Nigam","Sergey N. Pozdnyakov","Kevin K. Huguenin-Dumittan","Michele Ceriotti"],"pdf_url":"https://arxiv.org/pdf/2302.14770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07537v2","updated":"2023-02-28T16:57:56Z","published":"2022-02-15T16:13:40Z","title":"Information-Theoretic Analysis of Minimax Excess Risk","summary":"  Two main concepts studied in machine learning theory are generalization gap\n(difference between train and test error) and excess risk (difference between\ntest error and the minimum possible error). While information-theoretic tools\nhave been used extensively to study the generalization gap of learning\nalgorithms, the information-theoretic nature of excess risk has not yet been\nfully investigated. In this paper, some steps are taken toward this goal. We\nconsider the frequentist problem of minimax excess risk as a zero-sum game\nbetween the algorithm designer and the world. Then, we argue that it is\ndesirable to modify this game in a way that the order of play can be swapped.\nWe then prove that, under some regularity conditions, if the world and designer\ncan play randomly the duality gap is zero and the order of play can be changed.\nIn this case, a Bayesian problem surfaces in the dual representation. This\nmakes it possible to utilize recent information-theoretic results on minimum\nexcess risk in Bayesian learning to provide bounds on the minimax excess risk.\nWe demonstrate the applicability of the results by providing information\ntheoretic insight on two important classes of problems: classification when the\nhypothesis space has finite VC-dimension, and regularized least squares.\n","authors":["Hassan Hafez-Kolahi","Behrad Moniri","Shohreh Kasaei"],"pdf_url":"https://arxiv.org/pdf/2202.07537v2.pdf","comment":"Published in the IEEE Transactions on Information Theory"},{"id":"http://arxiv.org/abs/2210.10947v2","updated":"2023-02-28T16:54:02Z","published":"2022-10-20T01:32:41Z","title":"Does Learning from Decentralized Non-IID Unlabeled Data Benefit from\n  Self Supervision?","summary":"  Decentralized learning has been advocated and widely deployed to make\nefficient use of distributed datasets, with an extensive focus on supervised\nlearning (SL) problems. Unfortunately, the majority of real-world data are\nunlabeled and can be highly heterogeneous across sources. In this work, we\ncarefully study decentralized learning with unlabeled data through the lens of\nself-supervised learning (SSL), specifically contrastive visual representation\nlearning. We study the effectiveness of a range of contrastive learning\nalgorithms under decentralized learning settings, on relatively large-scale\ndatasets including ImageNet-100, MS-COCO, and a new real-world robotic\nwarehouse dataset. Our experiments show that the decentralized SSL (Dec-SSL)\napproach is robust to the heterogeneity of decentralized datasets, and learns\nuseful representation for object classification, detection, and segmentation\ntasks. This robustness makes it possible to significantly reduce communication\nand reduce the participation ratio of data sources with only minimal drops in\nperformance. Interestingly, using the same amount of data, the representation\nlearned by Dec-SSL can not only perform on par with that learned by centralized\nSSL which requires communication and excessive data storage costs, but also\nsometimes outperform representations extracted from decentralized SL which\nrequires extra knowledge about the data labels. Finally, we provide theoretical\ninsights into understanding why data heterogeneity is less of a concern for\nDec-SSL objectives, and introduce feature alignment and clustering techniques\nto develop a new Dec-SSL algorithm that further improves the performance, in\nthe face of highly non-IID data. Our study presents positive evidence to\nembrace unlabeled data in decentralized learning, and we hope to provide new\ninsights into whether and why decentralized SSL is effective.\n","authors":["Lirui Wang","Kaiqing Zhang","Yunzhu Li","Yonglong Tian","Russ Tedrake"],"pdf_url":"https://arxiv.org/pdf/2210.10947v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14754v1","updated":"2023-02-28T16:53:54Z","published":"2023-02-28T16:53:54Z","title":"Identifying roadway departure crash patterns on rural two-lane highways\n  under different lighting conditions: association knowledge using data mining\n  approach","summary":"  More than half of all fatalities on U.S. highways occur due to roadway\ndeparture (RwD) each year. Previous research has explored various risk factors\nthat contribute to RwD crashes, however, a comprehensive investigation\nconsidering the effect of lighting conditions has been insufficiently\naddressed. Using the Louisiana Department of Transportation and Development\ncrash database, fatal and injury RwD crashes occurring on rural two-lane (R2L)\nhighways between 2008-2017 were analyzed based on daylight and dark\n(with/without streetlight). This research employed a safe system approach to\nexplore meaningful complex interactions among multidimensional crash risk\nfactors. To accomplish this, an unsupervised data mining algorithm association\nrules mining (ARM) was utilized. Based on the generated rules, the findings\nreveal several interesting crash patterns in the daylight,\ndark-with-streetlight, and dark-no-streetlight, emphasizing the importance of\ninvestigating RwD crash patterns depending on the lighting conditions. In\ndaylight, fatal RwD crashes are associated with cloudy weather conditions,\ndistracted drivers, standing water on the roadway, no seat belt use, and\nconstruction zones. In dark lighting conditions (with/without streetlight), the\nmajority of the RwD crashes are associated with alcohol/drug involvement, young\ndrivers (15-24 years), driver condition (e.g., inattentive, distracted,\nillness/fatigued/asleep) and colliding with animal (s). The findings reveal how\ncertain driver behavior patterns are connected to RwD crashes, such as a strong\nassociation between alcohol/drug intoxication and no seat belt usage in the\ndark-no-streetlight condition. Based on the identified crash patterns and\nbehavioral characteristics under different lighting conditions, the findings\ncould aid researchers and safety specialists in developing the most effective\nRwD crash mitigation strategies.\n","authors":["Ahmed Hossain","Xiaoduan Sun","Shahrin Islam","Shah Alam","Md Mahmud Hossain"],"pdf_url":"https://arxiv.org/pdf/2302.14754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14753v1","updated":"2023-02-28T16:53:41Z","published":"2023-02-28T16:53:41Z","title":"Learning Hidden Markov Models Using Conditional Samples","summary":"  This paper is concerned with the computational complexity of learning the\nHidden Markov Model (HMM). Although HMMs are some of the most widely used tools\nin sequential and time series modeling, they are cryptographically hard to\nlearn in the standard setting where one has access to i.i.d. samples of\nobservation sequences. In this paper, we depart from this setup and consider an\ninteractive access model, in which the algorithm can query for samples from the\nconditional distributions of the HMMs. We show that interactive access to the\nHMM enables computationally efficient learning algorithms, thereby bypassing\ncryptographic hardness. Specifically, we obtain efficient algorithms for\nlearning HMMs in two settings:\n  (a) An easier setting where we have query access to the exact conditional\nprobabilities. Here our algorithm runs in polynomial time and makes\npolynomially many queries to approximate any HMM in total variation distance.\n  (b) A harder setting where we can only obtain samples from the conditional\ndistributions. Here the performance of the algorithm depends on a new\nparameter, called the fidelity of the HMM. We show that this captures\ncryptographically hard instances and previously known positive results.\n  We also show that these results extend to a broader class of distributions\nwith latent low rank structure. Our algorithms can be viewed as generalizations\nand robustifications of Angluin's $L^*$ algorithm for learning deterministic\nfinite automata from membership queries.\n","authors":["Sham M. Kakade","Akshay Krishnamurthy","Gaurav Mahajan","Cyril Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14748v1","updated":"2023-02-28T16:45:42Z","published":"2023-02-28T16:45:42Z","title":"Reducing the Prior Mismatch of Stochastic Differential Equations for\n  Diffusion-based Speech Enhancement","summary":"  Recently, score-based generative models have been successfully employed for\nthe task of speech enhancement. A stochastic differential equation is used to\nmodel the iterative forward process, where at each step environmental noise and\nwhite Gaussian noise are added to the clean speech signal. While in limit the\nmean of the forward process ends at the noisy mixture, in practice it stops\nearlier and thus only at an approximation of the noisy mixture. This results in\na discrepancy between the terminating distribution of the forward process and\nthe prior used for solving the reverse process at inference. In this paper, we\naddress this discrepancy. To this end, we propose a forward process based on a\nBrownian bridge and show that such a process leads to a reduction of the\nmismatch compared to previous diffusion processes. More importantly, we show\nthat our approach improves in objective metrics over the baseline process with\nonly half of the iteration steps and having one hyperparameter less to tune.\n","authors":["Bunlong Lay","Simon Welker","Julius Richter","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2302.14748v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.14744v1","updated":"2023-02-28T16:44:10Z","published":"2023-02-28T16:44:10Z","title":"Tightness of prescriptive tree-based mixed-integer optimization\n  formulations","summary":"  We focus on modeling the relationship between an input feature vector and the\npredicted outcome of a trained decision tree using mixed-integer optimization.\nThis can be used in many practical applications where a decision tree or tree\nensemble is incorporated into an optimization problem to model the predicted\noutcomes of a decision. We propose tighter mixed-integer optimization\nformulations than those previously introduced. Existing formulations can be\nshown to have linear relaxations that have fractional extreme points, even for\nthe simple case of modeling a single decision tree. A formulation we propose,\nbased on a projected union of polyhedra approach, is ideal for a single\ndecision tree. While the formulation is generally not ideal for tree ensembles\nor if additional constraints are added, it generally has fewer extreme points,\nleading to a faster time to solve, particularly if the formulation has\nrelatively few trees. However, previous work has shown that formulations based\non a binary representation of the feature vector perform well computationally\nand hence are attractive for use in practical applications. We present multiple\napproaches to tighten existing formulations with binary vectors, and show that\nfractional extreme points are removed when there are multiple splits on the\nsame feature. At an extreme, we prove that this results in ideal formulations\nfor tree ensembles modeling a one-dimensional feature vector. Building on this\nresult, we also show via numerical simulations that these additional\nconstraints result in significantly tighter linear relaxations when the feature\nvector is low dimensional. We also present instances where the time to solve to\noptimality is significantly improved using these formulations.\n","authors":["Max Biggs","Georgia Perakis"],"pdf_url":"https://arxiv.org/pdf/2302.14744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14740v1","updated":"2023-02-28T16:42:07Z","published":"2023-02-28T16:42:07Z","title":"Fusion of ML with numerical simulation for optimized propeller design","summary":"  In computer-aided engineering design, the goal of a designer is to find an\noptimal design on a given requirement using the numerical simulator in loop\nwith an optimization method. In this design optimization process, a good design\noptimization process is one that can reduce the time from inception to design.\nIn this work, we take a class of design problem, that is computationally cheap\nto evaluate but has high dimensional design space. In such cases, traditional\nsurrogate-based optimization does not offer any benefits. In this work, we\npropose an alternative way to use ML model to surrogate the design process that\nformulates the search problem as an inverse problem and can save time by\nfinding the optimal design or at least a good initial seed design for\noptimization. By using this trained surrogate model with the traditional\noptimization method, we can get the best of both worlds. We call this as\nSurrogate Assisted Optimization (SAO)- a hybrid approach by mixing ML surrogate\nwith the traditional optimization method. Empirical evaluations of propeller\ndesign problems show that a better efficient design can be found in fewer\nevaluations using SAO.\n","authors":["Harsh Vardhan","Peter Volgyesi","Janos Sztipanovits"],"pdf_url":"https://arxiv.org/pdf/2302.14740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14739v1","updated":"2023-02-28T16:41:24Z","published":"2023-02-28T16:41:24Z","title":"Deep Learning for Mean Field Optimal Transport","summary":"  Mean field control (MFC) problems have been introduced to study social optima\nin very large populations of strategic agents. The main idea is to consider an\ninfinite population and to simplify the analysis by using a mean field\napproximation. These problems can also be viewed as optimal control problems\nfor McKean-Vlasov dynamics. They have found applications in a wide range of\nfields, from economics and finance to social sciences and engineering. Usually,\nthe goal for the agents is to minimize a total cost which consists in the\nintegral of a running cost plus a terminal cost. In this work, we consider MFC\nproblems in which there is no terminal cost but, instead, the terminal\ndistribution is prescribed. We call such problems mean field optimal transport\nproblems since they can be viewed as a generalization of classical optimal\ntransport problems when mean field interactions occur in the dynamics or the\nrunning cost function. We propose three numerical methods based on neural\nnetworks. The first one is based on directly learning an optimal control. The\nsecond one amounts to solve a forward-backward PDE system characterizing the\nsolution. The third one relies on a primal-dual approach. We illustrate these\nmethods with numerical experiments conducted on two families of examples.\n","authors":["Sebastian Baudelet","Brieuc Frénais","Mathieu Laurière","Amal Machtalay","Yuchen Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.14739v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03561v2","updated":"2023-02-28T16:41:22Z","published":"2023-02-07T16:17:25Z","title":"Optimizing Audio Recommendations for the Long-Term: A Reinforcement\n  Learning Perspective","summary":"  We study the problem of optimizing a recommender system for outcomes that\noccur over several weeks or months. We begin by drawing on reinforcement\nlearning to formulate a comprehensive model of users' recurring relationships\nwith a recommender system. Measurement, attribution, and coordination\nchallenges complicate algorithm design. We describe careful modeling --\nincluding a new representation of user state and key conditional independence\nassumptions -- which overcomes these challenges and leads to simple, testable\nrecommender system prototypes. We apply our approach to a podcast recommender\nsystem that makes personalized recommendations to hundreds of millions of\nlisteners. A/B tests demonstrate that purposefully optimizing for long-term\noutcomes leads to large performance gains over conventional approaches that\noptimize for short-term proxies.\n","authors":["Lucas Maystre","Daniel Russo","Yu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.03561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14732v1","updated":"2023-02-28T16:36:26Z","published":"2023-02-28T16:36:26Z","title":"Constrained Bayesian Optimization for Automatic Underwater Vehicle Hull\n  Design","summary":"  Automatic underwater vehicle hull Design optimization is a complex\nengineering process for generating a UUV hull with optimized properties on a\ngiven requirement. First, it involves the integration of involved\ncomputationally complex engineering simulation tools. Second, it needs\nintegration of a sample efficient optimization framework with the integrated\ntoolchain. To this end, we integrated the CAD tool called FreeCAD with CFD tool\nopenFoam for automatic design evaluation. For optimization, we chose Bayesian\noptimization (BO), which is a well-known technique developed for optimizing\ntime-consuming expensive engineering simulations and has proven to be very\nsample efficient in a variety of problems, including hyper-parameter tuning and\nexperimental design. During the optimization process, we can handle infeasible\ndesign as constraints integrated into the optimization process. By integrating\ndomain-specific toolchain with AI-based optimization, we executed the automatic\ndesign optimization of underwater vehicle hull design. For empirical\nevaluation, we took two different use cases of real-world underwater vehicle\ndesign to validate the execution of our tool.\n","authors":["Harsh Vardhan","Peter Volgyesi","Janos Sztipanovits"],"pdf_url":"https://arxiv.org/pdf/2302.14732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14719v1","updated":"2023-02-28T16:31:17Z","published":"2023-02-28T16:31:17Z","title":"Self-training through Classifier Disagreement for Cross-Domain Opinion\n  Target Extraction","summary":"  Opinion target extraction (OTE) or aspect extraction (AE) is a fundamental\ntask in opinion mining that aims to extract the targets (or aspects) on which\nopinions have been expressed. Recent work focus on cross-domain OTE, which is\ntypically encountered in real-world scenarios, where the testing and training\ndistributions differ. Most methods use domain adversarial neural networks that\naim to reduce the domain gap between the labelled source and unlabelled target\ndomains to improve target domain performance. However, this approach only\naligns feature distributions and does not account for class-wise feature\nalignment, leading to suboptimal results. Semi-supervised learning (SSL) has\nbeen explored as a solution, but is limited by the quality of pseudo-labels\ngenerated by the model. Inspired by the theoretical foundations in domain\nadaptation [2], we propose a new SSL approach that opts for selecting target\nsamples whose model output from a domain-specific teacher and student network\ndisagree on the unlabelled target data, in an effort to boost the target domain\nperformance. Extensive experiments on benchmark cross-domain OTE datasets show\nthat this approach is effective and performs consistently well in settings with\nlarge domain shifts.\n","authors":["Kai Sun","Richong Zhang","Samuel Mensah","Nikolaos Aletras","Yongyi Mao","Xudong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.14719v1.pdf","comment":"Accepted at TheWebConf 2023"},{"id":"http://arxiv.org/abs/2302.14714v1","updated":"2023-02-28T16:26:23Z","published":"2023-02-28T16:26:23Z","title":"Minimizing the Outage Probability in a Markov Decision Process","summary":"  Standard Markov decision process (MDP) and reinforcement learning algorithms\noptimize the policy with respect to the expected gain. We propose an algorithm\nwhich enables to optimize an alternative objective: the probability that the\ngain is greater than a given value. The algorithm can be seen as an extension\nof the value iteration algorithm. We also show how the proposed algorithm could\nbe generalized to use neural networks, similarly to the deep Q learning\nextension of Q learning.\n","authors":["Vincent Corlay","Jean-Christophe Sibel"],"pdf_url":"https://arxiv.org/pdf/2302.14714v1.pdf","comment":"Accepted at the Information Theory Workshop (ITW) 2023"},{"id":"http://arxiv.org/abs/2302.14712v1","updated":"2023-02-28T16:23:18Z","published":"2023-02-28T16:23:18Z","title":"Generating Accurate Virtual Examples For Lifelong Machine Learning","summary":"  Lifelong machine learning (LML) is an area of machine learning research\nconcerned with human-like persistent and cumulative nature of learning. LML\nsystem's objective is consolidating new information into an existing machine\nlearning model without catastrophically disrupting the prior information. Our\nresearch addresses this LML retention problem for creating a knowledge\nconsolidation network through task rehearsal without retaining the prior task's\ntraining examples. We discovered that the training data reconstruction error\nfrom a trained Restricted Boltzmann Machine can be successfully used to\ngenerate accurate virtual examples from the reconstructed set of a uniform\nrandom set of examples given to the trained model. We also defined a measure\nfor comparing the probability distributions of two datasets given to a trained\nnetwork model based on their reconstruction mean square errors.\n","authors":["Sazia Mahfuz"],"pdf_url":"https://arxiv.org/pdf/2302.14712v1.pdf","comment":"4 pages, Canadian AI GSS 2019"},{"id":"http://arxiv.org/abs/2112.04720v2","updated":"2023-02-28T16:21:41Z","published":"2021-12-09T06:16:08Z","title":"Amicable Aid: Perturbing Images to Improve Classification Performance","summary":"  While adversarial perturbation of images to attack deep image classification\nmodels pose serious security concerns in practice, this paper suggests a novel\nparadigm where the concept of image perturbation can benefit classification\nperformance, which we call amicable aid. We show that by taking the opposite\nsearch direction of perturbation, an image can be modified to yield higher\nclassification confidence and even a misclassified image can be made correctly\nclassified. This can be also achieved with a large amount of perturbation by\nwhich the image is made unrecognizable by human eyes. The mechanism of the\namicable aid is explained in the viewpoint of the underlying natural image\nmanifold. Furthermore, we investigate the universal amicable aid, i.e., a fixed\nperturbation can be applied to multiple images to improve their classification\nresults. While it is challenging to find such perturbations, we show that\nmaking the decision boundary as perpendicular to the image manifold as possible\nvia training with modified data is effective to obtain a model for which\nuniversal amicable perturbations are more easily found.\n","authors":["Juyeop Kim","Jun-Ho Choi","Soobeom Jang","Jong-Seok Lee"],"pdf_url":"https://arxiv.org/pdf/2112.04720v2.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2302.14705v1","updated":"2023-02-28T16:17:23Z","published":"2023-02-28T16:17:23Z","title":"AccelTran: A Sparsity-Aware Accelerator for Dynamic Inference with\n  Transformers","summary":"  Self-attention-based transformer models have achieved tremendous success in\nthe domain of natural language processing. Despite their efficacy, accelerating\nthe transformer is challenging due to its quadratic computational complexity\nand large activation sizes. Existing transformer accelerators attempt to prune\nits tokens to reduce memory access, albeit with high compute overheads.\nMoreover, previous works directly operate on large matrices involved in the\nattention operation, which limits hardware utilization. In order to address\nthese challenges, this work proposes a novel dynamic inference scheme,\nDynaTran, which prunes activations at runtime with low overhead, substantially\nreducing the number of ineffectual operations. This improves the throughput of\ntransformer inference. We further propose tiling the matrices in transformer\noperations along with diverse dataflows to improve data reuse, thus enabling\nhigher energy efficiency. To effectively implement these methods, we propose\nAccelTran, a novel accelerator architecture for transformers. Extensive\nexperiments with different models and benchmarks demonstrate that DynaTran\nachieves higher accuracy than the state-of-the-art top-k hardware-aware pruning\nstrategy while attaining up to 1.2$\\times$ higher sparsity. One of our proposed\naccelerators, AccelTran-Edge, achieves 330K$\\times$ higher throughput with\n93K$\\times$ lower energy requirement when compared to a Raspberry Pi device. On\nthe other hand, AccelTran-Server achieves 5.73$\\times$ higher throughput and\n3.69$\\times$ lower energy consumption compared to the state-of-the-art\ntransformer co-processor, Energon.\n","authors":["Shikhar Tuli","Niraj K. Jha"],"pdf_url":"https://arxiv.org/pdf/2302.14705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14703v1","updated":"2023-02-28T16:16:45Z","published":"2023-02-28T16:16:45Z","title":"Improving Expert Specialization in Mixture of Experts","summary":"  Mixture of experts (MoE), introduced over 20 years ago, is the simplest gated\nmodular neural network architecture. There is renewed interest in MoE because\nthe conditional computation allows only parts of the network to be used during\neach inference, as was recently demonstrated in large scale natural language\nprocessing models. MoE is also of potential interest for continual learning, as\nexperts may be reused for new tasks, and new experts introduced. The gate in\nthe MoE architecture learns task decompositions and individual experts learn\nsimpler functions appropriate to the gate's decomposition. In this paper: (1)\nwe show that the original MoE architecture and its training method do not\nguarantee intuitive task decompositions and good expert utilization, indeed\nthey can fail spectacularly even for simple data such as MNIST and\nFashionMNIST; (2) we introduce a novel gating architecture, similar to\nattention, that improves performance and results in a lower entropy task\ndecomposition; and (3) we introduce a novel data-driven regularization that\nimproves expert specialization. We empirically validate our methods on MNIST,\nFashionMNIST and CIFAR-100 datasets.\n","authors":["Yamuna Krishnamurthy","Chris Watkins","Thomas Gaertner"],"pdf_url":"https://arxiv.org/pdf/2302.14703v1.pdf","comment":"14 pages including appendix"},{"id":"http://arxiv.org/abs/2302.14698v1","updated":"2023-02-28T16:11:08Z","published":"2023-02-28T16:11:08Z","title":"Heuristic Modularity Maximization Algorithms for Community Detection\n  Rarely Return an Optimal Partition or Anything Similar","summary":"  Community detection is a classic problem in network science with extensive\napplications in various fields. The most commonly used methods are the\nalgorithms designed to maximize modularity over different partitions of the\nnetwork nodes into communities. Using 80 real and random networks from a wide\nrange of contexts, we investigate the extent to which current heuristic\nmodularity maximization algorithms succeed in returning modularity-maximum\n(optimal) partitions. We evaluate (1) the ratio of their output modularity to\nthe maximum modularity for each input graph and (2) the maximum similarity\nbetween their output partition and any optimal partition of that graph. Our\ncomputational experiments involve eight existing heuristic algorithms which we\ncompare against an exact integer programming method that globally maximizes\nmodularity. The average modularity-based heuristic algorithm returns optimal\npartitions for only 16.9% of the 80 graphs considered. Results on adjusted\nmutual information show considerable dissimilarity between the sub-optimal\npartitions and any optimal partitions of the graphs in our experiments. More\nimportantly, our results show that near-optimal partitions tend to be\ndisproportionally dissimilar to any optimal partition. Taken together, our\nanalysis points to a crucial limitation of commonly used modularity-based\nalgorithms for discovering communities: they rarely return an optimal partition\nor a partition resembling an optimal partition. Given this finding, developing\nan exact or approximate algorithm for modularity maximization is recommendable\nfor a more methodologically sound usage of modularity in community detection.\n","authors":["Samin Aref","Mahdi Mostajabdaveh","Hriday Chheda"],"pdf_url":"https://arxiv.org/pdf/2302.14698v1.pdf","comment":"15 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2209.04562"},{"id":"http://arxiv.org/abs/2211.04772v2","updated":"2023-02-28T16:08:45Z","published":"2022-11-09T09:58:22Z","title":"Efficient Large-scale Audio Tagging via Transformer-to-CNN Knowledge\n  Distillation","summary":"  Audio Spectrogram Transformer models rule the field of Audio Tagging,\noutrunning previously dominating Convolutional Neural Networks (CNNs). Their\nsuperiority is based on the ability to scale up and exploit large-scale\ndatasets such as AudioSet. However, Transformers are demanding in terms of\nmodel size and computational requirements compared to CNNs. We propose a\ntraining procedure for efficient CNNs based on offline Knowledge Distillation\n(KD) from high-performing yet complex transformers. The proposed training\nschema and the efficient CNN design based on MobileNetV3 results in models\noutperforming previous solutions in terms of parameter and computational\nefficiency and prediction performance. We provide models of different\ncomplexity levels, scaling from low-complexity models up to a new\nstate-of-the-art performance of .483 mAP on AudioSet. Source Code available at:\nhttps://github.com/fschmid56/EfficientAT\n","authors":["Florian Schmid","Khaled Koutini","Gerhard Widmer"],"pdf_url":"https://arxiv.org/pdf/2211.04772v2.pdf","comment":"To appear in IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP) 2023. Source Code available at:\n  https://github.com/fschmid56/EfficientAT"},{"id":"http://arxiv.org/abs/2302.14695v1","updated":"2023-02-28T16:08:12Z","published":"2023-02-28T16:08:12Z","title":"Pushing One Pair of Labels Apart Each Time in Multi-Label Learning: From\n  Single Positive to Full Labels","summary":"  In Multi-Label Learning (MLL), it is extremely challenging to accurately\nannotate every appearing object due to expensive costs and limited knowledge.\nWhen facing such a challenge, a more practical and cheaper alternative should\nbe Single Positive Multi-Label Learning (SPMLL), where only one positive label\nneeds to be provided per sample. Existing SPMLL methods usually assume unknown\nlabels as negatives, which inevitably introduces false negatives as noisy\nlabels. More seriously, Binary Cross Entropy (BCE) loss is often used for\ntraining, which is notoriously not robust to noisy labels. To mitigate this\nissue, we customize an objective function for SPMLL by pushing only one pair of\nlabels apart each time to prevent the domination of negative labels, which is\nthe main culprit of fitting noisy labels in SPMLL. To further combat such noisy\nlabels, we explore the high-rankness of label matrix, which can also push apart\ndifferent labels. By directly extending from SPMLL to MLL with full labels, a\nunified loss applicable to both settings is derived. Experiments on real\ndatasets demonstrate that the proposed loss not only performs more robustly to\nnoisy labels for SPMLL but also works well for full labels. Besides, we\nempirically discover that high-rankness can mitigate the dramatic performance\ndrop in SPMLL. Most surprisingly, even without any regularization or fine-tuned\nlabel correction, only adopting our loss defeats state-of-the-art SPMLL methods\non CUB, a dataset that severely lacks labels.\n","authors":["Xiang Li","Xinrui Wang","Songcan Chen"],"pdf_url":"https://arxiv.org/pdf/2302.14695v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.14690v1","updated":"2023-02-28T16:01:38Z","published":"2023-02-28T16:01:38Z","title":"On the existence of minimizers in shallow residual ReLU neural network\n  optimization landscapes","summary":"  Many mathematical convergence results for gradient descent (GD) based\nalgorithms employ the assumption that the GD process is (almost surely) bounded\nand, also in concrete numerical simulations, divergence of the GD process may\nslow down, or even completely rule out, convergence of the error function. In\npractical relevant learning problems, it thus seems to be advisable to design\nthe ANN architectures in a way so that GD optimization processes remain\nbounded. The property of the boundedness of GD processes for a given learning\nproblem seems, however, to be closely related to the existence of minimizers in\nthe optimization landscape and, in particular, GD trajectories may escape to\ninfinity if the infimum of the error function (objective function) is not\nattained in the optimization landscape. This naturally raises the question of\nthe existence of minimizers in the optimization landscape and, in the situation\nof shallow residual ANNs with multi-dimensional input layers and\nmulti-dimensional hidden layers with the ReLU activation, the main result of\nthis work answers this question affirmatively for a general class of loss\nfunctions and all continuous target functions. In our proof of this statement,\nwe propose a kind of closure of the search space, where the limits are called\ngeneralized responses, and, thereafter, we provide sufficient criteria for the\nloss function and the underlying probability distribution which ensure that all\nadditional artificial generalized responses are suboptimal which finally allows\nus to conclude the existence of minimizers in the optimization landscape.\n","authors":["Steffen Dereich","Arnulf Jentzen","Sebastian Kassing"],"pdf_url":"https://arxiv.org/pdf/2302.14690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16114v4","updated":"2023-02-28T16:00:34Z","published":"2022-10-28T13:21:28Z","title":"Towards Reliable Neural Specifications","summary":"  Having reliable specifications is an unavoidable challenge in achieving\nverifiable correctness, robustness, and interpretability of AI systems.\nExisting specifications for neural networks are in the paradigm of data as\nspecification. That is, the local neighborhood centering around a reference\ninput is considered to be correct (or robust). While existing specifications\ncontribute to verifying adversarial robustness, a significant problem in many\nresearch domains, our empirical study shows that those verified regions are\nsomewhat tight, and thus fail to allow verification of test set inputs, making\nthem impractical for some real-world applications. To this end, we propose a\nnew family of specifications called neural representation as specification,\nwhich uses the intrinsic information of neural networks - neural activation\npatterns (NAPs), rather than input data to specify the correctness and/or\nrobustness of neural network predictions. We present a simple statistical\napproach to mining neural activation patterns. To show the effectiveness of\ndiscovered NAPs, we formally verify several important properties, such as\nvarious types of misclassifications will never happen for a given NAP, and\nthere is no ambiguity between different NAPs. We show that by using NAP, we can\nverify a significant region of the input space, while still recalling 84% of\nthe data on MNIST. Moreover, we can push the verifiable bound to 10 times\nlarger on the CIFAR10 benchmark. Thus, we argue that NAPs can potentially be\nused as a more reliable and extensible specification for neural network\nverification.\n","authors":["Chuqin Geng","Nham Le","Xiaojie Xu","Zhaoyue Wang","Arie Gurfinkel","Xujie Si"],"pdf_url":"https://arxiv.org/pdf/2210.16114v4.pdf","comment":"19 pages, 16 figures"},{"id":"http://arxiv.org/abs/2302.14686v1","updated":"2023-02-28T15:55:52Z","published":"2023-02-28T15:55:52Z","title":"Approximately Stationary Bandits with Knapsacks","summary":"  Bandits with Knapsacks (BwK), the generalization of the Multi-Armed Bandits\nunder budget constraints, has received a lot of attention in recent years. It\nhas numerous applications, including dynamic pricing, repeated auctions, etc.\nPrevious work has focused on one of the two extremes: Stochastic BwK where the\nrewards and consumptions of the resources each round are sampled from an i.i.d.\ndistribution, and Adversarial BwK where these values are picked by an\nadversary. Achievable guarantees in the two cases exhibit a massive gap:\nNo-regret learning is achievable in Stochastic BwK, but in Adversarial BwK,\nonly competitive ratio style guarantees are achievable, where the competitive\nratio depends on the budget. What makes this gap so vast is that in Adversarial\nBwK the guarantees get worse in the typical case when the budget is more\nbinding. While ``best-of-both-worlds'' type algorithms are known (algorithms\nthat provide the best achievable guarantee in both extreme cases), their\nguarantees degrade to the adversarial case as soon as the environment is not\nfully stochastic.\n  Our work aims to bridge this gap, offering guarantees for a workload that is\nnot exactly stochastic but is also not worst-case. We define a condition,\nApproximately Stationary BwK, that parameterizes how close to stochastic or\nadversarial an instance is. Based on these parameters, we explore what is the\nbest competitive ratio attainable in BwK. We explore two algorithms that are\noblivious to the values of the parameters but guarantee competitive ratios that\nsmoothly transition between the best possible guarantees in the two extreme\ncases, depending on the values of the parameters. Our guarantees offer great\nimprovement over the adversarial guarantee, especially when the available\nbudget is small. We also prove bounds on the achievable guarantee, showing that\nour results are approximately tight when the budget is small.\n","authors":["Giannis Fikioris","Éva Tardos"],"pdf_url":"https://arxiv.org/pdf/2302.14686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14685v1","updated":"2023-02-28T15:54:47Z","published":"2023-02-28T15:54:47Z","title":"DART: Diversify-Aggregate-Repeat Training Improves Generalization of\n  Neural Networks","summary":"  Generalization of neural networks is crucial for deploying them safely in the\nreal world. Common training strategies to improve generalization involve the\nuse of data augmentations, ensembling and model averaging. In this work, we\nfirst establish a surprisingly simple but strong benchmark for generalization\nwhich utilizes diverse augmentations within a training minibatch, and show that\nthis can learn a more balanced distribution of features. Further, we propose\nDiversify-Aggregate-Repeat Training (DART) strategy that first trains diverse\nmodels using different augmentations (or domains) to explore the loss basin,\nand further Aggregates their weights to combine their expertise and obtain\nimproved generalization. We find that Repeating the step of Aggregation\nthroughout training improves the overall optimization trajectory and also\nensures that the individual models have a sufficiently low loss barrier to\nobtain improved generalization on combining them. We shed light on our approach\nby casting it in the framework proposed by Shen et al. and theoretically show\nthat it indeed generalizes better. In addition to improvements in In- Domain\ngeneralization, we demonstrate SOTA performance on the Domain Generalization\nbenchmarks in the popular DomainBed framework as well. Our method is generic\nand can easily be integrated with several base training algorithms to achieve\nperformance gains.\n","authors":["Samyak Jain","Sravanti Addepalli","Pawan Sahu","Priyam Dey","R. Venkatesh Babu"],"pdf_url":"https://arxiv.org/pdf/2302.14685v1.pdf","comment":"Accepted at CVPR 2023. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2206.14507v3","updated":"2023-02-28T15:53:18Z","published":"2022-06-29T09:56:59Z","title":"Variational Quantum Approximate Support Vector Machine with Inference\n  Transfer","summary":"  A kernel-based quantum classifier is the most practical and influential\nquantum machine learning technique for the hyper-linear classification of\ncomplex data. We propose a Variational Quantum Approximate Support Vector\nMachine (VQASVM) algorithm that demonstrates empirical sub-quadratic run-time\ncomplexity with quantum operations feasible even in NISQ computers. We\nexperimented our algorithm with toy example dataset on cloud-based NISQ\nmachines as a proof of concept. We also numerically investigated its\nperformance on the standard Iris flower and MNIST datasets to confirm the\npracticality and scalability.\n","authors":["Siheon Park","Daniel K. Park","June-Koo Kevin Rhee"],"pdf_url":"https://arxiv.org/pdf/2206.14507v3.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2110.01960v3","updated":"2023-02-28T15:48:17Z","published":"2021-10-05T11:42:36Z","title":"Energy-based survival modelling using harmoniums","summary":"  Survival analysis concerns the study of timeline data where the event of\ninterest may remain unobserved (i.e., censored). Studies commonly record more\nthan one type of event, but conventional survival techniques focus on a single\nevent type. We set out to integrate both multiple independently censored\ntime-to-event variables as well as missing observations. An energy-based\napproach is taken with a bi-partite structure between latent and visible\nstates, known as harmoniums (or restricted Boltzmann machines). The present\nharmonium is shown, both theoretically and experimentally, to capture\nnon-linearly separable patterns between distinct time recordings. We illustrate\non real world data that, for a single time-to-event variable, our model is on\npar with established methods. In addition, we demonstrate that discriminative\npredictions improve by leveraging an extra time-to-event variable. In\nconclusion, multiple time-to-event variables can be successfully captured\nwithin the harmonium paradigm.\n","authors":["Hylke C. Donker","Harry J. M. Groen"],"pdf_url":"https://arxiv.org/pdf/2110.01960v3.pdf","comment":"11 + 9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.14679v1","updated":"2023-02-28T15:42:30Z","published":"2023-02-28T15:42:30Z","title":"Synthesizing Mixed-type Electronic Health Records using Diffusion Models","summary":"  Electronic Health Records (EHRs) contain sensitive patient information, which\npresents privacy concerns when sharing such data. Synthetic data generation is\na promising solution to mitigate these risks, often relying on deep generative\nmodels such as Generative Adversarial Networks (GANs). However, recent studies\nhave shown that diffusion models offer several advantages over GANs, such as\ngeneration of more realistic synthetic data and stable training in generating\ndata modalities, including image, text, and sound. In this work, we investigate\nthe potential of diffusion models for generating realistic mixed-type tabular\nEHRs, comparing TabDDPM model with existing methods on four datasets in terms\nof data quality, utility, privacy, and augmentation. Our experiments\ndemonstrate that TabDDPM outperforms the state-of-the-art models across all\nevaluation metrics, except for privacy, which confirms the trade-off between\nprivacy and utility.\n","authors":["Taha Ceritli","Ghadeer O. Ghosheh","Vinod Kumar Chauhan","Tingting Zhu","Andrew P. Creagh","David A. Clifton"],"pdf_url":"https://arxiv.org/pdf/2302.14679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14678v1","updated":"2023-02-28T15:39:42Z","published":"2023-02-28T15:39:42Z","title":"Graph Reinforcement Learning for Operator Selection in the ALNS\n  Metaheuristic","summary":"  ALNS is a popular metaheuristic with renowned efficiency in solving\ncombinatorial optimisation problems. However, despite 16 years of intensive\nresearch into ALNS, whether the embedded adaptive layer can efficiently select\noperators to improve the incumbent remains an open question. In this work, we\nformulate the choice of operators as a Markov Decision Process, and propose a\npractical approach based on Deep Reinforcement Learning and Graph Neural\nNetworks. The results show that our proposed method achieves better performance\nthan the classic ALNS adaptive layer due to the choice of operator being\nconditioned on the current solution. We also discuss important considerations\nsuch as the size of the operator portfolio and the impact of the choice of\noperator scales. Notably, our approach can also save significant time and\nlabour costs for handcrafting problem-specific operator portfolios.\n","authors":["Syu-Ning Johnn","Victor-Alexandru Darvariu","Julia Handl","Joerg Kalcsics"],"pdf_url":"https://arxiv.org/pdf/2302.14678v1.pdf","comment":"To appear in Proceedings of The International Conference in\n  Optimization and Learning (OLA2023)"},{"id":"http://arxiv.org/abs/2302.14670v1","updated":"2023-02-28T15:34:01Z","published":"2023-02-28T15:34:01Z","title":"Double Dynamic Sparse Training for GANs","summary":"  The past decade has witnessed a drastic increase in modern deep neural\nnetworks (DNNs) size, especially for generative adversarial networks (GANs).\nSince GANs usually suffer from high computational complexity, researchers have\nshown an increased interest in applying pruning methods to reduce the training\nand inference costs of GANs. Among different pruning methods invented for\nsupervised learning, dynamic sparse training (DST) has gained increasing\nattention recently as it enjoys excellent training efficiency with comparable\nperformance to post-hoc pruning. Hence, applying DST on GANs, where we train a\nsparse GAN with a fixed parameter count throughout training, seems to be a good\ncandidate for reducing GAN training costs. However, a few challenges, including\nthe degrading training instability, emerge due to the adversarial nature of\nGANs. Hence, we introduce a quantity called balance ratio (BR) to quantify the\nbalance of the generator and the discriminator. We conduct a series of\nexperiments to show the importance of BR in understanding sparse GAN training.\nBuilding upon single dynamic sparse training (SDST), where only the generator\nis adjusted during training, we propose double dynamic sparse training (DDST)\nto control the BR during GAN training. Empirically, DDST automatically\ndetermines the density of the discriminator and greatly boosts the performance\nof sparse GANs on multiple datasets.\n","authors":["Yite Wang","Jing Wu","Naira Hovakimyan","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2302.14670v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.14665v1","updated":"2023-02-28T15:31:23Z","published":"2023-02-28T15:31:23Z","title":"Parametrizing Product Shape Manifolds by Composite Networks","summary":"  Parametrizations of data manifolds in shape spaces can be computed using the\nrich toolbox of Riemannian geometry. This, however, often comes with high\ncomputational costs, which raises the question if one can learn an efficient\nneural network approximation. We show that this is indeed possible for shape\nspaces with a special product structure, namely those smoothly approximable by\na direct sum of low-dimensional manifolds. Our proposed architecture leverages\nthis structure by separately learning approximations for the low-dimensional\nfactors and a subsequent combination. After developing the approach as a\ngeneral framework, we apply it to a shape space of triangular surfaces. Here,\ntypical examples of data manifolds are given through datasets of articulated\nmodels and can be factorized, for example, by a Sparse Principal Geodesic\nAnalysis (SPGA). We demonstrate the effectiveness of our proposed approach with\nexperiments on synthetic data as well as manifolds extracted from data via\nSPGA.\n","authors":["Josua Sassen","Klaus Hildebrandt","Martin Rumpf","Benedikt Wirth"],"pdf_url":"https://arxiv.org/pdf/2302.14665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.13248v4","updated":"2023-02-28T15:19:57Z","published":"2022-02-26T23:00:34Z","title":"Automated Data Augmentations for Graph Classification","summary":"  Data augmentations are effective in improving the invariance of learning\nmachines. We argue that the core challenge of data augmentations lies in\ndesigning data transformations that preserve labels. This is relatively\nstraightforward for images, but much more challenging for graphs. In this work,\nwe propose GraphAug, a novel automated data augmentation method aiming at\ncomputing label-invariant augmentations for graph classification. Instead of\nusing uniform transformations as in existing studies, GraphAug uses an\nautomated augmentation model to avoid compromising critical label-related\ninformation of the graph, thereby producing label-invariant augmentations at\nmost times. To ensure label-invariance, we develop a training method based on\nreinforcement learning to maximize an estimated label-invariance probability.\nExperiments show that GraphAug outperforms previous graph augmentation methods\non various graph classification tasks.\n","authors":["Youzhi Luo","Michael McThrow","Wing Yee Au","Tao Komikado","Kanji Uchino","Koji Maruhashi","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2202.13248v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14640v1","updated":"2023-02-28T15:18:42Z","published":"2023-02-28T15:18:42Z","title":"Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start\n  Recommendation","summary":"  Sequential recommenders have made great strides in capturing a user's\npreferences. Nevertheless, the cold-start recommendation remains a fundamental\nchallenge in which only a few user-item interactions are available for\npersonalization. Gradient-based meta-learning approaches have recently emerged\nin the sequential recommendation field due to their fast adaptation and\neasy-to-integrate abilities. The meta-learning algorithms formulate the\ncold-start recommendation as a few-shot learning problem, where each user is\nrepresented as a task to be adapted. However, while meta-learning algorithms\ngenerally assume that task-wise samples are evenly distributed over classes or\nvalues, user-item interactions are not that way in real-world applications\n(e.g., watching favorite videos multiple times, leaving only good ratings and\nno bad ones). As a result, in the real-world, imbalanced user feedback that\naccounts for most task training data may dominate the user adaptation and\nprevent meta-learning algorithms from learning meaningful meta-knowledge for\npersonalized recommendations. To alleviate this limitation, we propose a novel\nsequential recommendation framework based on gradient-based meta-learning that\ncaptures the imbalance of each user's rating distribution and accordingly\ncomputes adaptive loss for user-specific learning. It is the first work to\ntackle the impact of imbalanced ratings in cold-start sequential recommendation\nscenarios. We design adaptive weighted loss and improve the existing\nmeta-learning algorithms for state-of-the-art sequential recommendation\nmethods. Extensive experiments conducted on real-world datasets demonstrate the\neffectiveness of our framework.\n","authors":["Minchang Kim","Yongjin Yang","Jung Hyun Ryu","Taesup Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14625v1","updated":"2023-02-28T15:06:03Z","published":"2023-02-28T15:06:03Z","title":"mmSense: Detecting Concealed Weapons with a Miniature Radar Sensor","summary":"  For widespread adoption, public security and surveillance systems must be\naccurate, portable, compact, and real-time, without impeding the privacy of the\nindividuals being observed. Current systems broadly fall into two categories --\nimage-based which are accurate, but lack privacy, and RF signal-based, which\npreserve privacy but lack portability, compactness and accuracy. Our paper\nproposes mmSense, an end-to-end portable miniaturised real-time system that can\naccurately detect the presence of concealed metallic objects on persons in a\ndiscrete, privacy-preserving modality. mmSense features millimeter wave radar\ntechnology, provided by Google's Soli sensor for its data acquisition, and\nTransDope, our real-time neural network, capable of processing a single radar\ndata frame in 19 ms. mmSense achieves high recognition rates on a diverse set\nof challenging scenes while running on standard laptop hardware, demonstrating\na significant advancement towards creating portable, cost-effective real-time\nradar based surveillance systems.\n","authors":["Kevin Mitchell","Khaled Kassem","Chaitanya Kaul","Valentin Kapitany","Philip Binner","Andrew Ramsay","Roderick Murray-Smith","Daniele Faccio"],"pdf_url":"https://arxiv.org/pdf/2302.14625v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.14624v1","updated":"2023-02-28T15:05:33Z","published":"2023-02-28T15:05:33Z","title":"The 2022 NIST Language Recognition Evaluation","summary":"  In 2022, the U.S. National Institute of Standards and Technology (NIST)\nconducted the latest Language Recognition Evaluation (LRE) in an ongoing series\nadministered by NIST since 1996 to foster research in language recognition and\nto measure state-of-the-art technology. Similar to previous LREs, LRE22 focused\non conversational telephone speech (CTS) and broadcast narrowband speech (BNBS)\ndata. LRE22 also introduced new evaluation features, such as an emphasis on\nAfrican languages, including low resource languages, and a test set consisting\nof segments containing between 3s and 35s of speech randomly sampled and\nextracted from longer recordings. A total of 21 research organizations, forming\n16 teams, participated in this 3-month long evaluation and made a total of 65\nvalid system submissions to be evaluated. This paper presents an overview of\nLRE22 and an analysis of system performance over different evaluation\nconditions. The evaluation results suggest that Oromo and Tigrinya are easier\nto detect while Xhosa and Zulu are more challenging. A greater confusability is\nseen for some language pairs. When speech duration increased, system\nperformance significantly increased up to a certain duration, and then a\ndiminishing return on system performance is observed afterward.\n","authors":["Yooyoung Lee","Craig Greenberg","Eliot Godard","Asad A. Butt","Elliot Singer","Trang Nguyen","Lisa Mason","Douglas Reynolds"],"pdf_url":"https://arxiv.org/pdf/2302.14624v1.pdf","comment":"5 pages, 10 figures"},{"id":"http://arxiv.org/abs/2302.14623v1","updated":"2023-02-28T15:03:18Z","published":"2023-02-28T15:03:18Z","title":"Fast as CHITA: Neural Network Pruning with Combinatorial Optimization","summary":"  The sheer size of modern neural networks makes model serving a serious\ncomputational challenge. A popular class of compression techniques overcomes\nthis challenge by pruning or sparsifying the weights of pretrained networks.\nWhile useful, these techniques often face serious tradeoffs between\ncomputational requirements and compression quality. In this work, we propose a\nnovel optimization-based pruning framework that considers the combined effect\nof pruning (and updating) multiple weights subject to a sparsity constraint.\nOur approach, CHITA, extends the classical Optimal Brain Surgeon framework and\nresults in significant improvements in speed, memory, and performance over\nexisting optimization-based approaches for network pruning. CHITA's main\nworkhorse performs combinatorial optimization updates on a memory-friendly\nrepresentation of local quadratic approximation(s) of the loss function. On a\nstandard benchmark of pretrained models and datasets, CHITA leads to\nsignificantly better sparsity-accuracy tradeoffs than competing methods. For\nexample, for MLPNet with only 2% of the weights retained, our approach improves\nthe accuracy by 63% relative to the state of the art. Furthermore, when used in\nconjunction with fine-tuning SGD steps, our method achieves significant\naccuracy gains over the state-of-the-art approaches.\n","authors":["Riade Benbaki","Wenyu Chen","Xiang Meng","Hussein Hazimeh","Natalia Ponomareva","Zhe Zhao","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2302.14623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09709v2","updated":"2023-02-28T14:57:32Z","published":"2023-01-23T20:32:41Z","title":"On The Convergence Of Policy Iteration-Based Reinforcement Learning With\n  Monte Carlo Policy Evaluation","summary":"  A common technique in reinforcement learning is to evaluate the value\nfunction from Monte Carlo simulations of a given policy, and use the estimated\nvalue function to obtain a new policy which is greedy with respect to the\nestimated value function. A well-known longstanding open problem in this\ncontext is to prove the convergence of such a scheme when the value function of\na policy is estimated from data collected from a single sample path obtained\nfrom implementing the policy (see page 99 of [Sutton and Barto, 2018], page 8\nof [Tsitsiklis, 2002]). We present a solution to the open problem by showing\nthat a first-visit version of such a policy iteration scheme indeed converges\nto the optimal policy provided that the policy improvement step uses lookahead\n[Silver et al., 2016, Mnih et al., 2016, Silver et al., 2017b] rather than a\nsimple greedy policy improvement. We provide results both for the original open\nproblem in the tabular setting and also present extensions to the function\napproximation setting, where we show that the policy resulting from the\nalgorithm performs close to the optimal policy within a function approximation\nerror.\n","authors":["Anna Winnicki","R. Srikant"],"pdf_url":"https://arxiv.org/pdf/2301.09709v2.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2302.14616v1","updated":"2023-02-28T14:55:57Z","published":"2023-02-28T14:55:57Z","title":"Metric Learning Improves the Ability of Combinatorial Coverage Metrics\n  to Anticipate Classification Error","summary":"  Machine learning models are increasingly used in practice. However, many\nmachine learning methods are sensitive to test or operational data that is\ndissimilar to training data. Out-of-distribution (OOD) data is known to\nincrease the probability of error and research into metrics that identify what\ndissimilarities in data affect model performance is on-going. Recently,\ncombinatorial coverage metrics have been explored in the literature as an\nalternative to distribution-based metrics. Results show that coverage metrics\ncan correlate with classification error. However, other results show that the\nutility of coverage metrics is highly dataset-dependent. In this paper, we show\nthat this dataset-dependence can be alleviated with metric learning, a machine\nlearning technique for learning latent spaces where data from different classes\nis further apart. In a study of 6 open-source datasets, we find that metric\nlearning increased the difference between set-difference coverage metrics\n(SDCCMs) calculated on correctly and incorrectly classified data, thereby\ndemonstrating that metric learning improves the ability of SDCCMs to anticipate\nclassification error. Paired t-tests validate the statistical significance of\nour findings. Overall, we conclude that metric learning improves the ability of\ncoverage metrics to anticipate classifier error and identify when OOD data is\nlikely to degrade model performance.\n","authors":["Tyler Cody","Laura Freeman"],"pdf_url":"https://arxiv.org/pdf/2302.14616v1.pdf","comment":"Accepted 2022 IEEE International Conference on Software Testing\n  International Workshop on Combinatorial Testing (IEEE ICST IWCT)"},{"id":"http://arxiv.org/abs/2302.14604v1","updated":"2023-02-28T14:44:29Z","published":"2023-02-28T14:44:29Z","title":"IQ-Flow: Mechanism Design for Inducing Cooperative Behavior to\n  Self-Interested Agents in Sequential Social Dilemmas","summary":"  Achieving and maintaining cooperation between agents to accomplish a common\nobjective is one of the central goals of Multi-Agent Reinforcement Learning\n(MARL). Nevertheless in many real-world scenarios, separately trained and\nspecialized agents are deployed into a shared environment, or the environment\nrequires multiple objectives to be achieved by different coexisting parties.\nThese variations among specialties and objectives are likely to cause mixed\nmotives that eventually result in a social dilemma where all the parties are at\na loss. In order to resolve this issue, we propose the Incentive Q-Flow\n(IQ-Flow) algorithm, which modifies the system's reward setup with an incentive\nregulator agent such that the cooperative policy also corresponds to the\nself-interested policy for the agents. Unlike the existing methods that learn\nto incentivize self-interested agents, IQ-Flow does not make any assumptions\nabout agents' policies or learning algorithms, which enables the generalization\nof the developed framework to a wider array of applications. IQ-Flow performs\nan offline evaluation of the optimality of the learned policies using the data\nprovided by other agents to determine cooperative and self-interested policies.\nNext, IQ-Flow uses meta-gradient learning to estimate how policy evaluation\nchanges according to given incentives and modifies the incentive such that the\ngreedy policy for cooperative objective and self-interested objective yield the\nsame actions. We present the operational characteristics of IQ-Flow in Iterated\nMatrix Games. We demonstrate that IQ-Flow outperforms the state-of-the-art\nincentive design algorithm in Escape Room and 2-Player Cleanup environments. We\nfurther demonstrate that the pretrained IQ-Flow mechanism significantly\noutperforms the performance of the shared reward setup in the 2-Player Cleanup\nenvironment.\n","authors":["Bengisu Guresti","Abdullah Vanlioglu","Nazim Kemal Ure"],"pdf_url":"https://arxiv.org/pdf/2302.14604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14599v1","updated":"2023-02-28T14:39:18Z","published":"2023-02-28T14:39:18Z","title":"Scalable Clustering: Large Scale Unsupervised Learning of Gaussian\n  Mixture Models with Outliers","summary":"  Clustering is a widely used technique with a long and rich history in a\nvariety of areas. However, most existing algorithms do not scale well to large\ndatasets, or are missing theoretical guarantees of convergence. This paper\nintroduces a provably robust clustering algorithm based on loss minimization\nthat performs well on Gaussian mixture models with outliers. It provides\ntheoretical guarantees that the algorithm obtains high accuracy with high\nprobability under certain assumptions. Moreover, it can also be used as an\ninitialization strategy for $k$-means clustering. Experiments on real-world\nlarge-scale datasets demonstrate the effectiveness of the algorithm when\nclustering a large number of clusters, and a $k$-means algorithm initialized by\nthe algorithm outperforms many of the classic clustering methods in both speed\nand accuracy, while scaling well to large datasets such as ImageNet.\n","authors":["Yijia Zhou","Kyle A. Gallivan","Adrian Barbu"],"pdf_url":"https://arxiv.org/pdf/2302.14599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07124v2","updated":"2023-02-28T14:21:09Z","published":"2022-09-15T08:13:40Z","title":"The Cost of Training Machine Learning Models over Distributed Data\n  Sources","summary":"  Federated learning is one of the most appealing alternatives to the standard\ncentralized learning paradigm, allowing a heterogeneous set of devices to train\na machine learning model without sharing their raw data. However, it requires a\ncentral server to coordinate the learning process, thus introducing potential\nscalability and security issues. In the literature, server-less federated\nlearning approaches like gossip federated learning and blockchain-enabled\nfederated learning have been proposed to mitigate these issues. In this work,\nwe propose a complete overview of these three techniques proposing a comparison\naccording to an integral set of performance indicators, including model\naccuracy, time complexity, communication overhead, convergence time, and energy\nconsumption. An extensive simulation campaign permits to draw a quantitative\nanalysis considering both feedforward and convolutional neural network models.\nResults show that gossip federated learning and standard federated solution are\nable to reach a similar level of accuracy, and their energy consumption is\ninfluenced by the machine learning model adopted, the software library, and the\nhardware used. Differently, blockchain-enabled federated learning represents a\nviable solution for implementing decentralized learning with a higher level of\nsecurity, at the cost of an extra energy usage and data sharing. Finally, we\nidentify open issues on the two decentralized federated learning\nimplementations and provide insights on potential extensions and possible\nresearch directions in this new research field.\n","authors":["Elia Guerra","Francesc Wilhelmi","Marco Miozzo","Paolo Dini"],"pdf_url":"https://arxiv.org/pdf/2209.07124v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2002.11021v2","updated":"2023-02-28T14:09:29Z","published":"2020-02-23T05:39:54Z","title":"SNIFF: Reverse Engineering of Neural Networks with Fault Attacks","summary":"  Neural networks have been shown to be vulnerable against fault injection\nattacks. These attacks change the physical behavior of the device during the\ncomputation, resulting in a change of value that is currently being computed.\nThey can be realized by various fault injection techniques, ranging from\nclock/voltage glitching to application of lasers to rowhammer. In this paper we\nexplore the possibility to reverse engineer neural networks with the usage of\nfault attacks. SNIFF stands for sign bit flip fault, which enables the reverse\nengineering by changing the sign of intermediate values. We develop the first\nexact extraction method on deep-layer feature extractor networks that provably\nallows the recovery of the model parameters. Our experiments with Keras library\nshow that the precision error for the parameter recovery for the tested\nnetworks is less than $10^{-13}$ with the usage of 64-bit floats, which\nimproves the current state of the art by 6 orders of magnitude. Additionally,\nwe discuss the protection techniques against fault injection attacks that can\nbe applied to enhance the fault resistance.\n","authors":["Jakub Breier","Dirmanto Jap","Xiaolu Hou","Shivam Bhasin","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2002.11021v2.pdf","comment":"Published in IEEE Transactions on Reliability"},{"id":"http://arxiv.org/abs/2302.14576v1","updated":"2023-02-28T13:55:19Z","published":"2023-02-28T13:55:19Z","title":"Co-Design of Approximate Multilayer Perceptron for Ultra-Resource\n  Constrained Printed Circuits","summary":"  Printed Electronics (PE) exhibits on-demand, extremely low-cost hardware due\nto its additive manufacturing process, enabling machine learning (ML)\napplications for domains that feature ultra-low cost, conformity, and\nnon-toxicity requirements that silicon-based systems cannot deliver.\nNevertheless, large feature sizes in PE prohibit the realization of complex\nprinted ML circuits. In this work, we present, for the first time, an automated\nprinted-aware software/hardware co-design framework that exploits approximate\ncomputing principles to enable ultra-resource constrained printed multilayer\nperceptrons (MLPs). Our evaluation demonstrates that, compared to the\nstate-of-the-art baseline, our circuits feature on average 6x (5.7x) lower area\n(power) and less than 1% accuracy loss.\n","authors":["Giorgos Armeniakos","Georgios Zervakis","Dimitrios Soudris","Mehdi B. Tahoori","Jörg Henkel"],"pdf_url":"https://arxiv.org/pdf/2302.14576v1.pdf","comment":"Accepted for publication by IEEE Transactions on Computers, February\n  2023"},{"id":"http://arxiv.org/abs/2302.14567v1","updated":"2023-02-28T13:43:23Z","published":"2023-02-28T13:43:23Z","title":"Active Learning with Combinatorial Coverage","summary":"  Active learning is a practical field of machine learning that automates the\nprocess of selecting which data to label. Current methods are effective in\nreducing the burden of data labeling but are heavily model-reliant. This has\nled to the inability of sampled data to be transferred to new models as well as\nissues with sampling bias. Both issues are of crucial concern in machine\nlearning deployment. We propose active learning methods utilizing combinatorial\ncoverage to overcome these issues. The proposed methods are data-centric, as\nopposed to model-centric, and through our experiments we show that the\ninclusion of coverage in active learning leads to sampling data that tends to\nbe the best in transferring to better performing models and has a competitive\nsampling bias compared to benchmark methods.\n","authors":["Sai Prathyush Katragadda","Tyler Cody","Peter Beling","Laura Freeman"],"pdf_url":"https://arxiv.org/pdf/2302.14567v1.pdf","comment":"Accepted 2022 IEEE International Conference on Machine Learning and\n  Applications (IEEE ICMLA)"},{"id":"http://arxiv.org/abs/2302.03662v2","updated":"2023-02-28T13:27:32Z","published":"2023-02-07T18:26:07Z","title":"Federated Learning with Regularized Client Participation","summary":"  Federated Learning (FL) is a distributed machine learning approach where\nmultiple clients work together to solve a machine learning task. One of the key\nchallenges in FL is the issue of partial participation, which occurs when a\nlarge number of clients are involved in the training process. The traditional\nmethod to address this problem is randomly selecting a subset of clients at\neach communication round. In our research, we propose a new technique and\ndesign a novel regularized client participation scheme. Under this scheme, each\nclient joins the learning process every $R$ communication rounds, which we\nrefer to as a meta epoch. We have found that this participation scheme leads to\na reduction in the variance caused by client sampling. Combined with the\npopular FedAvg algorithm (McMahan et al., 2017), it results in superior rates\nunder standard assumptions. For instance, the optimization term in our main\nconvergence bound decreases linearly with the product of the number of\ncommunication rounds and the size of the local dataset of each client, and the\nstatistical term scales with step size quadratically instead of linearly (the\ncase for client sampling with replacement), leading to better convergence rate\n$\\mathcal{O}\\left(\\frac{1}{T^2}\\right)$ compared to\n$\\mathcal{O}\\left(\\frac{1}{T}\\right)$, where $T$ is the total number of\ncommunication rounds. Furthermore, our results permit arbitrary client\navailability as long as each client is available for training once per each\nmeta epoch.\n","authors":["Grigory Malinovsky","Samuel Horváth","Konstantin Burlachenko","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2302.03662v2.pdf","comment":"33 pages, 10 figures,1 algorithm, 3 theorems"},{"id":"http://arxiv.org/abs/2207.02098v3","updated":"2023-02-28T13:22:17Z","published":"2022-07-05T15:06:11Z","title":"Neural Networks and the Chomsky Hierarchy","summary":"  Reliable generalization lies at the heart of safe ML and AI. However,\nunderstanding when and how neural networks generalize remains one of the most\nimportant unsolved problems in the field. In this work, we conduct an extensive\nempirical study (20'910 models, 15 tasks) to investigate whether insights from\nthe theory of computation can predict the limits of neural network\ngeneralization in practice. We demonstrate that grouping tasks according to the\nChomsky hierarchy allows us to forecast whether certain architectures will be\nable to generalize to out-of-distribution inputs. This includes negative\nresults where even extensive amounts of data and training time never lead to\nany non-trivial generalization, despite models having sufficient capacity to\nfit the training data perfectly. Our results show that, for our subset of\ntasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can\nsolve regular and counter-language tasks, and only networks augmented with\nstructured memory (such as a stack or memory tape) can successfully generalize\non context-free and context-sensitive tasks.\n","authors":["Grégoire Delétang","Anian Ruoss","Jordi Grau-Moya","Tim Genewein","Li Kevin Wenliang","Elliot Catt","Chris Cundy","Marcus Hutter","Shane Legg","Joel Veness","Pedro A. Ortega"],"pdf_url":"https://arxiv.org/pdf/2207.02098v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14552v1","updated":"2023-02-28T13:17:56Z","published":"2023-02-28T13:17:56Z","title":"Toward Robust Uncertainty Estimation with Random Activation Functions","summary":"  Deep neural networks are in the limelight of machine learning with their\nexcellent performance in many data-driven applications. However, they can lead\nto inaccurate predictions when queried in out-of-distribution data points,\nwhich can have detrimental effects especially in sensitive domains, such as\nhealthcare and transportation, where erroneous predictions can be very costly\nand/or dangerous. Subsequently, quantifying the uncertainty of the output of a\nneural network is often leveraged to evaluate the confidence of its\npredictions, and ensemble models have proved to be effective in measuring the\nuncertainty by utilizing the variance of predictions over a pool of models. In\nthis paper, we propose a novel approach for uncertainty quantification via\nensembles, called Random Activation Functions (RAFs) Ensemble, that aims at\nimproving the ensemble diversity toward a more robust estimation, by\naccommodating each neural network with a different (random) activation\nfunction. Extensive empirical study demonstrates that RAFs Ensemble outperforms\nstate-of-the-art ensemble uncertainty quantification methods on both synthetic\nand real-world datasets in a series of regression tasks.\n","authors":["Yana Stoyanova","Soroush Ghandi","Maryam Tavakol"],"pdf_url":"https://arxiv.org/pdf/2302.14552v1.pdf","comment":"Published at AAAI 2023, the Thirty-Seventh AAAI Conference on\n  Artificial Intelligence"},{"id":"http://arxiv.org/abs/2302.14548v1","updated":"2023-02-28T13:14:07Z","published":"2023-02-28T13:14:07Z","title":"Safe-DS: A Domain Specific Language to Make Data Science Safe","summary":"  Due to the long runtime of Data Science (DS) pipelines, even small\nprogramming mistakes can be very costly, if they are not detected statically.\nHowever, even basic static type checking of DS pipelines is difficult because\nmost are written in Python. Static typing is available in Python only via\nexternal linters. These require static type annotations for parameters or\nresults of functions, which many DS libraries do not provide. In this paper, we\nshow how the wealth of Python DS libraries can be used in a statically safe way\nvia Safe-DS, a domain specific language (DSL) for DS. Safe-DS catches\nconventional type errors plus errors related to range restrictions, data\nmanipulation, and call order of functions, going well beyond the abilities of\ncurrent Python linters. Python libraries are integrated into Safe-DS via a stub\nlanguage for specifying the interface of its declarations, and an API-Editor\nthat is able to extract type information from the code and documentation of\nPython libraries, and automatically generate suitable stubs.\n  Moreover, Safe-DS complements textual DS pipelines with a graphical\nrepresentation that eases safe development by preventing syntax errors. The\nseamless synchronization of textual and graphic view lets developers always\nchoose the one best suited for their skills and current task. We think that\nSafe-DS can make DS development easier, faster, and more reliable,\nsignificantly reducing development costs.\n","authors":["Lars Reimann","Günter Kniesel-Wünsche"],"pdf_url":"https://arxiv.org/pdf/2302.14548v1.pdf","comment":"Accepted for the NIER Track of the 45th International Conference on\n  Software Engineering (ICSE 2023)"},{"id":"http://arxiv.org/abs/2211.12005v2","updated":"2023-02-28T13:11:00Z","published":"2022-11-22T04:54:20Z","title":"Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors","summary":"  As data becomes increasingly vital, a company would be very cautious about\nreleasing data, because the competitors could use it to train high-performance\nmodels, thereby posing a tremendous threat to the company's commercial\ncompetence. To prevent training good models on the data, we could add\nimperceptible perturbations to it. Since such perturbations aim at hurting the\nentire training process, they should reflect the vulnerability of DNN training,\nrather than that of a single model. Based on this new idea, we seek perturbed\nexamples that are always unrecognized (never correctly classified) in training.\nIn this paper, we uncover them by model checkpoints' gradients, forming the\nproposed self-ensemble protection (SEP), which is very effective because (1)\nlearning on examples ignored during normal training tends to yield DNNs\nignoring normal examples; (2) checkpoints' cross-model gradients are close to\northogonal, meaning that they are as diverse as DNNs with different\narchitectures. That is, our amazing performance of ensemble only requires the\ncomputation of training one model. By extensive experiments with 9 baselines on\n3 datasets and 5 architectures, SEP is verified to be a new state-of-the-art,\ne.g., our small $\\ell_\\infty=2/255$ perturbations reduce the accuracy of a\nCIFAR-10 ResNet18 from 94.56% to 14.68%, compared to 41.35% by the best-known\nmethod. Code is available at https://github.com/Sizhe-Chen/SEP.\n","authors":["Sizhe Chen","Geng Yuan","Xinwen Cheng","Yifan Gong","Minghai Qin","Yanzhi Wang","Xiaolin Huang"],"pdf_url":"https://arxiv.org/pdf/2211.12005v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14545v1","updated":"2023-02-28T13:10:04Z","published":"2023-02-28T13:10:04Z","title":"Modern Bayesian Experimental Design","summary":"  Bayesian experimental design (BED) provides a powerful and general framework\nfor optimizing the design of experiments. However, its deployment often poses\nsubstantial computational challenges that can undermine its practical use. In\nthis review, we outline how recent advances have transformed our ability to\novercome these challenges and thus utilize BED effectively, before discussing\nsome key areas for future development in the field.\n","authors":["Tom Rainforth","Adam Foster","Desi R Ivanova","Freddie Bickford Smith"],"pdf_url":"https://arxiv.org/pdf/2302.14545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13531v2","updated":"2023-02-28T13:06:52Z","published":"2022-05-26T17:50:55Z","title":"Learning ReLU networks to high uniform accuracy is intractable","summary":"  Statistical learning theory provides bounds on the necessary number of\ntraining samples needed to reach a prescribed accuracy in a learning problem\nformulated over a given target class. This accuracy is typically measured in\nterms of a generalization error, that is, an expected value of a given loss\nfunction. However, for several applications -- for example in a\nsecurity-critical context or for problems in the computational sciences --\naccuracy in this sense is not sufficient. In such cases, one would like to have\nguarantees for high accuracy on every input value, that is, with respect to the\nuniform norm. In this paper we precisely quantify the number of training\nsamples needed for any conceivable training algorithm to guarantee a given\nuniform accuracy on any learning problem formulated over target classes\ncontaining (or consisting of) ReLU neural networks of a prescribed\narchitecture. We prove that, under very general assumptions, the minimal number\nof training samples for this task scales exponentially both in the depth and\nthe input dimension of the network architecture.\n","authors":["Julius Berner","Philipp Grohs","Felix Voigtlaender"],"pdf_url":"https://arxiv.org/pdf/2205.13531v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2203.01629v4","updated":"2023-02-28T12:47:28Z","published":"2022-03-03T10:44:50Z","title":"Learning Group Importance using the Differentiable Hypergeometric\n  Distribution","summary":"  Partitioning a set of elements into subsets of a priori unknown sizes is\nessential in many applications. These subset sizes are rarely explicitly\nlearned - be it the cluster sizes in clustering applications or the number of\nshared versus independent generative latent factors in weakly-supervised\nlearning. Probability distributions over correct combinations of subset sizes\nare non-differentiable due to hard constraints, which prohibit gradient-based\noptimization. In this work, we propose the differentiable hypergeometric\ndistribution. The hypergeometric distribution models the probability of\ndifferent group sizes based on their relative importance. We introduce\nreparameterizable gradients to learn the importance between groups and\nhighlight the advantage of explicitly learning the size of subsets in two\ntypical applications: weakly-supervised learning and clustering. In both\napplications, we outperform previous approaches, which rely on suboptimal\nheuristics to model the unknown size of groups.\n","authors":["Thomas M. Sutter","Laura Manduchi","Alain Ryser","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2203.01629v4.pdf","comment":"ICLR 2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2302.11716v2","updated":"2023-02-28T12:21:42Z","published":"2023-02-23T00:45:14Z","title":"VRA: Out-of-Distribution Detection with variational rectified\n  activations","summary":"  Detecting out-of-distribution (OOD) data is critical to building reliable\nmachine learning systems in the open world. Among the existing OOD detection\nmethods, ReAct is famous for its simplicity and efficiency, and has good\ntheoretical analysis. The gap between ID data and OOD data is enlarged by\nclipping the larger activation value. But the question is, is this operation\noptimal? Is there a better way to expand the spacing between ID samples and OOD\nsamples in theory? Driven by these questions, we propose the Variational\nRecified Acitvations method. To verify the effectiveness of our method, we\nconduct experiments on many benchmark datasets. Experimental results\ndemonstrate that our method outperforms existing state-of-the-art approaches.\nMeanwhile, our method is easy to implement and does not require additional OOD\ndata or fine-tuning process. We can realize OOD detection in only one forward\npass.\n","authors":["Mingyu Xu","Zheng Lian"],"pdf_url":"https://arxiv.org/pdf/2302.11716v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14518v1","updated":"2023-02-28T12:13:57Z","published":"2023-02-28T12:13:57Z","title":"Asymptotically Optimal Generalization Error Bounds for Noisy, Iterative\n  Algorithms","summary":"  We adopt an information-theoretic framework to analyze the generalization\nbehavior of the class of iterative, noisy learning algorithms. This class is\nparticularly suitable for study under information-theoretic metrics as the\nalgorithms are inherently randomized, and it includes commonly used algorithms\nsuch as Stochastic Gradient Langevin Dynamics (SGLD). Herein, we use the\nmaximal leakage (equivalently, the Sibson mutual information of order infinity)\nmetric, as it is simple to analyze, and it implies both bounds on the\nprobability of having a large generalization error and on its expected value.\nWe show that, if the update function (e.g., gradient) is bounded in $L_2$-norm,\nthen adding isotropic Gaussian noise leads to optimal generalization bounds:\nindeed, the input and output of the learning algorithm in this case are\nasymptotically statistically independent. Furthermore, we demonstrate how the\nassumptions on the update function affect the optimal (in the sense of\nminimizing the induced maximal leakage) choice of the noise. Finally, we\ncompute explicit tight upper bounds on the induced maximal leakage for several\nscenarios of interest.\n","authors":["Ibrahim Issa","Amedeo Roberto Esposito","Michael Gastpar"],"pdf_url":"https://arxiv.org/pdf/2302.14518v1.pdf","comment":"Submitted to COLT 2023"},{"id":"http://arxiv.org/abs/2302.14517v1","updated":"2023-02-28T12:13:43Z","published":"2023-02-28T12:13:43Z","title":"Arbitrary Decisions are a Hidden Cost of Differentially-Private Training","summary":"  Mechanisms used in privacy-preserving machine learning often aim to guarantee\ndifferential privacy (DP) during model training. Practical DP-ensuring training\nmethods use randomization when fitting model parameters to privacy-sensitive\ndata (e.g., adding Gaussian noise to clipped gradients). We demonstrate that\nsuch randomization incurs predictive multiplicity: for a given input example,\nthe output predicted by equally-private models depends on the randomness used\nin training. Thus, for a given input, the predicted output can vary drastically\nif a model is re-trained, even if the same training dataset is used. The\npredictive-multiplicity cost of DP training has not been studied, and is\ncurrently neither audited for nor communicated to model designers and\nstakeholders. We derive a bound on the number of re-trainings required to\nestimate predictive multiplicity reliably. We analyze -- both theoretically and\nthrough extensive experiments -- the predictive-multiplicity cost of three\nDP-ensuring algorithms: output perturbation, objective perturbation, and\nDP-SGD. We demonstrate that the degree of predictive multiplicity rises as the\nlevel of privacy increases, and is unevenly distributed across individuals and\ndemographic groups in the data. Because randomness used to ensure DP during\ntraining explains predictions for some examples, our results highlight a\nfundamental challenge to the justifiability of decisions supported by\ndifferentially-private models in high-stakes settings. We conclude that\npractitioners should audit the predictive multiplicity of their DP-ensuring\nalgorithms before deploying them in applications of individual-level\nconsequence.\n","authors":["Bogdan Kulynych","Hsiang Hsu","Carmela Troncoso","Flavio P. Calmon"],"pdf_url":"https://arxiv.org/pdf/2302.14517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14514v1","updated":"2023-02-28T12:07:27Z","published":"2023-02-28T12:07:27Z","title":"Differentially Private Distributed Convex Optimization","summary":"  This paper considers distributed optimization (DO) where multiple agents\ncooperate to minimize a global objective function, expressed as a sum of local\nobjectives, subject to some constraints. In DO, each agent iteratively solves a\nlocal optimization model constructed by its own data and communicates some\ninformation (e.g., a local solution) with its neighbors until a global solution\nis obtained. Even though locally stored data are not shared with other agents,\nit is still possible to reconstruct the data from the information communicated\namong agents, which could limit the practical usage of DO in applications with\nsensitive data. To address this issue, we propose a privacy-preserving DO\nalgorithm for constrained convex optimization models, which provides a\nstatistical guarantee of data privacy, known as differential privacy, and a\nsequence of iterates that converges to an optimal solution in expectation. The\nproposed algorithm generalizes a linearized alternating direction method of\nmultipliers by introducing a multiple local updates technique to reduce\ncommunication costs and incorporating an objective perturbation method in the\nlocal optimization models to compute and communicate randomized feasible local\nsolutions that cannot be utilized to reconstruct the local data, thus\npreserving data privacy. Under the existence of convex constraints, we show\nthat, while both algorithms provide the same level of data privacy, the\nobjective perturbation used in the proposed algorithm can provide better\nsolutions than does the widely adopted output perturbation method that\nrandomizes the local solutions by adding some noise. We present the details of\nprivacy and convergence analyses and numerically demonstrate the effectiveness\nof the proposed algorithm by applying it in two different applications, namely,\ndistributed control of power flow and federated learning, where data privacy is\nof concern.\n","authors":["Minseok Ryu","Kibaek Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14514v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.09409"},{"id":"http://arxiv.org/abs/2302.14510v1","updated":"2023-02-28T12:00:21Z","published":"2023-02-28T12:00:21Z","title":"Bayesian Kernelized Tensor Factorization as Surrogate for Bayesian\n  Optimization","summary":"  Bayesian optimization (BO) primarily uses Gaussian processes (GP) as the key\nsurrogate model, mostly with a simple stationary and separable kernel function\nsuch as the widely used squared-exponential kernel with automatic relevance\ndetermination (SE-ARD). However, such simple kernel specifications are\ndeficient in learning functions with complex features, such as being\nnonstationary, nonseparable, and multimodal. Approximating such functions using\na local GP, even in a low-dimensional space, will require a large number of\nsamples, not to mention in a high-dimensional setting. In this paper, we\npropose to use Bayesian Kernelized Tensor Factorization (BKTF) -- as a new\nsurrogate model -- for BO in a D-dimensional Cartesian product space. Our key\nidea is to approximate the underlying D-dimensional solid with a fully Bayesian\nlow-rank tensor CP decomposition, in which we place GP priors on the latent\nbasis functions for each dimension to encode local consistency and smoothness.\nWith this formulation, information from each sample can be shared not only with\nneighbors but also across dimensions. Although BKTF no longer has an analytical\nposterior, we can still efficiently approximate the posterior distribution\nthrough Markov chain Monte Carlo (MCMC) and obtain prediction and full\nuncertainty quantification (UQ). We conduct numerical experiments on both\nstandard BO testing problems and machine learning hyperparameter tuning\nproblems, and our results confirm the superiority of BKTF in terms of sample\nefficiency.\n","authors":["Mengying Lei","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2302.14510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14509v1","updated":"2023-02-28T11:58:39Z","published":"2023-02-28T11:58:39Z","title":"Policy Dispersion in Non-Markovian Environment","summary":"  Markov Decision Process (MDP) presents a mathematical framework to formulate\nthe learning processes of agents in reinforcement learning. MDP is limited by\nthe Markovian assumption that a reward only depends on the immediate state and\naction. However, a reward sometimes depends on the history of states and\nactions, which may result in the decision process in a non-Markovian\nenvironment. In such environments, agents receive rewards via\ntemporally-extended behaviors sparsely, and the learned policies may be\nsimilar. This leads the agents acquired with similar policies generally overfit\nto the given task and can not quickly adapt to perturbations of environments.\nTo resolve this problem, this paper tries to learn the diverse policies from\nthe history of state-action pairs under a non-Markovian environment, in which a\npolicy dispersion scheme is designed for seeking diverse policy representation.\nSpecifically, we first adopt a transformer-based method to learn policy\nembeddings. Then, we stack the policy embeddings to construct a dispersion\nmatrix to induce a set of diverse policies. Finally, we prove that if the\ndispersion matrix is positive definite, the dispersed embeddings can\neffectively enlarge the disagreements across policies, yielding a diverse\nexpression for the original policy embedding distribution. Experimental results\nshow that this dispersion scheme can obtain more expressive diverse policies,\nwhich then derive more robust performance than recent learning baselines under\nvarious learning environments.\n","authors":["Bohao Qu","Xiaofeng Cao","Jielong Yang","Hechang Chen","Chang Yi","Ivor W. Tsang","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2302.14509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10598v2","updated":"2023-02-28T11:54:43Z","published":"2022-06-18T06:33:06Z","title":"A deep inverse reinforcement learning approach to route choice modeling\n  with context-dependent rewards","summary":"  Route choice modeling is a fundamental task in transportation planning and\ndemand forecasting. Classical methods generally adopt the discrete choice model\n(DCM) framework with linear utility functions and high-level route\ncharacteristics. While several recent studies have started to explore the\napplicability of deep learning for route choice modeling, they are limited to\npath-based models with relatively simple model architectures and relying on\npredefined choice sets. Existing link-based models can capture the dynamic\nnature of link choices within the trip without the need for choice set\ngeneration, but still assume linear relationships and link-additive features.\nTo address these issues, this study proposes a general deep inverse\nreinforcement learning (IRL) framework for link-based route choice modeling,\nwhich is capable of incorporating diverse features (of the state, action and\ntrip context) and capturing complex relationships. Specifically, we adapt an\nadversarial IRL model to the route choice problem for efficient estimation of\ncontext-dependent reward functions without value iteration. Experiment results\nbased on taxi GPS data from Shanghai, China validate the superior prediction\nperformance of the proposed model over conventional DCMs and other imitation\nlearning baselines, even for destinations unseen in the training data. Further\nanalysis show that the model exhibits competitive computational efficiency and\nreasonable interpretability. The proposed methodology provides a new direction\nfor future development of route choice models. It is general and can be\nadaptable to other route choice problems across different modes and networks.\n","authors":["Zhan Zhao","Yuebing Liang"],"pdf_url":"https://arxiv.org/pdf/2206.10598v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.03834v2","updated":"2023-02-28T11:31:18Z","published":"2022-01-11T08:35:18Z","title":"STIR$^2$: Reward Relabelling for combined Reinforcement and Imitation\n  Learning on sparse-reward tasks","summary":"  In the search for more sample-efficient reinforcement-learning (RL)\nalgorithms, a promising direction is to leverage as much external off-policy\ndata as possible. For instance, expert demonstrations. In the past, multiple\nideas have been proposed to make good use of the demonstrations added to the\nreplay buffer, such as pretraining on demonstrations only or minimizing\nadditional cost functions. We present a new method, able to leverage both\ndemonstrations and episodes collected online in any sparse-reward environment\nwith any off-policy algorithm. Our method is based on a reward bonus given to\ndemonstrations and successful episodes (via relabeling), encouraging expert\nimitation and self-imitation. Our experiments focus on several\nrobotic-manipulation tasks across two different simulation environments. We\nshow that our method based on reward relabeling improves the performance of the\nbase algorithm (SAC and DDPG) on these tasks. Finally, our best algorithm\nSTIR$^2$ (Self and Teacher Imitation by Reward Relabeling), which integrates\ninto our method multiple improvements from previous works, is more\ndata-efficient than all baselines.\n","authors":["Jesus Bujalance Martin","Fabien Moutarde"],"pdf_url":"https://arxiv.org/pdf/2201.03834v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2110.14464"},{"id":"http://arxiv.org/abs/2302.14483v1","updated":"2023-02-28T10:54:36Z","published":"2023-02-28T10:54:36Z","title":"RoPAWS: Robust Semi-supervised Representation Learning from Uncurated\n  Data","summary":"  Semi-supervised learning aims to train a model using limited labels.\nState-of-the-art semi-supervised methods for image classification such as PAWS\nrely on self-supervised representations learned with large-scale unlabeled but\ncurated data. However, PAWS is often less effective when using real-world\nunlabeled data that is uncurated, e.g., contains out-of-class data. We propose\nRoPAWS, a robust extension of PAWS that can work with real-world unlabeled\ndata. We first reinterpret PAWS as a generative classifier that models\ndensities using kernel density estimation. From this probabilistic perspective,\nwe calibrate its prediction based on the densities of labeled and unlabeled\ndata, which leads to a simple closed-form solution from the Bayes' rule. We\ndemonstrate that RoPAWS significantly improves PAWS for uncurated Semi-iNat by\n+5.3% and curated ImageNet by +0.4%.\n","authors":["Sangwoo Mo","Jong-Chyi Su","Chih-Yao Ma","Mido Assran","Ishan Misra","Licheng Yu","Sean Bell"],"pdf_url":"https://arxiv.org/pdf/2302.14483v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2203.07893v3","updated":"2023-02-28T10:50:17Z","published":"2022-03-15T13:40:22Z","title":"Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear\n  Guarded Attribute Information","summary":"  We describe a simple and effective method (Spectral Attribute removaL; SAL)\nto remove private or guarded information from neural representations. Our\nmethod uses matrix decomposition to project the input representations into\ndirections with reduced covariance with the guarded information rather than\nmaximal covariance as factorization methods normally use. We begin with linear\ninformation removal and proceed to generalize our algorithm to the case of\nnonlinear information removal using kernels. Our experiments demonstrate that\nour algorithm retains better main task performance after removing the guarded\ninformation compared to previous work. In addition, our experiments demonstrate\nthat we need a relatively small amount of guarded attribute data to remove\ninformation about these attributes, which lowers the exposure to sensitive data\nand is more suitable for low-resource scenarios. Code is available at\nhttps://github.com/jasonshaoshun/SAL.\n","authors":["Shun Shao","Yftah Ziser","Shay B. Cohen"],"pdf_url":"https://arxiv.org/pdf/2203.07893v3.pdf","comment":"Accepted to the Conference of the European Chapter of the Association\n  for Computational Linguistics (EACL), 2023; 12 pages"},{"id":"http://arxiv.org/abs/2302.14475v1","updated":"2023-02-28T10:34:44Z","published":"2023-02-28T10:34:44Z","title":"Benchmarking Deepart Detection","summary":"  Deepfake technologies have been blurring the boundaries between the real and\nunreal, likely resulting in malicious events. By leveraging newly emerged\ndeepfake technologies, deepfake researchers have been making a great upending\nto create deepfake artworks (deeparts), which are further closing the gap\nbetween reality and fantasy. To address potentially appeared ethics questions,\nthis paper establishes a deepart detection database (DDDB) that consists of a\nset of high-quality conventional art images (conarts) and five sets of deepart\nimages generated by five state-of-the-art deepfake models. This database\nenables us to explore once-for-all deepart detection and continual deepart\ndetection. For the two new problems, we suggest four benchmark evaluations and\nfour families of solutions on the constructed DDDB. The comprehensive study\ndemonstrates the effectiveness of the proposed solutions on the established\nbenchmark dataset, which is capable of paving a way to more interesting\ndirections of deepart detection. The constructed benchmark dataset and the\nsource code will be made publicly available.\n","authors":["Yabin Wang","Zhiwu Huang","Xiaopeng Hong"],"pdf_url":"https://arxiv.org/pdf/2302.14475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14473v1","updated":"2023-02-28T10:32:17Z","published":"2023-02-28T10:32:17Z","title":"Implicit Bilevel Optimization: Differentiating through Bilevel\n  Optimization Programming","summary":"  Bilevel Optimization Programming is used to model complex and conflicting\ninteractions between agents, for example in Robust AI or Privacy-preserving AI.\nIntegrating bilevel mathematical programming within deep learning is thus an\nessential objective for the Machine Learning community. Previously proposed\napproaches only consider single-level programming. In this paper, we extend\nexisting single-level optimization programming approaches and thus propose\nDifferentiating through Bilevel Optimization Programming (BiGrad) for\nend-to-end learning of models that use Bilevel Programming as a layer. BiGrad\nhas wide applicability and can be used in modern machine learning frameworks.\nBiGrad is applicable to both continuous and combinatorial Bilevel optimization\nproblems. We describe a class of gradient estimators for the combinatorial case\nwhich reduces the requirements in terms of computation complexity; for the case\nof the continuous variable, the gradient computation takes advantage of the\npush-back approach (i.e. vector-jacobian product) for an efficient\nimplementation. Experiments show that the BiGrad successfully extends existing\nsingle-level approaches to Bilevel Programming.\n","authors":["Francesco Alesiani"],"pdf_url":"https://arxiv.org/pdf/2302.14473v1.pdf","comment":"Accepted for presentation at AAAI23; code will be submitted at\n  https://github.com/falesiani/bigrad"},{"id":"http://arxiv.org/abs/2212.01133v4","updated":"2023-02-28T10:31:40Z","published":"2022-12-02T12:26:00Z","title":"RIPPLE: Concept-Based Interpretation for Raw Time Series Models in\n  Education","summary":"  Time series is the most prevalent form of input data for educational\nprediction tasks. The vast majority of research using time series data focuses\non hand-crafted features, designed by experts for predictive performance and\ninterpretability. However, extracting these features is labor-intensive for\nhumans and computers. In this paper, we propose an approach that utilizes\nirregular multivariate time series modeling with graph neural networks to\nachieve comparable or better accuracy with raw time series clickstreams in\ncomparison to hand-crafted features. Furthermore, we extend concept activation\nvectors for interpretability in raw time series models. We analyze these\nadvances in the education domain, addressing the task of early student\nperformance prediction for downstream targeted interventions and instructional\nsupport. Our experimental analysis on 23 MOOCs with millions of combined\ninteractions over six behavioral dimensions show that models designed with our\napproach can (i) beat state-of-the-art educational time series baselines with\nno feature extraction and (ii) provide interpretable insights for personalized\ninterventions. Source code: https://github.com/epfl-ml4ed/ripple/.\n","authors":["Mohammad Asadi","Vinitra Swamy","Jibril Frej","Julien Vignoud","Mirko Marras","Tanja Käser"],"pdf_url":"https://arxiv.org/pdf/2212.01133v4.pdf","comment":"Accepted as a full paper at AAAI 2023: 37th AAAI Conference on\n  Artificial Intelligence (EAAI: AI for Education Special Track), 7-14 of\n  February 2023, Washington DC, USA"},{"id":"http://arxiv.org/abs/2302.14471v1","updated":"2023-02-28T10:29:42Z","published":"2023-02-28T10:29:42Z","title":"Safe peeling for l0-regularized least-squares with supplementary\n  material","summary":"  We introduce a new methodology dubbed ``safe peeling'' to accelerate the\nresolution of l0-regularized least-squares problems via a Branch-and-Bound\n(BnB) method. Our procedure enables to tighten the convex relaxation considered\nat each node of the BnB decision tree and therefore potentially allows for more\naggressive pruning. Numerical simulations show that our proposed methodology\nleads to significant gains in terms of number of nodes explored and overall\nsolving time.\n","authors":["Théo Guyard","Gilles Monnoyer","Clément Elvira","Cédric Herzet"],"pdf_url":"https://arxiv.org/pdf/2302.14471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09957v2","updated":"2023-02-28T10:26:48Z","published":"2022-10-18T16:11:55Z","title":"Contextual bandits with concave rewards, and an application to fair\n  ranking","summary":"  We consider Contextual Bandits with Concave Rewards (CBCR), a multi-objective\nbandit problem where the desired trade-off between the rewards is defined by a\nknown concave objective function, and the reward vector depends on an observed\nstochastic context. We present the first algorithm with provably vanishing\nregret for CBCR without restrictions on the policy space, whereas prior works\nwere restricted to finite policy spaces or tabular representations. Our\nsolution is based on a geometric interpretation of CBCR algorithms as\noptimization algorithms over the convex set of expected rewards spanned by all\nstochastic policies. Building on Frank-Wolfe analyses in constrained convex\noptimization, we derive a novel reduction from the CBCR regret to the regret of\na scalar-reward bandit problem. We illustrate how to apply the reduction\noff-the-shelf to obtain algorithms for CBCR with both linear and general reward\nfunctions, in the case of non-combinatorial actions. Motivated by fairness in\nrecommendation, we describe a special case of CBCR with rankings and\nfairness-aware objectives, leading to the first algorithm with regret\nguarantees for contextual combinatorial bandits with fairness of exposure.\n","authors":["Virginie Do","Elvis Dohmatob","Matteo Pirotta","Alessandro Lazaric","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2210.09957v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14470v1","updated":"2023-02-28T10:26:02Z","published":"2023-02-28T10:26:02Z","title":"Learning to Estimate Single-View Volumetric Flow Motions without 3D\n  Supervision","summary":"  We address the challenging problem of jointly inferring the 3D flow and\nvolumetric densities moving in a fluid from a monocular input video with a deep\nneural network. Despite the complexity of this task, we show that it is\npossible to train the corresponding networks without requiring any 3D ground\ntruth for training. In the absence of ground truth data we can train our model\nwith observations from real-world capture setups instead of relying on\nsynthetic reconstructions. We make this unsupervised training approach possible\nby first generating an initial prototype volume which is then moved and\ntransported over time without the need for volumetric supervision. Our approach\nrelies purely on image-based losses, an adversarial discriminator network, and\nregularization. Our method can estimate long-term sequences in a stable manner,\nwhile achieving closely matching targets for inputs such as rising smoke\nplumes.\n","authors":["Erik Franz","Barbara Solenthaler","Nils Thuerey"],"pdf_url":"https://arxiv.org/pdf/2302.14470v1.pdf","comment":"ICLR 2023 poster, source code:\n  https://github.com/tum-pbs/Neural-Global-Transport"},{"id":"http://arxiv.org/abs/2302.14460v1","updated":"2023-02-28T10:08:11Z","published":"2023-02-28T10:08:11Z","title":"Interpretable and Intervenable Ultrasonography-based Machine Learning\n  Models for Pediatric Appendicitis","summary":"  Appendicitis is among the most frequent reasons for pediatric abdominal\nsurgeries. With recent advances in machine learning, data-driven decision\nsupport could help clinicians diagnose and manage patients while reducing the\nnumber of non-critical surgeries. Previous decision support systems for\nappendicitis focused on clinical, laboratory, scoring and computed tomography\ndata, mainly ignoring abdominal ultrasound, a noninvasive and readily available\ndiagnostic modality. To this end, we developed and validated interpretable\nmachine learning models for predicting the diagnosis, management and severity\nof suspected appendicitis using ultrasound images. Our models were trained on a\ndataset comprising 579 pediatric patients with 1709 ultrasound images\naccompanied by clinical and laboratory data. Our methodological contribution is\nthe generalization of concept bottleneck models to prediction problems with\nmultiple views and incomplete concept sets. Notably, such models lend\nthemselves to interpretation and interaction via high-level concepts\nunderstandable to clinicians without sacrificing performance or requiring\ntime-consuming image annotation when deployed.\n","authors":["Ričards Marcinkevičs","Patricia Reis Wolfertstetter","Ugne Klimiene","Ece Ozkan","Kieran Chin-Cheong","Alyssia Paschke","Julia Zerres","Markus Denzinger","David Niederberger","Sven Wellmann","Christian Knorr","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2302.14460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13696v2","updated":"2023-02-28T10:07:47Z","published":"2023-02-27T11:55:24Z","title":"Moderate Adaptive Linear Units (MoLU)","summary":"  We propose a new high-performance activation function, Moderate Adaptive\nLinear Units (MoLU), for the deep neural network. The MoLU is a simple,\nbeautiful and powerful activation function that can be a good main activation\nfunction among hundreds of activation functions. Because the MoLU is made up of\nthe elementary functions, not only it is a infinite diffeomorphism (i.e. smooth\nand infinitely differentiable over whole domains), but also it decreases\ntraining time.\n","authors":["Hankyul Koh","Joon-hyuk Ko","Wonho Jhe"],"pdf_url":"https://arxiv.org/pdf/2302.13696v2.pdf","comment":"4 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.14458v1","updated":"2023-02-28T10:05:45Z","published":"2023-02-28T10:05:45Z","title":"Ultra-low Precision Multiplication-free Training for Deep Neural\n  Networks","summary":"  The training for deep neural networks (DNNs) demands immense energy\nconsumption, which restricts the development of deep learning as well as\nincreases carbon emissions. Thus, the study of energy-efficient training for\nDNNs is essential. In training, the linear layers consume the most energy\nbecause of the intense use of energy-consuming full-precision (FP32)\nmultiplication in multiply-accumulate (MAC). The energy-efficient works try to\ndecrease the precision of multiplication or replace the multiplication with\nenergy-efficient operations such as addition or bitwise shift, to reduce the\nenergy consumption of FP32 multiplications. However, the existing\nenergy-efficient works cannot replace all of the FP32 multiplications during\nboth forward and backward propagation with low-precision energy-efficient\noperations. In this work, we propose an Adaptive Layer-wise Scaling PoT\nQuantization (ALS-POTQ) method and a Multiplication-Free MAC (MF-MAC) to\nreplace all of the FP32 multiplications with the INT4 additions and 1-bit XOR\noperations. In addition, we propose Weight Bias Correction and Parameterized\nRatio Clipping techniques for stable training and improving accuracy. In our\ntraining scheme, all of the above methods do not introduce extra\nmultiplications, so we reduce up to 95.8% of the energy consumption in linear\nlayers during training. Experimentally, we achieve an accuracy degradation of\nless than 1% for CNN models on ImageNet and Transformer model on the WMT En-De\ntask. In summary, we significantly outperform the existing methods for both\nenergy efficiency and accuracy.\n","authors":["Chang Liu","Rui Zhang","Xishan Zhang","Yifan Hao","Zidong Du","Xing Hu","Ling Li","Qi Guo"],"pdf_url":"https://arxiv.org/pdf/2302.14458v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14451v1","updated":"2023-02-28T09:56:36Z","published":"2023-02-28T09:56:36Z","title":"Hierarchical Reinforcement Learning in Complex 3D Environments","summary":"  Hierarchical Reinforcement Learning (HRL) agents have the potential to\ndemonstrate appealing capabilities such as planning and exploration with\nabstraction, transfer, and skill reuse. Recent successes with HRL across\ndifferent domains provide evidence that practical, effective HRL agents are\npossible, even if existing agents do not yet fully realize the potential of\nHRL. Despite these successes, visually complex partially observable 3D\nenvironments remained a challenge for HRL agents. We address this issue with\nHierarchical Hybrid Offline-Online (H2O2), a hierarchical deep reinforcement\nlearning agent that discovers and learns to use options from scratch using its\nown experience. We show that H2O2 is competitive with a strong non-hierarchical\nMuesli baseline in the DeepMind Hard Eight tasks and we shed new light on the\nproblem of learning hierarchical agents in complex environments. Our empirical\nstudy of H2O2 reveals previously unnoticed practical challenges and brings new\nperspective to the current understanding of hierarchical agents in complex\ndomains.\n","authors":["Bernardo Avila Pires","Feryal Behbahani","Hubert Soyer","Kyriacos Nikiforou","Thomas Keck","Satinder Singh"],"pdf_url":"https://arxiv.org/pdf/2302.14451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02501v2","updated":"2023-02-28T09:50:50Z","published":"2022-11-04T15:03:41Z","title":"Weisfeiler and Leman go Hyperbolic: Learning Distance Preserving Node\n  Representations","summary":"  In recent years, graph neural networks (GNNs) have emerged as a promising\ntool for solving machine learning problems on graphs. Most GNNs are members of\nthe family of message passing neural networks (MPNNs). There is a close\nconnection between these models and the Weisfeiler-Leman (WL) test of\nisomorphism, an algorithm that can successfully test isomorphism for a broad\nclass of graphs. Recently, much research has focused on measuring the\nexpressive power of GNNs. For instance, it has been shown that standard MPNNs\nare at most as powerful as WL in terms of distinguishing non-isomorphic graphs.\nHowever, these studies have largely ignored the distances between the\nrepresentations of nodes/graphs which are of paramount importance for learning\ntasks. In this paper, we define a distance function between nodes which is\nbased on the hierarchy produced by the WL algorithm, and propose a model that\nlearns representations which preserve those distances between nodes. Since the\nemerging hierarchy corresponds to a tree, to learn these representations, we\ncapitalize on recent advances in the field of hyperbolic neural networks. We\nempirically evaluate the proposed model on standard node and graph\nclassification datasets where it achieves competitive performance with\nstate-of-the-art models.\n","authors":["Giannis Nikolentzos","Michail Chatzianastasis","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2211.02501v2.pdf","comment":"Accepted at AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.14446v1","updated":"2023-02-28T09:46:44Z","published":"2023-02-28T09:46:44Z","title":"Reproducing kernel Hilbert spaces in the mean field limit","summary":"  Kernel methods, being supported by a well-developed theory and coming with\nefficient algorithms, are among the most popular and successful machine\nlearning techniques. From a mathematical point of view, these methods rest on\nthe concept of kernels and function spaces generated by kernels, so called\nreproducing kernel Hilbert spaces. Motivated by recent developments of learning\napproaches in the context of interacting particle systems, we investigate\nkernel methods acting on data with many measurement variables. We show the\nrigorous mean field limit of kernels and provide a detailed analysis of the\nlimiting reproducing kernel Hilbert space. Furthermore, several examples of\nkernels, that allow a rigorous mean field limit, are presented.\n","authors":["Christian Fiedler","Michael Herty","Michael Rom","Chiara Segala","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2302.14446v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.12623v2","updated":"2023-02-28T09:37:59Z","published":"2021-04-26T14:50:59Z","title":"Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against\n  Image Translation Models","summary":"  Machine learning models are typically made available to potential client\nusers via inference APIs. Model extraction attacks occur when a malicious\nclient uses information gleaned from queries to the inference API of a victim\nmodel $F_V$ to build a surrogate model $F_A$ with comparable functionality.\nRecent research has shown successful model extraction of image classification,\nand natural language processing models. In this paper, we show the first model\nextraction attack against real-world generative adversarial network (GAN) image\ntranslation models. We present a framework for conducting such attacks, and\nshow that an adversary can successfully extract functional surrogate models by\nquerying $F_V$ using data from the same domain as the training data for $F_V$.\nThe adversary need not know $F_V$'s architecture or any other information about\nit beyond its intended task. We evaluate the effectiveness of our attacks using\nthree different instances of two popular categories of image translation: (1)\nSelfie-to-Anime and (2) Monet-to-Photo (image style transfer), and (3)\nSuper-Resolution (super resolution). Using standard performance metrics for\nGANs, we show that our attacks are effective. Furthermore, we conducted a large\nscale (125 participants) user study on Selfie-to-Anime and Monet-to-Photo to\nshow that human perception of the images produced by $F_V$ and $F_A$ can be\nconsidered equivalent, within an equivalence bound of Cohen's d = 0.3. Finally,\nwe show that existing defenses against model extraction attacks (watermarking,\nadversarial examples, poisoning) do not extend to image translation models.\n","authors":["Sebastian Szyller","Vasisht Duddu","Tommi Gröndahl","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2104.12623v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2302.14438v1","updated":"2023-02-28T09:30:24Z","published":"2023-02-28T09:30:24Z","title":"Self-Supervised Interest Transfer Network via Prototypical Contrastive\n  Learning for Recommendation","summary":"  Cross-domain recommendation has attracted increasing attention from industry\nand academia recently. However, most existing methods do not exploit the\ninterest invariance between domains, which would yield sub-optimal solutions.\nIn this paper, we propose a cross-domain recommendation method: Self-supervised\nInterest Transfer Network (SITN), which can effectively transfer invariant\nknowledge between domains via prototypical contrastive learning. Specifically,\nwe perform two levels of cross-domain contrastive learning: 1)\ninstance-to-instance contrastive learning, 2) instance-to-cluster contrastive\nlearning. Not only that, we also take into account users' multi-granularity and\nmulti-view interests. With this paradigm, SITN can explicitly learn the\ninvariant knowledge of interest clusters between domains and accurately capture\nusers' intents and preferences. We conducted extensive experiments on a public\ndataset and a large-scale industrial dataset collected from one of the world's\nleading e-commerce corporations. The experimental results indicate that SITN\nachieves significant improvements over state-of-the-art recommendation methods.\nAdditionally, SITN has been deployed on a micro-video recommendation platform,\nand the online A/B testing results further demonstrate its practical value.\nSupplement is available at: https://github.com/fanqieCoffee/SITN-Supplement.\n","authors":["Guoqiang Sun","Yibin Shen","Sijin Zhou","Xiang Chen","Hongyan Liu","Chunming Wu","Chenyi Lei","Xianhui Wei","Fei Fang"],"pdf_url":"https://arxiv.org/pdf/2302.14438v1.pdf","comment":"9 pages, 3 figures, accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.14428v1","updated":"2023-02-28T09:18:00Z","published":"2023-02-28T09:18:00Z","title":"Stochastic Gradient Descent under Markovian Sampling Schemes","summary":"  We study a variation of vanilla stochastic gradient descent where the\noptimizer only has access to a Markovian sampling scheme. These schemes\nencompass applications that range from decentralized optimization with a random\nwalker (token algorithms), to RL and online system identification problems. We\nfocus on obtaining rates of convergence under the least restrictive assumptions\npossible on the underlying Markov chain and on the functions optimized. We\nfirst unveil the theoretical lower bound for methods that sample stochastic\ngradients along the path of a Markov chain, making appear a dependency in the\nhitting time of the underlying Markov chain. We then study Markov chain SGD\n(MC-SGD) under much milder regularity assumptions than prior works. We finally\nintroduce MC-SAG, an alternative to MC-SGD with variance reduction, that only\ndepends on the hitting time of the Markov chain, therefore obtaining a\ncommunication-efficient token algorithm.\n","authors":["Mathieu Even"],"pdf_url":"https://arxiv.org/pdf/2302.14428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00702v6","updated":"2023-02-28T09:17:29Z","published":"2022-06-01T18:28:23Z","title":"Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal\n  Search","summary":"  Complex reasoning problems contain states that vary in the computational cost\nrequired to determine a good action plan. Taking advantage of this property, we\npropose Adaptive Subgoal Search (AdaSubS), a search method that adaptively\nadjusts the planning horizon. To this end, AdaSubS generates diverse sets of\nsubgoals at different distances. A verification mechanism is employed to filter\nout unreachable subgoals swiftly, allowing to focus on feasible further\nsubgoals. In this way, AdaSubS benefits from the efficiency of planning with\nlonger subgoals and the fine control with the shorter ones, and thus scales\nwell to difficult planning problems. We show that AdaSubS significantly\nsurpasses hierarchical planning algorithms on three complex reasoning tasks:\nSokoban, the Rubik's Cube, and inequality proving benchmark INT.\n","authors":["Michał Zawalski","Michał Tyrolski","Konrad Czechowski","Damian Stachura","Piotr Piękos","Tomasz Odrzygóźdź","Yuhuai Wu","Łukasz Kuciński","Piotr Miłoś"],"pdf_url":"https://arxiv.org/pdf/2206.00702v6.pdf","comment":"ICLR 2023 (oral)"},{"id":"http://arxiv.org/abs/2302.14427v1","updated":"2023-02-28T09:15:41Z","published":"2023-02-28T09:15:41Z","title":"Federated Covariate Shift Adaptation for Missing Target Output Values","summary":"  The most recent multi-source covariate shift algorithm is an efficient\nhyperparameter optimization algorithm for missing target output. In this paper,\nwe extend this algorithm to the framework of federated learning. For data\nislands in federated learning and covariate shift adaptation, we propose the\nfederated domain adaptation estimate of the target risk which is asymptotically\nunbiased with a desirable asymptotic variance property. We construct a weighted\nmodel for the target task and propose the federated covariate shift adaptation\nalgorithm which works preferably in our setting. The efficacy of our method is\njustified both theoretically and empirically.\n","authors":["Yaqian Xu","Wenquan Cui","Jianjun Xu","Haoyang Cheng"],"pdf_url":"https://arxiv.org/pdf/2302.14427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.13200v2","updated":"2023-02-28T08:47:14Z","published":"2021-06-24T17:27:22Z","title":"Software for Dataset-wide XAI: From Local Explanations to Global\n  Insights with Zennit, CoRelAy, and ViRelAy","summary":"  Deep Neural Networks (DNNs) are known to be strong predictors, but their\nprediction strategies can rarely be understood. With recent advances in\nExplainable Artificial Intelligence (XAI), approaches are available to explore\nthe reasoning behind those complex models' predictions. Among post-hoc\nattribution methods, Layer-wise Relevance Propagation (LRP) shows high\nperformance. For deeper quantitative analysis, manual approaches exist, but\nwithout the right tools they are unnecessarily labor intensive. In this\nsoftware paper, we introduce three software packages targeted at scientists to\nexplore model reasoning using attribution approaches and beyond: (1) Zennit - a\nhighly customizable and intuitive attribution framework implementing LRP and\nrelated approaches in PyTorch, (2) CoRelAy - a framework to easily and quickly\nconstruct quantitative analysis pipelines for dataset-wide analyses of\nexplanations, and (3) ViRelAy - a web-application to interactively explore\ndata, attributions, and analysis results. With this, we provide a standardized\nimplementation solution for XAI, to contribute towards more reproducibility in\nour field.\n","authors":["Christopher J. Anders","David Neumann","Wojciech Samek","Klaus-Robert Müller","Sebastian Lapuschkin"],"pdf_url":"https://arxiv.org/pdf/2106.13200v2.pdf","comment":"20 pages, 6 figures, 2 listings, 1 table"},{"id":"http://arxiv.org/abs/2302.14412v1","updated":"2023-02-28T08:46:51Z","published":"2023-02-28T08:46:51Z","title":"An Algorithm and Complexity Results for Causal Unit Selection","summary":"  The unit selection problem aims to identify objects, called units, that are\nmost likely to exhibit a desired mode of behavior when subjected to stimuli\n(e.g., customers who are about to churn but would change their mind if\nencouraged). Unit selection with counterfactual objective functions was\nintroduced relatively recently with existing work focusing on bounding a\nspecific class of objective functions, called the benefit functions, based on\nobservational and interventional data -- assuming a fully specified model is\nnot available to evaluate these functions. We complement this line of work by\nproposing the first exact algorithm for finding optimal units given a broad\nclass of causal objective functions and a fully specified structural causal\nmodel (SCM). We show that unit selection under this class of objective\nfunctions is $\\text{NP}^\\text{PP}$-complete but is $\\text{NP}$-complete when\nunit variables correspond to all exogenous variables in the SCM. We also\nprovide treewidth-based complexity bounds on our proposed algorithm while\nrelating it to a well-known algorithm for Maximum a Posteriori (MAP) inference.\n","authors":["Haiying Huang","Adnan Darwiche"],"pdf_url":"https://arxiv.org/pdf/2302.14412v1.pdf","comment":"To be published in the 2nd Conference on Causal Learning and\n  Reasoning (CLeaR 2023)"},{"id":"http://arxiv.org/abs/2302.13152v2","updated":"2023-02-28T08:43:40Z","published":"2023-02-25T20:36:41Z","title":"On Bellman's principle of optimality and Reinforcement learning for\n  safety-constrained Markov decision process","summary":"  We study optimality for the safety-constrained Markov decision process which\nis the underlying framework for safe reinforcement learning. Specifically, we\nconsider a constrained Markov decision process (with finite states and finite\nactions) where the goal of the decision maker is to reach a target set while\navoiding an unsafe set(s) with certain probabilistic guarantees. Therefore the\nunderlying Markov chain for any control policy will be multichain since by\ndefinition there exists a target set and an unsafe set. The decision maker also\nhas to be optimal (with respect to a cost function) while navigating to the\ntarget set. This gives rise to a multi-objective optimization problem. We\nhighlight the fact that Bellman's principle of optimality may not hold for\nconstrained Markov decision problems with an underlying multichain structure\n(as shown by the counterexample). We resolve the counterexample by formulating\nthe aforementioned multi-objective optimization problem as a zero-sum game and\nthereafter construct an asynchronous value iteration scheme for the Lagrangian\n(similar to Shapley's algorithm. Finally, we consider the reinforcement\nlearning problem for the same and construct a modified Q-learning algorithm for\nlearning the Lagrangian from data. We also provide a lower bound on the number\nof iterations required for learning the Lagrangian and corresponding error\nbounds.\n","authors":["Rahul Misra","Rafał Wisniewski","Carsten Skovmose Kallesøe"],"pdf_url":"https://arxiv.org/pdf/2302.13152v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14407v1","updated":"2023-02-28T08:42:42Z","published":"2023-02-28T08:42:42Z","title":"Asymptotically Optimal Thompson Sampling Based Policy for the Uniform\n  Bandits and the Gaussian Bandits","summary":"  Thompson sampling (TS) for the parametric stochastic multi-armed bandits has\nbeen well studied under the one-dimensional parametric models. It is often\nreported that TS is fairly insensitive to the choice of the prior when it comes\nto regret bounds. However, this property is not necessarily true when\nmultiparameter models are considered, e.g., a Gaussian model with unknown mean\nand variance parameters. In this paper, we first extend the regret analysis of\nTS to the model of uniform distributions with unknown supports. Specifically,\nwe show that a switch of noninformative priors drastically affects the regret\nin expectation. Through our analysis, the uniform prior is proven to be the\noptimal choice in terms of the expected regret, while the reference prior and\nthe Jeffreys prior are found to be suboptimal, which is consistent with\nprevious findings in the model of Gaussian distributions. However, the uniform\nprior is specific to the parameterization of the distributions, meaning that if\nan agent considers different parameterizations of the same model, the agent\nwith the uniform prior might not always achieve the optimal performance. In\nlight of this limitation, we propose a slightly modified TS-based policy,\ncalled TS with Truncation (TS-T), which can achieve the asymptotic optimality\nfor the Gaussian distributions and the uniform distributions by using the\nreference prior and the Jeffreys prior that are invariant under one-to-one\nreparameterizations. The pre-processig of the posterior distribution is the key\nto TS-T, where we add an adaptive truncation procedure on the parameter space\nof the posterior distributions. Simulation results support our analysis, where\nTS-T shows the best performance in a finite-time horizon compared to other\nknown optimal policies, while TS with the invariant priors performs poorly.\n","authors":["Jongyeong Lee","Chao-Kai Chiang","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2302.14407v1.pdf","comment":"47 pages, preprint"},{"id":"http://arxiv.org/abs/2302.12388v2","updated":"2023-02-28T08:41:46Z","published":"2023-02-24T01:29:21Z","title":"TrafFormer: A Transformer Model for Predicting Long-term Traffic","summary":"  Traffic prediction is a flourishing research field due to its importance in\nhuman mobility in the urban space. Despite this, existing studies only focus on\nshort-term prediction of up to few hours in advance, with most being up to one\nhour only. Long-term traffic prediction can enable more comprehensive,\ninformed, and proactive measures against traffic congestion and is therefore an\nimportant task to explore. In this paper, we explore the task of long-term\ntraffic prediction; where we predict traffic up to 24 hours in advance. We note\nthe weaknesses of existing models--which are based on recurrent structures--for\nlong-term traffic prediction and propose a modified Transformer model\n``TrafFormer\". Experiments comparing our model with existing hybrid neural\nnetwork models show the superiority of our model.\n","authors":["David Alexander Tedjopurnomo","Farhana M. Choudhury","A. K. Qin"],"pdf_url":"https://arxiv.org/pdf/2302.12388v2.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.01029v2","updated":"2023-02-28T08:38:39Z","published":"2023-02-02T11:46:23Z","title":"On Suppressing Range of Adaptive Stepsizes of Adam to Improve\n  Generalisation Performance","summary":"  A number of recent adaptive optimizers improve the generalisation performance\nof Adam by essentially reducing the variance of adaptive stepsizes to get\ncloser to SGD with momentum. Following the above motivation, we suppress the\nrange of the adaptive stepsizes of Adam by exploiting the layerwise gradient\nstatistics. In particular, at each iteration, we propose to perform three\nconsecutive operations on the second momentum v_t before using it to update a\nDNN model: (1): down-scaling, (2): epsilon-embedding, and (3):\ndown-translating. The resulting algorithm is referred to as SET-Adam, where SET\nis a brief notation of the three operations. The down-scaling operation on v_t\nis performed layerwise by making use of the angles between the layerwise\nsubvectors of v_t and the corresponding all-one subvectors. Extensive\nexperimental results show that SET-Adam outperforms eight adaptive optimizers\nwhen training transformers and LSTMs for NLP, and VGG and ResNet for image\nclassification over CIAF10 and CIFAR100 while matching the best performance of\nthe eight adaptive methods when training WGAN-GP models for image generation\ntasks. Furthermore, SET-Adam produces higher validation accuracies than Adam\nand AdaBelief for training ResNet18 over ImageNet.\n","authors":["Guoqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01029v2.pdf","comment":"12 pages. arXiv admin note: substantial text overlap with\n  arXiv:2203.13273"},{"id":"http://arxiv.org/abs/2302.14395v1","updated":"2023-02-28T08:23:15Z","published":"2023-02-28T08:23:15Z","title":"Item Cold Start Recommendation via Adversarial Variational Auto-encoder\n  Warm-up","summary":"  The gap between the randomly initialized item ID embedding and the\nwell-trained warm item ID embedding makes the cold items hard to suit the\nrecommendation system, which is trained on the data of historical warm items.\nTo alleviate the performance decline of new items recommendation, the\ndistribution of the new item ID embedding should be close to that of the\nhistorical warm items. To achieve this goal, we propose an Adversarial\nVariational Auto-encoder Warm-up model (AVAEW) to generate warm-up item ID\nembedding for cold items. Specifically, we develop a conditional variational\nauto-encoder model to leverage the side information of items for generating the\nwarm-up item ID embedding. Particularly, we introduce an adversarial module to\nenforce the alignment between warm-up item ID embedding distribution and\nhistorical item ID embedding distribution. We demonstrate the effectiveness and\ncompatibility of the proposed method by extensive offline experiments on public\ndatasets and online A/B tests on a real-world large-scale news recommendation\nplatform.\n","authors":["Shenzheng Zhang","Qi Tan","Xinzhi Zheng","Yi Ren","Xu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.14395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.15771v3","updated":"2023-02-28T08:18:32Z","published":"2021-10-29T13:39:14Z","title":"Collaborative Pure Exploration in Kernel Bandit","summary":"  In this paper, we formulate a Collaborative Pure Exploration in Kernel Bandit\nproblem (CoPE-KB), which provides a novel model for multi-agent multi-task\ndecision making under limited communication and general reward functions, and\nis applicable to many online learning tasks, e.g., recommendation systems and\nnetwork scheduling. We consider two settings of CoPE-KB, i.e., Fixed-Confidence\n(FC) and Fixed-Budget (FB), and design two optimal algorithms CoopKernelFC (for\nFC) and CoopKernelFB (for FB). Our algorithms are equipped with innovative and\nefficient kernelized estimators to simultaneously achieve computation and\ncommunication efficiency. Matching upper and lower bounds under both the\nstatistical and communication metrics are established to demonstrate the\noptimality of our algorithms. The theoretical bounds successfully quantify the\ninfluences of task similarities on learning acceleration and only depend on the\neffective dimension of the kernelized feature space. Our analytical techniques,\nincluding data dimension decomposition, linear structured instance\ntransformation and (communication) round-speedup induction, are novel and\napplicable to other bandit problems. Empirical evaluations are provided to\nvalidate our theoretical results and demonstrate the performance superiority of\nour algorithms.\n","authors":["Yihan Du","Wei Chen","Yuko Kuroki","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2110.15771v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14390v1","updated":"2023-02-28T08:17:50Z","published":"2023-02-28T08:17:50Z","title":"Your time series is worth a binary image: machine vision assisted deep\n  framework for time series forecasting","summary":"  Time series forecasting (TSF) has been a challenging research area, and\nvarious models have been developed to address this task. However, almost all\nthese models are trained with numerical time series data, which is not as\neffectively processed by the neural system as visual information. To address\nthis challenge, this paper proposes a novel machine vision assisted deep time\nseries analysis (MV-DTSA) framework. The MV-DTSA framework operates by\nanalyzing time series data in a novel binary machine vision time series metric\nspace, which includes a mapping and an inverse mapping function from the\nnumerical time series space to the binary machine vision space, and a deep\nmachine vision model designed to address the TSF task in the binary space. A\ncomprehensive computational analysis demonstrates that the proposed MV-DTSA\nframework outperforms state-of-the-art deep TSF models, without requiring\nsophisticated data decomposition or model customization. The code for our\nframework is accessible at https://github.com/IkeYang/\nmachine-vision-assisted-deep-time-series-analysis-MV-DTSA-.\n","authors":["Luoxiao Yang","Xinqi Fan","Zijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14386v1","updated":"2023-02-28T08:15:49Z","published":"2023-02-28T08:15:49Z","title":"Practical Algorithms for Orientations of Partially Directed Graphical\n  Models","summary":"  In observational studies, the true causal model is typically unknown and\nneeds to be estimated from available observational and limited experimental\ndata. In such cases, the learned causal model is commonly represented as a\npartially directed acyclic graph (PDAG), which contains both directed and\nundirected edges indicating uncertainty of causal relations between random\nvariables. The main focus of this paper is on the maximal orientation task,\nwhich, for a given PDAG, aims to orient the undirected edges maximally such\nthat the resulting graph represents the same Markov equivalent DAGs as the\ninput PDAG. This task is a subroutine used frequently in causal discovery, e.\ng., as the final step of the celebrated PC algorithm. Utilizing connections to\nthe problem of finding a consistent DAG extension of a PDAG, we derive faster\nalgorithms for computing the maximal orientation by proposing two novel\napproaches for extending PDAGs, both constructed with an emphasis on simplicity\nand practical effectiveness.\n","authors":["Malte Luttermann","Marcel Wienöbst","Maciej Liśkiewicz"],"pdf_url":"https://arxiv.org/pdf/2302.14386v1.pdf","comment":"Accepted to the Proceedings of the 2nd Conference on Causal Learning\n  and Reasoning (CLeaR-23)"},{"id":"http://arxiv.org/abs/2302.14383v1","updated":"2023-02-28T08:11:56Z","published":"2023-02-28T08:11:56Z","title":"Linear Spaces of Meanings: the Compositional Language of VLMs","summary":"  We investigate compositional structures in vector data embeddings from\npre-trained vision-language models (VLMs). Traditionally, compositionality has\nbeen associated with algebraic operations on embeddings of words from a\npre-existing vocabulary. In contrast, we seek to approximate label\nrepresentations from a text encoder as combinations of a smaller set of vectors\nin the embedding space. These vectors can be seen as \"ideal words\" which can be\nused to generate new concepts in an efficient way. We present a theoretical\nframework for understanding linear compositionality, drawing connections with\nmathematical representation theory and previous definitions of disentanglement.\nWe provide theoretical and empirical evidence that ideal words provide good\ncompositional approximations of composite concepts and can be more effective\nthan token-based decompositions of the same concepts.\n","authors":["Matthew Trager","Pramuditha Perera","Luca Zancato","Alessandro Achille","Parminder Bhatia","Bing Xiang","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2302.14383v1.pdf","comment":"24 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2302.12578v2","updated":"2023-02-28T08:08:29Z","published":"2023-02-24T11:25:50Z","title":"Fairness in Language Models Beyond English: Gaps and Challenges","summary":"  With language models becoming increasingly ubiquitous, it has become\nessential to address their inequitable treatment of diverse demographic groups\nand factors. Most research on evaluating and mitigating fairness harms has been\nconcentrated on English, while multilingual models and non-English languages\nhave received comparatively little attention. This paper presents a survey of\nfairness in multilingual and non-English contexts, highlighting the\nshortcomings of current research and the difficulties faced by methods designed\nfor English. We contend that the multitude of diverse cultures and languages\nacross the world makes it infeasible to achieve comprehensive coverage in terms\nof constructing fairness datasets. Thus, the measurement and mitigation of\nbiases must evolve beyond the current dataset-driven practices that are\nnarrowly focused on specific dimensions and types of biases and, therefore,\nimpossible to scale across languages and cultures.\n","authors":["Krithika Ramesh","Sunayana Sitaram","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2302.12578v2.pdf","comment":"Accepted to EACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2111.14039v3","updated":"2023-02-28T08:07:02Z","published":"2021-11-28T03:22:22Z","title":"Generalization Performance of Empirical Risk Minimization on\n  Over-parameterized Deep ReLU Nets","summary":"  In this paper, we study the generalization performance of global minima for\nimplementing empirical risk minimization (ERM) on over-parameterized deep ReLU\nnets. Using a novel deepening scheme for deep ReLU nets, we rigorously prove\nthat there exist perfect global minima achieving almost optimal generalization\nerror bounds for numerous types of data under mild conditions. Since\nover-parameterization is crucial to guarantee that the global minima of ERM on\ndeep ReLU nets can be realized by the widely used stochastic gradient descent\n(SGD) algorithm, our results indeed fill a gap between optimization and\ngeneralization.\n","authors":["Shao-Bo Lin","Yao Wang","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2111.14039v3.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.14376v1","updated":"2023-02-28T07:58:49Z","published":"2023-02-28T07:58:49Z","title":"GNOT: A General Neural Operator Transformer for Operator Learning","summary":"  Learning partial differential equations' (PDEs) solution operators is an\nessential problem in machine learning. However, there are several challenges\nfor learning operators in practical applications like the irregular mesh,\nmultiple input functions, and complexity of the PDEs' solution. To address\nthese challenges, we propose a general neural operator transformer (GNOT), a\nscalable and effective transformer-based framework for learning operators. By\ndesigning a novel heterogeneous normalized attention layer, our model is highly\nflexible to handle multiple input functions and irregular mesh. Besides, we\nintroduce a geometric gating mechanism which could be viewed as a soft domain\ndecomposition to solve the multi-scale problems. The large model capacity of\ntransformer architecture grants our model the possibility to scale to large\ndatasets and practical problems. We conduct extensive experiments on multiple\nchallenging datasets from different domains and achieve a remarkable\nimprovement compared with alternative methods.\n","authors":["Zhongkai Hao","Chengyang Ying","Zhengyi Wang","Hang Su","Yinpeng Dong","Songming Liu","Ze Cheng","Jun Zhu","Jian Song"],"pdf_url":"https://arxiv.org/pdf/2302.14376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.04553v4","updated":"2023-02-28T07:55:21Z","published":"2021-12-08T19:55:26Z","title":"Recent Advances in Reinforcement Learning in Finance","summary":"  The rapid changes in the finance industry due to the increasing amount of\ndata have revolutionized the techniques on data processing and data analysis\nand brought new theoretical and computational challenges. In contrast to\nclassical stochastic control theory and other analytical approaches for solving\nfinancial decision-making problems that heavily reply on model assumptions, new\ndevelopments from reinforcement learning (RL) are able to make full use of the\nlarge amount of financial data with fewer model assumptions and to improve\ndecisions in complex financial environments. This survey paper aims to review\nthe recent developments and use of RL approaches in finance. We give an\nintroduction to Markov decision processes, which is the setting for many of the\ncommonly used RL approaches. Various algorithms are then introduced with a\nfocus on value and policy based methods that do not require any model\nassumptions. Connections are made with neural networks to extend the framework\nto encompass deep RL algorithms. Our survey concludes by discussing the\napplication of these RL algorithms in a variety of decision-making problems in\nfinance, including optimal execution, portfolio optimization, option pricing\nand hedging, market making, smart order routing, and robo-advising.\n","authors":["Ben Hambly","Renyuan Xu","Huining Yang"],"pdf_url":"https://arxiv.org/pdf/2112.04553v4.pdf","comment":"60 pages, 1 figure"},{"id":"http://arxiv.org/abs/2302.14372v1","updated":"2023-02-28T07:55:02Z","published":"2023-02-28T07:55:02Z","title":"The In-Sample Softmax for Offline Reinforcement Learning","summary":"  Reinforcement learning (RL) agents can leverage batches of previously\ncollected data to extract a reasonable control policy. An emerging issue in\nthis offline RL setting, however, is that the bootstrapping update underlying\nmany of our methods suffers from insufficient action-coverage: standard max\noperator may select a maximal action that has not been seen in the dataset.\nBootstrapping from these inaccurate values can lead to overestimation and even\ndivergence. There are a growing number of methods that attempt to approximate\nan \\emph{in-sample} max, that only uses actions well-covered by the dataset. We\nhighlight a simple fact: it is more straightforward to approximate an in-sample\n\\emph{softmax} using only actions in the dataset. We show that policy iteration\nbased on the in-sample softmax converges, and that for decreasing temperatures\nit approaches the in-sample max. We derive an In-Sample Actor-Critic (AC),\nusing this in-sample softmax, and show that it is consistently better or\ncomparable to existing offline RL methods, and is also well-suited to\nfine-tuning.\n","authors":["Chenjun Xiao","Han Wang","Yangchen Pan","Adam White","Martha White"],"pdf_url":"https://arxiv.org/pdf/2302.14372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08915v3","updated":"2023-02-28T07:54:36Z","published":"2023-01-21T08:30:15Z","title":"Improving Deep Regression with Ordinal Entropy","summary":"  In computer vision, it is often observed that formulating regression problems\nas a classification task often yields better performance. We investigate this\ncurious phenomenon and provide a derivation to show that classification, with\nthe cross-entropy loss, outperforms regression with a mean squared error loss\nin its ability to learn high-entropy feature representations. Based on the\nanalysis, we propose an ordinal entropy loss to encourage higher-entropy\nfeature spaces while maintaining ordinal relationships to improve the\nperformance of regression tasks. Experiments on synthetic and real-world\nregression tasks demonstrate the importance and benefits of increasing entropy\nfor regression.\n","authors":["Shihao Zhang","Linlin Yang","Michael Bi Mi","Xiaoxu Zheng","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2301.08915v3.pdf","comment":"Accepted to ICLR 2023. Project page:\n  https://github.com/needylove/OrdinalEntropy"},{"id":"http://arxiv.org/abs/2207.12884v2","updated":"2023-02-28T07:53:10Z","published":"2022-07-26T13:17:28Z","title":"CFLIT: Coexisting Federated Learning and Information Transfer","summary":"  Future wireless networks are expected to support diverse mobile services,\nincluding artificial intelligence (AI) services and ubiquitous data\ntransmissions. Federated learning (FL), as a revolutionary learning approach,\nenables collaborative AI model training across distributed mobile edge devices.\nBy exploiting the superposition property of multiple-access channels,\nover-the-air computation allows concurrent model uploading from massive devices\nover the same radio resources, and thus significantly reduces the communication\ncost of FL. In this paper, we study the coexistence of over-the-air FL and\ntraditional information transfer (IT) in a mobile edge network. We propose a\ncoexisting federated learning and information transfer (CFLIT) communication\nframework, where the FL and IT devices share the wireless spectrum in an OFDM\nsystem. Under this framework, we aim to maximize the IT data rate and guarantee\na given FL convergence performance by optimizing the long-term radio resource\nallocation. A key challenge that limits the spectrum efficiency of the\ncoexisting system lies in the large overhead incurred by frequent communication\nbetween the server and edge devices for FL model aggregation. To address the\nchallenge, we rigorously analyze the impact of the computation-to-communication\nratio on the convergence of over-the-air FL in wireless fading channels. The\nanalysis reveals the existence of an optimal computation-to-communication ratio\nthat minimizes the amount of radio resources needed for over-the-air FL to\nconverge to a given error tolerance. Based on the analysis, we propose a\nlow-complexity online algorithm to jointly optimize the radio resource\nallocation for both the FL devices and IT devices. Extensive numerical\nsimulations verify the superior performance of the proposed design for the\ncoexistence of FL and IT devices in wireless cellular systems.\n","authors":["Zehong Lin","Hang Liu","Ying-Jun Angela Zhang"],"pdf_url":"https://arxiv.org/pdf/2207.12884v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2212.00328v2","updated":"2023-02-28T07:47:30Z","published":"2022-12-01T07:26:49Z","title":"Differentially Private Learning with Per-Sample Adaptive Clipping","summary":"  Privacy in AI remains a topic that draws attention from researchers and the\ngeneral public in recent years. As one way to implement privacy-preserving AI,\ndifferentially private learning is a framework that enables AI models to use\ndifferential privacy (DP). To achieve DP in the learning process, existing\nalgorithms typically limit the magnitude of gradients with a constant clipping,\nwhich requires carefully tuned due to its significant impact on model\nperformance. As a solution to this issue, latest works NSGD and Auto-S\ninnovatively propose to use normalization instead of clipping to avoid\nhyperparameter tuning. However, normalization-based approaches like NSGD and\nAuto-S rely on a monotonic weight function, which imposes excessive weight on\nsmall gradient samples and introduces extra deviation to the update. In this\npaper, we propose a Differentially Private Per-Sample Adaptive Clipping\n(DP-PSAC) algorithm based on a non-monotonic adaptive weight function, which\nguarantees privacy without the typical hyperparameter tuning process of using a\nconstant clipping while significantly reducing the deviation between the update\nand true batch-averaged gradient. We provide a rigorous theoretical convergence\nanalysis and show that with convergence rate at the same order, the proposed\nalgorithm achieves a lower non-vanishing bound, which is maintained over\ntraining iterations, compared with NSGD/Auto-S. In addition, through extensive\nexperimental evaluation, we show that DP-PSAC outperforms or matches the\nstate-of-the-art methods on multiple main-stream vision and language tasks.\n","authors":["Tianyu Xia","Shuheng Shen","Su Yao","Xinyi Fu","Ke Xu","Xiaolong Xu","Xing Fu","Weiqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.00328v2.pdf","comment":"To appear in AAAI 2023, Revised acknowledgments and citations"},{"id":"http://arxiv.org/abs/2302.14367v1","updated":"2023-02-28T07:40:37Z","published":"2023-02-28T07:40:37Z","title":"BrainBERT: Self-supervised representation learning for intracranial\n  recordings","summary":"  We create a reusable Transformer, BrainBERT, for intracranial recordings\nbringing modern representation learning approaches to neuroscience. Much like\nin NLP and speech recognition, this Transformer enables classifying complex\nconcepts, i.e., decoding neural data, with higher accuracy and with much less\ndata by being pretrained in an unsupervised manner on a large corpus of\nunannotated neural recordings. Our approach generalizes to new subjects with\nelectrodes in new positions and to unrelated tasks showing that the\nrepresentations robustly disentangle the neural signal. Just like in NLP where\none can study language by investigating what a language model learns, this\napproach opens the door to investigating the brain by what a model of the brain\nlearns. As a first step along this path, we demonstrate a new analysis of the\nintrinsic dimensionality of the computations in different areas of the brain.\nTo construct these representations, we combine a technique for producing\nsuper-resolution spectrograms of neural data with an approach designed for\ngenerating contextual representations of audio by masking. In the future, far\nmore concepts will be decodable from neural recordings by using representation\nlearning, potentially unlocking the brain like language models unlocked\nlanguage.\n","authors":["Christopher Wang","Vighnesh Subramaniam","Adam Uri Yaari","Gabriel Kreiman","Boris Katz","Ignacio Cases","Andrei Barbu"],"pdf_url":"https://arxiv.org/pdf/2302.14367v1.pdf","comment":"9 pages, 6 figures, ICLR 2023"},{"id":"http://arxiv.org/abs/2209.07075v2","updated":"2023-02-28T07:35:57Z","published":"2022-09-15T06:21:24Z","title":"Bi-level Physics-Informed Neural Networks for PDE Constrained\n  Optimization using Broyden's Hypergradients","summary":"  Deep learning based approaches like Physics-informed neural networks (PINNs)\nand DeepONets have shown promise on solving PDE constrained optimization\n(PDECO) problems. However, existing methods are insufficient to handle those\nPDE constraints that have a complicated or nonlinear dependency on optimization\ntargets. In this paper, we present a novel bi-level optimization framework to\nresolve the challenge by decoupling the optimization of the targets and\nconstraints. For the inner loop optimization, we adopt PINNs to solve the PDE\nconstraints only. For the outer loop, we design a novel method by using\nBroyden's method based on the Implicit Function Theorem (IFT), which is\nefficient and accurate for approximating hypergradients. We further present\ntheoretical explanations and error analysis of the hypergradients computation.\nExtensive experiments on multiple large-scale and nonlinear PDE constrained\noptimization problems demonstrate that our method achieves state-of-the-art\nresults compared with strong baselines.\n","authors":["Zhongkai Hao","Chengyang Ying","Hang Su","Jun Zhu","Jian Song","Ze Cheng"],"pdf_url":"https://arxiv.org/pdf/2209.07075v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11836v2","updated":"2023-02-28T07:35:33Z","published":"2023-02-23T07:52:31Z","title":"Sharpness-Aware Minimization: An Implicit Regularization Perspective","summary":"  Sharpness-Aware Minimization (SAM) is a recent optimization framework aiming\nto improve the deep neural network generalization, through obtaining flatter\n(i.e. less sharp) solutions. As SAM has been numerically successful, recent\npapers have studied the theoretical aspects of the framework. In this work, we\nstudy SAM through an implicit regularization lens, and present a new\ntheoretical explanation of why SAM generalizes well. To this end, we study the\nleast-squares linear regression problem and show a bias-variance trade-off for\nSAM's error over the course of the algorithm. We show SAM has lower bias\ncompared to Gradient Descent (GD), while having higher variance. This shows SAM\ncan outperform GD, specially if the algorithm is \\emph{stopped early}, which is\noften the case when training large neural networks due to the prohibitive\ncomputational cost. We extend our results to kernel regression, as well as\nstochastic optimization and discuss how implicit regularization of SAM can\nimprove upon vanilla training.\n","authors":["Kayhan Behdin","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2302.11836v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00939v4","updated":"2023-02-28T07:22:39Z","published":"2022-10-03T13:50:58Z","title":"Improving Sample Quality of Diffusion Models Using Self-Attention\n  Guidance","summary":"  Denoising diffusion models (DDMs) have attracted attention due to their\nexceptional sample quality and diversity. This success is largely attributed to\nthe use of class- or text-conditional diffusion guidance methods. In this\npaper, we propose a more comprehensive approach that expands beyond traditional\nguidance methods. By adopting this generalized perspective, we introduce two\nnovel condition-free strategies to enhance the quality of generated images:\nblur guidance and advanced Self-Attention Guidance (SAG). Employing benign\nproperties of Gaussian blur, blur guidance enhances the suitability of\nintermediate samples for fine-scale information and generates higher quality\nsamples with a moderate guidance scale. Improving upon this, SAG utilizes\nintermediate self-attention maps to enhance the stability and efficacy.\nSpecifically, SAG leverages intermediate attention maps of diffusion models at\neach iteration to capture essential information for the generative process and\nguide it accordingly. Our experimental results demonstrate that our zero-shot\nmethod enhances the performance of various diffusion models, including ADM,\nIDDPM, and Stable Diffusion. Furthermore, combining SAG with conventional\nguidance methods, such as classifier-free guidance, results in further\nimprovement.\n","authors":["Susung Hong","Gyuseong Lee","Wooseok Jang","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2210.00939v4.pdf","comment":"Project page: https://ku-cvlab.github.io/Self-Attention-Guidance"},{"id":"http://arxiv.org/abs/2302.14358v1","updated":"2023-02-28T07:22:30Z","published":"2023-02-28T07:22:30Z","title":"A Unified Representation Framework for Rideshare Marketplace Equilibrium\n  and Efficiency","summary":"  Ridesharing platforms are a type of two-sided marketplace where\n``supply-demand balance'' is critical for market efficiency and yet is complex\nto define and analyze. We present a unified analytical framework based on the\ngraph-based equilibrium metric (GEM) for quantifying the supply-demand\nspatiotemporal state and efficiency of a ridesharing marketplace. GEM was\ndeveloped as a generalized Wasserstein distance between the supply and demand\ndistributions in a ridesharing market and has been used as an evaluation metric\nfor algorithms expected to improve supply-demand alignment. Building upon GEM,\nwe develop SD-GEM, a dual-perspective (supply- and demand-side) representation\nof rideshare market equilibrium. We show that there are often disparities\nbetween the two views and examine how this dual-view leads to the notion of\nmarket efficiency, in which we propose novel statistical tests for capturing\nimprovement and explaining the underlying driving factors.\n","authors":["Alex Chin","Zhiwei Qin"],"pdf_url":"https://arxiv.org/pdf/2302.14358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14357v1","updated":"2023-02-28T07:20:49Z","published":"2023-02-28T07:20:49Z","title":"A Token-Wise Beam Search Algorithm for RNN-T","summary":"  Standard Recurrent Neural Network Transducers (RNN-T) decoding algorithms for\nspeech recognition are iterating over the time axis, such that one time step is\ndecoded before moving on to the next time step. Those algorithms result in a\nlarge number of calls to the joint network, that were shown in previous work to\nbe an important factor that reduces decoding speed. We present a decoding beam\nsearch algorithm that batches the joint network calls across a segment of time\nsteps, which results in 40%-70% decoding speedups, consistently across all\nmodels and settings experimented with. In addition, aggregating emission\nprobabilities over a segment may be seen as a better approximation to finding\nthe most likely model output, causing our algorithm to improve oracle word\nerror rate by up to 10% relative as the segment size increases, and to slightly\nimprove general word error rate.\n","authors":["Gil Keren"],"pdf_url":"https://arxiv.org/pdf/2302.14357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14353v1","updated":"2023-02-28T07:11:55Z","published":"2023-02-28T07:11:55Z","title":"A semantic backdoor attack against Graph Convolutional Networks","summary":"  Graph Convolutional Networks (GCNs) have been very effective in addressing\nthe issue of various graph-structured related tasks, such as node\nclassification and graph classification. However, extensive research has shown\nthat GCNs are vulnerable to adversarial attacks. One of the security threats\nfacing GCNs is the backdoor attack, which hides incorrect classification rules\nin models and activates only when the model encounters specific inputs\ncontaining special features (e.g., fixed patterns like subgraphs, called\ntriggers), thus outputting incorrect classification results, while the model\nbehaves normally on benign samples. The semantic backdoor attack is a type of\nthe backdoor attack where the trigger is a semantic part of the sample; i.e.,\nthe trigger exists naturally in the original dataset and the attacker can pick\na naturally occurring feature as the backdoor trigger, which causes the model\nto misclassify even unmodified inputs. Meanwhile, it is difficult to detect\neven if the attacker modifies the input samples in the inference phase as they\ndo not have any anomaly compared to normal samples. Thus, semantic backdoor\nattacks are more imperceptible than non-semantic ones. However, existed\nresearch on semantic backdoor attacks has only focused on image and text\ndomains, which have not been well explored against GCNs. In this work, we\npropose a black-box Semantic Backdoor Attack (SBA) against GCNs. We assign the\ntrigger as a certain class of nodes in the dataset and our trigger is semantic.\nThrough evaluation on several real-world benchmark graph datasets, the\nexperimental results demonstrate that our proposed SBA can achieve almost 100%\nattack success rate under the poisoning rate less than 5% while having no\nimpact on normal predictive accuracy.\n","authors":["Jiazhu Dai","Zhipeng Xiong"],"pdf_url":"https://arxiv.org/pdf/2302.14353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.02710v2","updated":"2023-02-28T06:50:59Z","published":"2022-02-06T05:25:22Z","title":"Spectrally Adapted Physics-Informed Neural Networks for Solving\n  Unbounded Domain Problems","summary":"  Solving analytically intractable partial differential equations (PDEs) that\ninvolve at least one variable defined on an unbounded domain arises in numerous\nphysical applications. Accurately solving unbounded domain PDEs requires\nefficient numerical methods that can resolve the dependence of the PDE on the\nunbounded variable over at least several orders of magnitude. We propose a\nsolution to such problems by combining two classes of numerical methods: (i)\nadaptive spectral methods and (ii) physics-informed neural networks (PINNs).\nThe numerical approach that we develop takes advantage of the ability of\nphysics-informed neural networks to easily implement high-order numerical\nschemes to efficiently solve PDEs and extrapolate numerical solutions at any\npoint in space and time. We then show how recently introduced adaptive\ntechniques for spectral methods can be integrated into PINN-based PDE solvers\nto obtain numerical solutions of unbounded domain problems that cannot be\nefficiently approximated by standard PINNs. Through a number of examples, we\ndemonstrate the advantages of the proposed spectrally adapted PINNs in solving\nPDEs and estimating model parameters from noisy observations in unbounded\ndomains.\n","authors":["Mingtao Xia","Lucas Böttcher","Tom Chou"],"pdf_url":"https://arxiv.org/pdf/2202.02710v2.pdf","comment":"29 pages, 8 figures"},{"id":"http://arxiv.org/abs/2206.09670v2","updated":"2023-02-28T06:45:07Z","published":"2022-06-20T09:22:20Z","title":"Benchmarking Constraint Inference in Inverse Reinforcement Learning","summary":"  When deploying Reinforcement Learning (RL) agents into a physical system, we\nmust ensure that these agents are well aware of the underlying constraints. In\nmany real-world problems, however, the constraints are often hard to specify\nmathematically and unknown to the RL agents. To tackle these issues, Inverse\nConstrained Reinforcement Learning (ICRL) empirically estimates constraints\nfrom expert demonstrations. As an emerging research topic, ICRL does not have\ncommon benchmarks, and previous works tested algorithms under hand-crafted\nenvironments with manually-generated expert demonstrations. In this paper, we\nconstruct an ICRL benchmark in the context of RL application domains, including\nrobot control, and autonomous driving. For each environment, we design relevant\nconstraints and train expert agents to generate demonstration data. Besides,\nunlike existing baselines that learn a deterministic constraint, we propose a\nvariational ICRL method to model a posterior distribution of candidate\nconstraints. We conduct extensive experiments on these algorithms under our\nbenchmark and show how they can facilitate studying important research\nchallenges for ICRL. The benchmark, including the instructions for reproducing\nICRL algorithms, is available at\nhttps://github.com/Guiliang/ICRL-benchmarks-public.\n","authors":["Guiliang Liu","Yudong Luo","Ashish Gaurav","Kasra Rezaee","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2206.09670v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14346v1","updated":"2023-02-28T06:38:05Z","published":"2023-02-28T06:38:05Z","title":"Sampled Transformer for Point Sets","summary":"  The sparse transformer can reduce the computational complexity of the\nself-attention layers to $O(n)$, whilst still being a universal approximator of\ncontinuous sequence-to-sequence functions. However, this permutation variant\noperation is not appropriate for direct application to sets. In this paper, we\nproposed an $O(n)$ complexity sampled transformer that can process point set\nelements directly without any additional inductive bias. Our sampled\ntransformer introduces random element sampling, which randomly splits point\nsets into subsets, followed by applying a shared Hamiltonian self-attention\nmechanism to each subset. The overall attention mechanism can be viewed as a\nHamiltonian cycle in the complete attention graph, and the permutation of point\nset elements is equivalent to randomly sampling Hamiltonian cycles. This\nmechanism implements a Monte Carlo simulation of the $O(n^2)$ dense attention\nconnections. We show that it is a universal approximator for continuous\nset-to-set functions. Experimental results on point-clouds show comparable or\nbetter accuracy with significantly reduced computational complexity compared to\nthe dense transformer or alternative sparse attention schemes.\n","authors":["Shidi Li","Christian Walder","Alexander Soen","Lexing Xie","Miaomiao Liu"],"pdf_url":"https://arxiv.org/pdf/2302.14346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13939v2","updated":"2023-02-28T06:28:43Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking neural networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the RWKV language model, we successfully\nimplement `SpikeGPT', a generative language model with pure binary,\nevent-driven spiking activation units. We train the proposed model on three\nmodel variants: 45M, 125M and 260M parameters. To the best of our knowledge,\nthis is 4x larger than any functional backprop-trained SNN to date. We achieve\nthis by modifying the transformer block to replace multi-head self attention to\nreduce quadratic computational complexity to linear with increasing sequence\nlength. Input tokens are instead streamed in sequentially to our attention\nmechanism (as with typical SNNs). Our preliminary experiments show that\nSpikeGPT remains competitive with non-spiking models on tested benchmarks,\nwhile maintaining 5x less energy consumption when processed on neuromorphic\nhardware that can leverage sparse, event-driven activations. Our code\nimplementation is available at https://github.com/ridgerchu/SpikeGPT.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08270v2","updated":"2023-02-28T06:17:36Z","published":"2022-08-17T13:02:17Z","title":"On the Privacy Effect of Data Enhancement via the Lens of Memorization","summary":"  Machine learning poses severe privacy concerns as it has been shown that the\nlearned models can reveal sensitive information about their training data. Many\nworks have investigated the effect of widely-adopted data augmentation (DA) and\nadversarial training (AT) techniques, termed data enhancement in the paper, on\nthe privacy leakage of machine learning models. Such privacy effects are often\nmeasured by membership inference attacks (MIAs), which aim to identify whether\na particular example belongs to the training set or not. We propose to\ninvestigate privacy from a new perspective called memorization. Through the\nlens of memorization, we find that previously deployed MIAs produce misleading\nresults as they are less likely to identify samples with higher privacy risks\nas members compared to samples with low privacy risks. To solve this problem,\nwe deploy a recent attack that can capture individual samples' memorization\ndegrees for evaluation. Through extensive experiments, we unveil non-trivial\nfindings about the connections between three essential properties of machine\nlearning models, including privacy, generalization gap, and adversarial\nrobustness. We demonstrate that, unlike existing results, the generalization\ngap is shown not highly correlated with privacy leakage. Moreover, stronger\nadversarial robustness does not necessarily imply that the model is more\nsusceptible to privacy attacks.\n","authors":["Xiao Li","Qiongxiu Li","Zhanhao Hu","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2208.08270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2001.09887v5","updated":"2023-02-28T06:07:24Z","published":"2020-01-27T16:22:05Z","title":"Estimating heterogeneous treatment effects with right-censored data via\n  causal survival forests","summary":"  Forest-based methods have recently gained in popularity for non-parametric\ntreatment effect estimation. Building on this line of work, we introduce causal\nsurvival forests, which can be used to estimate heterogeneous treatment effects\nin a survival and observational setting where outcomes may be right-censored.\nOur approach relies on orthogonal estimating equations to robustly adjust for\nboth censoring and selection effects under unconfoundedness. In our\nexperiments, we find our approach to perform well relative to a number of\nbaselines.\n","authors":["Yifan Cui","Michael R. Kosorok","Erik Sverdrup","Stefan Wager","Ruoqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2001.09887v5.pdf","comment":"To appear in the Journal of the Royal Statistical Society, Series B"},{"id":"http://arxiv.org/abs/2302.13582v2","updated":"2023-02-28T06:02:56Z","published":"2023-02-27T08:40:45Z","title":"Neural Graph Revealers","summary":"  Sparse graph recovery methods work well where the data follows their\nassumptions but often they are not designed for doing downstream probabilistic\nqueries. This limits their adoption to only identifying connections among the\ninput variables. On the other hand, the Probabilistic Graphical Models (PGMs)\nassume an underlying base graph between variables and learns a distribution\nover them. PGM design choices are carefully made such that the inference \\&\nsampling algorithms are efficient. This brings in certain restrictions and\noften simplifying assumptions. In this work, we propose Neural Graph Revealers\n(NGRs), that are an attempt to efficiently merge the sparse graph recovery\nmethods with PGMs into a single flow. The problem setting consists of an input\ndata X with D features and M samples and the task is to recover a sparse graph\nshowing connection between the features and learn a probability distribution\nover the D at the same time. NGRs view the neural networks as a `glass box' or\nmore specifically as a multitask learning framework. We introduce\n`Graph-constrained path norm' that NGRs leverage to learn a graphical model\nthat captures complex non-linear functional dependencies between the features\nin the form of an undirected sparse graph. Furthermore, NGRs can handle\nmultimodal inputs like images, text, categorical data, embeddings etc. which is\nnot straightforward to incorporate in the existing methods. We show\nexperimental results of doing sparse graph recovery and probabilistic inference\non data from Gaussian graphical models and a multimodal infant mortality\ndataset by Centers for Disease Control and Prevention.\n","authors":["Harsh Shrivastava","Urszula Chajewska"],"pdf_url":"https://arxiv.org/pdf/2302.13582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10959v2","updated":"2023-02-28T05:58:25Z","published":"2023-02-21T19:35:47Z","title":"Dealing with Collinearity in Large-Scale Linear System Identification\n  Using Gaussian Regression","summary":"  Many problems arising in control require the determination of a mathematical\nmodel of the application. This has often to be performed starting from\ninput-output data, leading to a task known as system identification in the\nengineering literature. One emerging topic in this field is estimation of\nnetworks consisting of several interconnected dynamic systems. We consider the\nlinear setting assuming that system outputs are the result of many correlated\ninputs, hence making system identification severely ill-conditioned. This is a\nscenario often encountered when modeling complex cybernetics systems composed\nby many sub-units with feedback and algebraic loops. We develop a strategy cast\nin a Bayesian regularization framework where any impulse response is seen as\nrealization of a zero-mean Gaussian process. Any covariance is defined by the\nso called stable spline kernel which includes information on smooth exponential\ndecay. We design a novel Markov chain Monte Carlo scheme able to reconstruct\nthe impulse responses posterior by efficiently dealing with collinearity. Our\nscheme relies on a variation of the Gibbs sampling technique: beyond\nconsidering blocks forming a partition of the parameter space, some other\n(overlapping) blocks are also updated on the basis of the level of collinearity\nof the system inputs. Theoretical properties of the algorithm are studied\nobtaining its convergence rate. Numerical experiments are included using\nsystems containing hundreds of impulse responses and highly correlated inputs.\n","authors":["Wenqi Cao","Gianluigi Pillonetto"],"pdf_url":"https://arxiv.org/pdf/2302.10959v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2203.13633"},{"id":"http://arxiv.org/abs/2302.14329v1","updated":"2023-02-28T05:45:05Z","published":"2023-02-28T05:45:05Z","title":"Towards Personalized Preprocessing Pipeline Search","summary":"  Feature preprocessing, which transforms raw input features into numerical\nrepresentations, is a crucial step in automated machine learning (AutoML)\nsystems. However, the existing systems often have a very small search space for\nfeature preprocessing with the same preprocessing pipeline applied to all the\nnumerical features. This may result in sub-optimal performance since different\ndatasets often have various feature characteristics, and features within a\ndataset may also have their own preprocessing preferences. To bridge this gap,\nwe explore personalized preprocessing pipeline search, where the search\nalgorithm is allowed to adopt a different preprocessing pipeline for each\nfeature. This is a challenging task because the search space grows\nexponentially with more features. To tackle this challenge, we propose\nClusterP3S, a novel framework for Personalized Preprocessing Pipeline Search\nvia Clustering. The key idea is to learn feature clusters such that the search\nspace can be significantly reduced by using the same preprocessing pipeline for\nthe features within a cluster. To this end, we propose a hierarchical search\nstrategy to jointly learn the clusters and search for the optimal pipelines,\nwhere the upper-level search optimizes the feature clustering to enable better\npipelines built upon the clusters, and the lower-level search optimizes the\npipeline given a specific cluster assignment. We instantiate this idea with a\ndeep clustering network that is trained with reinforcement learning at the\nupper level, and random search at the lower level. Experiments on benchmark\nclassification datasets demonstrate the effectiveness of enabling feature-wise\npreprocessing pipeline search.\n","authors":["Diego Martinez","Daochen Zha","Qiaoyu Tan","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2302.14329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14320v1","updated":"2023-02-28T05:22:54Z","published":"2023-02-28T05:22:54Z","title":"Towards Addressing GAN Training Instabilities: Dual-objective GANs with\n  Tunable Parameters","summary":"  In an effort to address the training instabilities of GANs, we introduce a\nclass of dual-objective GANs with different value functions (objectives) for\nthe generator (G) and discriminator (D). In particular, we model each objective\nusing $\\alpha$-loss, a tunable classification loss, to obtain\n$(\\alpha_D,\\alpha_G)$-GANs, parameterized by $(\\alpha_D,\\alpha_G)\\in\n[0,\\infty)^2$. For sufficiently large number of samples and capacities for G\nand D, we show that the resulting non-zero sum game simplifies to minimizing an\n$f$-divergence under appropriate conditions on $(\\alpha_D,\\alpha_G)$. In the\nfinite sample and capacity setting, we define estimation error to quantify the\ngap in the generator's performance relative to the optimal setting with\ninfinite samples and obtain upper bounds on this error, showing it to be order\noptimal under certain conditions. Finally, we highlight the value of tuning\n$(\\alpha_D,\\alpha_G)$ in alleviating training instabilities for the synthetic\n2D Gaussian mixture ring and the Stacked MNIST datasets.\n","authors":["Monica Welfert","Kyle Otstot","Gowtham R. Kurri","Lalitha Sankar"],"pdf_url":"https://arxiv.org/pdf/2302.14320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08772v2","updated":"2023-02-28T05:22:09Z","published":"2022-09-19T05:54:26Z","title":"TANDEM3D: Active Tactile Exploration for 3D Object Recognition","summary":"  Tactile recognition of 3D objects remains a challenging task. Compared to 2D\nshapes, the complex geometry of 3D surfaces requires richer tactile signals,\nmore dexterous actions, and more advanced encoding techniques. In this work, we\npropose TANDEM3D, a method that applies a co-training framework for exploration\nand decision making to 3D object recognition with tactile signals. Starting\nwith our previous work, which introduced a co-training paradigm for 2D\nrecognition problems, we introduce a number of advances that enable us to scale\nup to 3D. TANDEM3D is based on a novel encoder that builds 3D object\nrepresentation from contact positions and normals using PointNet++.\nFurthermore, by enabling 6DOF movement, TANDEM3D explores and collects\ndiscriminative touch information with high efficiency. Our method is trained\nentirely in simulation and validated with real-world experiments. Compared to\nstate-of-the-art baselines, TANDEM3D achieves higher accuracy and a lower\nnumber of actions in recognizing 3D objects and is also shown to be more robust\nto different types and amounts of sensor noise. Video is available at\nhttps://jxu.ai/tandem3d.\n","authors":["Jingxi Xu","Han Lin","Shuran Song","Matei Ciocarlie"],"pdf_url":"https://arxiv.org/pdf/2209.08772v2.pdf","comment":"7 pages. Accepted to International Conference on Robotics and\n  Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2302.14311v1","updated":"2023-02-28T05:01:01Z","published":"2023-02-28T05:01:01Z","title":"Towards Memory- and Time-Efficient Backpropagation for Training Spiking\n  Neural Networks","summary":"  Spiking Neural Networks (SNNs) are promising energy-efficient models for\nneuromorphic computing. For training the non-differentiable SNN models, the\nbackpropagation through time (BPTT) with surrogate gradients (SG) method has\nachieved high performance. However, this method suffers from considerable\nmemory cost and training time during training. In this paper, we propose the\nSpatial Learning Through Time (SLTT) method that can achieve high performance\nwhile greatly improving training efficiency compared with BPTT. First, we show\nthat the backpropagation of SNNs through the temporal domain contributes just a\nlittle to the final calculated gradients. Thus, we propose to ignore the\nunimportant routes in the computational graph during backpropagation. The\nproposed method reduces the number of scalar multiplications and achieves a\nsmall memory occupation that is independent of the total time steps.\nFurthermore, we propose a variant of SLTT, called SLTT-K, that allows\nbackpropagation only at K time steps, then the required number of scalar\nmultiplications is further reduced and is independent of the total time steps.\nExperiments on both static and neuromorphic datasets demonstrate superior\ntraining efficiency and performance of our SLTT. In particular, our method\nachieves state-of-the-art accuracy on ImageNet, while the memory cost and\ntraining time are reduced by more than 70% and 50%, respectively, compared with\nBPTT.\n","authors":["Qingyan Meng","Mingqing Xiao","Shen Yan","Yisen Wang","Zhouchen Lin","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2302.14311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14307v1","updated":"2023-02-28T04:45:31Z","published":"2023-02-28T04:45:31Z","title":"GradMA: A Gradient-Memory-based Accelerated Federated Learning with\n  Alleviated Catastrophic Forgetting","summary":"  Federated Learning (FL) has emerged as a de facto machine learning area and\nreceived rapid increasing research interests from the community. However,\ncatastrophic forgetting caused by data heterogeneity and partial participation\nposes distinctive challenges for FL, which are detrimental to the performance.\nTo tackle the problems, we propose a new FL approach (namely GradMA), which\ntakes inspiration from continual learning to simultaneously correct the\nserver-side and worker-side update directions as well as take full advantage of\nserver's rich computing and memory resources. Furthermore, we elaborate a\nmemory reduction strategy to enable GradMA to accommodate FL with a large scale\nof workers. We then analyze convergence of GradMA theoretically under the\nsmooth non-convex setting and show that its convergence rate achieves a linear\nspeed up w.r.t the increasing number of sampled active workers. At last, our\nextensive experiments on various image classification tasks show that GradMA\nachieves significant performance gains in accuracy and communication efficiency\ncompared to SOTA baselines.\n","authors":["Kangyang Luo","Xiang Li","Yunshi Lan","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2302.14307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14306v1","updated":"2023-02-28T04:38:52Z","published":"2023-02-28T04:38:52Z","title":"CLR-GAM: Contrastive Point Cloud Learning with Guided Augmentation and\n  Feature Mapping","summary":"  Point cloud data plays an essential role in robotics and self-driving\napplications. Yet, annotating point cloud data is time-consuming and nontrivial\nwhile they enable learning discriminative 3D representations that empower\ndownstream tasks, such as classification and segmentation. Recently,\ncontrastive learning-based frameworks have shown promising results for learning\n3D representations in a self-supervised manner. However, existing contrastive\nlearning methods cannot precisely encode and associate structural features and\nsearch the higher dimensional augmentation space efficiently. In this paper, we\npresent CLR-GAM, a novel contrastive learning-based framework with Guided\nAugmentation (GA) for efficient dynamic exploration strategy and Guided Feature\nMapping (GFM) for similar structural feature association between augmented\npoint clouds. We empirically demonstrate that the proposed approach achieves\nstate-of-the-art performance on both simulated and real-world 3D point cloud\ndatasets for three different downstream tasks, i.e., 3D point cloud\nclassification, few-shot learning, and object part segmentation.\n","authors":["Srikanth Malla","Yi-Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2302.14306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14548v2","updated":"2023-02-28T04:19:48Z","published":"2022-09-29T04:36:23Z","title":"Offline Reinforcement Learning via High-Fidelity Generative Behavior\n  Modeling","summary":"  In offline reinforcement learning, weighted regression is a common method to\nensure the learned policy stays close to the behavior policy and to prevent\nselecting out-of-sample actions. In this work, we show that due to the limited\ndistributional expressivity of policy models, previous methods might still\nselect unseen actions during training, which deviates from their initial\nmotivation. To address this problem, we adopt a generative approach by\ndecoupling the learned policy into two parts: an expressive generative behavior\nmodel and an action evaluation model. The key insight is that such decoupling\navoids learning an explicitly parameterized policy model with a closed-form\nexpression. Directly learning the behavior policy allows us to leverage\nexisting advances in generative modeling, such as diffusion-based methods, to\nmodel diverse behaviors. As for action evaluation, we combine our method with\nan in-sample planning technique to further avoid selecting out-of-sample\nactions and increase computational efficiency. Experimental results on D4RL\ndatasets show that our proposed method achieves competitive or superior\nperformance compared with state-of-the-art offline RL methods, especially in\ncomplex tasks such as AntMaze. We also empirically demonstrate that our method\ncan successfully learn from a heterogeneous dataset containing multiple\ndistinctive but similarly successful strategies, whereas previous unimodal\npolicies fail.\n","authors":["Huayu Chen","Cheng Lu","Chengyang Ying","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.14548v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04797v4","updated":"2023-02-28T04:18:22Z","published":"2022-06-06T21:56:11Z","title":"Memory-efficient model-based deep learning with convergence and\n  robustness guarantees","summary":"  Computational imaging has been revolutionized by compressed sensing\nalgorithms, which offer guaranteed uniqueness, convergence, and stability\nproperties. Model-based deep learning methods that combine imaging physics with\nlearned regularization priors have emerged as more powerful alternatives for\nimage recovery. The main focus of this paper is to introduce a memory efficient\nmodel-based algorithm with similar theoretical guarantees as CS methods. The\nproposed iterative algorithm alternates between a gradient descent involving\nthe score function and a conjugate gradient algorithm to encourage data\nconsistency. The score function is modeled as a monotone convolutional neural\nnetwork. Our analysis shows that the monotone constraint is necessary and\nsufficient to enforce the uniqueness of the fixed point in arbitrary inverse\nproblems. In addition, it also guarantees the convergence to a fixed point,\nwhich is robust to input perturbations. We introduce two implementations of the\nproposed MOL framework, which differ in the way the monotone property is\nimposed. The first approach enforces a strict monotone constraint, while the\nsecond one relies on an approximation. The guarantees are not valid for the\nsecond approach in the strict sense. However, our empirical studies show that\nthe convergence and robustness of both approaches are comparable, while the\nless constrained approximate implementation offers better performance. The\nproposed deep equilibrium formulation is significantly more memory efficient\nthan unrolled methods, which allows us to apply it to 3D or 2D+time problems\nthat current unrolled algorithms cannot handle.\n","authors":["Aniket Pramanik","M. Bridget Zimmerman","Mathews Jacob"],"pdf_url":"https://arxiv.org/pdf/2206.04797v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12366v2","updated":"2023-02-28T04:16:53Z","published":"2023-02-23T23:48:20Z","title":"Less is More: Data Pruning for Faster Adversarial Training","summary":"  Deep neural networks (DNNs) are sensitive to adversarial examples, resulting\nin fragile and unreliable performance in the real world. Although adversarial\ntraining (AT) is currently one of the most effective methodologies to robustify\nDNNs, it is computationally very expensive (e.g., 5-10X costlier than standard\ntraining). To address this challenge, existing approaches focus on single-step\nAT, referred to as Fast AT, reducing the overhead of adversarial example\ngeneration. Unfortunately, these approaches are known to fail against stronger\nadversaries. To make AT computationally efficient without compromising\nrobustness, this paper takes a different view of the efficient AT problem.\nSpecifically, we propose to minimize redundancies at the data level by\nleveraging data pruning. Extensive experiments demonstrate that the data\npruning based AT can achieve similar or superior robust (and clean) accuracy as\nits unpruned counterparts while being significantly faster. For instance,\nproposed strategies accelerate CIFAR-10 training up to 3.44X and CIFAR-100\ntraining to 2.02X. Additionally, the data pruning methods can readily be\nreconciled with existing adversarial acceleration tricks to obtain the striking\nspeed-ups of 5.66X and 5.12X on CIFAR-10, 3.67X and 3.07X on CIFAR-100 with\nTRADES and MART, respectively.\n","authors":["Yize Li","Pu Zhao","Xue Lin","Bhavya Kailkhura","Ryan Goldhahn"],"pdf_url":"https://arxiv.org/pdf/2302.12366v2.pdf","comment":"The AAAI-23 Workshop on Artificial Intelligence Safety (SafeAI 2023)"},{"id":"http://arxiv.org/abs/2302.14299v1","updated":"2023-02-28T04:16:42Z","published":"2023-02-28T04:16:42Z","title":"Gradient-Boosted Based Structured and Unstructured Learning","summary":"  We propose two frameworks to deal with problem settings in which both\nstructured and unstructured data are available. Structured data problems are\nbest solved by traditional machine learning models such as boosting and\ntree-based algorithms, whereas deep learning has been widely applied to\nproblems dealing with images, text, audio, and other unstructured data sources.\nHowever, for the setting in which both structured and unstructured data are\naccessible, it is not obvious what the best modeling approach is to enhance\nperformance on both data sources simultaneously. Our proposed frameworks allow\njoint learning on both kinds of data by integrating the paradigms of boosting\nmodels and deep neural networks. The first framework, the\nboosted-feature-vector deep learning network, learns features from the\nstructured data using gradient boosting and combines them with embeddings from\nunstructured data via a two-branch deep neural network. Secondly, the\ntwo-weak-learner boosting framework extends the boosting paradigm to the\nsetting with two input data sources. We present and compare first- and\nsecond-order methods of this framework. Our experimental results on both public\nand real-world datasets show performance gains achieved by the frameworks over\nselected baselines by magnitudes of 0.1% - 4.7%.\n","authors":["Andrea Treviño Gavito","Diego Klabjan","Jean Utke"],"pdf_url":"https://arxiv.org/pdf/2302.14299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14148v2","updated":"2023-02-28T04:16:04Z","published":"2022-09-28T14:58:41Z","title":"Guiding Safe Exploration with Weakest Preconditions","summary":"  In reinforcement learning for safety-critical settings, it is often desirable\nfor the agent to obey safety constraints at all points in time, including\nduring training. We present a novel neurosymbolic approach called SPICE to\nsolve this safe exploration problem. SPICE uses an online shielding layer based\non symbolic weakest preconditions to achieve a more precise safety analysis\nthan existing tools without unduly impacting the training process. We evaluate\nthe approach on a suite of continuous control benchmarks and show that it can\nachieve comparable performance to existing safe learning techniques while\nincurring fewer safety violations. Additionally, we present theoretical results\nshowing that SPICE converges to the optimal safe policy under reasonable\nassumptions.\n","authors":["Greg Anderson","Swarat Chaudhuri","Isil Dillig"],"pdf_url":"https://arxiv.org/pdf/2209.14148v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14290v1","updated":"2023-02-28T03:50:56Z","published":"2023-02-28T03:50:56Z","title":"Learning to Retain while Acquiring: Combating Distribution-Shift in\n  Adversarial Data-Free Knowledge Distillation","summary":"  Data-free Knowledge Distillation (DFKD) has gained popularity recently, with\nthe fundamental idea of carrying out knowledge transfer from a Teacher neural\nnetwork to a Student neural network in the absence of training data. However,\nin the Adversarial DFKD framework, the student network's accuracy, suffers due\nto the non-stationary distribution of the pseudo-samples under multiple\ngenerator updates. To this end, at every generator update, we aim to maintain\nthe student's performance on previously encountered examples while acquiring\nknowledge from samples of the current distribution. Thus, we propose a\nmeta-learning inspired framework by treating the task of Knowledge-Acquisition\n(learning from newly generated samples) and Knowledge-Retention (retaining\nknowledge on previously met samples) as meta-train and meta-test, respectively.\nHence, we dub our method as Learning to Retain while Acquiring. Moreover, we\nidentify an implicit aligning factor between the Knowledge-Retention and\nKnowledge-Acquisition tasks indicating that the proposed student update\nstrategy enforces a common gradient direction for both tasks, alleviating\ninterference between the two objectives. Finally, we support our hypothesis by\nexhibiting extensive evaluation and comparison of our method with prior arts on\nmultiple datasets.\n","authors":["Gaurav Patel","Konda Reddy Mopuri","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.14290v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00135v1","updated":"2023-02-28T23:40:41Z","published":"2023-02-28T23:40:41Z","title":"Deep learning for COVID-19 topic modelling via Twitter: Alpha, Delta and\n  Omicron","summary":"  Topic modelling with innovative deep learning methods has gained interest for\na wide range of applications that includes COVID-19. Topic modelling can\nprovide, psychological, social and cultural insights for understanding human\nbehaviour in extreme events such as the COVID-19 pandemic. In this paper, we\nuse prominent deep learning-based language models for COVID-19 topic modelling\ntaking into account data from emergence (Alpha) to the Omicron variant. We\napply topic modeling to review the public behaviour across the first, second\nand third waves based on Twitter dataset from India. Our results show that the\ntopics extracted for the subsequent waves had certain overlapping themes such\nas covers governance, vaccination, and pandemic management while novel issues\naroused in political, social and economic situation during COVID-19 pandemic.\nWe also found a strong correlation of the major topics qualitatively to news\nmedia prevalent at the respective time period. Hence, our framework has the\npotential to capture major issues arising during different phases of the\nCOVID-19 pandemic which can be extended to other countries and regions.\n","authors":["Janhavi Lande","Arti Pillay","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2303.00135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08639v2","updated":"2023-02-28T23:32:08Z","published":"2023-02-17T01:04:51Z","title":"Improving Transformer-based Networks With Locality For Automatic Speaker\n  Verification","summary":"  Recently, Transformer-based architectures have been explored for speaker\nembedding extraction. Although the Transformer employs the self-attention\nmechanism to efficiently model the global interaction between token embeddings,\nit is inadequate for capturing short-range local context, which is essential\nfor the accurate extraction of speaker information. In this study, we enhance\nthe Transformer with the enhanced locality modeling in two directions. First,\nwe propose the Locality-Enhanced Conformer (LE-Confomer) by introducing\ndepth-wise convolution and channel-wise attention into the Conformer blocks.\nSecond, we present the Speaker Swin Transformer (SST) by adapting the Swin\nTransformer, originally proposed for vision tasks, into speaker embedding\nnetwork. We evaluate the proposed approaches on the VoxCeleb datasets and a\nlarge-scale Microsoft internal multilingual (MS-internal) dataset. The proposed\nmodels achieve 0.75% EER on VoxCeleb 1 test set, outperforming the previously\nproposed Transformer-based models and CNN-based models, such as ResNet34 and\nECAPA-TDNN. When trained on the MS-internal dataset, the proposed models\nachieve promising results with 14.6% relative reduction in EER over the\nRes2Net50 model.\n","authors":["Mufan Sang","Yong Zhao","Gang Liu","John H. L. Hansen","Jian Wu"],"pdf_url":"https://arxiv.org/pdf/2302.08639v2.pdf","comment":"Accepted to ICASSP 2023"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.14757v1","updated":"2023-02-28T16:59:13Z","published":"2023-02-28T16:59:13Z","title":"Audio Retrieval for Multimodal Design Documents: A New Dataset and\n  Algorithms","summary":"  We consider and propose a new problem of retrieving audio files relevant to\nmultimodal design document inputs comprising both textual elements and visual\nimagery, e.g., birthday/greeting cards. In addition to enhancing user\nexperience, integrating audio that matches the theme/style of these inputs also\nhelps improve the accessibility of these documents (e.g., visually impaired\npeople can listen to the audio instead). While recent work in audio retrieval\nexists, these methods and datasets are targeted explicitly towards natural\nimages. However, our problem considers multimodal design documents (created by\nusers using creative software) substantially different from a naturally clicked\nphotograph. To this end, our first contribution is collecting and curating a\nnew large-scale dataset called Melodic-Design (or MELON), comprising design\ndocuments representing various styles, themes, templates, illustrations, etc.,\npaired with music audio. Given our paired image-text-audio dataset, our next\ncontribution is a novel multimodal cross-attention audio retrieval (MMCAR)\nalgorithm that enables training neural networks to learn a common shared\nfeature space across image, text, and audio dimensions. We use these learned\nfeatures to demonstrate that our method outperforms existing state-of-the-art\nmethods and produce a new reference benchmark for the research community on our\nnew dataset.\n","authors":["Prachi Singh","Srikrishna Karanam","Sumit Shekhar"],"pdf_url":"https://arxiv.org/pdf/2302.14757v1.pdf","comment":"5 pages including references"},{"id":"http://arxiv.org/abs/2302.14728v1","updated":"2023-02-28T16:34:55Z","published":"2023-02-28T16:34:55Z","title":"Global Context-Aware Person Image Generation","summary":"  We propose a data-driven approach for context-aware person image generation.\nSpecifically, we attempt to generate a person image such that the synthesized\ninstance can blend into a complex scene. In our method, the position, scale,\nand appearance of the generated person are semantically conditioned on the\nexisting persons in the scene. The proposed technique is divided into three\nsequential steps. At first, we employ a Pix2PixHD model to infer a coarse\nsemantic mask that represents the new person's spatial location, scale, and\npotential pose. Next, we use a data-centric approach to select the closest\nrepresentation from a precomputed cluster of fine semantic masks. Finally, we\nadopt a multi-scale, attention-guided architecture to transfer the appearance\nattributes from an exemplar image. The proposed strategy enables us to\nsynthesize semantically coherent realistic persons that can blend into an\nexisting scene without altering the global context. We conclude our findings\nwith relevant qualitative and quantitative evaluations.\n","authors":["Prasun Roy","Saumik Bhattacharya","Subhankar Ghosh","Umapada Pal","Michael Blumenstein"],"pdf_url":"https://arxiv.org/pdf/2302.14728v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2302.14472v1","updated":"2023-02-28T10:30:16Z","published":"2023-02-28T10:30:16Z","title":"TV-watching Companion Robot Powered by Open-domain Chatbot \"KACTUS\"","summary":"  Watching TV not only provides news information but also gives an opportunity\nfor different generations to communicate. With the proliferation of\nsmartphones, PC, and the Internet, increase the opportunities for communication\nin front of the television is also likely to diminish. This has led to some\nproblems further from face-to-face such as a lack of self-control and\ninsufficient development of communication skills. This paper proposes a\nTV-watching companion robot with open-domain chat ability. The robot contains\ntwo modes: TV-watching mode and conversation mode. In TV-watching mode, the\nrobot first extracts keywords from the TV program and then generates the\ndisclosure utterances based on the extracted keywords as if enjoying the TV\nprogram. In the conversation mode, the robot generates question utterances with\nkeywords in the same way and then employs a topics-based dialog management\nmethod consisting of multiple dialog engines for rich conversations related to\nthe TV program. We conduct the initial experiments and the result shows that\nall participants from the three groups enjoyed talking with the robot, and the\nquestion about their interests in the robot was rated 6.5/7-levels. This\nindicates that the proposed conversational features of TV-watching Companion\nRobot have the potential to make our daily lives more enjoyable. Under the\nanalysis of the initial experiments, we achieve further experiments with more\nparticipants by dividing them into two groups: a control group without a robot\nand an intervention group with a robot. The results show that people prefer to\ntalk to robots because the robot will bring more enjoyable, relaxed, and\ninteresting.\n","authors":["Donghuo Zeng","Jianming Wu","Gen Hattori","Yasuhiro Takishima"],"pdf_url":"https://arxiv.org/pdf/2302.14472v1.pdf","comment":"15 pages, 3 figures, 11 tables"},{"id":"http://arxiv.org/abs/2302.14465v1","updated":"2023-02-28T10:14:28Z","published":"2023-02-28T10:14:28Z","title":"Video Quality Assessment with Texture Information Fusion for Streaming\n  Applications","summary":"  The rise of video streaming applications has increased the demand for Video\nQuality Assessment (VQA). In 2016, Netflix introduced VMAF, a full reference\nVQA metric that strongly correlates with perceptual quality, but its\ncomputation is time-intensive. This paper proposes a Discrete Cosine Transform\n(DCT)-energy-based VQA with texture information fusion (VQ-TIF ) model for\nvideo streaming applications that predicts VMAF for the reconstructed video\ncompared to the original video. VQ-TIF extracts Structural Similarity (SSIM)\nand spatio-temporal features of the frames from the original and reconstructed\nvideos, fuses them using a Long Short-Term Memory (LSTM)-based model to\nestimate VMAF. Experimental results show that VQ-TIF estimates VMAF with a\nPearson Correlation Coefficient (PCC) of 0.96 and a Mean Absolute Error (MAE)\nof 2.71, on average, compared to the ground truth VMAF scores. Additionally,\nVQ-TIF estimates VMAF at a rate of 9.14 times faster than the state-of-the-art\nVMAF implementation and a 89.44% reduction in the energy consumption, assuming\nan Ultra HD (2160p) display resolution.\n","authors":["Vignesh V Menon","Prajit T Rajendran","Reza Farahani","Klaus Schoeffmann","Christian Timmerer"],"pdf_url":"https://arxiv.org/pdf/2302.14465v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2302.14409v1","updated":"2023-02-28T08:44:00Z","published":"2023-02-28T08:44:00Z","title":"An Adaptive Method for Camera Attribution under Complex Radial\n  Distortion Corrections","summary":"  Radial correction distortion, applied by in-camera or out-camera\nsoftware/firmware alters the supporting grid of the image so as to hamper\nPRNU-based camera attribution. Existing solutions to deal with this problem try\nto invert/estimate the correction using radial transformations parameterized\nwith few variables in order to restrain the computational load; however, with\never more prevalent complex distortion corrections their performance is\nunsatisfactory. In this paper we propose an adaptive algorithm that by dividing\nthe image into concentric annuli is able to deal with sophisticated corrections\nlike those applied out-camera by third party software like Adobe Lightroom,\nPhotoshop, Gimp and PT-Lens. We also introduce a statistic called cumulative\npeak of correlation energy (CPCE) that allows for an efficient early stopping\nstrategy. Experiments on a large dataset of in-camera and out-camera radially\ncorrected images show that our solution improves the state of the art in terms\nof both accuracy and computational cost.\n","authors":["Andrea Montibeller","Fernando Pérez-González"],"pdf_url":"https://arxiv.org/pdf/2302.14409v1.pdf","comment":"This paper was submitted to IEEE Transactions on Information\n  Forensics & Security the July 28, 2022"},{"id":"http://arxiv.org/abs/2302.14402v1","updated":"2023-02-28T08:35:50Z","published":"2023-02-28T08:35:50Z","title":"Neural Video Compression with Diverse Contexts","summary":"  For any video codecs, the coding efficiency highly relies on whether the\ncurrent signal to be encoded can find the relevant contexts from the previous\nreconstructed signals. Traditional codec has verified more contexts bring\nsubstantial coding gain, but in a time-consuming manner. However, for the\nemerging neural video codec (NVC), its contexts are still limited, leading to\nlow compression ratio. To boost NVC, this paper proposes increasing the context\ndiversity in both temporal and spatial dimensions. First, we guide the model to\nlearn hierarchical quality patterns across frames, which enriches long-term and\nyet high-quality temporal contexts. Furthermore, to tap the potential of\noptical flow-based coding framework, we introduce a group-based offset\ndiversity where the cross-group interaction is proposed for better context\nmining. In addition, this paper also adopts a quadtree-based partition to\nincrease spatial context diversity when encoding the latent representation in\nparallel. Experiments show that our codec obtains 23.5% bitrate saving over\nprevious SOTA NVC. Better yet, our codec has surpassed the under-developing\nnext generation traditional codec/ECM in both RGB and YUV420 colorspaces, in\nterms of PSNR. The codes are at https://github.com/microsoft/DCVC.\n","authors":["Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2302.14402v1.pdf","comment":"Accepted by CVPR 2023. Codes are at https://github.com/microsoft/DCVC"},{"id":"http://arxiv.org/abs/2303.00520v1","updated":"2023-02-28T05:43:25Z","published":"2023-02-28T05:43:25Z","title":"Valid Information Guidance Network for Compressed Video Quality\n  Enhancement","summary":"  In recent years deep learning methods have shown great superiority in\ncompressed video quality enhancement tasks. Existing methods generally take the\nraw video as the ground truth and extract practical information from\nconsecutive frames containing various artifacts. However, they do not fully\nexploit the valid information of compressed and raw videos to guide the quality\nenhancement for compressed videos. In this paper, we propose a unique Valid\nInformation Guidance scheme (VIG) to enhance the quality of compressed videos\nby mining valid information from both compressed videos and raw videos.\nSpecifically, we propose an efficient framework, Compressed Redundancy\nFiltering (CRF) network, to balance speed and enhancement. After removing the\nredundancy by filtering the information, CRF can use the valid information of\nthe compressed video to reconstruct the texture. Furthermore, we propose a\nprogressive Truth Guidance Distillation (TGD) strategy, which does not need to\ndesign additional teacher models and distillation loss functions. By only using\nthe ground truth as input to guide the model to aggregate the correct\nspatio-temporal correspondence across the raw frames, TGD can significantly\nimprove the enhancement effect without increasing the extra training cost.\nExtensive experiments show that our method achieves the state-of-the-art\nperformance of compressed video quality enhancement in terms of accuracy and\nefficiency.\n","authors":["Xuan Sun","Ziyue Zhang","Guannan Chen","Dan Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.00520v1.pdf","comment":null}]},"2023-03-01T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2210.12587v3","updated":"2023-03-01T18:56:01Z","published":"2022-10-23T01:33:16Z","title":"Model ensemble instead of prompt fusion: a sample-specific knowledge\n  transfer method for few-shot prompt tuning","summary":"  Prompt tuning approaches, which learn task-specific soft prompts for a\ndownstream task conditioning on frozen pre-trained models, have attracted\ngrowing interest due to its parameter efficiency. With large language models\nand sufficient training data, prompt tuning performs comparably to full-model\ntuning. However, with limited training samples in few-shot settings, prompt\ntuning fails to match the performance of full-model fine-tuning. In this work,\nwe focus on improving the few-shot performance of prompt tuning by transferring\nknowledge from soft prompts of source tasks. Recognizing the good\ngeneralization capabilities of ensemble methods in low-data regime, we first\nexperiment and show that a simple ensemble of model predictions based on\ndifferent source prompts, outperforms existing multi-prompt knowledge transfer\napproaches such as source prompt fusion in the few-shot setting. Motivated by\nthis observation, we further investigate model ensembles and propose\nSample-specific Ensemble of Source Models (SESoM). SESoM learns to adjust the\ncontribution of each source model for each target sample separately when\nensembling source model outputs. Through this way, SESoM inherits the superior\ngeneralization of model ensemble approaches and simultaneously captures the\nsample-specific competence of each source prompt. We conduct experiments across\na diverse set of eight NLP tasks using models of different scales (T5-{base,\nlarge, XL}) and find that SESoM consistently outperforms the existing models of\nthe same as well as larger parametric scale by a large margin.\n","authors":["Xiangyu Peng","Chen Xing","Prafulla Kumar Choubey","Chien-Sheng Wu","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2210.12587v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00733v1","updated":"2023-03-01T18:47:41Z","published":"2023-03-01T18:47:41Z","title":"SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks","summary":"  Prompt tuning is a technology that tunes a small set of parameters to steer a\npre-trained language model (LM) to directly generate the output for downstream\ntasks. Recently, prompt tuning has demonstrated its storage and computation\nefficiency in both natural language processing (NLP) and speech processing\nfields. These advantages have also revealed prompt tuning as a candidate\napproach to serving pre-trained LM for multiple tasks in a unified manner. For\nspeech processing, SpeechPrompt shows its high parameter efficiency and\ncompetitive performance on a few speech classification tasks. However, whether\nSpeechPrompt is capable of serving a large number of tasks is unanswered. In\nthis work, we propose SpeechPrompt v2, a prompt tuning framework capable of\nperforming a wide variety of speech classification tasks, covering multiple\nlanguages and prosody-related tasks. The experiment result shows that\nSpeechPrompt v2 achieves performance on par with prior works with less than\n0.15M trainable parameters in a unified framework.\n","authors":["Kai-Wei Chang","Yu-Kai Wang","Hua Shen","Iu-thing Kang","Wei-Cheng Tseng","Shang-Wen Li","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2303.00733v1.pdf","comment":"Project website: https://ga642381.github.io/SpeechPrompt"},{"id":"http://arxiv.org/abs/2303.00722v1","updated":"2023-03-01T18:26:47Z","published":"2023-03-01T18:26:47Z","title":"A Systematic Analysis of Vocabulary and BPE Settings for Optimal\n  Fine-tuning of NMT: A Case Study of In-domain Translation","summary":"  The effectiveness of Neural Machine Translation (NMT) models largely depends\non the vocabulary used at training; small vocabularies can lead to\nout-of-vocabulary problems -- large ones, to memory issues. Subword (SW)\ntokenization has been successfully employed to mitigate these issues. The\nchoice of vocabulary and SW tokenization has a significant impact on both\ntraining and fine-tuning an NMT model. Fine-tuning is a common practice in\noptimizing an MT model with respect to new data. However, new data potentially\nintroduces new words (or tokens), which, if not taken into consideration, may\nlead to suboptimal performance. In addition, the distribution of tokens in the\nnew data can differ from the distribution of the original data. As such, the\noriginal SW tokenization model could be less suitable for the new data. Through\na systematic empirical evaluation, in this work we compare different strategies\nfor SW tokenization and vocabulary generation with the ultimate goal to uncover\nan optimal setting for fine-tuning a domain-specific model. Furthermore, we\ndeveloped several (in-domain) models, the best of which achieves 6 BLEU points\nimprovement over the baseline.\n","authors":["J. Pourmostafa Roshan Sharami","D. Shterionov","P. Spronck"],"pdf_url":"https://arxiv.org/pdf/2303.00722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.04717v2","updated":"2023-03-01T17:59:06Z","published":"2022-11-09T07:23:15Z","title":"Improving Noisy Student Training on Non-target Domain Data for Automatic\n  Speech Recognition","summary":"  Noisy Student Training (NST) has recently demonstrated extremely strong\nperformance in Automatic Speech Recognition(ASR). In this paper, we propose a\ndata selection strategy named LM Filter to improve the performance of NST on\nnon-target domain data in ASR tasks. Hypotheses with and without a Language\nModel are generated and the CER differences between them are utilized as a\nfilter threshold. Results reveal that significant improvements of 10.4%\ncompared with no data filtering baselines. We can achieve 3.31% CER in\nAISHELL-1 test set, which is best result from our knowledge without any other\nsupervised data. We also perform evaluations on the supervised 1000 hour\nAISHELL-2 dataset and competitive results of 4.73% CER can be achieved.\n","authors":["Yu Chen","Wen Ding","Junjie Lai"],"pdf_url":"https://arxiv.org/pdf/2211.04717v2.pdf","comment":"This paper is accepted by the ICASSP 2023 conference"},{"id":"http://arxiv.org/abs/2302.12813v2","updated":"2023-03-01T17:21:48Z","published":"2023-02-24T18:48:43Z","title":"Check Your Facts and Try Again: Improving Large Language Models with\n  External Knowledge and Automated Feedback","summary":"  Large language models (LLMs), such as ChatGPT, are able to generate\nhuman-like, fluent responses for many downstream tasks, e.g., task-oriented\ndialog and question answering. However, applying LLMs to real-world,\nmission-critical applications remains challenging mainly due to their tendency\nto generate hallucinations and inability to use external knowledge.This paper\nproposes a LLM-Augmenter system, which augments a black-box LLM with a set of\nplug-and-play modules. Our system makes the LLM generate responses grounded in\nconsolidated external knowledge, e.g., stored in task-specific databases. It\nalso iteratively revises LLM prompts to improve model responses using feedback\ngenerated by utility functions, e.g., the factuality score of a LLM-generated\nresponse. The effectiveness of LLM-Augmenter is empirically validated on two\ntypes of mission-critical scenarios, task-oriented dialog and open-domain\nquestion answering. LLM-Augmenter significantly reduces ChatGPT's\nhallucinations without sacrificing the fluency and informativeness of its\nresponses. We make the source code and models publicly available.\n","authors":["Baolin Peng","Michel Galley","Pengcheng He","Hao Cheng","Yujia Xie","Yu Hu","Qiuyuan Huang","Lars Liden","Zhou Yu","Weizhu Chen","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2302.12813v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2303.00628v1","updated":"2023-03-01T16:31:01Z","published":"2023-03-01T16:31:01Z","title":"MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition\n  and Robust Speech-to-Text Translation","summary":"  We introduce MuAViC, a multilingual audio-visual corpus for robust speech\nrecognition and robust speech-to-text translation providing 1200 hours of\naudio-visual speech in 9 languages. It is fully transcribed and covers 6\nEnglish-to-X translation as well as 6 X-to-English translation directions. To\nthe best of our knowledge, this is the first open benchmark for audio-visual\nspeech-to-text translation and the largest open benchmark for multilingual\naudio-visual speech recognition. Our baseline results show that MuAViC is\neffective for building noise-robust speech recognition and translation models.\nWe make the corpus available at https://github.com/facebookresearch/muavic.\n","authors":["Mohamed Anwar","Bowen Shi","Vedanuj Goswami","Wei-Ning Hsu","Juan Pino","Changhan Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00595v1","updated":"2023-03-01T15:35:32Z","published":"2023-03-01T15:35:32Z","title":"A Universal Question-Answering Platform for Knowledge Graphs","summary":"  Knowledge from diverse application domains is organized as knowledge graphs\n(KGs) that are stored in RDF engines accessible in the web via SPARQL\nendpoints. Expressing a well-formed SPARQL query requires information about the\ngraph structure and the exact URIs of its components, which is impractical for\nthe average user. Question answering (QA) systems assist by translating natural\nlanguage questions to SPARQL. Existing QA systems are typically based on\napplication-specific human-curated rules, or require prior information,\nexpensive pre-processing and model adaptation for each targeted KG. Therefore,\nthey are hard to generalize to a broad set of applications and KGs.\n  In this paper, we propose KGQAn, a universal QA system that does not need to\nbe tailored to each target KG. Instead of curated rules, KGQAn introduces a\nnovel formalization of question understanding as a text generation problem to\nconvert a question into an intermediate abstract representation via a neural\nsequence-to-sequence model. We also develop a just-in-time linker that maps at\nquery time the abstract representation to a SPARQL query for a specific KG,\nusing only the publicly accessible APIs and the existing indices of the RDF\nstore, without requiring any pre-processing. Our experiments with several real\nKGs demonstrate that KGQAn is easily deployed and outperforms by a large margin\nthe state-of-the-art in terms of quality of answers and processing time,\nespecially for arbitrary KGs, unseen during the training.\n","authors":["Reham Omar","Ishika Dhall","Panos Kalnis","Essam Mansour"],"pdf_url":"https://arxiv.org/pdf/2303.00595v1.pdf","comment":"The paper is accepted to SIGMOD 2023"},{"id":"http://arxiv.org/abs/2301.12711v2","updated":"2023-03-01T14:31:12Z","published":"2023-01-30T07:40:45Z","title":"UzbekTagger: The rule-based POS tagger for Uzbek language","summary":"  This research paper presents a part-of-speech (POS) annotated dataset and\ntagger tool for the low-resource Uzbek language. The dataset includes 12 tags,\nwhich were used to develop a rule-based POS-tagger tool. The corpus text used\nin the annotation process was made sure to be balanced over 20 different fields\nin order to ensure its representativeness. Uzbek being an agglutinative\nlanguage so the most of the words in an Uzbek sentence are formed by adding\nsuffixes. This nature of it makes the POS-tagging task difficult to find the\nstems of words and the right part-of-speech they belong to. The methodology\nproposed in this research is the stemming of the words with an affix/suffix\nstripping approach including database of the stem forms of the words in the\nUzbek language. The tagger tool was tested on the annotated dataset and showed\nhigh accuracy in identifying and tagging parts of speech in Uzbek text. This\nnewly presented dataset and tagger tool can be used for a variety of natural\nlanguage processing tasks such as language modeling, machine translation, and\ntext-to-speech synthesis. The presented dataset is the first of its kind to be\nmade publicly available for Uzbek, and the POS-tagger tool created can also be\nused as a pivot to use as a base for other closely-related Turkic languages.\n","authors":["Maksud Sharipov","Elmurod Kuriyozov","Ollabergan Yuldashev","Ogabek Sobirov"],"pdf_url":"https://arxiv.org/pdf/2301.12711v2.pdf","comment":"Preprint of the accepted paper to The 10th Language & Technology\n  Conference: Human Language Technologies as a Challenge for Computer Science\n  and Linguistics, April 21-23, 2023, Poznan, Poland"},{"id":"http://arxiv.org/abs/2303.00534v1","updated":"2023-03-01T14:21:19Z","published":"2023-03-01T14:21:19Z","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with\n  Multi-modal Pre-training","summary":"  Vision-and-language multi-modal pretraining and fine-tuning have shown great\nsuccess in visual question answering (VQA). Compared to general domain VQA, the\nperformance of biomedical VQA suffers from limited data. In this paper, we\npropose a retrieval-augmented pretrain-and-finetune paradigm named RAMM for\nbiomedical VQA to overcome the data limitation issue. Specifically, we collect\na new biomedical dataset named PMCPM which offers patient-based image-text\npairs containing diverse patient situations from PubMed. Then, we pretrain the\nbiomedical multi-modal model to learn visual and textual representation for\nimage-text pairs and align these representations with image-text contrastive\nobjective (ITC). Finally, we propose a retrieval-augmented method to better use\nthe limited data. We propose to retrieve similar image-text pairs based on ITC\nfrom pretraining datasets and introduce a novel retrieval-attention module to\nfuse the representation of the image and the question with the retrieved images\nand texts. Experiments demonstrate that our retrieval-augmented\npretrain-and-finetune paradigm obtains state-of-the-art performance on\nMed-VQA2019, Med-VQA2021, VQARAD, and SLAKE datasets. Further analysis shows\nthat the proposed RAMM and PMCPM can enhance biomedical VQA performance\ncompared with previous resources and methods. We will open-source our dataset,\ncodes, and pretrained model.\n","authors":["Zheng Yuan","Qiao Jin","Chuanqi Tan","Zhengyun Zhao","Hongyi Yuan","Fei Huang","Songfang Huang"],"pdf_url":"https://arxiv.org/pdf/2303.00534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00465v1","updated":"2023-03-01T12:46:00Z","published":"2023-03-01T12:46:00Z","title":"Uzbek text's correspondence with the educational potential of pupils: a\n  case study of the School corpus","summary":"  One of the major challenges of an educational system is choosing appropriate\ncontent considering pupils' age and intellectual potential. In this article the\nexperiment of primary school grades (from 1st to 4th grades) is considered for\nautomatically determining the correspondence of an educational materials\nrecommended for pupils by using the School corpus where it includes the dataset\nof 25 school textbooks confirmed by the Ministry of preschool and school\neducation of the Republic of Uzbekistan. In this case, TF-IDF scores of the\ntexts are determined, they are converted into a vector representation, and the\ngiven educational materials are compared with the corresponding class of the\nSchool corpus using the cosine similarity algorithm. Based on the results of\nthe calculation, it is determined whether the given educational material is\nappropriate or not appropriate for the pupils' educational potential.\n","authors":["Khabibulla Madatov","Sanatbek Matlatipov","Mersaid Aripov"],"pdf_url":"https://arxiv.org/pdf/2303.00465v1.pdf","comment":"Preprint of the paper accepted to The 10th Language & Technology\n  Conference: Human Language Technologies as a Challenge for Computer Science\n  and Linguistics. April 21-23, 2023, Poznan, Poland"},{"id":"http://arxiv.org/abs/2303.00461v1","updated":"2023-03-01T12:39:46Z","published":"2023-03-01T12:39:46Z","title":"Uzbek text summarization based on TF-IDF","summary":"  The volume of information is increasing at an incredible rate with the rapid\ndevelopment of the Internet and electronic information services. Due to time\nconstraints, we don't have the opportunity to read all this information. Even\nthe task of analyzing textual data related to one field requires a lot of work.\nThe text summarization task helps to solve these problems. This article\npresents an experiment on summarization task for Uzbek language, the\nmethodology was based on text abstracting based on TF-IDF algorithm. Using this\ndensity function, semantically important parts of the text are extracted. We\nsummarize the given text by applying the n-gram method to important parts of\nthe whole text. The authors used a specially handcrafted corpus called \"School\ncorpus\" to evaluate the performance of the proposed method. The results show\nthat the proposed approach is effective in extracting summaries from Uzbek\nlanguage text and can potentially be used in various applications such as\ninformation retrieval and natural language processing. Overall, this research\ncontributes to the growing body of work on text summarization in\nunder-resourced languages.\n","authors":["Khabibulla Madatov","Shukurla Bekchanov","Jernej Vičič"],"pdf_url":"https://arxiv.org/pdf/2303.00461v1.pdf","comment":"Preprint of the paper accepted to The 10th Language & Technology\n  Conference: Human Language Technologies as a Challenge for Computer Science\n  and Linguistics. April 21-23, 2023, Poznan, Poland"},{"id":"http://arxiv.org/abs/2303.00456v1","updated":"2023-03-01T12:32:34Z","published":"2023-03-01T12:32:34Z","title":"N-best T5: Robust ASR Error Correction using Multiple Input Hypotheses\n  and Constrained Decoding Space","summary":"  Error correction models form an important part of Automatic Speech\nRecognition (ASR) post-processing to improve the readability and quality of\ntranscriptions. Most prior works use the 1-best ASR hypothesis as input and\ntherefore can only perform correction by leveraging the context within one\nsentence. In this work, we propose a novel N-best T5 model for this task, which\nis fine-tuned from a T5 model and utilizes ASR N-best lists as model input. By\ntransferring knowledge from the pre-trained language model and obtaining richer\ninformation from the ASR decoding space, the proposed approach outperforms a\nstrong Conformer-Transducer baseline. Another issue with standard error\ncorrection is that the generation process is not well-guided. To address this a\nconstrained decoding process, either based on the N-best list or an ASR\nlattice, is used which allows additional information to be propagated.\n","authors":["Rao Ma","Mark J F Gales","Kate Knill","Mengjie Qian"],"pdf_url":"https://arxiv.org/pdf/2303.00456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11703v3","updated":"2023-03-01T11:58:21Z","published":"2022-11-21T18:24:34Z","title":"Towards continually learning new languages","summary":"  Multilingual speech recognition with neural networks is often implemented\nwith batch-learning, when all of the languages are available before training.\nAn ability to add new languages after the prior training sessions can be\neconomically beneficial, but the main challenge is catastrophic forgetting. In\nthis work, we combine the qualities of weight factorization and elastic weight\nconsolidation in order to counter catastrophic forgetting and facilitate\nlearning new languages quickly. Such combination allowed us to eliminate\ncatastrophic forgetting while still achieving performance for the new languages\ncomparable with having all languages at once, in experiments of learning from\nan initial 10 languages to achieve 26 languages without catastrophic forgetting\nand a reasonable performance compared to training all languages from scratch.\n","authors":["Ngoc-Quan Pham","Jan Niehues","Alexander Waibel"],"pdf_url":"https://arxiv.org/pdf/2211.11703v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.14045v2","updated":"2023-03-01T11:04:51Z","published":"2023-02-27T18:55:27Z","title":"Language Is Not All You Need: Aligning Perception with Language Models","summary":"  A big convergence of language, multimodal perception, action, and world\nmodeling is a key step toward artificial general intelligence. In this work, we\nintroduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive\ngeneral modalities, learn in context (i.e., few-shot), and follow instructions\n(i.e., zero-shot). Specifically, we train Kosmos-1 from scratch on web-scale\nmultimodal corpora, including arbitrarily interleaved text and images,\nimage-caption pairs, and text data. We evaluate various settings, including\nzero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range\nof tasks without any gradient updates or finetuning. Experimental results show\nthat Kosmos-1 achieves impressive performance on (i) language understanding,\ngeneration, and even OCR-free NLP (directly fed with document images), (ii)\nperception-language tasks, including multimodal dialogue, image captioning,\nvisual question answering, and (iii) vision tasks, such as image recognition\nwith descriptions (specifying classification via text instructions). We also\nshow that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge\nfrom language to multimodal, and from multimodal to language. In addition, we\nintroduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning\ncapability of MLLMs.\n","authors":["Shaohan Huang","Li Dong","Wenhui Wang","Yaru Hao","Saksham Singhal","Shuming Ma","Tengchao Lv","Lei Cui","Owais Khan Mohammed","Barun Patra","Qiang Liu","Kriti Aggarwal","Zewen Chi","Johan Bjorck","Vishrav Chaudhary","Subhojit Som","Xia Song","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2302.14045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00408v1","updated":"2023-03-01T10:57:21Z","published":"2023-03-01T10:57:21Z","title":"A Persian Benchmark for Joint Intent Detection and Slot Filling","summary":"  Natural Language Understanding (NLU) is important in today's technology as it\nenables machines to comprehend and process human language, leading to improved\nhuman-computer interactions and advancements in fields such as virtual\nassistants, chatbots, and language-based AI systems. This paper highlights the\nsignificance of advancing the field of NLU for low-resource languages. With\nintent detection and slot filling being crucial tasks in NLU, the widely used\ndatasets ATIS and SNIPS have been utilized in the past. However, these datasets\nonly cater to the English language and do not support other languages. In this\nwork, we aim to address this gap by creating a Persian benchmark for joint\nintent detection and slot filling based on the ATIS dataset. To evaluate the\neffectiveness of our benchmark, we employ state-of-the-art methods for intent\ndetection and slot filling.\n","authors":["Masoud Akbari","Amir Hossein Karimi","Tayyebeh Saeedi","Zeinab Saeidi","Kiana Ghezelbash","Fatemeh Shamsezat","Mohammad Akbari","Ali Mohades"],"pdf_url":"https://arxiv.org/pdf/2303.00408v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2203.00162v3","updated":"2023-03-01T10:01:16Z","published":"2022-02-19T09:56:38Z","title":"Do Transformers know symbolic rules, and would we know if they did?","summary":"  To improve the explainability of leading Transformer networks used in NLP, it\nis important to tease apart genuine symbolic rules from merely associative\ninput-output patterns. However, we identify several inconsistencies in how\n``symbolicity'' has been construed in recent NLP literature. To mitigate this\nproblem, we propose two criteria to be the most relevant, one pertaining to a\nsystem's internal architecture and the other to the dissociation between\nabstract rules and specific input identities. From this perspective, we\ncritically examine prior work on the symbolic capacities of Transformers, and\ndeem the results to be fundamentally inconclusive for reasons inherent in\nexperiment design. We further maintain that there is no simple fix to this\nproblem, since it arises -- to an extent -- in all end-to-end settings.\nNonetheless, we emphasize the need for more robust evaluation of whether\nnon-symbolic explanations exist for success in seemingly symbolic tasks. To\nfacilitate this, we experiment on four sequence modelling tasks on the T5\nTransformer in two experiment settings: zero-shot generalization, and\ngeneralization across class-specific vocabularies flipped between the training\nand test set. We observe that T5's generalization is markedly stronger in\nsequence-to-sequence tasks than in comparable classification tasks. Based on\nthis, we propose a thus far overlooked analysis, where the Transformer itself\ndoes not need to be symbolic to be part of a symbolic architecture as the\nprocessor, operating on the input and output as external memory components.\n","authors":["Tommi Gröndahl","Yujia Guo","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2203.00162v3.pdf","comment":"15 pages, 1 figure"},{"id":"http://arxiv.org/abs/2301.00591v3","updated":"2023-03-01T09:59:54Z","published":"2023-01-02T10:36:40Z","title":"Analysing Discrete Self Supervised Speech Representation for Spoken\n  Language Modeling","summary":"  This work profoundly analyzes discrete self-supervised speech representations\n(units) through the eyes of Generative Spoken Language Modeling (GSLM).\nFollowing the findings of such an analysis, we propose practical improvements\nto the discrete unit for the GSLM. First, we start comprehending these units by\nanalyzing them in three axes: interpretation, visualization, and resynthesis.\nOur analysis finds a high correlation between the speech units to phonemes and\nphoneme families, while their correlation with speaker or gender is weaker.\nAdditionally, we found redundancies in the extracted units and claim that one\nreason may be the units' context. Following this analysis, we propose a new,\nunsupervised metric to measure unit redundancies. Finally, we use this metric\nto develop new methods that improve the robustness of units' clustering and\nshow significant improvement considering zero-resource speech metrics such as\nABX. Code and analysis tools are available under the following link:\nhttps://github.com/slp-rl/SLM-Discrete-Representations\n","authors":["Amitay Sicherman","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2301.00591v3.pdf","comment":"Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00344v1","updated":"2023-03-01T09:11:07Z","published":"2023-03-01T09:11:07Z","title":"Inline Citation Classification using Peripheral Context and\n  Time-evolving Augmentation","summary":"  Citation plays a pivotal role in determining the associations among research\narticles. It portrays essential information in indicative, supportive, or\ncontrastive studies. The task of inline citation classification aids in\nextrapolating these relationships; However, existing studies are still immature\nand demand further scrutiny. Current datasets and methods used for inline\ncitation classification only use citation-marked sentences constraining the\nmodel to turn a blind eye to domain knowledge and neighboring contextual\nsentences. In this paper, we propose a new dataset, named 3Cext, which along\nwith the cited sentences, provides discourse information using the vicinal\nsentences to analyze the contrasting and entailing relationships as well as\ndomain information. We propose PeriCite, a Transformer-based deep neural\nnetwork that fuses peripheral sentences and domain knowledge. Our model\nachieves the state-of-the-art on the 3Cext dataset by +0.09 F1 against the best\nbaseline. We conduct extensive ablations to analyze the efficacy of the\nproposed dataset and model fusion methods.\n","authors":["Priyanshi Gupta","Yash Kumar Atri","Apurva Nagvenkar","Sourish Dasgupta","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2303.00344v1.pdf","comment":"accepted to PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.00333v1","updated":"2023-03-01T08:53:36Z","published":"2023-03-01T08:53:36Z","title":"Competence-Based Analysis of Language Models","summary":"  Despite the recent success of large pretrained language models (LMs) on a\nvariety of prompting tasks, these models can be alarmingly brittle to small\nchanges in inputs or application contexts. To better understand such behavior\nand motivate the design of more robust LMs, we propose a general experimental\nframework, CALM (Competence-based Analysis of Language Models), where targeted\ncausal interventions are utilized to damage an LM's internal representation of\nvarious linguistic properties in order to evaluate its use of each\nrepresentation in performing a given task. We implement these interventions as\ngradient-based adversarial attacks, which (in contrast to prior causal probing\nmethodologies) are able to target arbitrarily-encoded representations of\nrelational properties, and carry out a case study of this approach to analyze\nhow BERT-like LMs use representations of several relational properties in\nperforming associated relation prompting tasks. We find that, while the\nrepresentations LMs leverage in performing each task are highly entangled, they\nmay be meaningfully interpreted in terms of the tasks where they are most\nutilized; and more broadly, that CALM enables an expanded scope of inquiry in\nLM analysis that may be useful in predicting and explaining weaknesses of\nexisting LMs.\n","authors":["Adam Davies","Jize Jiang","ChengXiang Zhai"],"pdf_url":"https://arxiv.org/pdf/2303.00333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12840v2","updated":"2023-03-01T08:43:13Z","published":"2023-02-24T18:17:38Z","title":"HULAT at SemEval-2023 Task 10: Data augmentation for pre-trained\n  transformers applied to the detection of sexism in social media","summary":"  This paper describes our participation in SemEval-2023 Task 10, whose goal is\nthe detection of sexism in social media. We explore some of the most popular\ntransformer models such as BERT, DistilBERT, RoBERTa, and XLNet. We also study\ndifferent data augmentation techniques to increase the training dataset. During\nthe development phase, our best results were obtained by using RoBERTa and data\naugmentation for tasks B and C. However, the use of synthetic data does not\nimprove the results for task C. We participated in the three subtasks. Our\napproach still has much room for improvement, especially in the two\nfine-grained classifications. All our code is available in the repository\nhttps://github.com/isegura/hulat_edos.\n","authors":["Isabel Segura-Bedmar"],"pdf_url":"https://arxiv.org/pdf/2302.12840v2.pdf","comment":"The experiments are not reproducible because I did not use a seed for\n  replicability"},{"id":"http://arxiv.org/abs/2303.00311v1","updated":"2023-03-01T08:15:48Z","published":"2023-03-01T08:15:48Z","title":"Modeling Multiple User Interests using Hierarchical Knowledge for\n  Conversational Recommender System","summary":"  A conversational recommender system (CRS) is a practical application for item\nrecommendation through natural language conversation. Such a system estimates\nuser interests for appropriate personalized recommendations. Users sometimes\nhave various interests in different categories or genres, but existing studies\nassume a unique user interest that can be covered by closely related items. In\nthis work, we propose to model such multiple user interests in CRS. We\ninvestigated its effects in experiments using the ReDial dataset and found that\nthe proposed method can recommend a wider variety of items than that of the\nbaseline CR-Walker.\n","authors":["Yuka Okuda","Katsuhito Sudoh","Seitaro Shinagawa","Satoshi Nakamura"],"pdf_url":"https://arxiv.org/pdf/2303.00311v1.pdf","comment":"Accepted as a conference paper at IWSDS 2023"},{"id":"http://arxiv.org/abs/2212.00959v2","updated":"2023-03-01T07:48:46Z","published":"2022-12-02T04:08:09Z","title":"UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question\n  Answering Over Knowledge Graph","summary":"  Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the\nanswer entities that are multiple hops away from the topic entities mentioned\nin a natural language question on a large-scale Knowledge Graph (KG). To cope\nwith the vast search space, existing work usually adopts a two-stage approach:\nit first retrieves a relatively small subgraph related to the question and then\nperforms the reasoning on the subgraph to find the answer entities accurately.\nAlthough these two stages are highly related, previous work employs very\ndifferent technical solutions for developing the retrieval and reasoning\nmodels, neglecting their relatedness in task essence. In this paper, we propose\nUniKGQA, a novel approach for multi-hop KGQA task, by unifying retrieval and\nreasoning in both model architecture and parameter learning. For model\narchitecture, UniKGQA consists of a semantic matching module based on a\npre-trained language model~(PLM) for question-relation semantic matching, and a\nmatching information propagation module to propagate the matching information\nalong the directed edges on KGs. For parameter learning, we design a shared\npre-training task based on question-relation matching for both retrieval and\nreasoning models, and then propose retrieval- and reasoning-oriented\nfine-tuning strategies. Compared with previous studies, our approach is more\nunified, tightly relating the retrieval and reasoning stages. Extensive\nexperiments on three benchmark datasets have demonstrated the effectiveness of\nour method on the multi-hop KGQA task. Our codes and data are publicly\navailable at~\\url{https://github.com/RUCAIBox/UniKGQA}.\n","authors":["Jinhao Jiang","Kun Zhou","Wayne Xin Zhao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2212.00959v2.pdf","comment":"Camera-ready of ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00293v1","updated":"2023-03-01T07:39:01Z","published":"2023-03-01T07:39:01Z","title":"How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language\n  Understanding Tasks","summary":"  The GPT-3.5 models have demonstrated impressive performance in various\nNatural Language Processing (NLP) tasks, showcasing their strong understanding\nand reasoning capabilities. However, their robustness and abilities to handle\nvarious complexities of the open world have yet to be explored, which is\nespecially crucial in assessing the stability of models and is a key aspect of\ntrustworthy AI. In this study, we perform a comprehensive experimental analysis\nof GPT-3.5, exploring its robustness using 21 datasets (about 116K test\nsamples) with 66 text transformations from TextFlint that cover 9 popular\nNatural Language Understanding (NLU) tasks. Our findings indicate that while\nGPT-3.5 outperforms existing fine-tuned models on some tasks, it still\nencounters significant robustness degradation, such as its average performance\ndropping by up to 35.74\\% and 43.59\\% in natural language inference and\nsentiment analysis tasks, respectively. We also show that GPT-3.5 faces some\nspecific robustness challenges, including robustness instability, prompt\nsensitivity, and number sensitivity. These insights are valuable for\nunderstanding its limitations and guiding future research in addressing these\nchallenges to enhance GPT-3.5's overall performance and generalization\nabilities.\n","authors":["Xuanting Chen","Junjie Ye","Can Zu","Nuo Xu","Rui Zheng","Minlong Peng","Jie Zhou","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2303.00293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00279v1","updated":"2023-03-01T07:01:29Z","published":"2023-03-01T07:01:29Z","title":"Coarse-to-Fine Covid-19 Segmentation via Vision-Language Alignment","summary":"  Segmentation of COVID-19 lesions can assist physicians in better diagnosis\nand treatment of COVID-19. However, there are few relevant studies due to the\nlack of detailed information and high-quality annotation in the COVID-19\ndataset. To solve the above problem, we propose C2FVL, a Coarse-to-Fine\nsegmentation framework via Vision-Language alignment to merge text information\ncontaining the number of lesions and specific locations of image information.\nThe introduction of text information allows the network to achieve better\nprediction results on challenging datasets. We conduct extensive experiments on\ntwo COVID-19 datasets including chest X-ray and CT, and the results demonstrate\nthat our proposed method outperforms other state-of-the-art segmentation\nmethods.\n","authors":["Dandan Shan","Zihan Li","Wentao Chen","Qingde Li","Jie Tian","Qingqi Hong"],"pdf_url":"https://arxiv.org/pdf/2303.00279v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00257v1","updated":"2023-03-01T06:28:33Z","published":"2023-03-01T06:28:33Z","title":"Hidden Markov Transformer for Simultaneous Machine Translation","summary":"  Simultaneous machine translation (SiMT) outputs the target sequence while\nreceiving the source sequence, and hence learning when to start translating\neach target token is the core challenge for SiMT task. However, it is\nnon-trivial to learn the optimal moment among many possible moments of starting\ntranslating, as the moments of starting translating always hide inside the\nmodel and can only be supervised with the observed target sequence. In this\npaper, we propose a Hidden Markov Transformer (HMT), which treats the moments\nof starting translating as hidden events and the target sequence as the\ncorresponding observed events, thereby organizing them as a hidden Markov\nmodel. HMT explicitly models multiple moments of starting translating as the\ncandidate hidden events, and then selects one to generate the target token.\nDuring training, by maximizing the marginal likelihood of the target sequence\nover multiple moments of starting translating, HMT learns to start translating\nat the moments that target tokens can be generated more accurately. Experiments\non multiple SiMT benchmarks show that HMT outperforms strong baselines and\nachieves state-of-the-art performance.\n","authors":["Shaolei Zhang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2303.00257v1.pdf","comment":"Accepted to ICLR 2023 Spotlight"},{"id":"http://arxiv.org/abs/2303.00242v1","updated":"2023-03-01T05:45:48Z","published":"2023-03-01T05:45:48Z","title":"DIFFQG: Generating Questions to Summarize Factual Changes","summary":"  Identifying the difference between two versions of the same article is useful\nto update knowledge bases and to understand how articles evolve. Paired texts\noccur naturally in diverse situations: reporters write similar news stories and\nmaintainers of authoritative websites must keep their information up to date.\nWe propose representing factual changes between paired documents as\nquestion-answer pairs, where the answer to the same question differs between\ntwo versions. We find that question-answer pairs can flexibly and concisely\ncapture the updated contents. Provided with paired documents, annotators\nidentify questions that are answered by one passage but answered differently or\ncannot be answered by the other. We release DIFFQG which consists of 759 QA\npairs and 1153 examples of paired passages with no factual change. These\nquestions are intended to be both unambiguous and information-seeking and\ninvolve complex edits, pushing beyond the capabilities of current question\ngeneration and factual change detection systems. Our dataset summarizes the\nchanges between two versions of the document as questions and answers, studying\nautomatic update summarization in a novel way.\n","authors":["Jeremy R. Cole","Palak Jain","Julian Martin Eisenschlos","Michael J. Q. Zhang","Eunsol Choi","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2303.00242v1.pdf","comment":"14 pages. Accepted at EACL 2023 (main, long)"},{"id":"http://arxiv.org/abs/2302.10186v3","updated":"2023-03-01T04:42:53Z","published":"2023-02-16T21:45:35Z","title":"E2E Spoken Entity Extraction for Virtual Agents","summary":"  This paper reimagines some aspects of speech processing using speech\nencoders, specifically about extracting entities directly from speech, with no\nintermediate textual representation. In human-computer conversations,\nextracting entities such as names, postal addresses and email addresses from\nspeech is a challenging task. In this paper, we study the impact of fine-tuning\npre-trained speech encoders on extracting spoken entities in human-readable\nform directly from speech without the need for text transcription. We\nillustrate that such a direct approach optimizes the encoder to transcribe only\nthe entity relevant portions of speech, ignoring the superfluous portions such\nas carrier phrases and spellings of entities. In the context of dialogs from an\nenterprise virtual agent, we demonstrate that the 1-step approach outperforms\nthe typical 2-step cascade of first generating lexical transcriptions followed\nby text-based entity extraction for identifying spoken entities.\n","authors":["Karan Singla","Yeon-Jun Kim","Ryan Price","Shahab Jalalvand","Srinivas Bangalore"],"pdf_url":"https://arxiv.org/pdf/2302.10186v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02875v2","updated":"2023-03-01T03:21:40Z","published":"2022-10-06T12:55:17Z","title":"Binding Language Models in Symbolic Languages","summary":"  Though end-to-end neural approaches have recently been dominating NLP tasks\nin both performance and ease-of-use, they lack interpretability and robustness.\nWe propose Binder, a training-free neural-symbolic framework that maps the task\ninput to a program, which (1) allows binding a unified API of language model\n(LM) functionalities to a programming language (e.g., SQL, Python) to extend\nits grammar coverage and thus tackle more diverse questions, (2) adopts an LM\nas both the program parser and the underlying model called by the API during\nexecution, and (3) requires only a few in-context exemplar annotations.\nSpecifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only\na few in-context exemplars, Codex is able to identify the part of the task\ninput that cannot be answerable by the original programming language, correctly\ngenerate API calls to prompt Codex to solve the unanswerable part, and identify\nwhere to place the API calls while being compatible with the original grammar.\nIn the execution stage, Codex can perform versatile functionalities (e.g.,\ncommonsense QA, information extraction) given proper prompts in the API calls.\nBinder achieves state-of-the-art results on WikiTableQuestions and TabFact\ndatasets, with explicit output programs that benefit human debugging. Note that\nprevious best systems are all finetuned on tens of thousands of task-specific\nsamples, while Binder only uses dozens of annotations as in-context exemplars\nwithout any training. Our code is available at https://github.com/HKUNLP/Binder .\n","authors":["Zhoujun Cheng","Tianbao Xie","Peng Shi","Chengzu Li","Rahul Nadkarni","Yushi Hu","Caiming Xiong","Dragomir Radev","Mari Ostendorf","Luke Zettlemoyer","Noah A. Smith","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2210.02875v2.pdf","comment":"ICLR 2023 camera ready, 27 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.10898v2","updated":"2023-03-01T03:20:08Z","published":"2022-12-21T10:15:19Z","title":"Training language models to summarize narratives improves brain\n  alignment","summary":"  Building systems that achieve a deeper understanding of language is one of\nthe central goals of natural language processing (NLP). Towards this goal,\nrecent works have begun to train language models on narrative datasets which\nrequire extracting the most critical information by integrating across long\ncontexts. However, it is still an open question whether these models are\nlearning a deeper understanding of the text, or if the models are simply\nlearning a heuristic to complete the task. This work investigates this further\nby turning to the one language processing system that truly understands complex\nlanguage: the human brain. We show that training language models for deeper\nnarrative understanding results in richer representations that have improved\nalignment to human brain activity. We further find that the improvements in\nbrain alignment are larger for character names than for other discourse\nfeatures, which indicates that these models are learning important narrative\nelements. Taken together, these results suggest that this type of training can\nindeed lead to deeper language understanding. These findings have consequences\nboth for cognitive neuroscience by revealing some of the significant factors\nbehind brain-NLP alignment, and for NLP by highlighting that understanding of\nlong-range context can be improved beyond language modeling.\n","authors":["Khai Loong Aw","Mariya Toneva"],"pdf_url":"https://arxiv.org/pdf/2212.10898v2.pdf","comment":"ICLR 2023 (notable top 25%)"},{"id":"http://arxiv.org/abs/2210.00312v4","updated":"2023-03-01T02:51:12Z","published":"2022-10-01T16:24:15Z","title":"Multimodal Analogical Reasoning over Knowledge Graphs","summary":"  Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.\n","authors":["Ningyu Zhang","Lei Li","Xiang Chen","Xiaozhuan Liang","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00312v4.pdf","comment":"Accepted by ICLR 2023. The project website is\n  https://zjunlp.github.io/project/MKG_Analogy/introduction.html"},{"id":"http://arxiv.org/abs/2210.01241v3","updated":"2023-03-01T01:31:17Z","published":"2022-10-03T21:38:29Z","title":"Is Reinforcement Learning (Not) for Natural Language Processing:\n  Benchmarks, Baselines, and Building Blocks for Natural Language Policy\n  Optimization","summary":"  We tackle the problem of aligning pre-trained large language models (LMs)\nwith human preferences. If we view text generation as a sequential\ndecision-making problem, reinforcement learning (RL) appears to be a natural\nconceptual framework. However, using RL for LM-based generation faces empirical\nchallenges, including training instability due to the combinatorial action\nspace, as well as a lack of open-source libraries and benchmarks customized for\nLM alignment. Thus, a question rises in the research community: is RL a\npractical paradigm for NLP?\n  To help answer this, we first introduce an open-source modular library,\nRL4LMs (Reinforcement Learning for Language Models), for optimizing language\ngenerators with RL. The library consists of on-policy RL algorithms that can be\nused to train any encoder or encoder-decoder LM in the HuggingFace library\n(Wolf et al. 2020) with an arbitrary reward function. Next, we present the GRUE\n(General Reinforced-language Understanding Evaluation) benchmark, a set of 6\nlanguage generation tasks which are supervised not by target strings, but by\nreward functions which capture automated measures of human preference.GRUE is\nthe first leaderboard-style evaluation of RL algorithms for NLP tasks. Finally,\nwe introduce an easy-to-use, performant RL algorithm, NLPO (Natural Language\nPolicy Optimization)} that learns to effectively reduce the combinatorial\naction space in language generation. We show 1) that RL techniques are\ngenerally better than supervised methods at aligning LMs to human preferences;\nand 2) that NLPO exhibits greater stability and performance than previous\npolicy gradient methods (e.g., PPO (Schulman et al. 2017)), based on both\nautomatic and human evaluations.\n","authors":["Rajkumar Ramamurthy","Prithviraj Ammanabrolu","Kianté Brantley","Jack Hessel","Rafet Sifa","Christian Bauckhage","Hannaneh Hajishirzi","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2210.01241v3.pdf","comment":"In Proceedings of ICLR 2023. Code found at\n  https://github.com/allenai/rl4lms and Project website at\n  https://rl4lms.apps.allenai.org/"},{"id":"http://arxiv.org/abs/2208.04202v2","updated":"2023-03-01T00:18:33Z","published":"2022-08-08T15:08:40Z","title":"Analog Bits: Generating Discrete Data using Diffusion Models with\n  Self-Conditioning","summary":"  We present Bit Diffusion: a simple and generic approach for generating\ndiscrete data with continuous state and continuous time diffusion models. The\nmain idea behind our approach is to first represent the discrete data as binary\nbits, and then train a continuous diffusion model to model these bits as real\nnumbers which we call analog bits. To generate samples, the model first\ngenerates the analog bits, which are then thresholded to obtain the bits that\nrepresent the discrete variables. We further propose two simple techniques,\nnamely Self-Conditioning and Asymmetric Time Intervals, which lead to a\nsignificant improvement in sample quality. Despite its simplicity, the proposed\napproach can achieve strong performance in both discrete image generation and\nimage captioning tasks. For discrete image generation, we significantly improve\nprevious state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens)\nand ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the\nbest autoregressive model in both sample quality (measured by FID) and\nefficiency. For image captioning on MS-COCO dataset, our approach achieves\ncompetitive results compared to autoregressive models.\n","authors":["Ting Chen","Ruixiang Zhang","Geoffrey Hinton"],"pdf_url":"https://arxiv.org/pdf/2208.04202v2.pdf","comment":"ICLR'23"},{"id":"http://arxiv.org/abs/2303.00855v1","updated":"2023-03-01T22:58:50Z","published":"2023-03-01T22:58:50Z","title":"Grounded Decoding: Guiding Text Generation with Grounded Models for\n  Robot Control","summary":"  Recent progress in large language models (LLMs) has demonstrated the ability\nto learn and leverage Internet-scale knowledge through pre-training with\nautoregressive models. Unfortunately, applying such models to settings with\nembodied agents, such as robots, is challenging due to their lack of experience\nwith the physical world, inability to parse non-language observations, and\nignorance of rewards or safety constraints that robots may require. On the\nother hand, language-conditioned robotic policies that learn from interaction\ndata can provide the necessary grounding that allows the agent to be correctly\nsituated in the real world, but such policies are limited by the lack of\nhigh-level semantic understanding due to the limited breadth of the interaction\ndata available for training them. Thus, if we want to make use of the semantic\nknowledge in a language model while still situating it in an embodied setting,\nwe must construct an action sequence that is both likely according to the\nlanguage model and also realizable according to grounded models of the\nenvironment. We frame this as a problem similar to probabilistic filtering:\ndecode a sequence that both has high probability under the language model and\nhigh probability under a set of grounded model objectives. We demonstrate this\nguided decoding strategy is able to solve complex, long-horizon embodiment\ntasks in a robotic setting by leveraging the knowledge of both models. The\nproject's website can be found at grounded-decoding.github.io.\n","authors":["Wenlong Huang","Fei Xia","Dhruv Shah","Danny Driess","Andy Zeng","Yao Lu","Pete Florence","Igor Mordatch","Sergey Levine","Karol Hausman","Brian Ichter"],"pdf_url":"https://arxiv.org/pdf/2303.00855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00815v1","updated":"2023-03-01T20:33:37Z","published":"2023-03-01T20:33:37Z","title":"Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis","summary":"  Aspect term extraction is a fundamental task in fine-grained sentiment\nanalysis, which aims at detecting customer's opinion targets from reviews on\nproduct or service. The traditional supervised models can achieve promising\nresults with annotated datasets, however, the performance dramatically\ndecreases when they are applied to the task of cross-domain aspect term\nextraction. Existing cross-domain transfer learning methods either directly\ninject linguistic features into Language models, making it difficult to\ntransfer linguistic knowledge to target domain, or rely on the fixed predefined\nprompts, which is time-consuming to construct the prompts over all potential\naspect term spans. To resolve the limitations, we propose a soft prompt-based\njoint learning method for cross domain aspect term extraction in this paper.\nSpecifically, by incorporating external linguistic features, the proposed\nmethod learn domain-invariant representations between source and target domains\nvia multiple objectives, which bridges the gap between domains with varied\ndistributions of aspect terms. Further, the proposed method interpolates a set\nof transferable soft prompts consisted of multiple learnable vectors that are\nbeneficial to detect aspect terms in target domain. Extensive experiments are\nconducted on the benchmark datasets and the experimental results demonstrate\nthe effectiveness of the proposed method for cross-domain aspect terms\nextraction.\n","authors":["Jingli Shi","Weihua Li","Quan Bai","Yi Yang","Jianhua Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.00815v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2302.12126v2","updated":"2023-03-01T20:32:01Z","published":"2023-02-23T16:09:42Z","title":"KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate\n  Political Stance Prediction","summary":"  The political stance prediction for news articles has been widely studied to\nmitigate the echo chamber effect -- people fall into their thoughts and\nreinforce their pre-existing beliefs. The previous works for the political\nstance problem focus on (1) identifying political factors that could reflect\nthe political stance of a news article and (2) capturing those factors\neffectively. Despite their empirical successes, they are not sufficiently\njustified in terms of how effective their identified factors are in the\npolitical stance prediction. Motivated by this, in this work, we conduct a user\nstudy to investigate important factors in political stance prediction, and\nobserve that the context and tone of a news article (implicit) and external\nknowledge for real-world entities appearing in the article (explicit) are\nimportant in determining its political stance. Based on this observation, we\npropose a novel knowledge-aware approach to political stance prediction (KHAN),\nemploying (1) hierarchical attention networks (HAN) to learn the relationships\namong words and sentences in three different levels and (2) knowledge encoding\n(KE) to incorporate external knowledge for real-world entities into the process\nof political stance prediction. Also, to take into account the subtle and\nimportant difference between opposite political stances, we build two\nindependent political knowledge graphs (KG) (i.e., KG-lib and KG-con) by\nourselves and learn to fuse the different political knowledge. Through\nextensive evaluations on three real-world datasets, we demonstrate the\nsuperiority of DASH in terms of (1) accuracy, (2) efficiency, and (3)\neffectiveness.\n","authors":["Yunyong Ko","Seongeun Ryu","Soeun Han","Yeongseung Jeon","Jaehoon Kim","Sohyun Park","Kyungsik Han","Hanghang Tong","Sang-Wook Kim"],"pdf_url":"https://arxiv.org/pdf/2302.12126v2.pdf","comment":"12 pages, 5 figures, 10 tables, the Web Conference 2023 (WWW)"},{"id":"http://arxiv.org/abs/2303.00807v1","updated":"2023-03-01T20:21:23Z","published":"2023-03-01T20:21:23Z","title":"UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and\n  Distillation of Rerankers","summary":"  Many information retrieval tasks require large labeled datasets for\nfine-tuning. However, such datasets are often unavailable, and their utility\nfor real-world applications can diminish quickly due to domain shifts. To\naddress this challenge, we develop and motivate a method for using large\nlanguage models (LLMs) to generate large numbers of synthetic queries cheaply.\nThe method begins by generating a small number of synthetic queries using an\nexpensive LLM. After that, a much less expensive one is used to create large\nnumbers of synthetic queries, which are used to fine-tune a family of reranker\nmodels. These rerankers are then distilled into a single efficient retriever\nfor use in the target domain. We show that this technique boosts zero-shot\naccuracy in long-tail domains, even where only 2K synthetic queries are used\nfor fine-tuning, and that it achieves substantially lower latency than standard\nreranking methods. We make our end-to-end approach, including our synthetic\ndatasets and replication code, publicly available on Github.\n","authors":["Jon Saad-Falcon","Omar Khattab","Keshav Santhanam","Radu Florian","Martin Franz","Salim Roukos","Avirup Sil","Md Arafat Sultan","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2303.00807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12112v2","updated":"2023-03-01T20:18:25Z","published":"2023-01-28T07:05:15Z","title":"On Pre-trained Language Models for Antibody","summary":"  Antibodies are vital proteins offering robust protection for the human body\nfrom pathogens. The development of general protein and antibody-specific\npre-trained language models both facilitate antibody prediction tasks. However,\nthere have been limited studies that comprehensively explore the representation\ncapability of distinct pre-trained language models on different antibody tasks.\nTo investigate the problem, we aim to answer several key questions in this\npaper, such as how pre-trained language models perform in antibody tasks with\ndifferent specificity and how introducing specific biological mechanisms to the\npre-training process can benefit the model. Additionally, we evaluate if the\nlearned antibody pre-trained representations can be applied to real-world\nantibody problems, like drug discovery and immune process understanding.\nPreviously, no benchmark available largely hindered the study to answer these\nquestions. To aid in our investigation, we provide an AnTibody Understanding\nEvaluation (ATUE) benchmark. We comprehensively evaluate the performance of\nprotein pre-trained language models by empirical study along with conclusions\nand new insights. Our ATUE and code are released at\nhttps://github.com/dqwang122/EATLM.\n","authors":["Danqing Wang","Fei Ye","Hao Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.12112v2.pdf","comment":"Accepted in ICLR 2023"},{"id":"http://arxiv.org/abs/2109.11034v3","updated":"2023-03-01T20:15:51Z","published":"2021-09-22T20:49:16Z","title":"Conditional Poisson Stochastic Beam Search","summary":"  Beam search is the default decoding strategy for many sequence generation\ntasks in NLP. The set of approximate K-best items returned by the algorithm is\na useful summary of the distribution for many applications; however, the\ncandidates typically exhibit high overlap and may give a highly biased estimate\nfor expectations under our model. These problems can be addressed by instead\nusing stochastic decoding strategies. In this work, we propose a new method for\nturning beam search into a stochastic process: Conditional Poisson stochastic\nbeam search. Rather than taking the maximizing set at each iteration, we sample\nK candidates without replacement according to the conditional Poisson sampling\ndesign. We view this as a more natural alternative to Kool et. al. 2019's\nstochastic beam search (SBS). Furthermore, we show how samples generated under\nthe CPSBS design can be used to build consistent estimators and sample diverse\nsets from sequence models. In our experiments, we observe CPSBS produces lower\nvariance and more efficient estimators than SBS, even showing improvements in\nhigh entropy settings.\n","authors":["Clara Meister","Afra Amini","Tim Vieira","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2109.11034v3.pdf","comment":"Proceedings of EMNLP 2021"},{"id":"http://arxiv.org/abs/2303.00802v1","updated":"2023-03-01T20:05:19Z","published":"2023-03-01T20:05:19Z","title":"Synthetic Cross-accent Data Augmentation for Automatic Speech\n  Recognition","summary":"  The awareness for biased ASR datasets or models has increased notably in\nrecent years. Even for English, despite a vast amount of available training\ndata, systems perform worse for non-native speakers. In this work, we improve\nan accent-conversion model (ACM) which transforms native US-English speech into\naccented pronunciation. We include phonetic knowledge in the ACM training to\nprovide accurate feedback about how well certain pronunciation patterns were\nrecovered in the synthesized waveform. Furthermore, we investigate the\nfeasibility of learned accent representations instead of static embeddings.\nGenerated data was then used to train two state-of-the-art ASR systems. We\nevaluated our approach on native and non-native English datasets and found that\nsynthetically accented data helped the ASR to better understand speech from\nseen accents. This observation did not translate to unseen accents, and it was\nnot observed for a model that had been pre-trained exclusively with native\nspeech.\n","authors":["Philipp Klumpp","Pooja Chitkara","Leda Sarı","Prashant Serai","Jilong Wu","Irina-Elena Veliche","Rongqing Huang","Qing He"],"pdf_url":"https://arxiv.org/pdf/2303.00802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.03787v4","updated":"2023-03-01T19:47:33Z","published":"2022-09-08T12:59:14Z","title":"Goodness of Pronunciation Pipelines for OOV Problem","summary":"  In the following report we propose pipelines for Goodness of Pronunciation\n(GoP) computation solving OOV problem at testing time using Vocab/Lexicon\nexpansion techniques. The pipeline uses different components of ASR system to\nquantify accent and automatically evaluate them as scores. We use the\nposteriors of an ASR model trained on native English speech, along with the\nphone level boundaries to obtain phone level pronunciation scores. We used this\nas a baseline pipeline and implemented methods to remove UNK and SPN phonemes\nin the GoP output by building three pipelines. The Online, Offline and Hybrid\npipeline which returns the scores but also can prevent unknown words in the\nfinal output. The Online method is based per utterance, Offline method\npre-incorporates a set of OOV words for a given data set and the Hybrid method\ncombines the above two ideas to expand the lexicon as well work per utterance.\nWe further provide utilities such as the Phoneme to posterior mappings, GoP\nscores of each utterance as a vector, and Word boundaries used in the GoP\npipeline for use in future research.\n","authors":["Ankit Grover"],"pdf_url":"https://arxiv.org/pdf/2209.03787v4.pdf","comment":"47 pages, 24 Figures, 1 Table"},{"id":"http://arxiv.org/abs/2108.00480v2","updated":"2023-03-01T19:47:21Z","published":"2021-08-01T15:43:57Z","title":"Realised Volatility Forecasting: Machine Learning via Financial Word\n  Embedding","summary":"  This study develops FinText, a financial word embedding compiled from 15\nyears of business news archives. The results show that FinText produces\nsubstantially more accurate results than general word embeddings based on the\ngold-standard financial benchmark we introduced. In contrast to well-known\neconometric models, and over the sample period from 27 July 2007 to 27 January\n2022 for 23 NASDAQ stocks, using stock-related news, our simple natural\nlanguage processing model supported by different word embeddings improves\nrealised volatility forecasts on high volatility days. This improvement in\nrealised volatility forecasting performance switches to normal volatility days\nwhen general hot news is used. By utilising SHAP, an Explainable AI method, we\nalso identify and classify key phrases in stock-related and general hot news\nthat moved volatility.\n","authors":["Eghbal Rahimikia","Stefan Zohren","Ser-Huang Poon"],"pdf_url":"https://arxiv.org/pdf/2108.00480v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00786v1","updated":"2023-03-01T19:20:01Z","published":"2023-03-01T19:20:01Z","title":"Building High-accuracy Multilingual ASR with Gated Language Experts and\n  Curriculum Training","summary":"  We propose gated language experts to improve multilingual transformer\ntransducer models without any language identification (LID) input from users\nduring inference. We define gating mechanism and LID loss to let transformer\nencoders learn language-dependent information, construct the multilingual\ntransformer block with gated transformer experts and shared transformer layers\nfor compact models, and apply linear experts on joint network output to better\nregularize speech acoustic and token label joint information. Furthermore, a\ncurriculum training scheme is proposed to let LID guide the gated language\nexperts for better serving their corresponding languages. Evaluated on the\nEnglish and Spanish bilingual task, our methods achieve average 12.5% and 7.3%\nrelative word error reductions over the baseline bilingual model and\nmonolingual models, respectively, obtaining similar results to the upper bound\nmodel trained and inferred with oracle LID. We further explore our method on\ntrilingual, quadrilingual, and pentalingual models, and observe similar\nadvantages as in the bilingual models, which demonstrates the easy extension to\nmore languages.\n","authors":["Eric Sun","Jinyu Li","Yuxuan Hu","Yimeng Zhu","Long Zhou","Jian Xue","Peidong Wang","Linquan Liu","Shujie Liu","Edward Lin","Yifan Gong"],"pdf_url":"https://arxiv.org/pdf/2303.00786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01261v1","updated":"2023-03-01T17:23:12Z","published":"2023-03-01T17:23:12Z","title":"ParrotTTS: Text-to-Speech synthesis by exploiting self-supervised\n  representations","summary":"  Text-to-speech (TTS) systems are modelled as mel-synthesizers followed by\nspeech-vocoders since the era of statistical TTS that is carried forward into\nneural designs. We propose an alternative approach to TTS modelling referred to\nas ParrotTTS borrowing from self-supervised learning (SSL) methods. ParrotTTS\ntakes a two-step approach by initially training a speech-to-speech model on\nunlabelled data that is abundantly available, followed by a text-to-embedding\nmodel that leverages speech with aligned transcriptions to extend it to TTS.\nParrotTTS achieves competitive mean opinion scores on naturalness compared to\ntraditional TTS models but significantly improves over the latter's data\nefficiency of transcribed pairs and speaker adaptation without transcriptions.\nThis further paves the path to training TTS models on generically trained SSL\nspeech models.\n","authors":["Saiteja Kosgi","Neil Kumar Shah","Vishal Tambrahalli","Neha Sherin","Vineet Gandhi"],"pdf_url":"https://arxiv.org/pdf/2303.01261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01258v1","updated":"2023-03-01T09:48:39Z","published":"2023-03-01T09:48:39Z","title":"Domain-adapted large language models for classifying nuclear medicine\n  reports","summary":"  With the growing use of transformer-based language models in medicine, it is\nunclear how well these models generalize to nuclear medicine which has\ndomain-specific vocabulary and unique reporting styles. In this study, we\nevaluated the value of domain adaptation in nuclear medicine by adapting\nlanguage models for the purpose of 5-point Deauville score prediction based on\nclinical 18F-fluorodeoxyglucose (FDG) PET/CT reports. We retrospectively\nretrieved 4542 text reports and 1664 images for FDG PET/CT lymphoma exams from\n2008-2018 in our clinical imaging database. Deauville scores were removed from\nthe reports and then the remaining text in the reports was used as the model\ninput. Multiple general-purpose transformer language models were used to\nclassify the reports into Deauville scores 1-5. We then adapted the models to\nthe nuclear medicine domain using masked language modeling and assessed its\nimpact on classification performance. The language models were compared against\nvision models, a multimodal vision language model, and a nuclear medicine\nphysician with seven-fold Monte Carlo cross validation, reported are the mean\nand standard deviations. Domain adaption improved all language models. For\nexample, BERT improved from 61.3% five-class accuracy to 65.7% following domain\nadaptation. The best performing model (domain-adapted RoBERTa) achieved a\nfive-class accuracy of 77.4%, which was better than the physician's performance\n(66%), the best vision model's performance (48.1), and was similar to the\nmultimodal model's performance (77.2). Domain adaptation improved the\nperformance of large language models in interpreting nuclear medicine text\nreports.\n","authors":["Zachary Huemann","Changhee Lee","Junjie Hu","Steve Y. Cho","Tyler Bradshaw"],"pdf_url":"https://arxiv.org/pdf/2303.01258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01248v1","updated":"2023-03-01T06:16:14Z","published":"2023-03-01T06:16:14Z","title":"Can ChatGPT Assess Human Personalities? A General Evaluation Framework","summary":"  Large Language Models (LLMs) especially ChatGPT have produced impressive\nresults in various areas, but their potential human-like psychology is still\nlargely unexplored. Existing works study the virtual personalities of LLMs but\nrarely explore the possibility of analyzing human personalities via LLMs. This\npaper presents a generic evaluation framework for LLMs to assess human\npersonalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically,\nwe first devise unbiased prompts by randomly permuting options in MBTI\nquestions and adopt the average testing result to encourage more impartial\nanswer generation. Then, we propose to replace the subject in question\nstatements to enable flexible queries and assessments on different subjects\nfrom LLMs. Finally, we re-formulate the question instructions in a manner of\ncorrectness evaluation to facilitate LLMs to generate clearer responses. The\nproposed framework enables LLMs to flexibly assess personalities of different\ngroups of people. We further propose three evaluation metrics to measure the\nconsistency, robustness, and fairness of assessment results from\nstate-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal\nChatGPT's ability to assess human personalities, and the average results\ndemonstrate that it can achieve more consistent and fairer assessments in spite\nof lower robustness against prompt biases compared with InstructGPT.\n","authors":["Haocong Rao","Cyril Leung","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2303.01248v1.pdf","comment":"Our codes are available at https://github.com/Kali-Hac/ChatGPT-MBTI"},{"id":"http://arxiv.org/abs/2303.01234v1","updated":"2023-03-01T06:04:25Z","published":"2023-03-01T06:04:25Z","title":"Frauds Bargain Attack: Generating Adversarial Text Samples via Word\n  Manipulation Process","summary":"  Recent studies on adversarial examples expose vulnerabilities of natural\nlanguage processing (NLP) models. Existing techniques for generating\nadversarial examples are typically driven by deterministic heuristic rules that\nare agnostic to the optimal adversarial examples, a strategy that often results\nin attack failures. To this end, this research proposes Fraud's Bargain Attack\n(FBA) which utilizes a novel randomization mechanism to enlarge the search\nspace and enables high-quality adversarial examples to be generated with high\nprobabilities. FBA applies the Metropolis-Hasting sampler, a member of Markov\nChain Monte Carlo samplers, to enhance the selection of adversarial examples\nfrom all candidates proposed by a customized stochastic process that we call\nthe Word Manipulation Process (WMP). WMP perturbs one word at a time via\ninsertion, removal or substitution in a contextual-aware manner. Extensive\nexperiments demonstrate that FBA outperforms the state-of-the-art methods in\nterms of both attack success rate and imperceptibility.\n","authors":["Mingze Ni","Zhensu Sun","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01234v1.pdf","comment":"21 pages, 9 tables, 3 figures"},{"id":"http://arxiv.org/abs/2303.01229v1","updated":"2023-03-01T02:30:11Z","published":"2023-03-01T02:30:11Z","title":"Almanac: Knowledge-Grounded Language Models for Clinical Medicine","summary":"  Large-language models have recently demonstrated impressive zero-shot\ncapabilities in a variety of natural language tasks such as summarization,\ndialogue generation, and question-answering. Despite many promising\napplications in clinical medicine (e.g. medical record documentation, treatment\nguideline-lookup), adoption of these models in real-world settings has been\nlargely limited by their tendency to generate factually incorrect and sometimes\neven toxic statements. In this paper we explore the ability of large-language\nmodels to facilitate and streamline medical guidelines and recommendation\nreferencing: by enabling these model to access external point-of-care tools in\nresponse to physician queries, we demonstrate significantly improved factual\ngrounding, helpfulness, and safety in a variety of clinical scenarios.\n","authors":["Cyril Zakka","Akash Chaurasia","Rohan Shad","William Hiesinger"],"pdf_url":"https://arxiv.org/pdf/2303.01229v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.00750v1","updated":"2023-03-01T18:59:33Z","published":"2023-03-01T18:59:33Z","title":"StraIT: Non-autoregressive Generation with Stratified Image Transformer","summary":"  We propose Stratified Image Transformer(StraIT), a pure\nnon-autoregressive(NAR) generative model that demonstrates superiority in\nhigh-quality image synthesis over existing autoregressive(AR) and diffusion\nmodels(DMs). In contrast to the under-exploitation of visual characteristics in\nexisting vision tokenizer, we leverage the hierarchical nature of images to\nencode visual tokens into stratified levels with emergent properties. Through\nthe proposed image stratification that obtains an interlinked token pair, we\nalleviate the modeling difficulty and lift the generative power of NAR models.\nOur experiments demonstrate that StraIT significantly improves NAR generation\nand out-performs existing DMs and AR methods while being order-of-magnitude\nfaster, achieving FID scores of 3.96 at 256*256 resolution on ImageNet without\nleveraging any guidance in sampling or auxiliary image classifiers. When\nequipped with classifier-free guidance, our method achieves an FID of 3.36 and\nIS of 259.3. In addition, we illustrate the decoupled modeling process of\nStraIT generation, showing its compelling properties on applications including\ndomain transfer.\n","authors":["Shengju Qian","Huiwen Chang","Yuanzhen Li","Zizhao Zhang","Jiaya Jia","Han Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00749v1","updated":"2023-03-01T18:59:30Z","published":"2023-03-01T18:59:30Z","title":"S-NeRF: Neural Radiance Fields for Street Views","summary":"  Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and\nscenes, given the object-centric camera views with large overlaps. However, we\nconjugate that this paradigm does not fit the nature of the street views that\nare collected by many self-driving cars from the large-scale unbounded scenes.\nAlso, the onboard cameras perceive scenes without much overlapping. Thus,\nexisting NeRFs often produce blurs, 'floaters' and other artifacts on\nstreet-view synthesis. In this paper, we propose a new street-view NeRF\n(S-NeRF) that considers novel view synthesis of both the large-scale background\nscenes and the foreground moving vehicles jointly. Specifically, we improve the\nscene parameterization function and the camera poses for learning better neural\nrepresentations from street views. We also use the the noisy and sparse LiDAR\npoints to boost the training and learn a robust geometry and reprojection based\nconfidence to address the depth outliers. Moreover, we extend our S-NeRF for\nreconstructing moving vehicles that is impracticable for conventional NeRFs.\nThorough experiments on the large-scale driving datasets (e.g., nuScenes and\nWaymo) demonstrate that our method beats the state-of-the-art rivals by\nreducing 7% to 40% of the mean-squared error in the street-view synthesis and a\n45% PSNR gain for the moving vehicles rendering.\n","authors":["Ziyang Xie","Junge Zhang","Wenye Li","Feihu Zhang","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00749v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00748v1","updated":"2023-03-01T18:59:29Z","published":"2023-03-01T18:59:29Z","title":"Efficient and Explicit Modelling of Image Hierarchies for Image\n  Restoration","summary":"  The aim of this paper is to propose a mechanism to efficiently and explicitly\nmodel image hierarchies in the global, regional, and local range for image\nrestoration. To achieve that, we start by analyzing two important properties of\nnatural images including cross-scale similarity and anisotropic image features.\nInspired by that, we propose the anchored stripe self-attention which achieves\na good balance between the space and time complexity of self-attention and the\nmodelling capacity beyond the regional range. Then we propose a new network\narchitecture dubbed GRL to explicitly model image hierarchies in the Global,\nRegional, and Local range via anchored stripe self-attention, window\nself-attention, and channel attention enhanced convolution. Finally, the\nproposed network is applied to 7 image restoration types, covering both real\nand synthetic settings. The proposed method sets the new state-of-the-art for\nseveral of those. Code will be available at\nhttps://github.com/ofsoundof/GRL-Image-Restoration.git.\n","authors":["Yawei Li","Yuchen Fan","Xiaoyu Xiang","Denis Demandolx","Rakesh Ranjan","Radu Timofte","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2303.00748v1.pdf","comment":"Accepted by CVPR 2023. 12 pages, 7 figures, 11 tables"},{"id":"http://arxiv.org/abs/2303.00744v1","updated":"2023-03-01T18:56:43Z","published":"2023-03-01T18:56:43Z","title":"READ Avatars: Realistic Emotion-controllable Audio Driven Avatars","summary":"  We present READ Avatars, a 3D-based approach for generating 2D avatars that\nare driven by audio input with direct and granular control over the emotion.\nPrevious methods are unable to achieve realistic animation due to the\nmany-to-many nature of audio to expression mappings. We alleviate this issue by\nintroducing an adversarial loss in the audio-to-expression generation process.\nThis removes the smoothing effect of regression-based models and helps to\nimprove the realism and expressiveness of the generated avatars. We note\nfurthermore, that audio should be directly utilized when generating mouth\ninteriors and that other 3D-based methods do not attempt this. We address this\nwith audio-conditioned neural textures, which are resolution-independent. To\nevaluate the performance of our method, we perform quantitative and qualitative\nexperiments, including a user study. We also propose a new metric for comparing\nhow well an actor's emotion is reconstructed in the generated avatar. Our\nresults show that our approach outperforms state of the art audio-driven avatar\ngeneration methods across several metrics. A demo video can be found at\n\\url{https://youtu.be/QSyMl3vV0pA}\n","authors":["Jack Saunders","Vinay Namboodiri"],"pdf_url":"https://arxiv.org/pdf/2303.00744v1.pdf","comment":"13 Pages, 8 Figures For demo video see https://youtu.be/QSyMl3vV0pA"},{"id":"http://arxiv.org/abs/2303.00725v1","updated":"2023-03-01T18:34:10Z","published":"2023-03-01T18:34:10Z","title":"OSRE: Object-to-Spot Rotation Estimation for Bike Parking Assessment","summary":"  Current deep models provide remarkable object detection in terms of object\nclassification and localization. However, estimating object rotation with\nrespect to other visual objects in the visual context of an input image still\nlacks deep studies due to the unavailability of object datasets with rotation\nannotations.\n  This paper tackles these two challenges to solve the rotation estimation of a\nparked bike with respect to its parking area. First, we leverage the power of\n3D graphics to build a camera-agnostic well-annotated Synthetic Bike Rotation\nDataset (SynthBRSet). Then, we propose an object-to-spot rotation estimator\n(OSRE) by extending the object detection task to further regress the bike\nrotations in two axes. Since our model is purely trained on synthetic data, we\nadopt image smoothing techniques when deploying it on real-world images. The\nproposed OSRE is evaluated on synthetic and real-world data providing promising\nresults. Our data and code are available at\n\\href{https://github.com/saghiralfasly/OSRE-Project}{https://github.com/saghiralfasly/OSRE-Project}.\n","authors":["Saghir Alfasly","Zaid Al-huda","Saifullah Bello","Ahmed Elazab","Jian Lu","Chen Xu"],"pdf_url":"https://arxiv.org/pdf/2303.00725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13371v2","updated":"2023-03-01T18:32:04Z","published":"2023-01-31T02:31:18Z","title":"Demystifying Disagreement-on-the-Line in High Dimensions","summary":"  Evaluating the performance of machine learning models under distribution\nshift is challenging, especially when we only have unlabeled data from the\nshifted (target) domain, along with labeled data from the original (source)\ndomain. Recent work suggests that the notion of disagreement, the degree to\nwhich two models trained with different randomness differ on the same input, is\na key to tackle this problem. Experimentally, disagreement and prediction error\nhave been shown to be strongly connected, which has been used to estimate model\nperformance. Experiments have led to the discovery of the\ndisagreement-on-the-line phenomenon, whereby the classification error under the\ntarget domain is often a linear function of the classification error under the\nsource domain; and whenever this property holds, disagreement under the source\nand target domain follow the same linear relation. In this work, we develop a\ntheoretical foundation for analyzing disagreement in high-dimensional random\nfeatures regression; and study under what conditions the\ndisagreement-on-the-line phenomenon occurs in our setting. Experiments on\nCIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and\nsupport the universality of the theoretical findings.\n","authors":["Donghwan Lee","Behrad Moniri","Xinmeng Huang","Edgar Dobriban","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2301.13371v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00716v1","updated":"2023-03-01T18:20:24Z","published":"2023-03-01T18:20:24Z","title":"Aligning benchmark datasets for table structure recognition","summary":"  Benchmark datasets for table structure recognition (TSR) must be carefully\nprocessed to ensure they are annotated consistently. However, even if a\ndataset's annotations are self-consistent, there may be significant\ninconsistency across datasets, which can harm the performance of models trained\nand evaluated on them. In this work, we show that aligning these\nbenchmarks$\\unicode{x2014}$removing both errors and inconsistency between\nthem$\\unicode{x2014}$improves model performance significantly. We demonstrate\nthis through a data-centric approach where we adopt a single model\narchitecture, the Table Transformer (TATR), that we hold fixed throughout.\nBaseline exact match accuracy for TATR evaluated on the ICDAR-2013 benchmark is\n65% when trained on PubTables-1M, 42% when trained on FinTabNet, and 69%\ncombined. After reducing annotation mistakes and inter-dataset inconsistency,\nperformance of TATR evaluated on ICDAR-2013 increases substantially to 75% when\ntrained on PubTables-1M, 65% when trained on FinTabNet, and 81% combined. We\nshow through ablations over the modification steps that canonicalization of the\ntable annotations has a significantly positive effect on performance, while\nother choices balance necessary trade-offs that arise when deciding a benchmark\ndataset's final composition. Overall we believe our work has significant\nimplications for benchmark design for TSR and potentially other tasks as well.\nAll dataset processing and training code will be released.\n","authors":["Brandon Smock","Rohith Pesala","Robin Abraham"],"pdf_url":"https://arxiv.org/pdf/2303.00716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00714v1","updated":"2023-03-01T18:19:10Z","published":"2023-03-01T18:19:10Z","title":"A Complementarity-Based Switch-Fuse System for Improved Visual Place\n  Recognition","summary":"  Recently several fusion and switching based approaches have been presented to\nsolve the problem of Visual Place Recognition. In spite of these systems\ndemonstrating significant boost in VPR performance they each have their own set\nof limitations. The multi-process fusion systems usually involve employing\nbrute force and running all available VPR techniques simultaneously while the\nswitching method attempts to negate this practise by only selecting the best\nsuited VPR technique for given query image. But switching does fail at times\nwhen no available suitable technique can be identified. An innovative solution\nwould be an amalgamation of the two otherwise discrete approaches to combine\ntheir competitive advantages while negating their shortcomings. The proposed,\nSwitch-Fuse system, is an interesting way to combine both the robustness of\nswitching VPR techniques based on complementarity and the force of fusing the\ncarefully selected techniques to significantly improve performance. Our system\nholds a structure superior to the basic fusion methods as instead of simply\nfusing all or any random techniques, it is structured to first select the best\npossible VPR techniques for fusion, according to the query image. The system\ncombines two significant processes, switching and fusing VPR techniques, which\ntogether as a hybrid model substantially improve performance on all major VPR\ndata sets illustrated using PR curves.\n","authors":["Maria Waheed","Sania Waheed","Michael Milford","Klaus McDonald-Maier","Shoaib Ehsan"],"pdf_url":"https://arxiv.org/pdf/2303.00714v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2203.00591"},{"id":"http://arxiv.org/abs/2303.00703v1","updated":"2023-03-01T17:57:09Z","published":"2023-03-01T17:57:09Z","title":"Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis","summary":"  Performances on standard 3D point cloud benchmarks have plateaued, resulting\nin oversized models and complex network design to make a fractional\nimprovement. We present an alternative to enhance existing deep neural networks\nwithout any redesigning or extra parameters, termed as Spatial-Neighbor Adapter\n(SN-Adapter). Building on any trained 3D network, we utilize its learned\nencoding capability to extract features of the training dataset and summarize\nthem as prototypical spatial knowledge. For a test point cloud, the SN-Adapter\nretrieves k nearest neighbors (k-NN) from the pre-constructed spatial\nprototypes and linearly interpolates the k-NN prediction with that of the\noriginal 3D network. By providing complementary characteristics, the proposed\nSN-Adapter serves as a plug-and-play module to economically improve performance\nin a non-parametric manner. More importantly, our SN-Adapter can be effectively\ngeneralized to various 3D tasks, including shape classification, part\nsegmentation, and 3D object detection, demonstrating its superiority and\nrobustness. We hope our approach could show a new perspective for point cloud\nanalysis and facilitate future research.\n","authors":["Renrui Zhang","Liuhui Wang","Ziyu Guo","Jianbo Shi"],"pdf_url":"https://arxiv.org/pdf/2303.00703v1.pdf","comment":"Accepted by WACV 2023"},{"id":"http://arxiv.org/abs/2303.00693v1","updated":"2023-03-01T17:41:36Z","published":"2023-03-01T17:41:36Z","title":"PE-GAN: Prior Embedding GAN for PXD images at Belle II","summary":"  The pixel vertex detector (PXD) is an essential part of the Belle II detector\nrecording particle positions. Data from the PXD and other sensors allow us to\nreconstruct particle tracks and decay vertices. The effect of background hits\non track reconstruction is simulated by adding measured or simulated background\nhit patterns to the hits produced by simulated signal particles. This model\nrequires a large set of statistically independent PXD background noise samples\nto avoid a systematic bias of reconstructed tracks. However, data from the\nfine-grained PXD requires a substantial amount of storage. As an efficient way\nof producing background noise, we explore the idea of an on-demand PXD\nbackground generator using conditional Generative Adversarial Networks (GANs)\nwith contrastive learning, adapted by the number of PXD sensors in order to\nboth increase the image fidelity and produce sensor-dependent PXD hitmaps.\n","authors":["Hosein Hashemi","Nikolai Hartmann","Thomas Kuhr","Martin Ritter","Matej srebre"],"pdf_url":"https://arxiv.org/pdf/2303.00693v1.pdf","comment":"25th International Conference on Computing in High Energy and Nuclear\n  Physics (CHEP 2021)"},{"id":"http://arxiv.org/abs/2303.00691v1","updated":"2023-03-01T17:39:08Z","published":"2023-03-01T17:39:08Z","title":"On the Importance of Feature Representation for Flood Mapping using\n  Classical Machine Learning Approaches","summary":"  Climate change has increased the severity and frequency of weather disasters\nall around the world. Flood inundation mapping based on earth observation data\ncan help in this context, by providing cheap and accurate maps depicting the\narea affected by a flood event to emergency-relief units in near-real-time.\nBuilding upon the recent development of the Sen1Floods11 dataset, which\nprovides a limited amount of hand-labeled high-quality training data, this\npaper evaluates the potential of five traditional machine learning approaches\nsuch as gradient boosted decision trees, support vector machines or quadratic\ndiscriminant analysis. By performing a grid-search-based hyperparameter\noptimization on 23 feature spaces we can show that all considered classifiers\nare capable of outperforming the current state-of-the-art neural network-based\napproaches in terms of total IoU on their best-performing feature spaces. With\ntotal and mean IoU values of 0.8751 and 0.7031 compared to 0.70 and 0.5873 as\nthe previous best-reported results, we show that a simple gradient boosting\nclassifier can significantly improve over deep neural network based approaches,\ndespite using less training data. Furthermore, an analysis of the regional\ndistribution of the Sen1Floods11 dataset reveals a problem of spatial\nimbalance. We show that traditional machine learning models can learn this bias\nand argue that modified metric evaluations are required to counter artifacts\ndue to spatial imbalance. Lastly, a qualitative analysis shows that this\npixel-wise classifier provides highly-precise surface water classifications\nindicating that a good choice of a feature space and pixel-wise classification\ncan generate high-quality flood maps using optical and SAR data. We make our\ncode publicly available at:\nhttps://github.com/DFKI-Earth-And-Space-Applications/Flood_Mapping_Feature_Space_Importance\n","authors":["Kevin Iselborn","Marco Stricker","Takashi Miyamoto","Marlon Nuske","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2303.00691v1.pdf","comment":"24 pages, 9 figures, submitted to Remote Sensing of Environment and\n  code is available at\n  https://github.com/DFKI-Earth-And-Space-Applications/Flood_Mapping_Feature_Space_Importance"},{"id":"http://arxiv.org/abs/2303.00690v1","updated":"2023-03-01T17:38:03Z","published":"2023-03-01T17:38:03Z","title":"Rethinking Efficient Tuning Methods from a Unified Perspective","summary":"  Parameter-efficient transfer learning (PETL) based on large-scale pre-trained\nfoundation models has achieved great success in various downstream\napplications. Existing tuning methods, such as prompt, prefix, and adapter,\nperform task-specific lightweight adjustments to different parts of the\noriginal architecture. However, they take effect on only some parts of the\npre-trained models, i.e., only the feed-forward layers or the self-attention\nlayers, which leaves the remaining frozen structures unable to adapt to the\ndata distributions of downstream tasks. Further, the existing structures are\nstrongly coupled with the Transformers, hindering parameter-efficient\ndeployment as well as the design flexibility for new approaches. In this paper,\nwe revisit the design paradigm of PETL and derive a unified framework U-Tuning\nfor parameter-efficient transfer learning, which is composed of an operation\nwith frozen parameters and a unified tuner that adapts the operation for\ndownstream applications. The U-Tuning framework can simultaneously encompass\nexisting methods and derive new approaches for parameter-efficient transfer\nlearning, which prove to achieve on-par or better performances on CIFAR-100 and\nFGVC datasets when compared with existing PETL methods.\n","authors":["Zeyinzi Jiang","Chaojie Mao","Ziyuan Huang","Yiliang Lv","Deli Zhao","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.00690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00616v1","updated":"2023-03-01T16:12:47Z","published":"2023-03-01T16:12:47Z","title":"Prediction of SLAM ATE Using an Ensemble Learning Regression Model and\n  1-D Global Pooling of Data Characterization","summary":"  Robustness and resilience of simultaneous localization and mapping (SLAM) are\ncritical requirements for modern autonomous robotic systems. One of the\nessential steps to achieve robustness and resilience is the ability of SLAM to\nhave an integrity measure for its localization estimates, and thus, have\ninternal fault tolerance mechanisms to deal with performance degradation. In\nthis work, we introduce a novel method for predicting SLAM localization error\nbased on the characterization of raw sensor inputs. The proposed method relies\non using a random forest regression model trained on 1-D global pooled features\nthat are generated from characterized raw sensor data. The model is validated\nby using it to predict the performance of ORB-SLAM3 on three different datasets\nrunning on four different operating modes, resulting in an average prediction\naccuracy of up to 94.7\\%. The paper also studies the impact of 12 different 1-D\nglobal pooling functions on regression quality, and the superiority of 1-D\nglobal averaging is quantitatively proven. Finally, the paper studies the\nquality of prediction with limited training data, and proves that we are able\nto maintain proper prediction quality when only 20 \\% of the training examples\nare used for training, which highlights how the proposed model can optimize the\nevaluation footprint of SLAM systems.\n","authors":["Islam Ali"," Bingqing"," Wan","Hong Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06316v2","updated":"2023-03-01T16:10:00Z","published":"2022-09-13T21:47:18Z","title":"Optimizing SLAM Evaluation Footprint Through Dynamic Range Coverage\n  Analysis of Datasets","summary":"  Simultaneous Localization and Mapping (SLAM) is considered an ever-evolving\nproblem due to its usage in many applications. Evaluation of SLAM is done\ntypically using publicly available datasets which are increasing in number and\nthe level of difficulty. Each dataset provides a certain level of dynamic range\ncoverage that is a key aspect of measuring the robustness and resilience of\nSLAM. In this paper, we provide a systematic analysis of the dynamic range\ncoverage of datasets based on a number of characterization metrics, and our\nanalysis shows a huge level of redundancy within and between datasets.\nSubsequently, we propose a dynamic programming (DP) algorithm for eliminating\nthe redundancy in the evaluation process of SLAM by selecting a subset of\nsequences that matches a single or multiple dynamic range coverage objectives.\nIt is shown that, with the help of dataset characterization and DP selection\nalgorithm, a reduction in the evaluation effort can be achieved while\nmaintaining the same level of coverage. We also study how the evaluation\nprocess of a real-world SLAM system can be optimized utilizing the method\nproposed.\n","authors":["Islam Ali","Hong Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.06316v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00612v1","updated":"2023-03-01T16:09:11Z","published":"2023-03-01T16:09:11Z","title":"Has the Virtualization of the Face Changed Facial Perception? A Study of\n  the Impact of Augmented Reality on Facial Perception","summary":"  Augmented reality and other photo editing filters are popular methods used to\nmodify images, especially images of faces, posted online. Considering the\nimportant role of human facial perception in social communication, how does\nexposure to an increasing number of modified faces online affect human facial\nperception? In this paper we present the results of six surveys designed to\nmeasure familiarity with different styles of facial filters, perceived\nstrangeness of faces edited with different facial filters, and ability to\ndiscern whether images are filtered or not. Our results indicate that faces\nfiltered with photo editing filters that change the image color tones, modify\nfacial structure, or add facial beautification tend to be perceived similarly\nto unmodified faces; however, faces filtered with augmented reality filters\n(\\textit{i.e.,} filters that overlay digital objects) are perceived differently\nfrom unmodified faces. We also found that responses differed based on different\nsurvey question phrasings, indicating that the shift in facial perception due\nto the prevalence of filtered images is noisy to detect. A better understanding\nof shifts in facial perception caused by facial filters will help us build\nonline spaces more responsibly and could inform the training of more accurate\nand equitable facial recognition models, especially those trained with human\npsychophysical annotations.\n","authors":["Louisa Conwill","Samuel Anthony","Walter Scheirer"],"pdf_url":"https://arxiv.org/pdf/2303.00612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00609v1","updated":"2023-03-01T16:03:25Z","published":"2023-03-01T16:03:25Z","title":"Unsupervised Pathology Detection: A Deep Dive Into the State of the Art","summary":"  Deep unsupervised approaches are gathering increased attention for\napplications such as pathology detection and segmentation in medical images\nsince they promise to alleviate the need for large labeled datasets and are\nmore generalizable than their supervised counterparts in detecting any kind of\nrare pathology. As the Unsupervised Anomaly Detection (UAD) literature\ncontinuously grows and new paradigms emerge, it is vital to continuously\nevaluate and benchmark new methods in a common framework, in order to reassess\nthe state-of-the-art (SOTA) and identify promising research directions. To this\nend, we evaluate a diverse selection of cutting-edge UAD methods on multiple\nmedical datasets, comparing them against the established SOTA in UAD for brain\nMRI. Our experiments demonstrate that newly developed feature-modeling methods\nfrom the industrial and medical literature achieve increased performance\ncompared to previous work and set the new SOTA in a variety of modalities and\ndatasets. Additionally, we show that such methods are capable of benefiting\nfrom recently developed self-supervised pre-training algorithms, further\nincreasing their performance. Finally, we perform a series of experiments in\norder to gain further insights into some unique characteristics of selected\nmodels and datasets. Our code can be found under\nhttps://github.com/iolag/UPD_study/.\n","authors":["Ioannis Lagogiannis","Felix Meissen","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2303.00609v1.pdf","comment":"12 pages, 4 figures, under review for IEEE Transactions on Medical\n  Imaging"},{"id":"http://arxiv.org/abs/2303.00608v1","updated":"2023-03-01T16:01:46Z","published":"2023-03-01T16:01:46Z","title":"Level Up the Deepfake Detection: a Method to Effectively Discriminate\n  Images Generated by GAN Architectures and Diffusion Models","summary":"  The image deepfake detection task has been greatly addressed by the\nscientific community to discriminate real images from those generated by\nArtificial Intelligence (AI) models: a binary classification task. In this\nwork, the deepfake detection and recognition task was investigated by\ncollecting a dedicated dataset of pristine images and fake ones generated by 9\ndifferent Generative Adversarial Network (GAN) architectures and by 4\nadditional Diffusion Models (DM). A hierarchical multi-level approach was then\nintroduced to solve three different deepfake detection and recognition tasks:\n(i) Real Vs AI generated; (ii) GANs Vs DMs; (iii) AI specific architecture\nrecognition. Experimental results demonstrated, in each case, more than 97%\nclassification accuracy, outperforming state-of-the-art methods.\n","authors":["Luca Guarnera","Oliver Giudice","Sebastiano Battiato"],"pdf_url":"https://arxiv.org/pdf/2303.00608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00601v1","updated":"2023-03-01T15:48:27Z","published":"2023-03-01T15:48:27Z","title":"Multimodal Industrial Anomaly Detection via Hybrid Fusion","summary":"  2D-based Industrial Anomaly Detection has been widely discussed, however,\nmultimodal industrial anomaly detection based on 3D point clouds and RGB images\nstill has many untouched fields. Existing multimodal industrial anomaly\ndetection methods directly concatenate the multimodal features, which leads to\na strong disturbance between features and harms the detection performance. In\nthis paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly\ndetection method with hybrid fusion scheme: firstly, we design an unsupervised\nfeature fusion with patch-wise contrastive learning to encourage the\ninteraction of different modal features; secondly, we use a decision layer\nfusion with multiple memory banks to avoid loss of information and additional\nnovelty classifiers to make the final decision. We further propose a point\nfeature alignment operation to better align the point cloud and RGB features.\nExtensive experiments show that our multimodal industrial anomaly detection\nmodel outperforms the state-of-the-art (SOTA) methods on both detection and\nsegmentation precision on MVTec-3D AD dataset. Code is available at\nhttps://github.com/nomewang/M3DM.\n","authors":["Yue Wang","Jinlong Peng","Jiangning Zhang","Ran Yi","Yabiao Wang","Chengjie Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00601v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2201.12240v3","updated":"2023-03-01T15:38:54Z","published":"2022-01-28T16:51:54Z","title":"Continuous Deep Equilibrium Models: Training Neural ODEs faster by\n  integrating them to Infinity","summary":"  Implicit models separate the definition of a layer from the description of\nits solution process. While implicit layers allow features such as depth to\nadapt to new scenarios and inputs automatically, this adaptivity makes its\ncomputational expense challenging to predict. In this manuscript, we\n\\textit{increase the ``implicitness\" of the DEQ by redefining the method in\nterms of an infinite time neural ODE}, which paradoxically decreases the\ntraining cost over a standard neural ODE by $\\mathit{2} - \\mathit{4 \\times}$.\nAdditionally, we address the question: \\textit{is there a way to simultaneously\nachieve the robustness of implicit layers while allowing the reduced\ncomputational expense of an explicit layer?} To solve this, we develop Skip and\nSkip Reg. DEQ, an implicit-explicit (IMEX) layer that simultaneously trains an\nexplicit prediction followed by an implicit correction. We show that training\nthis explicit predictor is free and even decreases the training time by\n$\\mathit{1.11} - \\mathit{3.19 \\times}$. Together, this manuscript shows how\nbridging the dichotomy of implicit and explicit deep learning can combine the\nadvantages of both techniques.\n","authors":["Avik Pal","Alan Edelman","Christopher Rackauckas"],"pdf_url":"https://arxiv.org/pdf/2201.12240v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00586v1","updated":"2023-03-01T15:28:26Z","published":"2023-03-01T15:28:26Z","title":"FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling","summary":"  Ensembling independent deep neural networks (DNNs) is a simple and effective\nway to improve top-line metrics and to outperform larger single models. In this\nwork, we go beyond top-line metrics and instead explore the impact of\nensembling on subgroup performances. Surprisingly, even with a simple\nhomogenous ensemble -- all the individual models share the same training set,\narchitecture, and design choices -- we find compelling and powerful gains in\nworst-k and minority group performance, i.e. fairness naturally emerges from\nensembling. We show that the gains in performance from ensembling for the\nminority group continue for far longer than for the majority group as more\nmodels are added. Our work establishes that simple DNN ensembles can be a\npowerful tool for alleviating disparate impact from DNN classifiers, thus\ncurbing algorithmic harm. We also explore why this is the case. We find that\neven in homogeneous ensembles, varying the sources of stochasticity through\nparameter initialization, mini-batch sampling, and the data-augmentation\nrealizations, results in different fairness outcomes.\n","authors":["Wei-Yin Ko","Daniel D'souza","Karina Nguyen","Randall Balestriero","Sara Hooker"],"pdf_url":"https://arxiv.org/pdf/2303.00586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13036v2","updated":"2023-03-01T15:27:29Z","published":"2022-09-26T21:29:50Z","title":"MonoGraspNet: 6-DoF Grasping with a Single RGB Image","summary":"  6-DoF robotic grasping is a long-lasting but unsolved problem. Recent methods\nutilize strong 3D networks to extract geometric grasping representations from\ndepth sensors, demonstrating superior accuracy on common objects but perform\nunsatisfactorily on photometrically challenging objects, e.g., objects in\ntransparent or reflective materials. The bottleneck lies in that the surface of\nthese objects can not reflect back accurate depth due to the absorption or\nrefraction of light. In this paper, in contrast to exploiting the inaccurate\ndepth data, we propose the first RGB-only 6-DoF grasping pipeline called\nMonoGraspNet that utilizes stable 2D features to simultaneously handle\narbitrary object grasping and overcome the problems induced by photometrically\nchallenging objects. MonoGraspNet leverages keypoint heatmap and normal map to\nrecover the 6-DoF grasping poses represented by our novel representation\nparameterized with 2D keypoints with corresponding depth, grasping direction,\ngrasping width, and angle. Extensive experiments in real scenes demonstrate\nthat our method can achieve competitive results in grasping common objects and\nsurpass the depth-based competitor by a large margin in grasping\nphotometrically challenging objects. To further stimulate robotic manipulation\nresearch, we additionally annotate and open-source a multi-view and multi-scene\nreal-world grasping dataset, containing 120 objects of mixed photometric\ncomplexity with 20M accurate grasping labels.\n","authors":["Guangyao Zhai","Dianye Huang","Shun-Cheng Wu","Hyunjun Jung","Yan Di","Fabian Manhardt","Federico Tombari","Nassir Navab","Benjamin Busam"],"pdf_url":"https://arxiv.org/pdf/2209.13036v2.pdf","comment":"ICRA 2023 accepted. Project website:\n  https://sites.google.com/view/monograsp"},{"id":"http://arxiv.org/abs/2303.00575v1","updated":"2023-03-01T15:16:56Z","published":"2023-03-01T15:16:56Z","title":"IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint\n  Multi-Agent Trajectory Prediction","summary":"  Reliable multi-agent trajectory prediction is crucial for the safe planning\nand control of autonomous systems. Compared with single-agent cases, the major\nchallenge in simultaneously processing multiple agents lies in modeling complex\nsocial interactions caused by various driving intentions and road conditions.\nPrevious methods typically leverage graph-based message propagation or\nattention mechanism to encapsulate such interactions in the format of marginal\nprobabilistic distributions. However, it is inherently sub-optimal. In this\npaper, we propose IPCC-TP, a novel relevance-aware module based on Incremental\nPearson Correlation Coefficient to improve multi-agent interaction modeling.\nIPCC-TP learns pairwise joint Gaussian Distributions through the\ntightly-coupled estimation of the means and covariances according to\ninteractive incremental movements. Our module can be conveniently embedded into\nexisting multi-agent prediction methods to extend original motion distribution\ndecoders. Extensive experiments on nuScenes and Argoverse 2 datasets\ndemonstrate that IPCC-TP improves the performance of baselines by a large\nmargin.\n","authors":["Dekai Zhu","Guangyao Zhai","Yan Di","Fabian Manhardt","Hendrik Berkemeyer","Tuan Tran","Nassir Navab","Federico Tombari","Benjamin Busam"],"pdf_url":"https://arxiv.org/pdf/2303.00575v1.pdf","comment":"CVPR 2023 accepted. More details are coming soon"},{"id":"http://arxiv.org/abs/2303.00566v1","updated":"2023-03-01T15:12:55Z","published":"2023-03-01T15:12:55Z","title":"Structured Pruning for Deep Convolutional Neural Networks: A survey","summary":"  The remarkable performance of deep Convolutional neural networks (CNNs) is\ngenerally attributed to their deeper and wider architectures, which can come\nwith significant computational costs. Pruning neural networks has thus gained\ninterest since it effectively lowers storage and computational costs. In\ncontrast to weight pruning, which results in unstructured models, structured\npruning provides the benefit of realistic acceleration by producing models that\nare friendly to hardware implementation. The special requirements of structured\npruning have led to the discovery of numerous new challenges and the\ndevelopment of innovative solutions. This article surveys the recent progress\ntowards structured pruning of deep CNNs. We summarize and compare the\nstate-of-the-art structured pruning techniques with respect to filter ranking\nmethods, regularization methods, dynamic execution, neural architecture search,\nthe lottery ticket hypothesis, and the applications of pruning. While\ndiscussing structured pruning algorithms, we briefly introduce the unstructured\npruning counterpart to emphasize their differences. Furthermore, we provide\ninsights into potential research opportunities in the field of structured\npruning. A curated list of neural network pruning papers can be found at\nhttps://github.com/he-y/Awesome-Pruning\n","authors":["Yang He","Lingao Xiao"],"pdf_url":"https://arxiv.org/pdf/2303.00566v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2303.00563v1","updated":"2023-03-01T15:09:45Z","published":"2023-03-01T15:09:45Z","title":"ROCO: A Roundabout Traffic Conflict Dataset","summary":"  Traffic conflicts have been studied by the transportation research community\nas a surrogate safety measure for decades. However, due to the rarity of\ntraffic conflicts, collecting large-scale real-world traffic conflict data\nbecomes extremely challenging. In this paper, we introduce and analyze ROCO - a\nreal-world roundabout traffic conflict dataset. The data is collected at a\ntwo-lane roundabout at the intersection of State St. and W. Ellsworth Rd. in\nAnn Arbor, Michigan. We use raw video dataflow captured from four fisheye\ncameras installed at the roundabout as our input data source. We adopt a\nlearning-based conflict identification algorithm from video to find potential\ntraffic conflicts, and then manually label them for dataset collection and\nannotation. In total 557 traffic conflicts and 17 traffic crashes are collected\nfrom August 2021 to October 2021. We provide trajectory data of the traffic\nconflict scenes extracted using our roadside perception system. Taxonomy based\non traffic conflict severity, reason for the traffic conflict, and its effect\non the traffic flow is provided. With the traffic conflict data collected, we\ndiscover that failure to yield to circulating vehicles when entering the\nroundabout is the largest contributing reason for traffic conflicts. ROCO\ndataset will be made public in the short future.\n","authors":["Depu Meng","Owen Sayer","Rusheng Zhang","Shengyin Shen","Houqiang Li","Henry X. Liu"],"pdf_url":"https://arxiv.org/pdf/2303.00563v1.pdf","comment":"Accepted by TRBAM 2023 presentation"},{"id":"http://arxiv.org/abs/2302.10763v2","updated":"2023-03-01T14:58:09Z","published":"2023-02-12T12:19:57Z","title":"Contrastive Learning and the Emergence of Attributes Associations","summary":"  In response to an object presentation, supervised learning schemes generally\nrespond with a parsimonious label. Upon a similar presentation we humans\nrespond again with a label, but are flooded, in addition, by a myriad of\nassociations. A significant portion of these consist of the presented object\nattributes. Contrastive learning is a semi-supervised learning scheme based on\nthe application of identity preserving transformations on the object input\nrepresentations. It is conjectured in this work that these same applied\ntransformations preserve, in addition to the identity of the presented object,\nalso the identity of its semantically meaningful attributes. The corollary of\nthis is that the output representations of such a contrastive learning scheme\ncontain valuable information not only for the classification of the presented\nobject, but also for the presence or absence decision of any attribute of\ninterest. Simulation results which demonstrate this idea and the feasibility of\nthis conjecture are presented.\n","authors":["Daniel N. Nissani"],"pdf_url":"https://arxiv.org/pdf/2302.10763v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2302.13838v2","updated":"2023-03-01T14:50:41Z","published":"2023-02-27T14:39:50Z","title":"Cross-modal Face- and Voice-style Transfer","summary":"  Image-to-image translation and voice conversion enable the generation of a\nnew facial image and voice while maintaining some of the semantics such as a\npose in an image and linguistic content in audio, respectively. They can aid in\nthe content-creation process in many applications. However, as they are limited\nto the conversion within each modality, matching the impression of the\ngenerated face and voice remains an open question. We propose a cross-modal\nstyle transfer framework called XFaVoT that jointly learns four tasks: image\ntranslation and voice conversion tasks with audio or image guidance, which\nenables the generation of ``face that matches given voice\" and ``voice that\nmatches given face\", and intra-modality translation tasks with a single\nframework. Experimental results on multiple datasets show that XFaVoT achieves\ncross-modal style translation of image and voice, outperforming baselines in\nterms of quality, diversity, and face-voice correspondence.\n","authors":["Naoya Takahashi","Mayank K. Singh","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2302.13838v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00542v1","updated":"2023-03-01T14:36:19Z","published":"2023-03-01T14:36:19Z","title":"D2Q-DETR: Decoupling and Dynamic Queries for Oriented Object Detection\n  with Transformers","summary":"  Despite the promising results, existing oriented object detection methods\nusually involve heuristically designed rules, e.g., RRoI generation, rotated\nNMS. In this paper, we propose an end-to-end framework for oriented object\ndetection, which simplifies the model pipeline and obtains superior\nperformance. Our framework is based on DETR, with the box regression head\nreplaced with a points prediction head. The learning of points is more\nflexible, and the distribution of points can reflect the angle and size of the\ntarget rotated box. We further propose to decouple the query features into\nclassification and regression features, which significantly improves the model\nprecision. Aerial images usually contain thousands of instances. To better\nbalance model precision and efficiency, we propose a novel dynamic query\ndesign, which reduces the number of object queries in stacked decoder layers\nwithout sacrificing model performance. Finally, we rethink the label assignment\nstrategy of existing DETR-like detectors and propose an effective label\nre-assignment strategy for improved performance. We name our method D2Q-DETR.\nExperiments on the largest and challenging DOTA-v1.0 and DOTA-v1.5 datasets\nshow that D2Q-DETR outperforms existing NMS-based and NMS-free oriented object\ndetection methods and achieves the new state-of-the-art.\n","authors":["Qiang Zhou","Chaohui Yu","Zhibin Wang","Fan Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00542v1.pdf","comment":"5 figures"},{"id":"http://arxiv.org/abs/2303.00534v1","updated":"2023-03-01T14:21:19Z","published":"2023-03-01T14:21:19Z","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with\n  Multi-modal Pre-training","summary":"  Vision-and-language multi-modal pretraining and fine-tuning have shown great\nsuccess in visual question answering (VQA). Compared to general domain VQA, the\nperformance of biomedical VQA suffers from limited data. In this paper, we\npropose a retrieval-augmented pretrain-and-finetune paradigm named RAMM for\nbiomedical VQA to overcome the data limitation issue. Specifically, we collect\na new biomedical dataset named PMCPM which offers patient-based image-text\npairs containing diverse patient situations from PubMed. Then, we pretrain the\nbiomedical multi-modal model to learn visual and textual representation for\nimage-text pairs and align these representations with image-text contrastive\nobjective (ITC). Finally, we propose a retrieval-augmented method to better use\nthe limited data. We propose to retrieve similar image-text pairs based on ITC\nfrom pretraining datasets and introduce a novel retrieval-attention module to\nfuse the representation of the image and the question with the retrieved images\nand texts. Experiments demonstrate that our retrieval-augmented\npretrain-and-finetune paradigm obtains state-of-the-art performance on\nMed-VQA2019, Med-VQA2021, VQARAD, and SLAKE datasets. Further analysis shows\nthat the proposed RAMM and PMCPM can enhance biomedical VQA performance\ncompared with previous resources and methods. We will open-source our dataset,\ncodes, and pretrained model.\n","authors":["Zheng Yuan","Qiao Jin","Chuanqi Tan","Zhengyun Zhao","Hongyi Yuan","Fei Huang","Songfang Huang"],"pdf_url":"https://arxiv.org/pdf/2303.00534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00521v1","updated":"2023-03-01T13:52:40Z","published":"2023-03-01T13:52:40Z","title":"Quality-aware Pre-trained Models for Blind Image Quality Assessment","summary":"  Blind image quality assessment (BIQA) aims to automatically evaluate the\nperceived quality of a single image, whose performance has been improved by\ndeep learning-based methods in recent years. However, the paucity of labeled\ndata somewhat restrains deep learning-based BIQA methods from unleashing their\nfull potential. In this paper, we propose to solve the problem by a pretext\ntask customized for BIQA in a self-supervised learning manner, which enables\nlearning representations from orders of magnitude more data. To constrain the\nlearning process, we propose a quality-aware contrastive loss based on a simple\nassumption: the quality of patches from a distorted image should be similar,\nbut vary from patches from the same image with different degradations and\npatches from different images. Further, we improve the existing degradation\nprocess and form a degradation space with the size of roughly $2\\times10^7$.\nAfter pre-trained on ImageNet using our method, models are more sensitive to\nimage quality and perform significantly better on downstream BIQA tasks.\nExperimental results show that our method obtains remarkable improvements on\npopular BIQA datasets.\n","authors":["Kai Zhao","Kun Yuan","Ming Sun","Mading Li","Xing Wen"],"pdf_url":"https://arxiv.org/pdf/2303.00521v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.13602v2","updated":"2023-03-01T13:48:55Z","published":"2023-02-27T09:10:08Z","title":"The Role of Pre-training Data in Transfer Learning","summary":"  The transfer learning paradigm of model pre-training and subsequent\nfine-tuning produces high-accuracy models. While most studies recommend scaling\nthe pre-training size to benefit most from transfer learning, a question\nremains: what data and method should be used for pre-training? We investigate\nthe impact of pre-training data distribution on the few-shot and full\nfine-tuning performance using 3 pre-training methods (supervised, contrastive\nlanguage-image and image-image), 7 pre-training datasets, and 9 downstream\ndatasets. Through extensive controlled experiments, we find that the choice of\nthe pre-training data source is essential for the few-shot transfer, but its\nrole decreases as more data is made available for fine-tuning. Additionally, we\nexplore the role of data curation and examine the trade-offs between label\nnoise and the size of the pre-training dataset. We find that using 2000X more\npre-training data from LAION can match the performance of supervised ImageNet\npre-training. Furthermore, we investigate the effect of pre-training methods,\ncomparing language-image contrastive vs. image-image contrastive, and find that\nthe latter leads to better downstream accuracy\n","authors":["Rahim Entezari","Mitchell Wortsman","Olga Saukh","M. Moein Shariatnia","Hanie Sedghi","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2302.13602v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00502v1","updated":"2023-03-01T13:35:35Z","published":"2023-03-01T13:35:35Z","title":"On the Audio-visual Synchronization for Lip-to-Speech Synthesis","summary":"  Most lip-to-speech (LTS) synthesis models are trained and evaluated under the\nassumption that the audio-video pairs in the dataset are perfectly\nsynchronized. In this work, we show that the commonly used audio-visual\ndatasets, such as GRID, TCD-TIMIT, and Lip2Wav, can have data asynchrony\nissues. Training lip-to-speech with such datasets may further cause the model\nasynchrony issue -- that is, the generated speech and the input video are out\nof sync. To address these asynchrony issues, we propose a synchronized\nlip-to-speech (SLTS) model with an automatic synchronization mechanism (ASM) to\ncorrect data asynchrony and penalize model asynchrony. We further demonstrate\nthe limitation of the commonly adopted evaluation metrics for LTS with\nasynchronous test data and introduce an audio alignment frontend before the\nmetrics sensitive to time alignment for better evaluation. We compare our\nmethod with state-of-the-art approaches on conventional and time-aligned\nmetrics to show the benefits of synchronization training.\n","authors":["Zhe Niu","Brian Mak"],"pdf_url":"https://arxiv.org/pdf/2303.00502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00500v1","updated":"2023-03-01T13:32:55Z","published":"2023-03-01T13:32:55Z","title":"Inherently Interpretable Multi-Label Classification Using Class-Specific\n  Counterfactuals","summary":"  Interpretability is essential for machine learning algorithms in high-stakes\napplication fields such as medical image analysis. However, high-performing\nblack-box neural networks do not provide explanations for their predictions,\nwhich can lead to mistrust and suboptimal human-ML collaboration. Post-hoc\nexplanation techniques, which are widely used in practice, have been shown to\nsuffer from severe conceptual problems. Furthermore, as we show in this paper,\ncurrent explanation techniques do not perform adequately in the multi-label\nscenario, in which multiple medical findings may co-occur in a single image. We\npropose Attri-Net, an inherently interpretable model for multi-label\nclassification. Attri-Net is a powerful classifier that provides transparent,\ntrustworthy, and human-understandable explanations. The model first generates\nclass-specific attribution maps based on counterfactuals to identify which\nimage regions correspond to certain medical findings. Then a simple logistic\nregression classifier is used to make predictions based solely on these\nattribution maps. We compare Attri-Net to five post-hoc explanation techniques\nand one inherently interpretable classifier on three chest X-ray datasets. We\nfind that Attri-Net produces high-quality multi-label explanations consistent\nwith clinical knowledge and has comparable classification performance to\nstate-of-the-art classification models.\n","authors":["Susu Sun","Stefano Woerner","Andreas Maier","Lisa M. Koch","Christian F. Baumgartner"],"pdf_url":"https://arxiv.org/pdf/2303.00500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00491v1","updated":"2023-03-01T13:26:39Z","published":"2023-03-01T13:26:39Z","title":"Pose Impact Estimation on Face Recognition using 3D-Aware Synthetic Data\n  with Application to Quality Assessment","summary":"  Evaluating the quality of facial images is essential for operating face\nrecognition systems with sufficient accuracy. The recent advances in face\nquality standardisation (ISO/IEC WD 29794-5) recommend the usage of component\nquality measures for breaking down face quality into its individual factors,\nhence providing valuable feedback for operators to re-capture low-quality\nimages. In light of recent advances in 3D-aware generative adversarial\nnetworks, we propose a novel dataset, \"Syn-YawPitch\", comprising 1,000\nidentities with varying yaw-pitch angle combinations. Utilizing this dataset,\nwe demonstrate that pitch angles beyond 30 degrees have a significant impact on\nthe biometric performance of current face recognition systems. Furthermore, we\npropose a lightweight and efficient pose quality predictor that adheres to the\nstandards of ISO/IEC WD 29794-5 and is freely available for use at\nhttps://github.com/datasciencegrimmer/Syn-YawPitch/.\n","authors":["Marcel Grimmer","Christian Rathgeb","Christoph Busch"],"pdf_url":"https://arxiv.org/pdf/2303.00491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09617v2","updated":"2023-03-01T13:25:59Z","published":"2023-01-23T18:33:38Z","title":"Fully transformer-based biomarker prediction from colorectal cancer\n  histology: a large-scale multicentric study","summary":"  Background: Deep learning (DL) can extract predictive and prognostic\nbiomarkers from routine pathology slides in colorectal cancer. For example, a\nDL test for the diagnosis of microsatellite instability (MSI) in CRC has been\napproved in 2022. Current approaches rely on convolutional neural networks\n(CNNs). Transformer networks are outperforming CNNs and are replacing them in\nmany applications, but have not been used for biomarker prediction in cancer at\na large scale. In addition, most DL approaches have been trained on small\npatient cohorts, which limits their clinical utility. Methods: In this study,\nwe developed a new fully transformer-based pipeline for end-to-end biomarker\nprediction from pathology slides. We combine a pre-trained transformer encoder\nand a transformer network for patch aggregation, capable of yielding single and\nmulti-target prediction at patient level. We train our pipeline on over 9,000\npatients from 10 colorectal cancer cohorts. Results: A fully transformer-based\napproach massively improves the performance, generalizability, data efficiency,\nand interpretability as compared with current state-of-the-art algorithms.\nAfter training on a large multicenter cohort, we achieve a sensitivity of 0.97\nwith a negative predictive value of 0.99 for MSI prediction on surgical\nresection specimens. We demonstrate for the first time that resection\nspecimen-only training reaches clinical-grade performance on endoscopic biopsy\ntissue, solving a long-standing diagnostic problem. Interpretation: A fully\ntransformer-based end-to-end pipeline trained on thousands of pathology slides\nyields clinical-grade performance for biomarker prediction on surgical\nresections and biopsies. Our new methods are freely available under an open\nsource license.\n","authors":["Sophia J. Wagner","Daniel Reisenbüchler","Nicholas P. West","Jan Moritz Niehues","Gregory Patrick Veldhuizen","Philip Quirke","Heike I. Grabsch","Piet A. van den Brandt","Gordon G. A. Hutchins","Susan D. Richman","Tanwei Yuan","Rupert Langer","Josien Christina Anna Jenniskens","Kelly Offermans","Wolfram Mueller","Richard Gray","Stephen B. Gruber","Joel K. Greenson","Gad Rennert","Joseph D. Bonner","Daniel Schmolze","Jacqueline A. James","Maurice B. Loughrey","Manuel Salto-Tellez","Hermann Brenner","Michael Hoffmeister","Daniel Truhn","Julia A. Schnabel","Melanie Boxberg","Tingying Peng","Jakob Nikolas Kather"],"pdf_url":"https://arxiv.org/pdf/2301.09617v2.pdf","comment":"Updated Figure 2 and Table A.5"},{"id":"http://arxiv.org/abs/2209.08343v2","updated":"2023-03-01T13:13:47Z","published":"2022-09-17T14:46:28Z","title":"Data Efficient Visual Place Recognition Using Extremely JPEG-Compressed\n  Images","summary":"  Visual Place Recognition (VPR) is the ability of a robotic platform to\ncorrectly interpret visual stimuli from its on-board cameras in order to\ndetermine whether it is currently located in a previously visited place,\ndespite different viewpoint, illumination and appearance changes. JPEG is a\nwidely used image compression standard that is capable of significantly\nreducing the size of an image at the cost of image clarity. For applications\nwhere several robotic platforms are simultaneously deployed, the visual data\ngathered must be transmitted remotely between each robot. Hence, JPEG\ncompression can be employed to drastically reduce the amount of data\ntransmitted over a communication channel, as working with limited bandwidth for\nVPR can be proven to be a challenging task. However, the effects of JPEG\ncompression on the performance of current VPR techniques have not been\npreviously studied. For this reason, this paper presents an in-depth study of\nJPEG compression in VPR related scenarios. We use a selection of\nwell-established VPR techniques on well-established benchmark datasets with\nvarious amounts of compression applied. We show that by introducing\ncompression, the VPR performance is drastically reduced, especially in the\nhigher spectrum of compression. Moreover, this paper demonstrates how\nfine-tuning a CNN can be utilised as an optimisation method for JPEG compressed\ndata to perform more consistently with the image transformations detected in\nextremely JPEG compressed images.\n","authors":["Mihnea-Alexandru Tomita","Bruno Ferrarini","Michael Milford","Klaus McDonald-Maier","Shoaib Ehsan"],"pdf_url":"https://arxiv.org/pdf/2209.08343v2.pdf","comment":"The paper is currently under-review. 8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.00477v1","updated":"2023-03-01T13:04:45Z","published":"2023-03-01T13:04:45Z","title":"ORCHNet: A Robust Global Feature Aggregation approach for 3D LiDAR-based\n  Place recognition in Orchards","summary":"  Robust and reliable place recognition and loop closure detection in\nagricultural environments is still an open problem. In particular, orchards are\na difficult case study due to structural similarity across the entire field. In\nthis work, we address the place recognition problem in orchards resorting to 3D\nLiDAR data, which is considered a key modality for robustness. Hence, we\npropose ORCHNet, a deep-learning-based approach that maps 3D-LiDAR scans to\nglobal descriptors. Specifically, this work proposes a new global feature\naggregation approach, which fuses multiple aggregation methods into a robust\nglobal descriptor. ORCHNet is evaluated on real-world data collected in\norchards, comprising data from the summer and autumn seasons. To assess the\nrobustness, We compare ORCHNet with state-of-the-art aggregation approaches on\ndata from the same season and across seasons. Moreover, we additionally\nevaluate the proposed approach as part of a localization framework, where\nORCHNet is used as a loop closure detector. The empirical results indicate\nthat, on the place recognition task, ORCHNet outperforms the remaining\napproaches, and is also more robust across seasons. As for the localization,\nthe edge cases where the path goes through the trees are solved when\nintegrating ORCHNet as a loop detector, showing the potential applicability of\nthe proposed approach in this task. The code and dataset will be publicly\navailable at:\\url{https://github.com/Cybonic/ORCHNet.git}\n","authors":["T. Barros","L. Garrote","P. Conde","M. J. Coombes","C. Liu","C. Premebida","U. J. Nunes"],"pdf_url":"https://arxiv.org/pdf/2303.00477v1.pdf","comment":"This preprint has been submitted to IEEE Robotics & Automation\n  Magazine"},{"id":"http://arxiv.org/abs/2209.09359v3","updated":"2023-03-01T12:52:16Z","published":"2022-09-19T21:40:32Z","title":"E-VFIA : Event-Based Video Frame Interpolation with Attention","summary":"  Video frame interpolation (VFI) is a fundamental vision task that aims to\nsynthesize several frames between two consecutive original video images. Most\nalgorithms aim to accomplish VFI by using only keyframes, which is an ill-posed\nproblem since the keyframes usually do not yield any accurate precision about\nthe trajectories of the objects in the scene. On the other hand, event-based\ncameras provide more precise information between the keyframes of a video. Some\nrecent state-of-the-art event-based methods approach this problem by utilizing\nevent data for better optical flow estimation to interpolate for video frame by\nwarping. Nonetheless, those methods heavily suffer from the ghosting effect. On\nthe other hand, some of kernel-based VFI methods that only use frames as input,\nhave shown that deformable convolutions, when backed up with transformers, can\nbe a reliable way of dealing with long-range dependencies. We propose\nevent-based video frame interpolation with attention (E-VFIA), as a lightweight\nkernel-based method. E-VFIA fuses event information with standard video frames\nby deformable convolutions to generate high quality interpolated frames. The\nproposed method represents events with high temporal resolution and uses a\nmulti-head self-attention mechanism to better encode event-based information,\nwhile being less vulnerable to blurring and ghosting artifacts; thus,\ngenerating crispier frames. The simulation results show that the proposed\ntechnique outperforms current state-of-the-art methods (both frame and\nevent-based) with a significantly smaller model size.\n","authors":["Onur Selim Kılıç","Ahmet Akman","A. Aydın Alatan"],"pdf_url":"https://arxiv.org/pdf/2209.09359v3.pdf","comment":"Accepted to 2023 IEEE International Conference on Robotics and\n  Automation (ICRA 2023)"},{"id":"http://arxiv.org/abs/2301.01970v2","updated":"2023-03-01T12:42:10Z","published":"2023-01-05T09:11:16Z","title":"CAT: LoCalization and IdentificAtion Cascade Detection Transformer for\n  Open-World Object Detection","summary":"  Open-world object detection (OWOD), as a more general and challenging goal,\nrequires the model trained from data on known objects to detect both known and\nunknown objects and incrementally learn to identify these unknown objects. The\nexisting works which employ standard detection framework and fixed\npseudo-labelling mechanism (PLM) have the following problems: (i) The inclusion\nof detecting unknown objects substantially reduces the model's ability to\ndetect known ones. (ii) The PLM does not adequately utilize the priori\nknowledge of inputs. (iii) The fixed selection manner of PLM cannot guarantee\nthat the model is trained in the right direction. We observe that humans\nsubconsciously prefer to focus on all foreground objects and then identify each\none in detail, rather than localize and identify a single object\nsimultaneously, for alleviating the confusion. This motivates us to propose a\nnovel solution called CAT: LoCalization and IdentificAtion Cascade Detection\nTransformer which decouples the detection process via the shared decoder in the\ncascade decoding way. In the meanwhile, we propose the self-adaptive\npseudo-labelling mechanism which combines the model-driven with input-driven\nPLM and self-adaptively generates robust pseudo-labels for unknown objects,\nsignificantly improving the ability of CAT to retrieve unknown objects.\nComprehensive experiments on two benchmark datasets, i.e., MS-COCO and PASCAL\nVOC, show that our model outperforms the state-of-the-art in terms of all\nmetrics in the task of OWOD, incremental object detection (IOD) and open-set\ndetection.\n","authors":["Shuailei Ma","Yuefeng Wang","Jiaqi Fan","Ying Wei","Thomas H. Li","Hongli Liu","Fanbing Lv"],"pdf_url":"https://arxiv.org/pdf/2301.01970v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00462v1","updated":"2023-03-01T12:41:12Z","published":"2023-03-01T12:41:12Z","title":"Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision","summary":"  This work proposes a novel approach to 4D radar-based scene flow estimation\nvia cross-modal learning. Our approach is motivated by the co-located sensing\nredundancy in modern autonomous vehicles. Such redundancy implicitly provides\nvarious forms of supervision cues to the radar scene flow estimation.\nSpecifically, we introduce a multi-task model architecture for the identified\ncross-modal learning problem and propose loss functions to opportunistically\nengage scene flow estimation using multiple cross-modal constraints for\neffective model training. Extensive experiments show the state-of-the-art\nperformance of our method and demonstrate the effectiveness of cross-modal\nsupervised learning to infer more accurate 4D radar scene flow. We also show\nits usefulness to two subtasks - motion segmentation and ego-motion estimation.\nOur source code will be available on \\url{https://github.com/Toytiny/CMFlow.}\n","authors":["Fangqiang Ding","Andras Palffy","Dariu M. Gavrila","Chris Xiaoxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2303.00462v1.pdf","comment":"10 pages, 7 figures. Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.14340v2","updated":"2023-03-01T12:24:02Z","published":"2023-02-28T06:20:07Z","title":"HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of\n  Indoor Scenes with Iterative Intertwined Regularization","summary":"  Recovery of an underlying scene geometry from multiview images stands as a\nlong-time challenge in computer vision research. The recent promise leverages\nneural implicit surface learning and differentiable volume rendering, and\nachieves both the recovery of scene geometry and synthesis of novel views,\nwhere deep priors of neural models are used as an inductive smoothness bias.\nWhile promising for object-level surfaces, these methods suffer when coping\nwith complex scene surfaces. In the meanwhile, traditional multi-view stereo\ncan recover the geometry of scenes with rich textures, by globally optimizing\nthe local, pixel-wise correspondences across multiple views. We are thus\nmotivated to make use of the complementary benefits from the two strategies,\nand propose a method termed Helix-shaped neural implicit Surface learning or\nHelixSurf; HelixSurf uses the intermediate prediction from one strategy as the\nguidance to regularize the learning of the other one, and conducts such\nintertwined regularization iteratively during the learning process. We also\npropose an efficient scheme for differentiable volume rendering in HelixSurf.\nExperiments on surface reconstruction of indoor scenes show that our method\ncompares favorably with existing methods and is orders of magnitude faster,\neven when some of existing methods are assisted with auxiliary training data.\nThe source code is available at https://github.com/Gorilla-Lab-SCUT/HelixSurf.\n","authors":["Zhihao Liang","Zhangjin Huang","Changxing Ding","Kui Jia"],"pdf_url":"https://arxiv.org/pdf/2302.14340v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00449v1","updated":"2023-03-01T12:18:03Z","published":"2023-03-01T12:18:03Z","title":"Motion Compensation via Epipolar Consistency for In-Vivo X-Ray\n  Microscopy","summary":"  Intravital X-ray microscopy (XRM) in preclinical mouse models is of vital\nimportance for the identification of microscopic structural pathological\nchanges in the bone which are characteristic of osteoporosis. The complexity of\nthis method stems from the requirement for high-quality 3D reconstructions of\nthe murine bones. However, respiratory motion and muscle relaxation lead to\ninconsistencies in the projection data which result in artifacts in\nuncompensated reconstructions. Motion compensation using epipolar consistency\nconditions (ECC) has previously shown good performance in clinical CT settings.\nHere, we explore whether such algorithms are suitable for correcting\nmotion-corrupted XRM data. Different rigid motion patterns are simulated and\nthe quality of the motion-compensated reconstructions is assessed. The method\nis able to restore microscopic features for out-of-plane motion, but artifacts\nremain for more realistic motion patterns including all six degrees of freedom\nof rigid motion. Therefore, ECC is valuable for the initial alignment of the\nprojection data followed by further fine-tuning of motion parameters using a\nreconstruction-based method\n","authors":["Mareike Thies","Fabian Wagner","Mingxuan Gu","Yixing Huang","Sabrina Pechmann","Oliver Aust","Daniela Weidner","Georgiana Neag","Stefan Uderhardt","Georg Schett","Silke Christiansen","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2303.00449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00448v1","updated":"2023-03-01T12:17:33Z","published":"2023-03-01T12:17:33Z","title":"The style transformer with common knowledge optimization for image-text\n  retrieval","summary":"  Image-text retrieval which associates different modalities has drawn broad\nattention due to its excellent research value and broad real-world application.\nWhile the algorithms keep updated, most of them haven't taken the high-level\nsemantic relationships (\"style embedding\") and common knowledge from\nmulti-modalities into full consideration. To this end, we propose a novel style\ntransformer network with common knowledge optimization (CKSTN) for image-text\nretrieval. The main module is the common knowledge adaptor (CKA) with both the\nstyle embedding extractor (SEE) and the common knowledge optimization (CKO)\nmodules. Specifically, the SEE is designed to effectively extract high-level\nfeatures. The CKO module is introduced to dynamically capture the latent\nconcepts of common knowledge from different modalities. Together, they could\nassist in the formation of item representations in lightweight transformers.\nBesides, to get generalized temporal common knowledge, we propose a sequential\nupdate strategy to effectively integrate the features of different layers in\nSEE with previous common feature units. CKSTN outperforms the results of\nstate-of-the-art methods in image-text retrieval on MSCOCO and Flickr30K\ndatasets. Moreover, CKSTN is more convenient and practical for the application\nof real scenes, due to the better performance and lower parameters.\n","authors":["Wenrui Li","Zhengyu Ma","Xiaopeng Fan"],"pdf_url":"https://arxiv.org/pdf/2303.00448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01540v3","updated":"2023-03-01T12:02:21Z","published":"2023-02-03T04:31:13Z","title":"DEVICE: DEpth and VIsual ConcEpts Aware Transformer for TextCaps","summary":"  Text-based image captioning is an important but under-explored task, aiming\nto generate descriptions containing visual objects and scene text. Recent\nstudies have made encouraging progress, but they are still suffering from a\nlack of overall understanding of scenes and generating inaccurate captions. One\npossible reason is that current studies mainly focus on constructing the\nplane-level geometric relationship of scene text without depth information.\nThis leads to insufficient scene text relational reasoning so that models may\ndescribe scene text inaccurately. The other possible reason is that existing\nmethods fail to generate fine-grained descriptions of some visual objects. In\naddition, they may ignore essential visual objects, leading to the scene text\nbelonging to these ignored objects not being utilized. To address the above\nissues, we propose a DEpth and VIsual ConcEpts Aware Transformer (DEVICE) for\nTextCaps. Concretely, to construct three-dimensional geometric relations, we\nintroduce depth information and propose a depth-enhanced feature updating\nmodule to ameliorate OCR token features. To generate more precise and\ncomprehensive captions, we introduce semantic features of detected visual\nobject concepts as auxiliary information. Our DEVICE is capable of generalizing\nscenes more comprehensively and boosting the accuracy of described visual\nentities. Sufficient experiments demonstrate the effectiveness of our proposed\nDEVICE, which outperforms state-of-the-art models on the TextCaps test set. Our\ncode will be publicly available.\n","authors":["Dongsheng Xu","Qingbao Huang","Feng Shuang","Yi Cai"],"pdf_url":"https://arxiv.org/pdf/2302.01540v3.pdf","comment":"11pages, 7figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2303.00440v1","updated":"2023-03-01T12:00:15Z","published":"2023-03-01T12:00:15Z","title":"Extracting Motion and Appearance via Inter-Frame Attention for Efficient\n  Video Frame Interpolation","summary":"  Effectively extracting inter-frame motion and appearance information is\nimportant for video frame interpolation (VFI). Previous works either extract\nboth types of information in a mixed way or elaborate separate modules for each\ntype of information, which lead to representation ambiguity and low efficiency.\nIn this paper, we propose a novel module to explicitly extract motion and\nappearance information via a unifying operation. Specifically, we rethink the\ninformation process in inter-frame attention and reuse its attention map for\nboth appearance feature enhancement and motion information extraction.\nFurthermore, for efficient VFI, our proposed module could be seamlessly\nintegrated into a hybrid CNN and Transformer architecture. This hybrid pipeline\ncan alleviate the computational complexity of inter-frame attention as well as\npreserve detailed low-level structure information. Experimental results\ndemonstrate that, for both fixed- and arbitrary-timestep interpolation, our\nmethod achieves state-of-the-art performance on various datasets. Meanwhile,\nour approach enjoys a lighter computation overhead over models with close\nperformance. The source code and models are available at\nhttps://github.com/MCG-NJU/EMA-VFI.\n","authors":["Guozhen Zhang","Yuhan Zhu","Haonan Wang","Youxin Chen","Gangshan Wu","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00440v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00431v1","updated":"2023-03-01T11:39:54Z","published":"2023-03-01T11:39:54Z","title":"OliVaR: Improving Olive Variety Recognition using Deep Neural Networks","summary":"  The easy and accurate identification of varieties is fundamental in\nagriculture, especially in the olive sector, where more than 1200 olive\nvarieties are currently known worldwide. Varietal misidentification leads to\nmany potential problems for all the actors in the sector: farmers and nursery\nworkers may establish the wrong variety, leading to its maladaptation in the\nfield; olive oil and table olive producers may label and sell a non-authentic\nproduct; consumers may be misled; and breeders may commit errors during\ntargeted crossings between different varieties. To date, the standard for\nvarietal identification and certification consists of two methods:\nmorphological classification and genetic analysis. The morphological\nclassification consists of the visual pairwise comparison of different organs\nof the olive tree, where the most important organ is considered to be the\nendocarp. In contrast, different methods for genetic classification exist\n(RAPDs, SSR, and SNP). Both classification methods present advantages and\ndisadvantages. Visual morphological classification requires highly specialized\npersonnel and is prone to human error. Genetic identification methods are more\naccurate but incur a high cost and are difficult to implement. This paper\nintroduces OliVaR, a novel approach to olive varietal identification. OliVaR\nuses a teacher-student deep learning architecture to learn the defining\ncharacteristics of the endocarp of each specific olive variety and perform\nclassification. We construct what is, to the best of our knowledge, the largest\nolive variety dataset to date, comprising image data for 131 varieties from the\nMediterranean basin. We thoroughly test OliVaR on this dataset and show that it\ncorrectly predicts olive varieties with over 86% accuracy.\n","authors":["Hristofor Miho","Giulio Pagnotta","Dorjan Hitaj","Fabio De Gaspari","Luigi V. Mancini","Georgios Koubouris","Gianluca Godino","Mehmet Hakan","Concepcion Muñoz Diez"],"pdf_url":"https://arxiv.org/pdf/2303.00431v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.14045v2","updated":"2023-03-01T11:04:51Z","published":"2023-02-27T18:55:27Z","title":"Language Is Not All You Need: Aligning Perception with Language Models","summary":"  A big convergence of language, multimodal perception, action, and world\nmodeling is a key step toward artificial general intelligence. In this work, we\nintroduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive\ngeneral modalities, learn in context (i.e., few-shot), and follow instructions\n(i.e., zero-shot). Specifically, we train Kosmos-1 from scratch on web-scale\nmultimodal corpora, including arbitrarily interleaved text and images,\nimage-caption pairs, and text data. We evaluate various settings, including\nzero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range\nof tasks without any gradient updates or finetuning. Experimental results show\nthat Kosmos-1 achieves impressive performance on (i) language understanding,\ngeneration, and even OCR-free NLP (directly fed with document images), (ii)\nperception-language tasks, including multimodal dialogue, image captioning,\nvisual question answering, and (iii) vision tasks, such as image recognition\nwith descriptions (specifying classification via text instructions). We also\nshow that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge\nfrom language to multimodal, and from multimodal to language. In addition, we\nintroduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning\ncapability of MLLMs.\n","authors":["Shaohan Huang","Li Dong","Wenhui Wang","Yaru Hao","Saksham Singhal","Shuming Ma","Tengchao Lv","Lei Cui","Owais Khan Mohammed","Barun Patra","Qiang Liu","Kriti Aggarwal","Zewen Chi","Johan Bjorck","Vishrav Chaudhary","Subhojit Som","Xia Song","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2302.14045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00404v1","updated":"2023-03-01T10:52:20Z","published":"2023-03-01T10:52:20Z","title":"Distilled Reverse Attention Network for Open-world Compositional\n  Zero-Shot Learning","summary":"  Open-World Compositional Zero-Shot Learning (OW-CZSL) aims to recognize new\ncompositions of seen attributes and objects. In OW-CZSL, methods built on the\nconventional closed-world setting degrade severely due to the unconstrained OW\ntest space. While previous works alleviate the issue by pruning compositions\naccording to external knowledge or correlations in seen pairs, they introduce\nbiases that harm the generalization. Some methods thus predict state and object\nwith independently constructed and trained classifiers, ignoring that\nattributes are highly context-dependent and visually entangled with objects. In\nthis paper, we propose a novel Distilled Reverse Attention Network to address\nthe challenges. We also model attributes and objects separately but with\ndifferent motivations, capturing contextuality and locality, respectively. We\nfurther design a reverse-and-distill strategy that learns disentangled\nrepresentations of elementary components in training data supervised by reverse\nattention and knowledge distillation. We conduct experiments on three datasets\nand consistently achieve state-of-the-art (SOTA) performance.\n","authors":["Yun Li","Zhe Liu","Saurav Jha","Sally Cripps","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2303.00404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00403v1","updated":"2023-03-01T10:51:27Z","published":"2023-03-01T10:51:27Z","title":"Can representation learning for multimodal image registration be\n  improved by supervision of intermediate layers?","summary":"  Multimodal imaging and correlative analysis typically require image\nalignment. Contrastive learning can generate representations of multimodal\nimages, reducing the challenging task of multimodal image registration to a\nmonomodal one. Previously, additional supervision on intermediate layers in\ncontrastive learning has improved biomedical image classification. We evaluate\nif a similar approach improves representations learned for registration to\nboost registration performance. We explore three approaches to add contrastive\nsupervision to the latent features of the bottleneck layer in the U-Nets\nencoding the multimodal images and evaluate three different critic functions.\nOur results show that representations learned without additional supervision on\nlatent features perform best in the downstream task of registration on two\npublic biomedical datasets. We investigate the performance drop by exploiting\nrecent insights in contrastive learning in classification and self-supervised\nlearning. We visualize the spatial relations of the learned representations by\nmeans of multidimensional scaling, and show that additional supervision on the\nbottleneck layer can lead to partial dimensional collapse of the intermediate\nembedding space.\n","authors":["Elisabeth Wetzer","Joakim Lindblad","Nataša Sladoje"],"pdf_url":"https://arxiv.org/pdf/2303.00403v1.pdf","comment":"15 Pages + 9 Pages Appendix, 10 Figures"},{"id":"http://arxiv.org/abs/2303.00396v1","updated":"2023-03-01T10:33:02Z","published":"2023-03-01T10:33:02Z","title":"Controlling Class Layout for Deep Ordinal Classification via Constrained\n  Proxies Learning","summary":"  For deep ordinal classification, learning a well-structured feature space\nspecific to ordinal classification is helpful to properly capture the ordinal\nnature among classes. Intuitively, when Euclidean distance metric is used, an\nideal ordinal layout in feature space would be that the sample clusters are\narranged in class order along a straight line in space. However, enforcing\nsamples to conform to a specific layout in the feature space is a challenging\nproblem. To address this problem, in this paper, we propose a novel Constrained\nProxies Learning (CPL) method, which can learn a proxy for each ordinal class\nand then adjusts the global layout of classes by constraining these proxies.\nSpecifically, we propose two kinds of strategies: hard layout constraint and\nsoft layout constraint. The hard layout constraint is realized by directly\ncontrolling the generation of proxies to force them to be placed in a strict\nlinear layout or semicircular layout (i.e., two instantiations of strict\nordinal layout). The soft layout constraint is realized by constraining that\nthe proxy layout should always produce unimodal proxy-to-proxies similarity\ndistribution for each proxy (i.e., to be a relaxed ordinal layout). Experiments\nshow that the proposed CPL method outperforms previous deep ordinal\nclassification methods under the same setting of feature extractor.\n","authors":["Cong Wang","Zhiwei Jiang","Yafeng Yin","Zifeng Cheng","Shiping Ge","Qing Gu"],"pdf_url":"https://arxiv.org/pdf/2303.00396v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.00377v1","updated":"2023-03-01T10:02:12Z","published":"2023-03-01T10:02:12Z","title":"Few-shots Portrait Generation with Style Enhancement and Identity\n  Preservation","summary":"  Nowadays, the wide application of virtual digital human promotes the\ncomprehensive prosperity and development of digital culture supported by\ndigital economy. The personalized portrait automatically generated by AI\ntechnology needs both the natural artistic style and human sentiment. In this\npaper, we propose a novel StyleIdentityGAN model, which can ensure the identity\nand artistry of the generated portrait at the same time. Specifically, the\nstyle-enhanced module focuses on artistic style features decoupling and\ntransferring to improve the artistry of generated virtual face images.\nMeanwhile, the identity-enhanced module preserves the significant features\nextracted from the input photo. Furthermore, the proposed method requires a\nsmall number of reference style data. Experiments demonstrate the superiority\nof StyleIdentityGAN over state-of-art methods in artistry and identity effects,\nwith comparisons done qualitatively, quantitatively and through a perceptual\nuser study. Code has been released on Github3.\n","authors":["Runchuan Zhu","Naye Ji","Youbing Zhao","Fan Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00369v1","updated":"2023-03-01T09:50:39Z","published":"2023-03-01T09:50:39Z","title":"Indescribable Multi-modal Spatial Evaluator","summary":"  Multi-modal image registration spatially aligns two images with different\ndistributions. One of its major challenges is that images acquired from\ndifferent imaging machines have different imaging distributions, making it\ndifficult to focus only on the spatial aspect of the images and ignore\ndifferences in distributions. In this study, we developed a self-supervised\napproach, Indescribable Multi-model Spatial Evaluator (IMSE), to address\nmulti-modal image registration. IMSE creates an accurate multi-modal spatial\nevaluator to measure spatial differences between two images, and then optimizes\nregistration by minimizing the error predicted of the evaluator. To optimize\nIMSE performance, we also proposed a new style enhancement method called\nShuffle Remap which randomizes the image distribution into multiple segments,\nand then randomly disorders and remaps these segments, so that the distribution\nof the original image is changed. Shuffle Remap can help IMSE to predict the\ndifference in spatial location from unseen target distributions. Our results\nshow that IMSE outperformed the existing methods for registration using T1-T2\nand CT-MRI datasets. IMSE also can be easily integrated into the traditional\nregistration process, and can provide a convenient way to evaluate and\nvisualize registration results. IMSE also has the potential to be used as a new\nparadigm for image-to-image translation. Our code is available at\nhttps://github.com/Kid-Liet/IMSE.\n","authors":["Lingke Kong","X. Sharon Qi","Qijin Shen","Jiacheng Wang","Jingyi Zhang","Yanle Hu","Qichao Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.00369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00364v1","updated":"2023-03-01T09:45:17Z","published":"2023-03-01T09:45:17Z","title":"Lessons Learned Report: Super-Resolution for Detection Tasks in\n  Engineering Problem-Solving","summary":"  We describe the lessons learned from targeting agricultural detection\nproblem-solving, when subject to low resolution input maps, by means of Machine\nLearning-based super-resolution approaches. The underlying domain is the\nso-called agro-detection class of problems, and the specific objective is to\nlearn a complementary ensemble of sporadic input maps. While super-resolution\nalgorithms are branded with the capacity to enhance various attractive features\nin generic photography, we argue that they must meet certain requirements, and\nmore importantly, that their outcome does not necessarily guarantee an\nimprovement in engineering detection problem-solving (unlike so-called\naesthetics/artistic super-resolution in ImageNet-like datasets). By presenting\nspecific data-driven case studies, we outline a set of limitations and\nrecommendations for deploying super-resolution algorithms for agro-detection\nproblems. Another conclusion states that super-resolution algorithms can be\nused for learning missing spectral channels, and that their usage may result in\nsome desired side-effects such as channels' synchronization.\n","authors":["Martin Feder","Michal Horovitz","Assaf Chen","Raphael Linker","Ofer M. Shir"],"pdf_url":"https://arxiv.org/pdf/2303.00364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00355v1","updated":"2023-03-01T09:33:49Z","published":"2023-03-01T09:33:49Z","title":"Progressive Scale-aware Network for Remote sensing Image Change\n  Captioning","summary":"  Remote sensing (RS) images contain numerous objects of different scales,\nwhich poses significant challenges for the RS image change captioning (RSICC)\ntask to identify visual changes of interest in complex scenes and describe them\nvia language. However, current methods still have some weaknesses in\nsufficiently extracting and utilizing multi-scale information. In this paper,\nwe propose a progressive scale-aware network (PSNet) to address the problem.\nPSNet is a pure Transformer-based model. To sufficiently extract multi-scale\nvisual features, multiple progressive difference perception (PDP) layers are\nstacked to progressively exploit the differencing features of bitemporal\nfeatures. To sufficiently utilize the extracted multi-scale features for\ncaptioning, we propose a scale-aware reinforcement (SR) module and combine it\nwith the Transformer decoding layer to progressively utilize the features from\ndifferent PDP layers. Experiments show that the PDP layer and SR module are\neffective and our PSNet outperforms previous methods.\n","authors":["Chenyang Liu","Jiajun Yang","Zipeng Qi","Zhengxia Zou","Zhenwei Shi"],"pdf_url":"https://arxiv.org/pdf/2303.00355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00354v1","updated":"2023-03-01T09:30:48Z","published":"2023-03-01T09:30:48Z","title":"Unlimited-Size Diffusion Restoration","summary":"  Recently, using diffusion models for zero-shot image restoration (IR) has\nbecome a new hot paradigm. This type of method only needs to use the\npre-trained off-the-shelf diffusion models, without any finetuning, and can\ndirectly handle various IR tasks. The upper limit of the restoration\nperformance depends on the pre-trained diffusion models, which are in rapid\nevolution. However, current methods only discuss how to deal with fixed-size\nimages, but dealing with images of arbitrary sizes is very important for\npractical applications. This paper focuses on how to use those diffusion-based\nzero-shot IR methods to deal with any size while maintaining the excellent\ncharacteristics of zero-shot. A simple way to solve arbitrary size is to divide\nit into fixed-size patches and solve each patch independently. But this may\nyield significant artifacts since it neither considers the global semantics of\nall patches nor the local information of adjacent patches. Inspired by the\nRange-Null space Decomposition, we propose the Mask-Shift Restoration to\naddress local incoherence and propose the Hierarchical Restoration to alleviate\nout-of-domain issues. Our simple, parameter-free approaches can be used not\nonly for image restoration but also for image generation of unlimited sizes,\nwith the potential to be a general tool for diffusion models. Code:\nhttps://github.com/wyhuai/DDNM/tree/main/hq_demo\n","authors":["Yinhuai Wang","Jiwen Yu","Runyi Yu","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00351v1","updated":"2023-03-01T09:27:08Z","published":"2023-03-01T09:27:08Z","title":"An end-to-end SE(3)-equivariant segmentation network","summary":"  Convolutional neural networks (CNNs) allow for parameter sharing and\ntranslational equivariance by using convolutional kernels in their linear\nlayers. By restricting these kernels to be SO(3)-steerable, CNNs can further\nimprove parameter sharing and equivariance. These equivariant convolutional\nlayers have several advantages over standard convolutional layers, including\nincreased robustness to unseen poses, smaller network size, and improved sample\nefficiency. Despite this, most segmentation networks used in medical image\nanalysis continue to rely on standard convolutional kernels. In this paper, we\npresent a new family of segmentation networks that use equivariant voxel\nconvolutions based on spherical harmonics, as well as equivariant pooling and\nnormalization operations. These SE(3)-equivariant volumetric segmentation\nnetworks, which are robust to data poses not seen during training, do not\nrequire rotation-based data augmentation during training. In addition, we\ndemonstrate improved segmentation performance in MRI brain tumor and healthy\nbrain structure segmentation tasks, with enhanced robustness to reduced amounts\nof training data and improved parameter efficiency. Code to reproduce our\nresults, and to implement the equivariant segmentation networks for other tasks\nis available at~\\url{http://github.com/SCAN-NRAD/e3nn_Unet}.\n","authors":["Ivan Diaz","Mario Geiger","Richard Iain McKinley"],"pdf_url":"https://arxiv.org/pdf/2303.00351v1.pdf","comment":"19 pages, 10 figures, submitted to the Journal of Machine Learning\n  for Biomedical Imaging"},{"id":"http://arxiv.org/abs/2209.00588v2","updated":"2023-03-01T09:21:14Z","published":"2022-09-01T17:03:07Z","title":"Transformers are Sample-Efficient World Models","summary":"  Deep reinforcement learning agents are notoriously sample inefficient, which\nconsiderably limits their application to real-world problems. Recently, many\nmodel-based methods have been designed to address this issue, with learning in\nthe imagination of a world model being one of the most prominent approaches.\nHowever, while virtually unlimited interaction with a simulated environment\nsounds appealing, the world model has to be accurate over extended periods of\ntime. Motivated by the success of Transformers in sequence modeling tasks, we\nintroduce IRIS, a data-efficient agent that learns in a world model composed of\na discrete autoencoder and an autoregressive Transformer. With the equivalent\nof only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean\nhuman normalized score of 1.046, and outperforms humans on 10 out of 26 games,\nsetting a new state of the art for methods without lookahead search. To foster\nfuture research on Transformers and world models for sample-efficient\nreinforcement learning, we release our code and models at\nhttps://github.com/eloialonso/iris.\n","authors":["Vincent Micheli","Eloi Alonso","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2209.00588v2.pdf","comment":"ICLR 2023 (notable top 5%)"},{"id":"http://arxiv.org/abs/2303.00340v1","updated":"2023-03-01T09:07:27Z","published":"2023-03-01T09:07:27Z","title":"A Practical Upper Bound for the Worst-Case Attribution Deviations","summary":"  Model attribution is a critical component of deep neural networks (DNNs) for\nits interpretability to complex models. Recent studies bring up attention to\nthe security of attribution methods as they are vulnerable to attribution\nattacks that generate similar images with dramatically different attributions.\nExisting works have been investigating empirically improving the robustness of\nDNNs against those attacks; however, none of them explicitly quantifies the\nactual deviations of attributions. In this work, for the first time, a\nconstrained optimization problem is formulated to derive an upper bound that\nmeasures the largest dissimilarity of attributions after the samples are\nperturbed by any noises within a certain region while the classification\nresults remain the same. Based on the formulation, different practical\napproaches are introduced to bound the attributions above using Euclidean\ndistance and cosine similarity under both $\\ell_2$ and $\\ell_\\infty$-norm\nperturbations constraints. The bounds developed by our theoretical study are\nvalidated on various datasets and two different types of attacks (PGD attack\nand IFIA attribution attack). Over 10 million attacks in the experiments\nindicate that the proposed upper bounds effectively quantify the robustness of\nmodels based on the worst-case attribution dissimilarities.\n","authors":["Fan Wang","Adams Wai-Kin Kong"],"pdf_url":"https://arxiv.org/pdf/2303.00340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14415v2","updated":"2023-03-01T09:07:01Z","published":"2023-02-28T08:47:53Z","title":"Mesh-SORT: Simple and effective of location-wise tracker","summary":"  In recent years, Multi-Object Tracking (MOT) has gained increased attention\ndue to its potential applications in traffic and person detection. We have\nobserved that in most tracking scenarios, objects tend to move and be lost\nwithin specific locations. To address this, we propose different strategies for\ntracking and association that can identify and target these regions.\nAdditionally, we note that tracking by detection may be impacted by errors in\nthe detector, such as an imprecise bounding box. To counter this, we present a\nrobust strategy for dealing with lost objects, as well as a location-wise\nmethod for tracking by detection that includes three improvements in lost\ntracklet management. Resulting Mesh-SORT, it gives mesh division for the\noriginal frame, and applying strategies for differentiation. Experiments\ndemonstrate the potential of our approach and the improvements it provides over\nthe baseline.\n","authors":["ZongTan Li"],"pdf_url":"https://arxiv.org/pdf/2302.14415v2.pdf","comment":"10 pages 16 figs"},{"id":"http://arxiv.org/abs/2303.00337v1","updated":"2023-03-01T09:03:44Z","published":"2023-03-01T09:03:44Z","title":"TAU: A Framework for Video-Based Traffic Analytics Leveraging Artificial\n  Intelligence and Unmanned Aerial Systems","summary":"  Smart traffic engineering and intelligent transportation services are in\nincreasing demand from governmental authorities to optimize traffic performance\nand thus reduce energy costs, increase the drivers' safety and comfort, ensure\ntraffic laws enforcement, and detect traffic violations. In this paper, we\naddress this challenge, and we leverage the use of Artificial Intelligence (AI)\nand Unmanned Aerial Vehicles (UAVs) to develop an AI-integrated video analytics\nframework, called TAU (Traffic Analysis from UAVs), for automated traffic\nanalytics and understanding. Unlike previous works on traffic video analytics,\nwe propose an automated object detection and tracking pipeline from video\nprocessing to advanced traffic understanding using high-resolution UAV images.\nTAU combines six main contributions. First, it proposes a pre-processing\nalgorithm to adapt the high-resolution UAV image as input to the object\ndetector without lowering the resolution. This ensures an excellent detection\naccuracy from high-quality features, particularly the small size of detected\nobjects from UAV images. Second, it introduces an algorithm for recalibrating\nthe vehicle coordinates to ensure that vehicles are uniquely identified and\ntracked across the multiple crops of the same frame. Third, it presents a speed\ncalculation algorithm based on accumulating information from successive frames.\nFourth, TAU counts the number of vehicles per traffic zone based on the Ray\nTracing algorithm. Fifth, TAU has a fully independent algorithm for crossroad\narbitration based on the data gathered from the different zones surrounding it.\nSixth, TAU introduces a set of algorithms for extracting twenty-four types of\ninsights from the raw data collected. The code is shared here:\nhttps://github.com/bilel-bj/TAU. Video demonstrations are provided here:\nhttps://youtu.be/wXJV0H7LviU and here: https://youtu.be/kGv0gmtVEbI.\n","authors":["Bilel Benjdira","Anis Koubaa","Ahmad Taher Azar","Zahid Khan","Adel Ammar","Wadii Boulila"],"pdf_url":"https://arxiv.org/pdf/2303.00337v1.pdf","comment":"This is the final proofread version submitted to Elsevier EAAI:\n  please see the published version at:\n  https://doi.org/10.1016/j.engappai.2022.105095"},{"id":"http://arxiv.org/abs/2303.00334v1","updated":"2023-03-01T08:54:56Z","published":"2023-03-01T08:54:56Z","title":"Online Video Streaming Super-Resolution with Adaptive Look-Up Table\n  Fusion","summary":"  This paper focuses on Super-resolution for online video streaming data.\nApplying existing super-resolution methods to video streaming data is\nnon-trivial for two reasons. First, to support application with constant\ninteractions, video streaming has a high requirement for latency that most\nexisting methods are less applicable, especially on low-end devices. Second,\nexisting video streaming protocols (e.g., WebRTC) dynamically adapt the video\nquality to the network condition, thus video streaming in the wild varies\ngreatly under different network bandwidths, which leads to diverse and dynamic\ndegradations. To tackle the above two challenges, we proposed a novel video\nsuper-resolution method for online video streaming. First, we incorporate\nLook-Up Table (LUT) to lightweight convolution modules to achieve real-time\nlatency. Second, for variant degradations, we propose a pixel-level LUT fusion\nstrategy, where a set of LUT bases are built upon state-of-the-art SR networks\npre-trained on different degraded data, and those LUT bases are combined with\nextracted weights from lightweight convolution modules to adaptively handle\ndynamic degradations. Extensive experiments are conducted on a newly proposed\nonline video streaming dataset named LDV-WebRTC. All the results show that our\nmethod significantly outperforms existing LUT-based methods and offers\ncompetitive SR performance with faster speed compared to efficient CNN-based\nmethods. Accelerated with our parallel LUT inference, our proposed method can\neven support online 720P video SR around 100 FPS.\n","authors":["Guanghao Yin","Xinyang Jiang","Shan Jiang","Zhenhua Han","Ningxin Zheng","Huan Yang","Donglin Bai","Haisheng Tan","Shouqian Sun","Yuqing Yang","Dongsheng Li","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2303.00334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00326v1","updated":"2023-03-01T08:43:05Z","published":"2023-03-01T08:43:05Z","title":"Empowering Networks With Scale and Rotation Equivariance Using A\n  Similarity Convolution","summary":"  The translational equivariant nature of Convolutional Neural Networks (CNNs)\nis a reason for its great success in computer vision. However, networks do not\nenjoy more general equivariance properties such as rotation or scaling,\nultimately limiting their generalization performance. To address this\nlimitation, we devise a method that endows CNNs with simultaneous equivariance\nwith respect to translation, rotation, and scaling. Our approach defines a\nconvolution-like operation and ensures equivariance based on our proposed\nscalable Fourier-Argand representation. The method maintains similar efficiency\nas a traditional network and hardly introduces any additional learnable\nparameters, since it does not face the computational issue that often occurs in\ngroup-convolution operators. We validate the efficacy of our approach in the\nimage classification task, demonstrating its robustness and the generalization\nability to both scaled and rotated inputs.\n","authors":["Zikai Sun","Thierry Blu"],"pdf_url":"https://arxiv.org/pdf/2303.00326v1.pdf","comment":"Accepted for ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00319v1","updated":"2023-03-01T08:32:44Z","published":"2023-03-01T08:32:44Z","title":"RIFT2: Speeding-up RIFT with A New Rotation-Invariance Technique","summary":"  Multimodal image matching is an important prerequisite for multisource image\ninformation fusion. Compared with the traditional matching problem, multimodal\nfeature matching is more challenging due to the severe nonlinear radiation\ndistortion (NRD). Radiation-variation insensitive feature transform\n(RIFT)~\\cite{li2019rift} has shown very good robustness to NRD and become a\nbaseline method in multimodal feature matching. However, the high computational\ncost for rotation invariance largely limits its usage in practice. In this\npaper, we propose an improved RIFT method, called RIFT2. We develop a new\nrotation invariance technique based on dominant index value, which avoids the\nconstruction process of convolution sequence ring. Hence, it can speed up the\nrunning time and reduce the memory consumption of the original RIFT by almost 3\ntimes in theory. Extensive experiments show that RIFT2 achieves similar\nmatching performance to RIFT while being much faster and having less memory\nconsumption. The source code will be made publicly available in\n\\url{https://github.com/LJY-RS/RIFT2-multimodal-matching-rotation}\n","authors":["Jiayuan Li","Pengcheng Shi","Qingwu Hu","Yongjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.00372v2","updated":"2023-03-01T08:20:17Z","published":"2021-07-01T11:16:44Z","title":"Egocentric Image Captioning for Privacy-Preserved Passive Dietary Intake\n  Monitoring","summary":"  Camera-based passive dietary intake monitoring is able to continuously\ncapture the eating episodes of a subject, recording rich visual information,\nsuch as the type and volume of food being consumed, as well as the eating\nbehaviours of the subject. However, there currently is no method that is able\nto incorporate these visual clues and provide a comprehensive context of\ndietary intake from passive recording (e.g., is the subject sharing food with\nothers, what food the subject is eating, and how much food is left in the\nbowl). On the other hand, privacy is a major concern while egocentric wearable\ncameras are used for capturing. In this paper, we propose a privacy-preserved\nsecure solution (i.e., egocentric image captioning) for dietary assessment with\npassive monitoring, which unifies food recognition, volume estimation, and\nscene understanding. By converting images into rich text descriptions,\nnutritionists can assess individual dietary intake based on the captions\ninstead of the original images, reducing the risk of privacy leakage from\nimages. To this end, an egocentric dietary image captioning dataset has been\nbuilt, which consists of in-the-wild images captured by head-worn and\nchest-worn cameras in field studies in Ghana. A novel transformer-based\narchitecture is designed to caption egocentric dietary images. Comprehensive\nexperiments have been conducted to evaluate the effectiveness and to justify\nthe design of the proposed architecture for egocentric dietary image\ncaptioning. To the best of our knowledge, this is the first work that applies\nimage captioning for dietary intake assessment in real life settings.\n","authors":["Jianing Qiu","Frank P. -W. Lo","Xiao Gu","Modou L. Jobarteh","Wenyan Jia","Tom Baranowski","Matilda Steiner-Asiedu","Alex K. Anderson","Megan A McCrory","Edward Sazonov","Mingui Sun","Gary Frost","Benny Lo"],"pdf_url":"https://arxiv.org/pdf/2107.00372v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12886v2","updated":"2023-03-01T08:18:42Z","published":"2022-11-23T11:44:35Z","title":"OReX: Object Reconstruction from Planar Cross-sections Using Neural\n  Fields","summary":"  Reconstructing 3D shapes from planar cross-sections is a challenge inspired\nby downstream applications like medical imaging and geographic informatics. The\ninput is an in/out indicator function fully defined on a sparse collection of\nplanes in space, and the output is an interpolation of the indicator function\nto the entire volume. Previous works addressing this sparse and ill-posed\nproblem either produce low quality results, or rely on additional priors such\nas target topology, appearance information, or input normal directions. In this\npaper, we present OReX, a method for 3D shape reconstruction from slices alone,\nfeaturing a Neural Field as the interpolation prior. A simple neural network is\ntrained on the input planes to receive a 3D coordinate and return an\ninside/outside estimate for the query point. This prior is powerful in inducing\nsmoothness and self-similarities. The main challenge for this approach is\nhigh-frequency details, as the neural prior is overly smoothing. To alleviate\nthis, we offer an iterative estimation architecture and a hierarchical input\nsampling scheme that encourage coarse-to-fine training, allowing focusing on\nhigh frequencies at later stages. In addition, we identify and analyze a common\nripple-like effect stemming from the mesh extraction step. We mitigate it by\nregularizing the spatial gradients of the indicator function around input\nin/out boundaries, cutting the problem at the root.\n  Through extensive qualitative and quantitative experimentation, we\ndemonstrate our method is robust, accurate, and scales well with the size of\nthe input. We report state-of-the-art results compared to previous approaches\nand recent potential solutions, and demonstrate the benefit of our individual\ncontributions through analysis and ablation studies.\n","authors":["Haim Sawdayee","Amir Vaxman","Amit H. Bermano"],"pdf_url":"https://arxiv.org/pdf/2211.12886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00308v1","updated":"2023-03-01T08:13:26Z","published":"2023-03-01T08:13:26Z","title":"Event Fusion Photometric Stereo Network","summary":"  We introduce a novel method to estimate surface normal of an object in an\nambient light environment using RGB and event cameras. Modern photometric\nstereo methods rely on RGB cameras in a darkroom to avoid ambient illumination.\nTo alleviate the limitations of using an RGB camera in a darkroom setting, we\nutilize an event camera with high dynamic range and low latency by capturing\nessential light information. This is the first study to use event cameras for\nphotometric stereo in continuous light sources and ambient light environments.\nAdditionally, we curate a new photometric stereo dataset captured by RGB and\nevent cameras under various ambient lights. Our proposed framework, Event\nFusion Photometric Stereo Network (EFPS-Net), estimates surface normals using\nRGB frames and event signals. EFPS-Net outperforms state-of-the-art methods on\na real-world dataset with ambient lights, demonstrating the effectiveness of\nincorporating additional modalities to alleviate limitations caused by ambient\nillumination.\n","authors":["Wonjeong Ryoo","Giljoo Nam","Jae-Sang Hyun","Sangpil Kim"],"pdf_url":"https://arxiv.org/pdf/2303.00308v1.pdf","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2302.14350v2","updated":"2023-03-01T08:12:08Z","published":"2023-02-28T06:59:05Z","title":"Knowledge Augmented Relation Inference for Group Activity Recognition","summary":"  Most existing group activity recognition methods construct spatial-temporal\nrelations merely based on visual representation. Some methods introduce extra\nknowledge, such as action labels, to build semantic relations and use them to\nrefine the visual presentation. However, the knowledge they explored just stay\nat the semantic-level, which is insufficient for pursing notable accuracy. In\nthis paper, we propose to exploit knowledge concretization for the group\nactivity recognition, and develop a novel Knowledge Augmented Relation\nInference framework that can effectively use the concretized knowledge to\nimprove the individual representations. Specifically, the framework consists of\na Visual Representation Module to extract individual appearance features, a\nKnowledge Augmented Semantic Relation Module explore semantic representations\nof individual actions, and a Knowledge-Semantic-Visual Interaction Module aims\nto integrate visual and semantic information by the knowledge. Benefiting from\nthese modules, the proposed framework can utilize knowledge to enhance the\nrelation inference process and the individual representations, thus improving\nthe performance of group activity recognition. Experimental results on two\npublic datasets show that the proposed framework achieves competitive\nperformance compared with state-of-the-art methods.\n","authors":["Xianglong Lang","Zhuming Wang","Zun Li","Meng Tian","Ge Shi","Lifang Wu","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14350v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.12428v3","updated":"2023-03-01T08:05:18Z","published":"2022-08-26T03:53:04Z","title":"Robust Prototypical Few-Shot Organ Segmentation with Regularized\n  Neural-ODEs","summary":"  Despite the tremendous progress made by deep learning models in image\nsemantic segmentation, they typically require large annotated examples, and\nincreasing attention is being diverted to problem settings like Few-Shot\nLearning (FSL) where only a small amount of annotation is needed for\ngeneralisation to novel classes. This is especially seen in medical domains\nwhere dense pixel-level annotations are expensive to obtain. In this paper, we\npropose Regularized Prototypical Neural Ordinary Differential Equation\n(R-PNODE), a method that leverages intrinsic properties of Neural-ODEs,\nassisted and enhanced by additional cluster and consistency losses to perform\nFew-Shot Segmentation (FSS) of organs. R-PNODE constrains support and query\nfeatures from the same classes to lie closer in the representation space\nthereby improving the performance over the existing Convolutional Neural\nNetwork (CNN) based FSS methods. We further demonstrate that while many\nexisting Deep CNN based methods tend to be extremely vulnerable to adversarial\nattacks, R-PNODE exhibits increased adversarial robustness for a wide array of\nthese attacks. We experiment with three publicly available multi-organ\nsegmentation datasets in both in-domain and cross-domain FSS settings to\ndemonstrate the efficacy of our method. In addition, we perform experiments\nwith seven commonly used adversarial attacks in various settings to demonstrate\nR-PNODE's robustness. R-PNODE outperforms the baselines for FSS by significant\nmargins and also shows superior performance for a wide array of attacks varying\nin intensity and design.\n","authors":["Prashant Pandey","Mustafa Chasmai","Tanuj Sur","Brejesh Lall"],"pdf_url":"https://arxiv.org/pdf/2208.12428v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00304v1","updated":"2023-03-01T08:00:46Z","published":"2023-03-01T08:00:46Z","title":"Renderable Neural Radiance Map for Visual Navigation","summary":"  We propose a novel type of map for visual navigation, a renderable neural\nradiance map (RNR-Map), which is designed to contain the overall visual\ninformation of a 3D environment. The RNR-Map has a grid form and consists of\nlatent codes at each pixel. These latent codes are embedded from image\nobservations, and can be converted to the neural radiance field which enables\nimage rendering given a camera pose. The recorded latent codes implicitly\ncontain visual information about the environment, which makes the RNR-Map\nvisually descriptive. This visual information in RNR-Map can be a useful\nguideline for visual localization and navigation. We develop localization and\nnavigation frameworks that can effectively utilize the RNR-Map. We evaluate the\nproposed frameworks on camera tracking, visual localization, and image-goal\nnavigation. Experimental results show that the RNR-Map-based localization\nframework can find the target location based on a single query image with fast\nspeed and competitive accuracy compared to other baselines. Also, this\nlocalization framework is robust to environmental changes, and even finds the\nmost visually similar places when a query image from a different environment is\ngiven. The proposed navigation framework outperforms the existing image-goal\nnavigation methods in difficult scenarios, under odometry and actuation noises.\nThe navigation framework shows 65.7% success rate in curved scenarios of the\nNRNS dataset, which is an improvement of 18.6% over the current\nstate-of-the-art.\n","authors":["Obin Kwon","Jeongho Park","Songhwai Oh"],"pdf_url":"https://arxiv.org/pdf/2303.00304v1.pdf","comment":"Preprint version, CVPR 2023 accepted. Supplementary Video:\n  https://youtu.be/DHlcKbVDt5A. This will be replaced by a camera-ready version\n  with some minor revisions"},{"id":"http://arxiv.org/abs/2303.00300v1","updated":"2023-03-01T07:50:34Z","published":"2023-03-01T07:50:34Z","title":"BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex\n  Prediction","summary":"  Extracting building footprints from remote sensing images has been attracting\nextensive attention recently. Dominant approaches address this challenging\nproblem by generating vectorized building masks with cumbersome refinement\nstages, which limits the application of such methods. In this paper, we\nintroduce a new refinement-free and end-to-end building footprint extraction\nmethod, which is conceptually intuitive, simple, and effective. Our method,\ntermed as BiSVP, represents a building instance with ordered vertices and\nformulates the building footprint extraction as predicting the serialized\nvertices directly in a bidirectional fashion. Moreover, we propose a\ncross-scale feature fusion (CSFF) module to facilitate high resolution and rich\nsemantic feature learning, which is essential for the dense building vertex\nprediction task. Without bells and whistles, our BiSVP outperforms\nstate-of-the-art methods by considerable margins on three building instance\nsegmentation benchmarks, clearly demonstrating its superiority. The code and\ndatasets will be made public available.\n","authors":["Mingming Zhang","Ye Du","Zhenghui Hu","Qingjie Liu","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14348v2","updated":"2023-03-01T07:50:20Z","published":"2023-02-28T06:38:25Z","title":"Im2Hands: Learning Attentive Implicit Representation of Interacting\n  Two-Hand Shapes","summary":"  We present Implicit Two Hands (Im2Hands), the first neural implicit\nrepresentation of two interacting hands. Unlike existing methods on two-hand\nreconstruction that rely on a parametric hand model and/or low-resolution\nmeshes, Im2Hands can produce fine-grained geometry of two hands with high\nhand-to-hand and hand-to-image coherency. To handle the shape complexity and\ninteraction context between two hands, Im2Hands models the occupancy volume of\ntwo hands - conditioned on an RGB image and coarse 3D keypoints - by two novel\nattention-based modules responsible for (1) initial occupancy estimation and\n(2) context-aware occupancy refinement, respectively. Im2Hands first learns\nper-hand neural articulated occupancy in the canonical space designed for each\nhand using query-image attention. It then refines the initial two-hand\noccupancy in the posed space to enhance the coherency between the two hand\nshapes using query-anchor attention. In addition, we introduce an optional\nkeypoint refinement module to enable robust two-hand shape estimation from\npredicted hand keypoints in a single-image reconstruction scenario. We\nexperimentally demonstrate the effectiveness of Im2Hands on two-hand\nreconstruction in comparison to related methods, where ours achieves\nstate-of-the-art results. Our code is publicly available at\nhttps://github.com/jyunlee/Im2Hands.\n","authors":["Jihyun Lee","Minhyuk Sung","Honggyu Choi","Tae-Kyun Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14348v2.pdf","comment":"6 figures, 14 pages, accepted to CVPR 2023, project page:\n  https://jyunlee.github.io/projects/implicit-two-hands/"},{"id":"http://arxiv.org/abs/2303.00298v1","updated":"2023-03-01T07:48:01Z","published":"2023-03-01T07:48:01Z","title":"Capturing the motion of every joint: 3D human pose and shape estimation\n  with independent tokens","summary":"  In this paper we present a novel method to estimate 3D human pose and shape\nfrom monocular videos. This task requires directly recovering pixel-alignment\n3D human pose and body shape from monocular images or videos, which is\nchallenging due to its inherent ambiguity. To improve precision, existing\nmethods highly rely on the initialized mean pose and shape as prior estimates\nand parameter regression with an iterative error feedback manner. In addition,\nvideo-based approaches model the overall change over the image-level features\nto temporally enhance the single-frame feature, but fail to capture the\nrotational motion at the joint level, and cannot guarantee local temporal\nconsistency. To address these issues, we propose a novel Transformer-based\nmodel with a design of independent tokens. First, we introduce three types of\ntokens independent of the image feature: \\textit{joint rotation tokens, shape\ntoken, and camera token}. By progressively interacting with image features\nthrough Transformer layers, these tokens learn to encode the prior knowledge of\nhuman 3D joint rotations, body shape, and position information from large-scale\ndata, and are updated to estimate SMPL parameters conditioned on a given image.\nSecond, benefiting from the proposed token-based representation, we further use\na temporal model to focus on capturing the rotational temporal information of\neach joint, which is empirically conducive to preventing large jitters in local\nparts. Despite being conceptually simple, the proposed method attains superior\nperformances on the 3DPW and Human3.6M datasets. Using ResNet-50 and\nTransformer architectures, it obtains 42.0 mm error on the PA-MPJPE metric of\nthe challenging 3DPW, outperforming state-of-the-art counterparts by a large\nmargin. Code will be publicly available at\nhttps://github.com/yangsenius/INT_HMR_Model\n","authors":["Sen Yang","Wen Heng","Gang Liu","Guozhong Luo","Wankou Yang","Gang Yu"],"pdf_url":"https://arxiv.org/pdf/2303.00298v1.pdf","comment":"17 pages, 12 figures. ICLR 2023 (spotlight)"},{"id":"http://arxiv.org/abs/2207.12988v2","updated":"2023-03-01T07:41:59Z","published":"2022-07-26T15:48:46Z","title":"Monocular 3D Object Detection with Depth from Motion","summary":"  Perceiving 3D objects from monocular inputs is crucial for robotic systems,\ngiven its economy compared to multi-sensor settings. It is notably difficult as\na single image can not provide any clues for predicting absolute depth values.\nMotivated by binocular methods for 3D object detection, we take advantage of\nthe strong geometry structure provided by camera ego-motion for accurate object\ndepth estimation and detection. We first make a theoretical analysis on this\ngeneral two-view case and notice two challenges: 1) Cumulative errors from\nmultiple estimations that make the direct prediction intractable; 2) Inherent\ndilemmas caused by static cameras and matching ambiguity. Accordingly, we\nestablish the stereo correspondence with a geometry-aware cost volume as the\nalternative for depth estimation and further compensate it with monocular\nunderstanding to address the second problem. Our framework, named Depth from\nMotion (DfM), then uses the established geometry to lift 2D image features to\nthe 3D space and detects 3D objects thereon. We also present a pose-free DfM to\nmake it usable when the camera pose is unavailable. Our framework outperforms\nstate-of-the-art methods by a large margin on the KITTI benchmark. Detailed\nquantitative and qualitative analyses also validate our theoretical\nconclusions. The code will be released at\nhttps://github.com/Tai-Wang/Depth-from-Motion.\n","authors":["Tai Wang","Jiangmiao Pang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2207.12988v2.pdf","comment":"ECCV 2022 Oral"},{"id":"http://arxiv.org/abs/2012.08950v5","updated":"2023-03-01T07:35:43Z","published":"2020-12-16T13:48:48Z","title":"Revocable Deep Reinforcement Learning with Affinity Regularization for\n  Outlier-Robust Graph Matching","summary":"  Graph matching (GM) has been a building block in various areas including\ncomputer vision and pattern recognition. Despite recent impressive progress,\nexisting deep GM methods often have obvious difficulty in handling outliers,\nwhich are ubiquitous in practice. We propose a deep reinforcement learning\nbased approach RGM, whose sequential node matching scheme naturally fits the\nstrategy for selective inlier matching against outliers. A revocable action\nframework is devised to improve the agent's flexibility against the complex\nconstrained GM. Moreover, we propose a quadratic approximation technique to\nregularize the affinity score, in the presence of outliers. As such, the agent\ncan finish inlier matching timely when the affinity score stops growing, for\nwhich otherwise an additional parameter i.e. the number of inliers is needed to\navoid matching outliers. In this paper, we focus on learning the back-end\nsolver under the most general form of GM: the Lawler's QAP, whose input is the\naffinity matrix. Especially, our approach can also boost existing GM methods\nthat use such input. Experiments on multiple real-world datasets demonstrate\nits performance regarding both accuracy and robustness.\n","authors":["Chang Liu","Zetian Jiang","Runzhong Wang","Junchi Yan","Lingxiao Huang","Pinyan Lu"],"pdf_url":"https://arxiv.org/pdf/2012.08950v5.pdf","comment":"Proceedings of The Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2303.00289v1","updated":"2023-03-01T07:32:51Z","published":"2023-03-01T07:32:51Z","title":"StrucTexTv2: Masked Visual-Textual Prediction for Document Image\n  Pre-training","summary":"  In this paper, we present StrucTexTv2, an effective document image\npre-training framework, by performing masked visual-textual prediction. It\nconsists of two self-supervised pre-training tasks: masked image modeling and\nmasked language modeling, based on text region-level image masking. The\nproposed method randomly masks some image regions according to the bounding box\ncoordinates of text words. The objectives of our pre-training tasks are\nreconstructing the pixels of masked image regions and the corresponding masked\ntokens simultaneously. Hence the pre-trained encoder can capture more textual\nsemantics in comparison to the masked image modeling that usually predicts the\nmasked image patches. Compared to the masked multi-modal modeling methods for\ndocument image understanding that rely on both the image and text modalities,\nStrucTexTv2 models image-only input and potentially deals with more application\nscenarios free from OCR pre-processing. Extensive experiments on mainstream\nbenchmarks of document image understanding demonstrate the effectiveness of\nStrucTexTv2. It achieves competitive or even new state-of-the-art performance\nin various downstream tasks such as image classification, layout analysis,\ntable structure recognition, document OCR, and information extraction under the\nend-to-end scenario.\n","authors":["Yuechen Yu","Yulin Li","Chengquan Zhang","Xiaoqiang Zhang","Zengyuan Guo","Xiameng Qin","Kun Yao","Junyu Han","Errui Ding","Jingdong Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00289v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00284v1","updated":"2023-03-01T07:22:39Z","published":"2023-03-01T07:22:39Z","title":"To Make Yourself Invisible with Adversarial Semantic Contours","summary":"  Modern object detectors are vulnerable to adversarial examples, which may\nbring risks to real-world applications. The sparse attack is an important task\nwhich, compared with the popular adversarial perturbation on the whole image,\nneeds to select the potential pixels that is generally regularized by an\n$\\ell_0$-norm constraint, and simultaneously optimize the corresponding\ntexture. The non-differentiability of $\\ell_0$ norm brings challenges and many\nworks on attacking object detection adopted manually-designed patterns to\naddress them, which are meaningless and independent of objects, and therefore\nlead to relatively poor attack performance.\n  In this paper, we propose Adversarial Semantic Contour (ASC), an MAP estimate\nof a Bayesian formulation of sparse attack with a deceived prior of object\ncontour. The object contour prior effectively reduces the search space of pixel\nselection and improves the attack by introducing more semantic bias. Extensive\nexperiments demonstrate that ASC can corrupt the prediction of 9 modern\ndetectors with different architectures (\\e.g., one-stage, two-stage and\nTransformer) by modifying fewer than 5\\% of the pixels of the object area in\nCOCO in white-box scenario and around 10\\% of those in black-box scenario. We\nfurther extend the attack to datasets for autonomous driving systems to verify\nthe effectiveness. We conclude with cautions about contour being the common\nweakness of object detectors with various architecture and the care needed in\napplying them in safety-sensitive scenarios.\n","authors":["Yichi Zhang","Zijian Zhu","Hang Su","Jun Zhu","Shibao Zheng","Yuan He","Hui Xue"],"pdf_url":"https://arxiv.org/pdf/2303.00284v1.pdf","comment":"11 pages, 7 figures, published in Computer Vision and Image\n  Understanding in 2023"},{"id":"http://arxiv.org/abs/2302.12172v3","updated":"2023-03-01T07:11:16Z","published":"2023-02-23T17:13:25Z","title":"Unified Chest X-ray and Radiology Report Generation Model with\n  Multi-view Chest X-rays","summary":"  Generated synthetic data in medical research can substitute privacy and\nsecurity-sensitive data with a large-scale curated dataset, reducing data\ncollection and annotation costs. As part of this effort, we propose UniXGen, a\nunified chest X-ray and report generation model, with the following\ncontributions. First, we design a unified model for bidirectional chest X-ray\nand report generation by adopting a vector quantization method to discretize\nchest X-rays into discrete visual tokens and formulating both tasks as sequence\ngeneration tasks. Second, we introduce several special tokens to generate chest\nX-rays with specific views that can be useful when the desired views are\nunavailable. Furthermore, UniXGen can flexibly take various inputs from single\nto multiple views to take advantage of the additional findings available in\nother X-ray views. We adopt an efficient transformer for computational and\nmemory efficiency to handle the long-range input sequence of multi-view chest\nX-rays with high resolution and long paragraph reports. In extensive\nexperiments, we show that our unified model has a synergistic effect on both\ngeneration tasks, as opposed to training only the task-specific models. We also\nfind that view-specific special tokens can distinguish between different views\nand properly generate specific views even if they do not exist in the dataset,\nand utilizing multi-view chest X-rays can faithfully capture the abnormal\nfindings in the additional X-rays. The source code is publicly available at:\nhttps://github.com/ttumyche/UniXGen.\n","authors":["Hyungyung Lee","Da Young Lee","Wonjae Kim","Jin-Hwa Kim","Tackeun Kim","Jihang Kim","Leonard Sunwoo","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2302.12172v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03741v3","updated":"2023-03-01T07:09:41Z","published":"2022-12-07T16:10:08Z","title":"Magic: Multi Art Genre Intelligent Choreography Dataset and Network for\n  3D Dance Generation","summary":"  Achieving multiple genres and long-term choreography sequences from given\nmusic is a challenging task, due to the lack of a multi-genre dataset. To\ntackle this problem,we propose a Multi Art Genre Intelligent Choreography\nDataset (MagicDance). The data of MagicDance is captured from professional\ndancers assisted by motion capture technicians. It has a total of 8 hours 3D\nmotioncapture human dances with paired music, and 16 different dance genres. To\nthe best of our knowledge, MagicDance is the 3D dance dataset with the most\ngenres. In addition, we find that the existing two types of methods\n(generation-based method and synthesis-based method) can only satisfy one of\nthe diversity and duration, but they can complement to some extent. Based on\nthis observation, we also propose a generation-synthesis choreography network\n(MagicNet), which cascades a Diffusion-based 3D Diverse Dance fragments\nGeneration Network (3DGNet) and a Genre&Coherent aware Retrieval Module (GCRM).\nThe former can generate various dance fragments from only one music clip. The\nlatter is utilized to select the best dance fragment generated by 3DGNet and\nswitch them into a complete dance according to the genre and coherent matching\nscore. Quantitative and qualitative experiments demonstrate the quality of\nMagicDance, and the state-of-the-art performance of MagicNet.\n","authors":["Ronghui Li","Junfan Zhao","Yachao Zhang","Mingyang Su","Zeping Ren","Han Zhang","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2212.03741v3.pdf","comment":"We realize that there are methods and experiments that better support\n  our conclusions, so we decide to withdraw this release and investigate this\n  further in future work"},{"id":"http://arxiv.org/abs/2303.00279v1","updated":"2023-03-01T07:01:29Z","published":"2023-03-01T07:01:29Z","title":"Coarse-to-Fine Covid-19 Segmentation via Vision-Language Alignment","summary":"  Segmentation of COVID-19 lesions can assist physicians in better diagnosis\nand treatment of COVID-19. However, there are few relevant studies due to the\nlack of detailed information and high-quality annotation in the COVID-19\ndataset. To solve the above problem, we propose C2FVL, a Coarse-to-Fine\nsegmentation framework via Vision-Language alignment to merge text information\ncontaining the number of lesions and specific locations of image information.\nThe introduction of text information allows the network to achieve better\nprediction results on challenging datasets. We conduct extensive experiments on\ntwo COVID-19 datasets including chest X-ray and CT, and the results demonstrate\nthat our proposed method outperforms other state-of-the-art segmentation\nmethods.\n","authors":["Dandan Shan","Zihan Li","Wentao Chen","Qingde Li","Jie Tian","Qingqi Hong"],"pdf_url":"https://arxiv.org/pdf/2303.00279v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00262v1","updated":"2023-03-01T06:35:42Z","published":"2023-03-01T06:35:42Z","title":"Collage Diffusion","summary":"  Text-conditional diffusion models generate high-quality, diverse images.\nHowever, text is often an ambiguous specification for a desired target image,\ncreating the need for additional user-friendly controls for diffusion-based\nimage generation. We focus on having precise control over image output for\nscenes with several objects. Users control image generation by defining a\ncollage: a text prompt paired with an ordered sequence of layers, where each\nlayer is an RGBA image and a corresponding text prompt. We introduce Collage\nDiffusion, a collage-conditional diffusion algorithm that allows users to\ncontrol both the spatial arrangement and visual attributes of objects in the\nscene, and also enables users to edit individual components of generated\nimages. To ensure that different parts of the input text correspond to the\nvarious locations specified in the input collage layers, Collage Diffusion\nmodifies text-image cross-attention with the layers' alpha masks. To maintain\ncharacteristics of individual collage layers that are not specified in text,\nCollage Diffusion learns specialized text representations per layer. Collage\ninput also enables layer-based controls that provide fine-grained control over\nthe final output: users can control image harmonization on a layer-by-layer\nbasis, and they can edit individual objects in generated images while keeping\nother objects fixed. Collage-conditional image generation requires harmonizing\nthe input collage to make objects fit together--the key challenge involves\nminimizing changes in the positions and key visual attributes of objects in the\ninput collage while allowing other attributes of the collage to change in the\nharmonization process. By leveraging the rich information present in layer\ninput, Collage Diffusion generates globally harmonized images that maintain\ndesired object locations and visual characteristics better than prior\napproaches.\n","authors":["Vishnu Sarukkai","Linden Li","Arden Ma","Christopher Ré","Kayvon Fatahalian"],"pdf_url":"https://arxiv.org/pdf/2303.00262v1.pdf","comment":"26 pages, 20 figures"},{"id":"http://arxiv.org/abs/2303.00261v1","updated":"2023-03-01T06:35:29Z","published":"2023-03-01T06:35:29Z","title":"Speeding Up EfficientNet: Selecting Update Blocks of Convolutional\n  Neural Networks using Genetic Algorithm in Transfer Learning","summary":"  The performance of convolutional neural networks (CNN) depends heavily on\ntheir architectures. Transfer learning performance of a CNN relies quite\nstrongly on selection of its trainable layers. Selecting the most effective\nupdate layers for a certain target dataset often requires expert knowledge on\nCNN architecture which many practitioners do not posses. General users prefer\nto use an available architecture (e.g. GoogleNet, ResNet, EfficientNet etc.)\nthat is developed by domain experts. With the ever-growing number of layers, it\nis increasingly becoming quite difficult and cumbersome to handpick the update\nlayers. Therefore, in this paper we explore the application of genetic\nalgorithm to mitigate this problem. The convolutional layers of popular\npretrained networks are often grouped into modules that constitute their\nbuilding blocks. We devise a genetic algorithm to select blocks of layers for\nupdating the parameters. By experimenting with EfficientNetB0 pre-trained on\nImageNet and using Food-101, CIFAR-100 and MangoLeafBD as target datasets, we\nshow that our algorithm yields similar or better results than the baseline in\nterms of accuracy, and requires lower training and evaluation time due to\nlearning less number of parameters. We also devise a metric called block\nimportance to measure efficacy of each block as update block and analyze the\nimportance of the blocks selected by our algorithm.\n","authors":["Md. Mehedi Hasana","Muhammad Ibrahim","Md. Sawkat Ali"],"pdf_url":"https://arxiv.org/pdf/2303.00261v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2209.06954v2","updated":"2023-03-01T06:28:54Z","published":"2022-09-14T22:04:10Z","title":"Correlation Information Bottleneck: Towards Adapting Pretrained\n  Multimodal Models for Robust Visual Question Answering","summary":"  Benefiting from large-scale pretrained vision language models (VLMs), the\nperformance of Visual Question Answering (VQA) has approached human oracle\nperformance. However, finetuning large-scale pretrained VLMs with limited data\nusually suffers from overfitting and poor generalization issues, leading to a\nlack of model robustness. In this paper, we aim to improve the input\nrobustness, \\ie the ability of models to defend against visual and linguistic\ninput variations as well as shortcut learning involved in inputs, from the\nperspective of Information Bottleneck when adapting pretrained VLMs to the\ndownstream VQA task. Generally, internal representations obtained by pretrained\nVLMs inevitably contain irrelevant and redundant information for a specific\ndownstream task, resulting in statistically spurious correlations and\ninsensitivity to input variations. To encourage the obtained representations to\nconverge to a minimal sufficient statistic in vision-language learning, we\npropose the Correlation Information Bottleneck (CIB) principle, which seeks a\ntradeoff between representation compression and redundancy by minimizing the\nmutual information (MI) between inputs and internal representations while\nmaximizing the MI between outputs and the representations. Furthermore, CIB\nmeasures the internal correlations among visual and linguistic inputs and\nrepresentations via a symmetrized joint MI estimation. Extensive experiments on\nfive VQA datasets of input robustness demonstrate the effectiveness and\nsuperiority of the proposed CIB in terms of robustness and accuracy.\n","authors":["Jingjing Jiang","Ziyi Liu","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2209.06954v2.pdf","comment":"17 pages, 4 figures, 11 tables"},{"id":"http://arxiv.org/abs/2303.00246v1","updated":"2023-03-01T06:06:28Z","published":"2023-03-01T06:06:28Z","title":"ISBNet: a 3D Point Cloud Instance Segmentation Network with\n  Instance-aware Sampling and Box-aware Dynamic Convolution","summary":"  Existing 3D instance segmentation methods are predominated by the bottom-up\ndesign -- manually fine-tuned algorithm to group points into clusters followed\nby a refinement network. However, by relying on the quality of the clusters,\nthese methods generate susceptible results when (1) nearby objects with the\nsame semantic class are packed together, or (2) large objects with loosely\nconnected regions. To address these limitations, we introduce ISBNet, a novel\ncluster-free method that represents instances as kernels and decodes instance\nmasks via dynamic convolution. To efficiently generate high-recall and\ndiscriminative kernels, we propose a simple strategy named Instance-aware\nFarthest Point Sampling to sample candidates and leverage the local aggregation\nlayer inspired by PointNet++ to encode candidate features. Moreover, we show\nthat predicting and leveraging the 3D axis-aligned bounding boxes in the\ndynamic convolution further boosts performance. Our method set new\nstate-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2)\nin terms of AP and retains fast inference time (237ms per scene on ScanNetV2).\n","authors":["Tuan Duc Ngo","Binh-Son Hua","Khoi Nguyen"],"pdf_url":"https://arxiv.org/pdf/2303.00246v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2210.01302v2","updated":"2023-03-01T06:00:47Z","published":"2022-10-04T01:40:31Z","title":"Nuisances via Negativa: Adjusting for Spurious Correlations via Data\n  Augmentation","summary":"  In prediction tasks, there exist features that are related to the label in\nthe same way across different settings for that task; these are semantic\nfeatures or semantics. Features with varying relationships to the label are\nnuisances. For example, in detecting cows from natural images, the shape of the\nhead is a semantic but because images of cows often have grass backgrounds but\nnot always, the background is a nuisance. Relationships between a nuisance and\nthe label are unstable across settings and, consequently, models that exploit\nnuisance-label relationships face performance degradation when these\nrelationships change. Direct knowledge of a nuisance helps build models that\nare robust to such changes, but requires extra annotations beyond labels and\ncovariates. In this paper, we develop an alternative way to produce robust\nmodels by data augmentation. These data augmentations corrupt semantic\ninformation to produce models that identify and adjust for where nuisances\ndrive predictions. We study semantic corruptions in powering different\nspurious-correlation avoiding methods on multiple out-of distribution (OOD)\ntasks like classifying waterbirds, natural language inference (NLI), and\ndetecting cardiomegaly in chest X-rays.\n","authors":["Aahlad Puli","Nitish Joshi","He He","Rajesh Ranganath"],"pdf_url":"https://arxiv.org/pdf/2210.01302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00244v1","updated":"2023-03-01T05:54:52Z","published":"2023-03-01T05:54:52Z","title":"SUNY: A Visual Interpretation Framework for Convolutional Neural\n  Networks from a Necessary and Sufficient Perspective","summary":"  Researchers have proposed various methods for visually interpreting the\nConvolutional Neural Network (CNN) via saliency maps, which include\nClass-Activation-Map (CAM) based approaches as a leading family. However, in\nterms of the internal design logic, existing CAM-based approaches often\noverlook the causal perspective that answers the core \"why\" question to help\nhumans understand the explanation. Additionally, current CNN explanations lack\nthe consideration of both necessity and sufficiency, two complementary sides of\na desirable explanation. This paper presents a causality-driven framework,\nSUNY, designed to rationalize the explanations toward better human\nunderstanding. Using the CNN model's input features or internal filters as\nhypothetical causes, SUNY generates explanations by bi-directional\nquantifications on both the necessary and sufficient perspectives. Extensive\nevaluations justify that SUNY not only produces more informative and convincing\nexplanations from the angles of necessity and sufficiency, but also achieves\nperformances competitive to other approaches across different CNN architectures\nover large-scale datasets, including ILSVRC2012 and CUB-200-2011.\n","authors":["Xiwei Xuan","Ziquan Deng","Hsuan-Tien Lin","Zhaodan Kong","Kwan-Liu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.00244v1.pdf","comment":"10 pages, 6 figures. This manuscript is currently under review"},{"id":"http://arxiv.org/abs/2209.14499v2","updated":"2023-03-01T05:45:02Z","published":"2022-09-29T01:30:34Z","title":"NVRadarNet: Real-Time Radar Obstacle and Free Space Detection for\n  Autonomous Driving","summary":"  Detecting obstacles is crucial for safe and efficient autonomous driving. To\nthis end, we present NVRadarNet, a deep neural network (DNN) that detects\ndynamic obstacles and drivable free space using automotive RADAR sensors. The\nnetwork utilizes temporally accumulated data from multiple RADAR sensors to\ndetect dynamic obstacles and compute their orientation in a top-down bird's-eye\nview (BEV). The network also regresses drivable free space to detect\nunclassified obstacles. Our DNN is the first of its kind to utilize sparse\nRADAR signals in order to perform obstacle and free space detection in real\ntime from RADAR data only. The network has been successfully used for\nperception on our autonomous vehicles in real self-driving scenarios. The\nnetwork runs faster than real time on an embedded GPU and shows good\ngeneralization across geographic regions.\n","authors":["Alexander Popov","Patrik Gebhardt","Ke Chen","Ryan Oldja","Heeseok Lee","Shane Murray","Ruchi Bhargava","Nikolai Smolyanskiy"],"pdf_url":"https://arxiv.org/pdf/2209.14499v2.pdf","comment":"7 pages, 6 figures, ICRA 2023 conference, for associated video file,\n  see https://youtu.be/WlwJJMltoJY"},{"id":"http://arxiv.org/abs/2303.00236v1","updated":"2023-03-01T05:07:48Z","published":"2023-03-01T05:07:48Z","title":"P$^2$SDF for Neural Indoor Scene Reconstruction","summary":"  Given only a set of images, neural implicit surface representation has shown\nits capability in 3D surface reconstruction. However, as the nature of\nper-scene optimization is based on the volumetric rendering of color, previous\nneural implicit surface reconstruction methods usually fail in low-textured\nregions, including the floors, walls, etc., which commonly exist for indoor\nscenes. Being aware of the fact that these low-textured regions usually\ncorrespond to planes, without introducing additional ground-truth supervisory\nsignals or making additional assumptions about the room layout, we propose to\nleverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for\nindoor scene reconstruction. Specifically, we consider adjacent pixels with\nsimilar colors to be on the same pseudo planes. The plane parameters are then\nestimated on the fly during training by an efficient and effective two-step\nscheme. Then the signed distances of the points on the planes are regularized\nby the estimated plane parameters in the training phase. As the unsupervised\nplane segments are usually noisy and inaccurate, we propose to assign different\nweights to the sampled points on the plane in plane estimation as well as the\nregularization loss. The weights come by fusing the plane segments from\ndifferent views. As the sampled rays in the planar regions are redundant,\nleading to inefficient training, we further propose a keypoint-guided rays\nsampling strategy that attends to the informative textured regions with large\ncolor variations, and the implicit network gets a better reconstruction,\ncompared with the original uniform ray sampling strategy. Experiments show that\nour P$^2$SDF achieves competitive reconstruction performance in Manhattan\nscenes. Further, as we do not introduce any additional room layout assumption,\nour P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.\n","authors":["Jing Li","Jinpeng Yu","Ruoyu Wang","Zhengxin Li","Zhengyu Zhang","Lina Cao","Shenghua Gao"],"pdf_url":"https://arxiv.org/pdf/2303.00236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00232v1","updated":"2023-03-01T04:52:49Z","published":"2023-03-01T04:52:49Z","title":"Towards more precise automatic analysis: a comprehensive survey of deep\n  learning-based multi-organ segmentation","summary":"  Accurate segmentation of multiple organs of the head, neck, chest, and\nabdomen from medical images is an essential step in computer-aided diagnosis,\nsurgical navigation, and radiation therapy. In the past few years, with a\ndata-driven feature extraction approach and end-to-end training, automatic deep\nlearning-based multi-organ segmentation method has far outperformed traditional\nmethods and become a new research topic. This review systematically summarizes\nthe latest research in this field. For the first time, from the perspective of\nfull and imperfect annotation, we comprehensively compile 161 studies on deep\nlearning-based multi-organ segmentation in multiple regions such as the head\nand neck, chest, and abdomen, containing a total of 214 related references. The\nmethod based on full annotation summarizes the existing methods from four\naspects: network architecture, network dimension, network dedicated modules,\nand network loss function. The method based on imperfect annotation summarizes\nthe existing methods from two aspects: weak annotation-based methods and semi\nannotation-based methods. We also summarize frequently used datasets for\nmulti-organ segmentation and discuss new challenges and new research trends in\nthis field.\n","authors":["Xiaoyu Liu","Linhao Qu","Ziyue Xie","Jiayue Zhao","Yonghong Shi","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2303.00232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13473v2","updated":"2023-03-01T04:41:51Z","published":"2023-01-31T08:41:18Z","title":"CRC-RL: A Novel Visual Feature Representation Architecture for\n  Unsupervised Reinforcement Learning","summary":"  This paper addresses the problem of visual feature representation learning\nwith an aim to improve the performance of end-to-end reinforcement learning\n(RL) models. Specifically, a novel architecture is proposed that uses a\nheterogeneous loss function, called CRC loss, to learn improved visual features\nwhich can then be used for policy learning in RL. The CRC-loss function is a\ncombination of three individual loss functions, namely, contrastive,\nreconstruction and consistency loss. The feature representation is learned in\nparallel to the policy learning while sharing the weight updates through a\nSiamese Twin encoder model. This encoder model is augmented with a decoder\nnetwork and a feature projection network to facilitate computation of the above\nloss components. Through empirical analysis involving latent feature\nvisualization, an attempt is made to provide an insight into the role played by\nthis loss function in learning new action-dependent features and how they are\nlinked to the complexity of the problems being solved. The proposed\narchitecture, called CRC-RL, is shown to outperform the existing\nstate-of-the-art methods on the challenging Deep mind control suite\nenvironments by a significant margin thereby creating a new benchmark in this\nfield.\n","authors":["Darshita Jain","Anima Majumder","Samrat Dutta","Swagat Kumar"],"pdf_url":"https://arxiv.org/pdf/2301.13473v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.05833v2","updated":"2023-03-01T04:40:21Z","published":"2022-07-12T20:52:26Z","title":"Earthformer: Exploring Space-Time Transformers for Earth System\n  Forecasting","summary":"  Conventionally, Earth system (e.g., weather and climate) forecasting relies\non numerical simulation with complex physical models and are hence both\nexpensive in computation and demanding on domain expertise. With the explosive\ngrowth of the spatiotemporal Earth observation data in the past decade,\ndata-driven models that apply Deep Learning (DL) are demonstrating impressive\npotential for various Earth system forecasting tasks. The Transformer as an\nemerging DL architecture, despite its broad success in other domains, has\nlimited adoption in this area. In this paper, we propose Earthformer, a\nspace-time Transformer for Earth system forecasting. Earthformer is based on a\ngeneric, flexible and efficient space-time attention block, named Cuboid\nAttention. The idea is to decompose the data into cuboids and apply\ncuboid-level self-attention in parallel. These cuboids are further connected\nwith a collection of global vectors. We conduct experiments on the MovingMNIST\ndataset and a newly proposed chaotic N-body MNIST dataset to verify the\neffectiveness of cuboid attention and figure out the best design of\nEarthformer. Experiments on two real-world benchmarks about precipitation\nnowcasting and El Nino/Southern Oscillation (ENSO) forecasting show Earthformer\nachieves state-of-the-art performance. Code is available:\nhttps://github.com/amazon-science/earth-forecasting-transformer .\n","authors":["Zhihan Gao","Xingjian Shi","Hao Wang","Yi Zhu","Yuyang Wang","Mu Li","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2207.05833v2.pdf","comment":"Published at NeurIPS 2022. Camera-ready version"},{"id":"http://arxiv.org/abs/2302.14338v2","updated":"2023-03-01T04:36:26Z","published":"2023-02-28T06:06:12Z","title":"Turning a CLIP Model into a Scene Text Detector","summary":"  The recent large-scale Contrastive Language-Image Pretraining (CLIP) model\nhas shown great potential in various downstream tasks via leveraging the\npretrained vision and language knowledge. Scene text, which contains rich\ntextual and visual information, has an inherent connection with a model like\nCLIP. Recently, pretraining approaches based on vision language models have\nmade effective progresses in the field of text detection. In contrast to these\nworks, this paper proposes a new method, termed TCM, focusing on Turning the\nCLIP Model directly for text detection without pretraining process. We\ndemonstrate the advantages of the proposed TCM as follows: (1) The underlying\nprinciple of our framework can be applied to improve existing scene text\ndetector. (2) It facilitates the few-shot training capability of existing\nmethods, e.g., by using 10% of labeled data, we significantly improve the\nperformance of the baseline method with an average of 22% in terms of the\nF-measure on 4 benchmarks. (3) By turning the CLIP model into existing scene\ntext detection methods, we further achieve promising domain adaptation ability.\nThe code will be publicly released at https://github.com/wenwenyu/TCM.\n","authors":["Wenwen Yu","Yuliang Liu","Wei Hua","Deqiang Jiang","Bo Ren","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2302.14338v2.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2212.12990v3","updated":"2023-03-01T04:35:39Z","published":"2022-12-26T02:37:38Z","title":"Unsupervised Representation Learning from Pre-trained Diffusion\n  Probabilistic Models","summary":"  Diffusion Probabilistic Models (DPMs) have shown a powerful capacity of\ngenerating high-quality image samples. Recently, diffusion autoencoders\n(Diff-AE) have been proposed to explore DPMs for representation learning via\nautoencoding. Their key idea is to jointly train an encoder for discovering\nmeaningful representations from images and a conditional DPM as the decoder for\nreconstructing images. Considering that training DPMs from scratch will take a\nlong time and there have existed numerous pre-trained DPMs, we propose\n\\textbf{P}re-trained \\textbf{D}PM \\textbf{A}uto\\textbf{E}ncoding\n(\\textbf{PDAE}), a general method to adapt existing pre-trained DPMs to the\ndecoders for image reconstruction, with better training efficiency and\nperformance than Diff-AE. Specifically, we find that the reason that\npre-trained DPMs fail to reconstruct an image from its latent variables is due\nto the information loss of forward process, which causes a gap between their\npredicted posterior mean and the true one. From this perspective, the\nclassifier-guided sampling method can be explained as computing an extra mean\nshift to fill the gap, reconstructing the lost class information in samples.\nThese imply that the gap corresponds to the lost information of the image, and\nwe can reconstruct the image by filling the gap. Drawing inspiration from this,\nwe employ a trainable model to predict a mean shift according to encoded\nrepresentation and train it to fill as much gap as possible, in this way, the\nencoder is forced to learn as much information as possible from images to help\nthe filling. By reusing a part of network of pre-trained DPMs and redesigning\nthe weighting scheme of diffusion loss, PDAE can learn meaningful\nrepresentations from images efficiently. Extensive experiments demonstrate the\neffectiveness, efficiency and flexibility of PDAE.\n","authors":["Zijian Zhang","Zhou Zhao","Zhijie Lin"],"pdf_url":"https://arxiv.org/pdf/2212.12990v3.pdf","comment":"Accepted by NeurIPS 2022 Conference"},{"id":"http://arxiv.org/abs/2302.09369v2","updated":"2023-03-01T03:48:17Z","published":"2023-02-18T15:53:55Z","title":"Calibrating the Rigged Lottery: Making All Tickets Reliable","summary":"  Although sparse training has been successfully used in various\nresource-limited deep learning tasks to save memory, accelerate training, and\nreduce inference time, the reliability of the produced sparse models remains\nunexplored. Previous research has shown that deep neural networks tend to be\nover-confident, and we find that sparse training exacerbates this problem.\nTherefore, calibrating the sparse models is crucial for reliable prediction and\ndecision-making. In this paper, we propose a new sparse training method to\nproduce sparse models with improved confidence calibration. In contrast to\nprevious research that uses only one mask to control the sparse topology, our\nmethod utilizes two masks, including a deterministic mask and a random mask.\nThe former efficiently searches and activates important weights by exploiting\nthe magnitude of weights and gradients. While the latter brings better\nexploration and finds more appropriate weight values by random updates.\nTheoretically, we prove our method can be viewed as a hierarchical variational\napproximation of a probabilistic deep Gaussian process. Extensive experiments\non multiple datasets, model architectures, and sparsities show that our method\nreduces ECE values by up to 47.8\\% and simultaneously maintains or even\nimproves accuracy with only a slight increase in computation and storage\nburden.\n","authors":["Bowen Lei","Ruqi Zhang","Dongkuan Xu","Bani Mallick"],"pdf_url":"https://arxiv.org/pdf/2302.09369v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13130v2","updated":"2023-03-01T03:46:43Z","published":"2023-02-25T18:12:37Z","title":"Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting","summary":"  Predicting how the world can evolve in the future is crucial for motion\nplanning in autonomous systems. Classical methods are limited because they rely\non costly human annotations in the form of semantic class labels, bounding\nboxes, and tracks or HD maps of cities to plan their motion and thus are\ndifficult to scale to large unlabeled datasets. One promising self-supervised\ntask is 3D point cloud forecasting from unannotated LiDAR sequences. We show\nthat this task requires algorithms to implicitly capture (1) sensor extrinsics\n(i.e., the egomotion of the autonomous vehicle), (2) sensor intrinsics (i.e.,\nthe sampling pattern specific to the particular LiDAR sensor), and (3) the\nshape and motion of other objects in the scene. But autonomous systems should\nmake predictions about the world and not their sensors. To this end, we factor\nout (1) and (2) by recasting the task as one of spacetime (4D) occupancy\nforecasting. But because it is expensive to obtain ground-truth 4D occupancy,\nwe render point cloud data from 4D occupancy predictions given sensor\nextrinsics and intrinsics, allowing one to train and test occupancy algorithms\nwith unannotated LiDAR sequences. This also allows one to evaluate and compare\npoint cloud forecasting algorithms across diverse datasets, sensors, and\nvehicles.\n","authors":["Tarasha Khurana","Peiyun Hu","David Held","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2302.13130v2.pdf","comment":"CVPR 2023. Project page:\n  https://www.cs.cmu.edu/~tkhurana/ff4d/index.html; Code:\n  https://github.com/tarashakhurana/4d-occ-forecasting"},{"id":"http://arxiv.org/abs/2303.00215v1","updated":"2023-03-01T03:37:42Z","published":"2023-03-01T03:37:42Z","title":"Single Image Backdoor Inversion via Robust Smoothed Classifiers","summary":"  Backdoor inversion, the process of finding a backdoor trigger inserted into a\nmachine learning model, has become the pillar of many backdoor detection and\ndefense methods. Previous works on backdoor inversion often recover the\nbackdoor through an optimization process to flip a support set of clean images\ninto the target class. However, it is rarely studied and understood how large\nthis support set should be to recover a successful backdoor. In this work, we\nshow that one can reliably recover the backdoor trigger with as few as a single\nimage. Specifically, we propose the SmoothInv method, which first constructs a\nrobust smoothed version of the backdoored classifier and then performs guided\nimage synthesis towards the target class to reveal the backdoor pattern.\nSmoothInv requires neither an explicit modeling of the backdoor via a mask\nvariable, nor any complex regularization schemes, which has become the standard\npractice in backdoor inversion methods. We perform both quantitaive and\nqualitative study on backdoored classifiers from previous published backdoor\nattacks. We demonstrate that compared to existing methods, SmoothInv is able to\nrecover successful backdoors from single images, while maintaining high\nfidelity to the original backdoor. We also show how we identify the target\nbackdoored class from the backdoored classifier. Last, we propose and analyze\ntwo countermeasures to our approach and show that SmoothInv remains robust in\nthe face of an adaptive attacker. Our code is available at\nhttps://github.com/locuslab/smoothinv .\n","authors":["Mingjie Sun","Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2303.00215v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00212v1","updated":"2023-03-01T03:33:12Z","published":"2023-03-01T03:33:12Z","title":"A task-specific deep-learning-based denoising approach for myocardial\n  perfusion SPECT","summary":"  Deep-learning (DL)-based methods have shown significant promise in denoising\nmyocardial perfusion SPECT images acquired at low dose. For clinical\napplication of these methods, evaluation on clinical tasks is crucial.\nTypically, these methods are designed to minimize some fidelity-based criterion\nbetween the predicted denoised image and some reference normal-dose image.\nHowever, while promising, studies have shown that these methods may have\nlimited impact on the performance of clinical tasks in SPECT. To address this\nissue, we use concepts from the literature on model observers and our\nunderstanding of the human visual system to propose a DL-based denoising\napproach designed to preserve observer-related information for detection tasks.\nThe proposed method was objectively evaluated on the task of detecting\nperfusion defect in myocardial perfusion SPECT images using a retrospective\nstudy with anonymized clinical data. Our results demonstrate that the proposed\nmethod yields improved performance on this detection task compared to using\nlow-dose images. The results show that by preserving task-specific information,\nDL may provide a mechanism to improve observer performance in low-dose\nmyocardial perfusion SPECT.\n","authors":["Md Ashequr Rahman","Zitong Yu","Barry A. Siegel","Abhinav K. Jha"],"pdf_url":"https://arxiv.org/pdf/2303.00212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00205v1","updated":"2023-03-01T03:15:31Z","published":"2023-03-01T03:15:31Z","title":"RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training","summary":"  As an essential indicator for cancer progression and treatment response,\ntumor size is often measured following the response evaluation criteria in\nsolid tumors (RECIST) guideline in CT slices. By marking each lesion with its\nlongest axis and the longest perpendicular one, laborious pixel-wise manual\nannotation can be avoided. However, such a coarse substitute cannot provide a\nrich and accurate base to allow versatile quantitative analysis of lesions. To\nthis end, we propose a novel weakly supervised framework to exploit the\nexisting rich RECIST annotations for pixel-wise lesion segmentation.\nSpecifically, a pair of under- and over-segmenting masks are constructed for\neach lesion based on its RECIST annotation and served as the label for\nco-training a pair of subnets, respectively, along with the proposed\nlabel-space perturbation induced consistency loss to bridge the gap between the\ntwo subnets and enable effective co-training. Extensive experiments are\nconducted on a public dataset to demonstrate the superiority of the proposed\nframework regarding the RECIST-based weakly supervised segmentation task and\nits universal applicability to various backbone networks.\n","authors":["Lianyu Zhou","Dong Wei","Donghuan Lu","Wei Xue","Liansheng Wang","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.00205v1.pdf","comment":"ISBI 2023"},{"id":"http://arxiv.org/abs/2303.00200v1","updated":"2023-03-01T03:08:40Z","published":"2023-03-01T03:08:40Z","title":"Feature Extraction Matters More: Universal Deepfake Disruption through\n  Attacking Ensemble Feature Extractors","summary":"  Adversarial example is a rising way of protecting facial privacy security\nfrom deepfake modification. To prevent massive facial images from being\nillegally modified by various deepfake models, it is essential to design a\nuniversal deepfake disruptor. However, existing works treat deepfake disruption\nas an End-to-End process, ignoring the functional difference between feature\nextraction and image reconstruction, which makes it difficult to generate a\ncross-model universal disruptor. In this work, we propose a novel\nFeature-Output ensemble UNiversal Disruptor (FOUND) against deepfake networks,\nwhich explores a new opinion that considers attacking feature extractors as the\nmore critical and general task in deepfake disruption. We conduct an effective\ntwo-stage disruption process. We first disrupt multi-model feature extractors\nthrough multi-feature aggregation and individual-feature maintenance, and then\ndevelop a gradient-ensemble algorithm to enhance the disruption effect by\nsimplifying the complex optimization problem of disrupting multiple End-to-End\nmodels. Extensive experiments demonstrate that FOUND can significantly boost\nthe disruption effect against ensemble deepfake benchmark models. Besides, our\nmethod can fast obtain a cross-attribute, cross-image, and cross-model\nuniversal deepfake disruptor with only a few training images, surpassing\nstate-of-the-art universal disruptors in both success rate and efficiency.\n","authors":["Long Tang","Dengpan Ye","Zhenhao Lu","Yunming Zhang","Shengshan Hu","Yue Xu","Chuanxi Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00199v1","updated":"2023-03-01T03:08:30Z","published":"2023-03-01T03:08:30Z","title":"DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on\n  Adaptive Affinity","summary":"  The proposed method in this paper proposes an end-to-end unsupervised\nsemantic segmentation architecture DMSA based on four loss functions. The\nframework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature\nextraction. At the same time, a dynamic dilation strategy is designed to better\ncapture multi-scale context information. Secondly, a Pixel-Adaptive Refinement\n(PAR) module is introduced, which can adaptively refine the initial pseudo\nlabels after feature fusion to obtain high quality pseudo labels. Experiments\nshow that the proposed DSMA framework is superior to the existing methods on\nthe saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and\nthe accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the\nMIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the\nconvergence speed of the model is also greatly improved after the introduction\nof the PAR module.\n","authors":["Kun Yang","Jun Lu"],"pdf_url":"https://arxiv.org/pdf/2303.00199v1.pdf","comment":"5 pages,4 figures"},{"id":"http://arxiv.org/abs/2303.00198v1","updated":"2023-03-01T03:06:29Z","published":"2023-03-01T03:06:29Z","title":"Self-Supervised Convolutional Visual Prompts","summary":"  Machine learning models often fail on out-of-distribution (OOD) samples.\nVisual prompts emerge as a light-weight adaptation method in input space for\nlarge-scale vision models. Existing vision prompts optimize a high-dimensional\nadditive vector and require labeled data on training. However, we find this\nparadigm fails on test-time adaptation when labeled data is unavailable, where\nthe high-dimensional visual prompt overfits to the self-supervised objective.\nWe present convolutional visual prompts for test-time adaptation without\nlabels. Our convolutional prompt is structured and requires fewer trainable\nparameters (less than 1 % parameters of standard visual prompts). Extensive\nexperiments on a wide variety of OOD recognition tasks show that our approach\nis effective, improving robustness by up to 5.87 % over a number of large-scale\nmodel architectures.\n","authors":["Yun-Yun Tsai","Chengzhi Mao","Yow-Kuan Lin","Junfeng Yang"],"pdf_url":"https://arxiv.org/pdf/2303.00198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00193v1","updated":"2023-03-01T02:59:55Z","published":"2023-03-01T02:59:55Z","title":"CLIPER: A Unified Vision-Language Framework for In-the-Wild Facial\n  Expression Recognition","summary":"  Facial expression recognition (FER) is an essential task for understanding\nhuman behaviors. As one of the most informative behaviors of humans, facial\nexpressions are often compound and variable, which is manifested by the fact\nthat different people may express the same expression in very different ways.\nHowever, most FER methods still use one-hot or soft labels as the supervision,\nwhich lack sufficient semantic descriptions of facial expressions and are less\ninterpretable. Recently, contrastive vision-language pre-training (VLP) models\n(e.g., CLIP) use text as supervision and have injected new vitality into\nvarious computer vision tasks, benefiting from the rich semantics in text.\nTherefore, in this work, we propose CLIPER, a unified framework for both static\nand dynamic facial Expression Recognition based on CLIP. Besides, we introduce\nmultiple expression text descriptors (METD) to learn fine-grained expression\nrepresentations that make CLIPER more interpretable. We conduct extensive\nexperiments on several popular FER benchmarks and achieve state-of-the-art\nperformance, which demonstrates the effectiveness of CLIPER.\n","authors":["Hanting Li","Hongjing Niu","Zhaoqing Zhu","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.00193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00312v4","updated":"2023-03-01T02:51:12Z","published":"2022-10-01T16:24:15Z","title":"Multimodal Analogical Reasoning over Knowledge Graphs","summary":"  Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.\n","authors":["Ningyu Zhang","Lei Li","Xiang Chen","Xiaozhuan Liang","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00312v4.pdf","comment":"Accepted by ICLR 2023. The project website is\n  https://zjunlp.github.io/project/MKG_Analogy/introduction.html"},{"id":"http://arxiv.org/abs/2303.00181v1","updated":"2023-03-01T02:15:07Z","published":"2023-03-01T02:15:07Z","title":"Selectively Hard Negative Mining for Alleviating Gradient Vanishing in\n  Image-Text Matching","summary":"  Recently, a series of Image-Text Matching (ITM) methods achieve impressive\nperformance. However, we observe that most existing ITM models suffer from\ngradients vanishing at the beginning of training, which makes these models\nprone to falling into local minima. Most ITM models adopt triplet loss with\nHard Negative mining (HN) as the optimization objective. We find that\noptimizing an ITM model using only the hard negative samples can easily lead to\ngradient vanishing. In this paper, we derive the condition under which the\ngradient vanishes during training. When the difference between the positive\npair similarity and the negative pair similarity is close to 0, the gradients\non both the image and text encoders will approach 0. To alleviate the gradient\nvanishing problem, we propose a Selectively Hard Negative Mining (SelHN)\nstrategy, which chooses whether to mine hard negative samples according to the\ngradient vanishing condition. SelHN can be plug-and-play applied to existing\nITM models to give them better training behavior. To further ensure the\nback-propagation of gradients, we construct a Residual Visual Semantic\nEmbedding model with SelHN, denoted as RVSE++. Extensive experiments on two ITM\nbenchmarks demonstrate the strength of RVSE++, achieving state-of-the-art\nperformance.\n","authors":["Zheng Li","Caili Guo","Xin Wang","Zerun Feng","Zhongtian Du"],"pdf_url":"https://arxiv.org/pdf/2303.00181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00180v1","updated":"2023-03-01T02:14:20Z","published":"2023-03-01T02:14:20Z","title":"FaceRNET: a Facial Expression Intensity Estimation Network","summary":"  This paper presents our approach for Facial Expression Intensity Estimation\nfrom videos. It includes two components: i) a representation extractor network\nthat extracts various emotion descriptors (valence-arousal, action units and\nbasic expressions) from each videoframe; ii) a RNN that captures temporal\ninformation in the data, followed by a mask layer which enables handling\nvarying input video lengths through dynamic routing. This approach has been\ntested on the Hume-Reaction dataset yielding excellent results.\n","authors":["Dimitrios Kollias","Andreas Psaroudakis","Anastasios Arsenos","Paraskeui Theofilou"],"pdf_url":"https://arxiv.org/pdf/2303.00180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00175v1","updated":"2023-03-01T02:07:48Z","published":"2023-03-01T02:07:48Z","title":"A Deep Neural Architecture for Harmonizing 3-D Input Data Analysis and\n  Decision Making in Medical Imaging","summary":"  Harmonizing the analysis of data, especially of 3-D image volumes, consisting\nof different number of slices and annotated per volume, is a significant\nproblem in training and using deep neural networks in various applications,\nincluding medical imaging. Moreover, unifying the decision making of the\nnetworks over different input datasets is crucial for the generation of rich\ndata-driven knowledge and for trusted usage in the applications. This paper\npresents a new deep neural architecture, named RACNet, which includes routing\nand feature alignment steps and effectively handles different input lengths and\nsingle annotations of the 3-D image inputs, whilst providing highly accurate\ndecisions. In addition, through latent variable extraction from the trained\nRACNet, a set of anchors are generated providing further insight on the\nnetwork's decision making. These can be used to enrich and unify data-driven\nknowledge extracted from different datasets. An extensive experimental study\nillustrates the above developments, focusing on COVID-19 diagnosis through\nanalysis of 3-D chest CT scans from databases generated in different countries\nand medical centers.\n","authors":["Dimitrios Kollias","Anastasios Arsenos","Stefanos Kollias"],"pdf_url":"https://arxiv.org/pdf/2303.00175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15274v2","updated":"2023-03-01T02:06:06Z","published":"2022-10-27T09:08:40Z","title":"Improved Feature Distillation via Projector Ensemble","summary":"  In knowledge distillation, previous feature distillation methods mainly focus\non the design of loss functions and the selection of the distilled layers,\nwhile the effect of the feature projector between the student and the teacher\nremains under-explored. In this paper, we first discuss a plausible mechanism\nof the projector with empirical evidence and then propose a new feature\ndistillation method based on a projector ensemble for further performance\nimprovement. We observe that the student network benefits from a projector even\nif the feature dimensions of the student and the teacher are the same. Training\na student backbone without a projector can be considered as a multi-task\nlearning process, namely achieving discriminative feature extraction for\nclassification and feature matching between the student and the teacher for\ndistillation at the same time. We hypothesize and empirically verify that\nwithout a projector, the student network tends to overfit the teacher's feature\ndistributions despite having different architecture and weights initialization.\nThis leads to degradation on the quality of the student's deep features that\nare eventually used in classification. Adding a projector, on the other hand,\ndisentangles the two learning tasks and helps the student network to focus\nbetter on the main feature extraction task while still being able to utilize\nteacher features as a guidance through the projector. Motivated by the positive\neffect of the projector in feature distillation, we propose an ensemble of\nprojectors to further improve the quality of student features. Experimental\nresults on different datasets with a series of teacher-student pairs illustrate\nthe effectiveness of the proposed method.\n","authors":["Yudong Chen","Sen Wang","Jiajun Liu","Xuwei Xu","Frank de Hoog","Zi Huang"],"pdf_url":"https://arxiv.org/pdf/2210.15274v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.00167v1","updated":"2023-03-01T01:45:28Z","published":"2023-03-01T01:45:28Z","title":"Sketch2Cloth: Sketch-based 3D Garment Generation with Unsigned Distance\n  Fields","summary":"  3D model reconstruction from a single image has achieved great progress with\nthe recent deep generative models. However, the conventional reconstruction\napproaches with template mesh deformation and implicit fields have difficulty\nin reconstructing non-watertight 3D mesh models, such as garments. In contrast\nto image-based modeling, the sketch-based approach can help users generate 3D\nmodels to meet the design intentions from hand-drawn sketches. In this study,\nwe propose Sketch2Cloth, a sketch-based 3D garment generation system using the\nunsigned distance fields from the user's sketch input. Sketch2Cloth first\nestimates the unsigned distance function of the target 3D model from the sketch\ninput, and extracts the mesh from the estimated field with Marching Cubes. We\nalso provide the model editing function to modify the generated mesh. We\nverified the proposed Sketch2Cloth with quantitative evaluations on garment\ngeneration and editing with a state-of-the-art approach.\n","authors":["Yi He","Haoran Xie","Kazunori Miyata"],"pdf_url":"https://arxiv.org/pdf/2303.00167v1.pdf","comment":"8 pages, 9 figures, video is here https://youtu.be/miisvVTpqj8"},{"id":"http://arxiv.org/abs/2303.00165v1","updated":"2023-03-01T01:37:24Z","published":"2023-03-01T01:37:24Z","title":"Diffusion Probabilistic Fields","summary":"  Diffusion probabilistic models have quickly become a major approach for\ngenerative modeling of images, 3D geometry, video and other domains. However,\nto adapt diffusion generative modeling to these domains the denoising network\nneeds to be carefully designed for each domain independently, oftentimes under\nthe assumption that data lives in a Euclidean grid. In this paper we introduce\nDiffusion Probabilistic Fields (DPF), a diffusion model that can learn\ndistributions over continuous functions defined over metric spaces, commonly\nknown as fields. We extend the formulation of diffusion probabilistic models to\ndeal with this field parametrization in an explicit way, enabling us to define\nan end-to-end learning algorithm that side-steps the requirement of\nrepresenting fields with latent vectors as in previous approaches (Dupont et\nal., 2022a; Du et al., 2021). We empirically show that, while using the same\ndenoising network, DPF effectively deals with different modalities like 2D\nimages and 3D geometry, in addition to modeling distributions over fields\ndefined on non-Euclidean metric spaces.\n","authors":["Peiye Zhuang","Samira Abnar","Jiatao Gu","Alex Schwing","Joshua M. Susskind","Miguel Ángel Bautista"],"pdf_url":"https://arxiv.org/pdf/2303.00165v1.pdf","comment":"Accepted to ICLR 2023. 20 pages, 17 figures"},{"id":"http://arxiv.org/abs/2210.10992v3","updated":"2023-03-01T01:30:41Z","published":"2022-10-20T03:35:05Z","title":"NIFT: Neural Interaction Field and Template for Object Manipulation","summary":"  We introduce NIFT, Neural Interaction Field and Template, a descriptive and\nrobust interaction representation of object manipulations to facilitate\nimitation learning. Given a few object manipulation demos, NIFT guides the\ngeneration of the interaction imitation for a new object instance by matching\nthe Neural Interaction Template (NIT) extracted from the demos in the target\nNeural Interaction Field (NIF) defined for the new object. Specifically, the\nNIF is a neural field that encodes the relationship between each spatial point\nand a given object, where the relative position is defined by a spherical\ndistance function rather than occupancies or signed distances, which are\ncommonly adopted by conventional neural fields but less informative. For a\ngiven demo interaction, the corresponding NIT is defined by a set of spatial\npoints sampled in the demo NIF with associated neural features. To better\ncapture the interaction, the points are sampled on the Interaction Bisector\nSurface (IBS), which consists of points that are equidistant to the two\ninteracting objects and has been used extensively for interaction\nrepresentation. With both point selection and pointwise features defined for\nbetter interaction encoding, NIT effectively guides the feature matching in the\nNIFs of the new object instances such that the relative poses are optimized to\nrealize the manipulation while imitating the demo interactions. Experiments\nshow that our NIFT solution outperforms state-of-the-art imitation learning\nmethods for object manipulation and generalizes better to objects from new\ncategories.\n","authors":["Zeyu Huang","Juzhan Xu","Sisi Dai","Kai Xu","Hao Zhang","Hui Huang","Ruizhen Hu"],"pdf_url":"https://arxiv.org/pdf/2210.10992v3.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2303.00157v1","updated":"2023-03-01T01:09:01Z","published":"2023-03-01T01:09:01Z","title":"Semi-supervised Parametric Real-world Image Harmonization","summary":"  Learning-based image harmonization techniques are usually trained to undo\nsynthetic random global transformations applied to a masked foreground in a\nsingle ground truth photo. This simulated data does not model many of the\nimportant appearance mismatches (illumination, object boundaries, etc.) between\nforeground and background in real composites, leading to models that do not\ngeneralize well and cannot model complex local changes. We propose a new\nsemi-supervised training strategy that addresses this problem and lets us learn\ncomplex local appearance harmonization from unpaired real composites, where\nforeground and background come from different images. Our model is fully\nparametric. It uses RGB curves to correct the global colors and tone and a\nshading map to model local variations. Our method outperforms previous work on\nestablished benchmarks and real composites, as shown in a user study, and\nprocesses high-resolution images interactively.\n","authors":["Ke Wang","Michaël Gharbi","He Zhang","Zhihao Xia","Eli Shechtman"],"pdf_url":"https://arxiv.org/pdf/2303.00157v1.pdf","comment":"19 pages, 16 figures, 5 tables"},{"id":"http://arxiv.org/abs/2303.00154v1","updated":"2023-03-01T00:56:39Z","published":"2023-03-01T00:56:39Z","title":"Neural inverse procedural modeling of knitting yarns from images","summary":"  We investigate the capabilities of neural inverse procedural modeling to\ninfer high-quality procedural yarn models with fiber-level details from single\nimages of depicted yarn samples. While directly inferring all parameters of the\nunderlying yarn model based on a single neural network may seem an intuitive\nchoice, we show that the complexity of yarn structures in terms of twisting and\nmigration characteristics of the involved fibers can be better encountered in\nterms of ensembles of networks that focus on individual characteristics. We\nanalyze the effect of different loss functions including a parameter loss to\npenalize the deviation of inferred parameters to ground truth annotations, a\nreconstruction loss to enforce similar statistics of the image generated for\nthe estimated parameters in comparison to training images as well as an\nadditional regularization term to explicitly penalize deviations between latent\ncodes of synthetic images and the average latent code of real images in the\nlatent space of the encoder. We demonstrate that the combination of a carefully\ndesigned parametric, procedural yarn model with respective network ensembles as\nwell as loss functions even allows robust parameter inference when solely\ntrained on synthetic data. Since our approach relies on the availability of a\nyarn database with parameter annotations and we are not aware of such a\nrespectively available dataset, we additionally provide, to the best of our\nknowledge, the first dataset of yarn images with annotations regarding the\nrespective yarn parameters. For this purpose, we use a novel yarn generator\nthat improves the realism of the produced results over previous approaches.\n","authors":["Elena Trunz","Jonathan Klein","Jan Müller","Lukas Bode","Ralf Sarlette","Michael Weinmann","Reinhard Klein"],"pdf_url":"https://arxiv.org/pdf/2303.00154v1.pdf","comment":"23 pages, 16 figures"},{"id":"http://arxiv.org/abs/2208.04202v2","updated":"2023-03-01T00:18:33Z","published":"2022-08-08T15:08:40Z","title":"Analog Bits: Generating Discrete Data using Diffusion Models with\n  Self-Conditioning","summary":"  We present Bit Diffusion: a simple and generic approach for generating\ndiscrete data with continuous state and continuous time diffusion models. The\nmain idea behind our approach is to first represent the discrete data as binary\nbits, and then train a continuous diffusion model to model these bits as real\nnumbers which we call analog bits. To generate samples, the model first\ngenerates the analog bits, which are then thresholded to obtain the bits that\nrepresent the discrete variables. We further propose two simple techniques,\nnamely Self-Conditioning and Asymmetric Time Intervals, which lead to a\nsignificant improvement in sample quality. Despite its simplicity, the proposed\napproach can achieve strong performance in both discrete image generation and\nimage captioning tasks. For discrete image generation, we significantly improve\nprevious state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens)\nand ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the\nbest autoregressive model in both sample quality (measured by FID) and\nefficiency. For image captioning on MS-COCO dataset, our approach achieves\ncompetitive results compared to autoregressive models.\n","authors":["Ting Chen","Ruixiang Zhang","Geoffrey Hinton"],"pdf_url":"https://arxiv.org/pdf/2208.04202v2.pdf","comment":"ICLR'23"},{"id":"http://arxiv.org/abs/2209.07725v3","updated":"2023-03-01T23:49:35Z","published":"2022-09-16T05:14:08Z","title":"VINet: Visual and Inertial-based Terrain Classification and Adaptive\n  Navigation over Unknown Terrain","summary":"  We present a visual and inertial-based terrain classification network (VINet)\nfor robotic navigation over different traversable surfaces. We use a novel\nnavigation-based labeling scheme for terrain classification and generalization\non unknown surfaces. Our proposed perception method and adaptive scheduling\ncontrol framework can make predictions according to terrain navigation\nproperties and lead to better performance on both terrain classification and\nnavigation control on known and unknown surfaces. Our VINet can achieve 98.37%\nin terms of accuracy under supervised setting on known terrains and improve the\naccuracy by 8.51% on unknown terrains compared to previous methods. We deploy\nVINet on a mobile tracked robot for trajectory following and navigation on\ndifferent terrains, and we demonstrate an improvement of 10.3% compared to a\nbaseline controller in terms of RMSE.\n","authors":["Tianrui Guan","Ruitao Song","Zhixian Ye","Liangjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.07725v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00865v1","updated":"2023-03-01T23:37:45Z","published":"2023-03-01T23:37:45Z","title":"AMIGO: Sparse Multi-Modal Graph Transformer with Shared-Context\n  Processing for Representation Learning of Giga-pixel Images","summary":"  Processing giga-pixel whole slide histopathology images (WSI) is a\ncomputationally expensive task. Multiple instance learning (MIL) has become the\nconventional approach to process WSIs, in which these images are split into\nsmaller patches for further processing. However, MIL-based techniques ignore\nexplicit information about the individual cells within a patch. In this paper,\nby defining the novel concept of shared-context processing, we designed a\nmulti-modal Graph Transformer (AMIGO) that uses the celluar graph within the\ntissue to provide a single representation for a patient while taking advantage\nof the hierarchical structure of the tissue, enabling a dynamic focus between\ncell-level and tissue-level information. We benchmarked the performance of our\nmodel against multiple state-of-the-art methods in survival prediction and\nshowed that ours can significantly outperform all of them including\nhierarchical Vision Transformer (ViT). More importantly, we show that our model\nis strongly robust to missing information to an extent that it can achieve the\nsame performance with as low as 20% of the data. Finally, in two different\ncancer datasets, we demonstrated that our model was able to stratify the\npatients into low-risk and high-risk groups while other state-of-the-art\nmethods failed to achieve this goal. We also publish a large dataset of\nimmunohistochemistry images (InUIT) containing 1,600 tissue microarray (TMA)\ncores from 188 patients along with their survival information, making it one of\nthe largest publicly available datasets in this context.\n","authors":["Ramin Nakhli","Puria Azadi Moghadam","Haoyang Mi","Hossein Farahani","Alexander Baras","Blake Gilks","Ali Bashashati"],"pdf_url":"https://arxiv.org/pdf/2303.00865v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00855v1","updated":"2023-03-01T22:58:50Z","published":"2023-03-01T22:58:50Z","title":"Grounded Decoding: Guiding Text Generation with Grounded Models for\n  Robot Control","summary":"  Recent progress in large language models (LLMs) has demonstrated the ability\nto learn and leverage Internet-scale knowledge through pre-training with\nautoregressive models. Unfortunately, applying such models to settings with\nembodied agents, such as robots, is challenging due to their lack of experience\nwith the physical world, inability to parse non-language observations, and\nignorance of rewards or safety constraints that robots may require. On the\nother hand, language-conditioned robotic policies that learn from interaction\ndata can provide the necessary grounding that allows the agent to be correctly\nsituated in the real world, but such policies are limited by the lack of\nhigh-level semantic understanding due to the limited breadth of the interaction\ndata available for training them. Thus, if we want to make use of the semantic\nknowledge in a language model while still situating it in an embodied setting,\nwe must construct an action sequence that is both likely according to the\nlanguage model and also realizable according to grounded models of the\nenvironment. We frame this as a problem similar to probabilistic filtering:\ndecode a sequence that both has high probability under the language model and\nhigh probability under a set of grounded model objectives. We demonstrate this\nguided decoding strategy is able to solve complex, long-horizon embodiment\ntasks in a robotic setting by leveraging the knowledge of both models. The\nproject's website can be found at grounded-decoding.github.io.\n","authors":["Wenlong Huang","Fei Xia","Dhruv Shah","Danny Driess","Andy Zeng","Yao Lu","Pete Florence","Igor Mordatch","Sergey Levine","Karol Hausman","Brian Ichter"],"pdf_url":"https://arxiv.org/pdf/2303.00855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.13443v2","updated":"2023-03-01T21:02:26Z","published":"2021-12-26T19:31:34Z","title":"Sinogram upsampling using Primal-Dual UNet for undersampled CT and\n  radial MRI reconstruction","summary":"  Computed tomography and magnetic resonance imaging are two widely used\nclinical imaging modalities for non-invasive diagnosis. However, both of these\nmodalities come with certain problems. CT uses harmful ionising radiation, and\nMRI suffers from slow acquisition speed. Both problems can be tackled by\nundersampling, such as sparse sampling. However, such undersampled data leads\nto lower resolution and introduces artefacts. Several techniques, including\ndeep learning based methods, have been proposed to reconstruct such data.\nHowever, the undersampled reconstruction problem for these two modalities was\nalways considered as two different problems and tackled separately by different\nresearch works. This paper proposes a unified solution for both sparse CT and\nundersampled radial MRI reconstruction, achieved by applying Fourier\ntransform-based pre-processing on the radial MRI and then finally\nreconstructing both modalities using sinogram upsampling combined with filtered\nback-projection. The Primal-Dual network is a deep learning based method for\nreconstructing sparsely-sampled CT data. This paper introduces Primal-Dual\nUNet, which improves the Primal-Dual network in terms of accuracy and\nreconstruction speed. The proposed method resulted in an average SSIM of\n0.932\\textpm0.021 while performing sparse CT reconstruction for fan-beam\ngeometry with a sparsity level of 16, achieving a statistically significant\nimprovement over the previous model, which resulted in 0.919\\textpm0.016.\nFurthermore, the proposed model resulted in 0.903\\textpm0.019 and\n0.957\\textpm0.023 average SSIM while reconstructing undersampled brain and\nabdominal MRI data with an acceleration factor of 16, respectively -\nstatistically significant improvements over the original model, which resulted\nin 0.867\\textpm0.025 and 0.949\\textpm0.025.\n","authors":["Philipp Ernst","Soumick Chatterjee","Georg Rose","Oliver Speck","Andreas Nürnberger"],"pdf_url":"https://arxiv.org/pdf/2112.13443v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06725v2","updated":"2023-03-01T20:50:07Z","published":"2022-06-14T10:16:54Z","title":"Automated SSIM Regression for Detection and Quantification of Motion\n  Artefacts in Brain MR Images","summary":"  Motion artefacts in magnetic resonance brain images can have a strong impact\non diagnostic confidence. The assessment of MR image quality is fundamental\nbefore proceeding with the clinical diagnosis. Motion artefacts can alter the\ndelineation of structures such as the brain, lesions or tumours and may require\na repeat scan. Otherwise, an inaccurate (e.g. correct pathology but wrong\nseverity) or incorrect diagnosis (e.g. wrong pathology) may occur.\n\"\\textit{Image quality assessment}\" as a fast, automated step right after\nscanning can assist in deciding if the acquired images are diagnostically\nsufficient. An automated image quality assessment based on the structural\nsimilarity index (SSIM) regression through a residual neural network is\nproposed in this work. Additionally, a classification into different groups -\nby subdividing with SSIM ranges - is evaluated. Importantly, this method\npredicts SSIM values of an input image in the absence of a reference ground\ntruth image. The networks were able to detect motion artefacts, and the best\nperformance for the regression and classification task has always been achieved\nwith ResNet-18 with contrast augmentation. The mean and standard deviation of\nresiduals' distribution were $\\mu=-0.0009$ and $\\sigma=0.0139$, respectively.\nWhilst for the classification task in 3, 5 and 10 classes, the best accuracies\nwere 97, 95 and 89\\%, respectively. The results show that the proposed method\ncould be a tool for supporting neuro-radiologists and radiographers in\nevaluating image quality quickly.\n","authors":["Alessandro Sciarra","Soumick Chatterjee","Max Dünnwald","Giuseppe Placidi","Andreas Nürnberger","Oliver Speck","Steffen Oeltze-Jafra"],"pdf_url":"https://arxiv.org/pdf/2206.06725v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00818v1","updated":"2023-03-01T20:39:46Z","published":"2023-03-01T20:39:46Z","title":"Improving Model's Focus Improves Performance of Deep Learning-Based\n  Synthetic Face Detectors","summary":"  Deep learning-based models generalize better to unknown data samples after\nbeing guided \"where to look\" by incorporating human perception into training\nstrategies. We made an observation that the entropy of the model's salience\ntrained in that way is lower when compared to salience entropy computed for\nmodels training without human perceptual intelligence. Thus the question: does\nfurther increase of model's focus, by lowering the entropy of model's class\nactivation map, help in further increasing the performance? In this paper we\npropose and evaluate several entropy-based new loss function components\ncontrolling the model's focus, covering the full range of the level of such\ncontrol, from none to its \"aggressive\" minimization. We show, using a problem\nof synthetic face detection, that improving the model's focus, through lowering\nentropy, leads to models that perform better in an open-set scenario, in which\nthe test samples are synthesized by unknown generative models. We also show\nthat optimal performance is obtained when the model's loss function blends\nthree aspects: regular classification, low-entropy of the model's focus, and\nhuman-guided saliency.\n","authors":["Jacob Piland","Adam Czajka","Christopher Sweet"],"pdf_url":"https://arxiv.org/pdf/2303.00818v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2206.09034v4","updated":"2023-03-01T20:36:43Z","published":"2022-06-17T22:23:11Z","title":"Towards Better Selective Classification","summary":"  We tackle the problem of Selective Classification where the objective is to\nachieve the best performance on a predetermined ratio (coverage) of the\ndataset. Recent state-of-the-art selective methods come with architectural\nchanges either via introducing a separate selection head or an extra abstention\nlogit. In this paper, we challenge the aforementioned methods. The results\nsuggest that the superior performance of state-of-the-art methods is owed to\ntraining a more generalizable classifier rather than their proposed selection\nmechanisms. We argue that the best performing selection mechanism should\ninstead be rooted in the classifier itself. Our proposed selection strategy\nuses the classification scores and achieves better results by a significant\nmargin, consistently, across all coverages and all datasets, without any added\ncompute cost. Furthermore, inspired by semi-supervised learning, we propose an\nentropy-based regularizer that improves the performance of selective\nclassification methods. Our proposed selection mechanism with the proposed\nentropy-based regularizer achieves new state-of-the-art results.\n","authors":["Leo Feng","Mohamed Osama Ahmed","Hossein Hajimirsadeghi","Amir Abdi"],"pdf_url":"https://arxiv.org/pdf/2206.09034v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05282v3","updated":"2023-03-01T20:24:58Z","published":"2022-06-10T07:09:28Z","title":"Learning to Estimate Shapley Values with Vision Transformers","summary":"  Transformers have become a default architecture in computer vision, but\nunderstanding what drives their predictions remains a challenging problem.\nCurrent explanation approaches rely on attention values or input gradients, but\nthese provide a limited view of a model's dependencies. Shapley values offer a\ntheoretically sound alternative, but their computational cost makes them\nimpractical for large, high-dimensional models. In this work, we aim to make\nShapley values practical for vision transformers (ViTs). To do so, we first\nleverage an attention masking approach to evaluate ViTs with partial\ninformation, and we then develop a procedure to generate Shapley value\nexplanations via a separate, learned explainer model. Our experiments compare\nShapley values to many baseline methods (e.g., attention rollout, GradCAM,\nLRP), and we find that our approach provides more accurate explanations than\nexisting methods for ViTs.\n","authors":["Ian Covert","Chanwoo Kim","Su-In Lee"],"pdf_url":"https://arxiv.org/pdf/2206.05282v3.pdf","comment":"ICLR 2023 camera-ready"},{"id":"http://arxiv.org/abs/2210.11924v2","updated":"2023-03-01T19:58:01Z","published":"2022-10-21T12:50:15Z","title":"Men Also Do Laundry: Multi-Attribute Bias Amplification","summary":"  As computer vision systems become more widely deployed, there is increasing\nconcern from both the research community and the public that these systems are\nnot only reproducing but amplifying harmful social biases. The phenomenon of\nbias amplification, which is the focus of this work, refers to models\namplifying inherent training set biases at test time. Existing metrics measure\nbias amplification with respect to single annotated attributes (e.g.,\n$\\texttt{computer}$). However, several visual datasets consist of images with\nmultiple attribute annotations. We show models can learn to exploit\ncorrelations with respect to multiple attributes (e.g., {$\\texttt{computer}$,\n$\\texttt{keyboard}$}), which are not accounted for by current metrics. In\naddition, we show current metrics can give the erroneous impression that\nminimal or no bias amplification has occurred as they involve aggregating over\npositive and negative values. Further, these metrics lack a clear desired\nvalue, making them difficult to interpret. To address these shortcomings, we\npropose a new metric: Multi-Attribute Bias Amplification. We validate our\nproposed metric through an analysis of gender bias amplification on the COCO\nand imSitu datasets. Finally, we benchmark bias mitigation methods using our\nproposed metric, suggesting possible avenues for future bias mitigation\n","authors":["Dora Zhao","Jerone T. A. Andrews","Alice Xiang"],"pdf_url":"https://arxiv.org/pdf/2210.11924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13224v2","updated":"2023-03-01T19:54:06Z","published":"2022-08-28T13:58:54Z","title":"Deep learning for automatic head and neck lymph node level delineation\n  provides expert-level accuracy","summary":"  Background: Deep learning (DL)-based head and neck lymph node level (HN_LNL)\nautodelineation is of high relevance to radiotherapy research and clinical\ntreatment planning but still underinvestigated in academic literature. Methods:\nAn expert-delineated cohort of 35 planning CTs was used for training of an\nnnU-net 3D-fullres/2D-ensemble model for autosegmentation of 20 different\nHN_LNL. A second cohort acquired at the same institution later in time served\nas the test set (n=20). In a completely blinded evaluation, 3 clinical experts\nrated the quality of DL autosegmentations in a head-to-head comparison with\nexpert-created contours. For a subgroup of 10 cases, intraobserver variability\nwas compared to the average DL autosegmentation accuracy on the original and\nrecontoured set of expert segmentations. A postprocessing step to adjust\ncraniocaudal boundaries of level autosegmentations to the CT slice plane was\nintroduced and the effect on geometric accuracy and expert rating was\ninvestigated. Results: Blinded expert ratings for DL segmentations and\nexpert-created contours were not significantly different. DL segmentations with\nslice plane adjustment were rated numerically higher (mean, 81.0 vs.\n79.6,p=0.185) and DL segmentations without slice plane adjustment were rated\nnumerically lower (77.2 vs. 79.6,p=0.167) than manually drawn contours. DL\nsegmentations with CT slice plane adjustment were rated significantly better\nthan DL contours without slice plane adjustment (81.0 vs. 77.2,p=0.004).\nGeometric accuracy of DL segmentations was not different from intraobserver\nvariability (mean, 0.76 vs. 0.77, p=0.307). Conclusions: We show that a nnU-net\n3D-fullres/2D-ensemble model can be used for highly accurate autodelineation of\nHN_LNL using only a limited training dataset that is ideally suited for\nlarge-scale standardized autodelineation of HN_LNL in the research setting.\n","authors":["Thomas Weissmann","Yixing Huang","Stefan Fischer","Johannes Roesch","Sina Mansoorian","Horacio Ayala Gaona","Antoniu-Oreste Gostian","Markus Hecht","Sebastian Lettmaier","Lisa Deloch","Benjamin Frey","Udo S. Gaipl","Luitpold V. Distel","Andreas Maier","Heinrich Iro","Sabine Semrau","Christoph Bert","Rainer Fietkau","Florian Putz"],"pdf_url":"https://arxiv.org/pdf/2208.13224v2.pdf","comment":"14 pages, 6 figures, published in Frontiers in Oncology"},{"id":"http://arxiv.org/abs/2303.00795v1","updated":"2023-03-01T19:48:45Z","published":"2023-03-01T19:48:45Z","title":"Improved Segmentation of Deep Sulci in Cortical Gray Matter Using a Deep\n  Learning Framework Incorporating Laplace's Equation","summary":"  When developing tools for automated cortical segmentation, the ability to\nproduce topologically correct segmentations is important in order to compute\ngeometrically valid morphometry measures. In practice, accurate cortical\nsegmentation is challenged by image artifacts and the highly convoluted anatomy\nof the cortex itself. To address this, we propose a novel deep learning-based\ncortical segmentation method in which prior knowledge about the geometry of the\ncortex is incorporated into the network during the training process. We design\na loss function which uses the theory of Laplace's equation applied to the\ncortex to locally penalize unresolved boundaries between tightly folded sulci.\nUsing an ex vivo MRI dataset of human medial temporal lobe specimens, we\ndemonstrate that our approach outperforms baseline segmentation networks, both\nquantitatively and qualitatively.\n","authors":["Sadhana Ravikumar","Ranjit Itttyerah","Sydney Lim","Long Xie","Sandhitsu Das","Pulkit Khandelwal","Laura E. M. Wisse","Madigan L. Bedard","John L. Robinson","Terry Schuck","Murray Grossman","John Q. Trojanowski","Edward B. Lee","M. Dylan Tisdall","Karthik Prabhakaran","John A. Detre","David J. Irwin","Winifred Trotman","Gabor Mizsei","Emilio Artacho-Pérula","Maria Mercedes Iñiguez de Onzono Martin","Maria del Mar Arroyo Jiménez","Monica Muñoz","Francisco Javier Molina Romero","Maria del Pilar Marcos Rabal","Sandra Cebada-Sánchez","José Carlos Delgado González","Carlos de la Rosa-Prieto","Marta Córcoles Parada","David A. Wolk","Ricardo Insausti","Paul A. Yushkevich"],"pdf_url":"https://arxiv.org/pdf/2303.00795v1.pdf","comment":"Accepted at the 28th biennial international conference on Information\n  Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/2210.09461v3","updated":"2023-03-01T19:45:11Z","published":"2022-10-17T22:23:40Z","title":"Token Merging: Your ViT But Faster","summary":"  We introduce Token Merging (ToMe), a simple method to increase the throughput\nof existing ViT models without needing to train. ToMe gradually combines\nsimilar tokens in a transformer using a general and light-weight matching\nalgorithm that is as fast as pruning while being more accurate. Off-the-shelf,\nToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518\nmodels on images and 2.2x the throughput of ViT-L on video with only a 0.2-0.3%\naccuracy drop in each case. ToMe can also easily be applied during training,\nimproving in practice training speed up to 2x for MAE fine-tuning on video.\nTraining with ToMe further minimizes accuracy drop, leading to 2x the\nthroughput of ViT-B on audio for only a 0.4% mAP drop. Qualitatively, we find\nthat ToMe merges object parts into one token, even over multiple frames of\nvideo. Overall, ToMe's accuracy and speed are competitive with state-of-the-art\non images, video, and audio.\n","authors":["Daniel Bolya","Cheng-Yang Fu","Xiaoliang Dai","Peizhao Zhang","Christoph Feichtenhofer","Judy Hoffman"],"pdf_url":"https://arxiv.org/pdf/2210.09461v3.pdf","comment":"Accepted ICLR 2023 Oral (top 5%) [final v2]. This version includes\n  stable diffusion experiments. See code at\n  https://github.com/facebookresearch/ToMe"},{"id":"http://arxiv.org/abs/2210.07998v2","updated":"2023-03-01T19:03:18Z","published":"2022-10-14T17:54:01Z","title":"$Λ$-DARTS: Mitigating Performance Collapse by Harmonizing\n  Operation Selection among Cells","summary":"  Differentiable neural architecture search (DARTS) is a popular method for\nneural architecture search (NAS), which performs cell-search and utilizes\ncontinuous relaxation to improve the search efficiency via gradient-based\noptimization. The main shortcoming of DARTS is performance collapse, where the\ndiscovered architecture suffers from a pattern of declining quality during\nsearch. Performance collapse has become an important topic of research, with\nmany methods trying to solve the issue through either regularization or\nfundamental changes to DARTS. However, the weight-sharing framework used for\ncell-search in DARTS and the convergence of architecture parameters has not\nbeen analyzed yet. In this paper, we provide a thorough and novel theoretical\nand empirical analysis on DARTS and its point of convergence. We show that\nDARTS suffers from a specific structural flaw due to its weight-sharing\nframework that limits the convergence of DARTS to saturation points of the\nsoftmax function. This point of convergence gives an unfair advantage to layers\ncloser to the output in choosing the optimal architecture, causing performance\ncollapse. We then propose two new regularization terms that aim to prevent\nperformance collapse by harmonizing operation selection via aligning gradients\nof layers. Experimental results on six different search spaces and three\ndifferent datasets show that our method ($\\Lambda$-DARTS) does indeed prevent\nperformance collapse, providing justification for our theoretical analysis and\nthe proposed remedy.\n","authors":["Sajad Movahedi","Melika Adabinejad","Ayyoob Imani","Arezou Keshavarz","Mostafa Dehghani","Azadeh Shakery","Babak N. Araabi"],"pdf_url":"https://arxiv.org/pdf/2210.07998v2.pdf","comment":"Published as a conference paper at ICLR 2023"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.00720v1","updated":"2023-03-01T18:26:14Z","published":"2023-03-01T18:26:14Z","title":"Cross-Modal Entity Matching for Visually Rich Documents","summary":"  Visually rich documents (VRD) are physical/digital documents that utilize\nvisual cues to augment their semantics. The information contained in these\ndocuments are often incomplete. Existing works that enable automated querying\non VRDs do not take this aspect into account. Consequently, they support a\nlimited set of queries. In this paper, we describe Juno -- a multimodal\nframework that identifies a set of tuples from a relational database to augment\nan incomplete VRD with supplementary information. Our main contribution in this\nis an end-to-end-trainable neural network with bi-directional attention that\nexecutes this cross-modal entity matching task without any prior knowledge\nabout the document type or the underlying database-schema. Exhaustive\nexperiments on two heteroegeneous datasets show that Juno outperforms\nstate-of-the-art baselines by more than 6% in F1-score, while reducing the\namount of human-effort in its workflow by more than 80%. To the best of our\nknowledge, ours is the first work that investigates the incompleteness of VRDs\nand proposes a robust framework to address it in a seamless way.\n","authors":["Ritesh Sarkhel","Arnab Nandi"],"pdf_url":"https://arxiv.org/pdf/2303.00720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12000v2","updated":"2023-03-01T12:43:16Z","published":"2023-02-22T12:02:23Z","title":"Graph Construction using Principal Axis Trees for Simple Graph\n  Convolution","summary":"  Graph Neural Networks (GNNs) are increasingly becoming the favorite method\nfor graph learning. They exploit the semi-supervised nature of deep learning,\nand they bypass computational bottlenecks associated with traditional graph\nlearning methods. In addition to the feature matrix $X$, GNNs need an adjacency\nmatrix $A$ to perform feature propagation. In many cases the adjacency matrix\n$A$ is missing. We introduce a graph construction scheme that construct the\nadjacency matrix $A$ using unsupervised and supervised information.\nUnsupervised information characterize the neighborhood around points. We used\nPrincipal Axis trees (PA-trees) as a source of unsupervised information, where\nwe create edges between points falling onto the same leaf node. For supervised\ninformation, we used the concept of penalty and intrinsic graphs. A penalty\ngraph connects points with different class labels, whereas intrinsic graph\nconnects points with the same class label. We used the penalty and intrinsic\ngraphs to remove or add edges to the graph constructed via PA-tree. This graph\nconstruction scheme was tested on two well-known GNNs: 1) Graph Convolutional\nNetwork (GCN) and 2) Simple Graph Convolution (SGC). The experiments show that\nit is better to use SGC because it is faster and delivers better or the same\nresults as GCN. We also test the effect of oversmoothing on both GCN and SGC.\nWe found out that the level of smoothing has to be selected carefully for SGC\nto avoid oversmoothing.\n","authors":["Mashaan Alshammari","John Stavrakakis","Adel F. Ahmed","Masahiro Takatsuka"],"pdf_url":"https://arxiv.org/pdf/2302.12000v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00400v1","updated":"2023-03-01T10:39:58Z","published":"2023-03-01T10:39:58Z","title":"A Study on Accuracy, Miscalibration, and Popularity Bias in\n  Recommendations","summary":"  Recent research has suggested different metrics to measure the inconsistency\nof recommendation performance, including the accuracy difference between user\ngroups, miscalibration, and popularity lift. However, a study that relates\nmiscalibration and popularity lift to recommendation accuracy across different\nuser groups is still missing. Additionally, it is unclear if particular genres\ncontribute to the emergence of inconsistency in recommendation performance\nacross user groups. In this paper, we present an analysis of these three\naspects of five well-known recommendation algorithms for user groups that\ndiffer in their preference for popular content. Additionally, we study how\ndifferent genres affect the inconsistency of recommendation performance, and\nhow this is aligned with the popularity of the genres. Using data from LastFm,\nMovieLens, and MyAnimeList, we present two key findings. First, we find that\nusers with little interest in popular content receive the worst recommendation\naccuracy, and that this is aligned with miscalibration and popularity lift.\nSecond, our experiments show that particular genres contribute to a different\nextent to the inconsistency of recommendation performance, especially in terms\nof miscalibration in the case of the MyAnimeList dataset.\n","authors":["Dominik Kowald","Gregor Mayr","Markus Schedl","Elisabeth Lex"],"pdf_url":"https://arxiv.org/pdf/2303.00400v1.pdf","comment":"Accepted at BIAS@ECIR WS 2023"},{"id":"http://arxiv.org/abs/2303.00386v1","updated":"2023-03-01T10:11:50Z","published":"2023-03-01T10:11:50Z","title":"Authorship Conflicts in Academia: an International Cross-Discipline\n  Survey","summary":"  Collaboration among scholars has emerged as a significant characteristic of\ncontemporary science. As a result, the number of authors listed in publications\ncontinues to rise steadily. Unfortunately, determining the authors to be\nincluded in the byline and their respective order entails multiple difficulties\nwhich often lead to conflicts. Despite the large volume of literature about\nconflicts in academia, it remains unclear how exactly it is distributed over\nthe main socio-demographic properties, as well as the different types of\ninteractions academics experience. To address this gap, we conducted an\ninternational and cross-disciplinary survey answered by 752 academics from 41\nfields of research and 93 countries that statistically well-represent the\noverall academic workforce. Our findings are concerning and suggest that\nauthorship credit conflicts arise very early in one's academic career, even at\nthe level of Master and Ph.D., and become increasingly common over time.\n","authors":["Elizaveta Savchenko","Teddy Lazebnik","Ariel Rosenfeld"],"pdf_url":"https://arxiv.org/pdf/2303.00386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02817v2","updated":"2023-03-01T09:58:16Z","published":"2023-01-07T09:36:35Z","title":"Cost-optimal Seeding Strategy During a Botanical Pandemic in\n  Domesticated Fields","summary":"  Context: Botanical pandemics cause enormous economic damage and food shortage\naround the globe. However, since botanical pandemics are here to stay in the\nshort-medium term, domesticated field owners can strategically seed their\nfields to optimize each session's economic profit. Objective: Given the\npathogen's epidemiological properties, we aim to find an economically optimal\ngrid-based seeding strategy for field owners and policymakers. Methods: We\npropose a novel epidemiological-economic mathematical model that describes the\neconomic profit from a field of plants during a botanical pandemic. We describe\nthe epidemiological dynamics using a spatio-temporal extended\nSusceptible-Infected-Recovered epidemiological model with a non-linear output\nepidemiological model. Results and Conclusions: We provide an algorithm to\nobtain an optimal grid-formed seeding strategy to maximize economic profit,\ngiven field and pathogen properties. In addition, we implement the proposed\nmodel in realistic settings, analyzing the sensitivity of the economic profit\nas a function of several epidemiological and economic properties. We show that\nthe recovery and basic infection rates have a similar economic influence.\nUnintuitively, we show that in the context of a botanic pandemic, a larger farm\ndoes not promise higher economic profit. Significance: Our results demonstrate\na significant benefit of using the proposed seeding strategy and shed more\nlight on the dynamics of the botanical pandemic in domesticated fields.\n","authors":["Teddy Lazebnik"],"pdf_url":"https://arxiv.org/pdf/2301.02817v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00311v1","updated":"2023-03-01T08:15:48Z","published":"2023-03-01T08:15:48Z","title":"Modeling Multiple User Interests using Hierarchical Knowledge for\n  Conversational Recommender System","summary":"  A conversational recommender system (CRS) is a practical application for item\nrecommendation through natural language conversation. Such a system estimates\nuser interests for appropriate personalized recommendations. Users sometimes\nhave various interests in different categories or genres, but existing studies\nassume a unique user interest that can be covered by closely related items. In\nthis work, we propose to model such multiple user interests in CRS. We\ninvestigated its effects in experiments using the ReDial dataset and found that\nthe proposed method can recommend a wider variety of items than that of the\nbaseline CR-Walker.\n","authors":["Yuka Okuda","Katsuhito Sudoh","Seitaro Shinagawa","Satoshi Nakamura"],"pdf_url":"https://arxiv.org/pdf/2303.00311v1.pdf","comment":"Accepted as a conference paper at IWSDS 2023"},{"id":"http://arxiv.org/abs/2303.00279v1","updated":"2023-03-01T07:01:29Z","published":"2023-03-01T07:01:29Z","title":"Coarse-to-Fine Covid-19 Segmentation via Vision-Language Alignment","summary":"  Segmentation of COVID-19 lesions can assist physicians in better diagnosis\nand treatment of COVID-19. However, there are few relevant studies due to the\nlack of detailed information and high-quality annotation in the COVID-19\ndataset. To solve the above problem, we propose C2FVL, a Coarse-to-Fine\nsegmentation framework via Vision-Language alignment to merge text information\ncontaining the number of lesions and specific locations of image information.\nThe introduction of text information allows the network to achieve better\nprediction results on challenging datasets. We conduct extensive experiments on\ntwo COVID-19 datasets including chest X-ray and CT, and the results demonstrate\nthat our proposed method outperforms other state-of-the-art segmentation\nmethods.\n","authors":["Dandan Shan","Zihan Li","Wentao Chen","Qingde Li","Jie Tian","Qingqi Hong"],"pdf_url":"https://arxiv.org/pdf/2303.00279v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00276v1","updated":"2023-03-01T06:55:43Z","published":"2023-03-01T06:55:43Z","title":"Entire Space Learning Framework: Unbias Conversion Rate Prediction in\n  Full Stages of Recommender System","summary":"  Recommender system is an essential part of online services, especially for\ne-commerce platform. Conversion Rate (CVR) prediction in RS plays a significant\nrole in optimizing Gross Merchandise Volume (GMV) goal of e-commerce. However,\nCVR suffers from well-known Sample Selection Bias (SSB) and Data Sparsity (DS)\nproblems. Although existing methods ESMM and ESM2 train with all impression\nsamples over the entire space by modeling user behavior paths, SSB and DS\nproblems still exist. In real practice, the online inference space are samples\nfrom previous stage of RS process, rather than the impression space modeled by\nexisting methods. Moreover, existing methods solve the DS problem mainly by\nbuilding behavior paths of their own specific scene, ignoring the behaviors in\nvarious scenes of e-commerce platform. In this paper, we propose Entire Space\nLearning Framework: Unbias Conversion Rate Prediction in Full Stages of\nRecommender System, solving SSB and DS problems by reformulating GMV goal in a\nnovel manner. Specifically, we rebuild the CVR on the entire data space with\nsamples from previous stage of RS process, unifying training and online\ninference space. Moreover, we explicitly introduce purchase samples from other\nscenes of e-commerce platform in model learning process. Online A/B test and\noffline experiments show the superiority of our framework. Our framework has\nbeen deployed in rank stage of Taobao recommendation, providing recommendation\nservice for hundreds of millions of consumers everyday.\n","authors":["Shanshan Lyu","Qiwei Chen","Tao Zhuang","Junfeng Ge"],"pdf_url":"https://arxiv.org/pdf/2303.00276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00243v1","updated":"2023-03-01T05:46:36Z","published":"2023-03-01T05:46:36Z","title":"GUESR: A Global Unsupervised Data-Enhancement with Bucket-Cluster\n  Sampling for Sequential Recommendation","summary":"  Sequential Recommendation is a widely studied paradigm for learning users'\ndynamic interests from historical interactions for predicting the next\npotential item. Although lots of research work has achieved remarkable\nprogress, they are still plagued by the common issues: data sparsity of limited\nsupervised signals and data noise of accidentally clicking. To this end,\nseveral works have attempted to address these issues, which ignored the complex\nassociation of items across several sequences. Along this line, with the aim of\nlearning representative item embedding to alleviate this dilemma, we propose\nGUESR, from the view of graph contrastive learning. Specifically, we first\nconstruct the Global Item Relationship Graph (GIRG) from all interaction\nsequences and present the Bucket-Cluster Sampling (BCS) method to conduct the\nsub-graphs. Then, graph contrastive learning on this reduced graph is developed\nto enhance item representations with complex associations from the global view.\nWe subsequently extend the CapsNet module with the elaborately introduced\ntarget-attention mechanism to derive users' dynamic preferences. Extensive\nexperimental results have demonstrated our proposed GUESR could not only\nachieve significant improvements but also could be regarded as a general\nenhancement strategy to improve the performance in combination with other\nsequential recommendation methods.\n","authors":["Yongqiang Han","Likang Wu","Hao Wang","Guifeng Wang","Mengdi Zhang","Zhi Li","Defu Lian","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00168v1","updated":"2023-03-01T01:46:52Z","published":"2023-03-01T01:46:52Z","title":"REASONER: An Explainable Recommendation Dataset with Multi-aspect Real\n  User Labeled Ground Truths Towards more Measurable Explainable Recommendation","summary":"  Explainable recommendation has attracted much attention from the industry and\nacademic communities. It has shown great potential for improving the\nrecommendation persuasiveness, informativeness and user satisfaction. Despite a\nlot of promising explainable recommender models have been proposed in the past\nfew years, the evaluation strategies of these models suffer from several\nlimitations. For example, the explanation ground truths are not labeled by real\nusers, the explanations are mostly evaluated based on only one aspect and the\nevaluation strategies can be hard to unify. To alleviate the above problems, we\npropose to build an explainable recommendation dataset with multi-aspect real\nuser labeled ground truths. In specific, we firstly develop a video\nrecommendation platform, where a series of questions around the recommendation\nexplainability are carefully designed. Then, we recruit about 3000 users with\ndifferent backgrounds to use the system, and collect their behaviors and\nfeedback to our questions. In this paper, we detail the construction process of\nour dataset and also provide extensive analysis on its characteristics. In\naddition, we develop a library, where ten well-known explainable recommender\nmodels are implemented in a unified framework. Based on this library, we build\nseveral benchmarks for different explainable recommendation tasks. At last, we\npresent many new opportunities brought by our dataset, which are expected to\nshed some new lights to the explainable recommendation field. Our dataset,\nlibrary and the related documents have been released at\nhttps://reasoner2023.github.io/.\n","authors":["Xu Chen","Jingsen Zhang","Lei Wang","Quanyu Dai","Zhenhua Dong","Ruiming Tang","Rui Zhang","Li Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2303.00168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00807v1","updated":"2023-03-01T20:21:23Z","published":"2023-03-01T20:21:23Z","title":"UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and\n  Distillation of Rerankers","summary":"  Many information retrieval tasks require large labeled datasets for\nfine-tuning. However, such datasets are often unavailable, and their utility\nfor real-world applications can diminish quickly due to domain shifts. To\naddress this challenge, we develop and motivate a method for using large\nlanguage models (LLMs) to generate large numbers of synthetic queries cheaply.\nThe method begins by generating a small number of synthetic queries using an\nexpensive LLM. After that, a much less expensive one is used to create large\nnumbers of synthetic queries, which are used to fine-tune a family of reranker\nmodels. These rerankers are then distilled into a single efficient retriever\nfor use in the target domain. We show that this technique boosts zero-shot\naccuracy in long-tail domains, even where only 2K synthetic queries are used\nfor fine-tuning, and that it achieves substantially lower latency than standard\nreranking methods. We make our end-to-end approach, including our synthetic\ndatasets and replication code, publicly available on Github.\n","authors":["Jon Saad-Falcon","Omar Khattab","Keshav Santhanam","Radu Florian","Martin Franz","Salim Roukos","Avirup Sil","Md Arafat Sultan","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2303.00807v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.07605v2","updated":"2023-03-01T18:53:22Z","published":"2023-01-18T15:37:11Z","title":"Strong inductive biases provably prevent harmless interpolation","summary":"  Classical wisdom suggests that estimators should avoid fitting noise to\nachieve good generalization. In contrast, modern overparameterized models can\nyield small test error despite interpolating noise -- a phenomenon often called\n\"benign overfitting\" or \"harmless interpolation\". This paper argues that the\ndegree to which interpolation is harmless hinges upon the strength of an\nestimator's inductive bias, i.e., how heavily the estimator favors solutions\nwith a certain structure: while strong inductive biases prevent harmless\ninterpolation, weak inductive biases can even require fitting noise to\ngeneralize well. Our main theoretical result establishes tight non-asymptotic\nbounds for high-dimensional kernel regression that reflect this phenomenon for\nconvolutional kernels, where the filter size regulates the strength of the\ninductive bias. We further provide empirical evidence of the same behavior for\ndeep neural networks with varying filter sizes and rotational invariance.\n","authors":["Michael Aerni","Marco Milanta","Konstantin Donhauser","Fanny Yang"],"pdf_url":"https://arxiv.org/pdf/2301.07605v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00735v1","updated":"2023-03-01T18:50:59Z","published":"2023-03-01T18:50:59Z","title":"DOTE: Rethinking (Predictive) WAN Traffic Engineering","summary":"  We explore a new design point for traffic engineering on wide-area networks\n(WANs): directly optimizing traffic flow on the WAN using only historical data\nabout traffic demands. Doing so obviates the need to explicitly estimate, or\npredict, future demands. Our method, which utilizes stochastic optimization,\nprovably converges to the global optimum in well-studied theoretical models. We\nemploy deep learning to scale to large WANs and real-world traffic. Our\nextensive empirical evaluation on real-world traffic and network topologies\nestablishes that our approach's TE quality almost matches that of an\n(infeasible) omniscient oracle, outperforming previously proposed approaches,\nand also substantially lowers runtimes.\n","authors":["Yarin Perry","Felipe Vieira Frujeri","Chaim Hoch","Srikanth Kandula","Ishai Menache","Michael Schapira","Aviv Tamar"],"pdf_url":"https://arxiv.org/pdf/2303.00735v1.pdf","comment":"To appear at NSDI 2023"},{"id":"http://arxiv.org/abs/2303.00733v1","updated":"2023-03-01T18:47:41Z","published":"2023-03-01T18:47:41Z","title":"SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks","summary":"  Prompt tuning is a technology that tunes a small set of parameters to steer a\npre-trained language model (LM) to directly generate the output for downstream\ntasks. Recently, prompt tuning has demonstrated its storage and computation\nefficiency in both natural language processing (NLP) and speech processing\nfields. These advantages have also revealed prompt tuning as a candidate\napproach to serving pre-trained LM for multiple tasks in a unified manner. For\nspeech processing, SpeechPrompt shows its high parameter efficiency and\ncompetitive performance on a few speech classification tasks. However, whether\nSpeechPrompt is capable of serving a large number of tasks is unanswered. In\nthis work, we propose SpeechPrompt v2, a prompt tuning framework capable of\nperforming a wide variety of speech classification tasks, covering multiple\nlanguages and prosody-related tasks. The experiment result shows that\nSpeechPrompt v2 achieves performance on par with prior works with less than\n0.15M trainable parameters in a unified framework.\n","authors":["Kai-Wei Chang","Yu-Kai Wang","Hua Shen","Iu-thing Kang","Wei-Cheng Tseng","Shang-Wen Li","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2303.00733v1.pdf","comment":"Project website: https://ga642381.github.io/SpeechPrompt"},{"id":"http://arxiv.org/abs/2303.00732v1","updated":"2023-03-01T18:46:40Z","published":"2023-03-01T18:46:40Z","title":"R-U-SURE? Uncertainty-Aware Code Suggestions By Maximizing Utility\n  Across Random User Intents","summary":"  Large language models show impressive results at predicting structured text\nsuch as code, but also commonly introduce errors and hallucinations in their\noutput. When used to assist software developers, these models may make mistakes\nthat users must go back and fix, or worse, introduce subtle bugs that users may\nmiss entirely. We propose Randomized Utility-driven Synthesis of Uncertain\nREgions (R-U-SURE), an approach for building uncertainty-aware suggestions\nbased on a decision-theoretic model of goal-conditioned utility, using random\nsamples from a generative model as a proxy for the unobserved possible intents\nof the end user. Our technique combines minimum-Bayes-risk decoding, dual\ndecomposition, and decision diagrams in order to efficiently produce structured\nuncertainty summaries, given only sample access to an arbitrary generative\nmodel of code and an optional AST parser. We demonstrate R-U-SURE on three\ndeveloper-assistance tasks, and show that it can be applied different user\ninteraction patterns without retraining the model and leads to more accurate\nuncertainty estimates than token-probability baselines.\n","authors":["Daniel D. Johnson","Daniel Tarlow","Christian Walder"],"pdf_url":"https://arxiv.org/pdf/2303.00732v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.00728v1","updated":"2023-03-01T18:42:14Z","published":"2023-03-01T18:42:14Z","title":"On the universality of $S_n$-equivariant $k$-body gates","summary":"  The importance of symmetries has recently been recognized in quantum machine\nlearning from the simple motto: if a task exhibits a symmetry (given by a group\n$\\mathfrak{G}$), the learning model should respect said symmetry. This can be\ninstantiated via $\\mathfrak{G}$-equivariant Quantum Neural Networks (QNNs),\ni.e., parametrized quantum circuits whose gates are generated by operators\ncommuting with a given representation of $\\mathfrak{G}$. In practice, however,\nthere might be additional restrictions to the types of gates one can use, such\nas being able to act on at most $k$ qubits. In this work we study how the\ninterplay between symmetry and $k$-bodyness in the QNN generators affect its\nexpressiveness for the special case of $\\mathfrak{G}=S_n$, the symmetric group.\nOur results show that if the QNN is generated by one- and two-body\n$S_n$-equivariant gates, the QNN is semi-universal but not universal. That is,\nthe QNN can generate any arbitrary special unitary matrix in the invariant\nsubspaces, but has no control over the relative phases between them. Then, we\nshow that in order to reach universality one needs to include $n$-body\ngenerators (if $n$ is even) or $(n-1)$-body generators (if $n$ is odd). As\nsuch, our results brings us a step closer to better understanding the\ncapabilities and limitations of equivariant QNNs.\n","authors":["Sujay Kazi","Martin Larocca","M. Cerezo"],"pdf_url":"https://arxiv.org/pdf/2303.00728v1.pdf","comment":"8+14 pages, 3+5 figures"},{"id":"http://arxiv.org/abs/2302.00695v2","updated":"2023-03-01T18:38:26Z","published":"2023-02-01T19:00:10Z","title":"Versatile Energy-Based Models for High Energy Physics","summary":"  Energy-based models have the natural advantage of flexibility in the form of\nthe energy function. Recently, energy-based models have achieved great success\nin modeling high-dimensional data in computer vision and natural language\nprocessing. In accordance with these signs of progress, we build a versatile\nenergy-based model for High Energy Physics events at the Large Hadron Collider.\nThis framework builds on a powerful generative model and describes higher-order\ninter-particle interactions. It suits different encoding architectures and\nbuilds on implicit generation. As for applicational aspects, it can serve as a\npowerful parameterized event generator, a generic anomalous signal detector,\nand an augmented event classifier.\n","authors":["Taoli Cheng","Aaron Courville"],"pdf_url":"https://arxiv.org/pdf/2302.00695v2.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2301.13371v2","updated":"2023-03-01T18:32:04Z","published":"2023-01-31T02:31:18Z","title":"Demystifying Disagreement-on-the-Line in High Dimensions","summary":"  Evaluating the performance of machine learning models under distribution\nshift is challenging, especially when we only have unlabeled data from the\nshifted (target) domain, along with labeled data from the original (source)\ndomain. Recent work suggests that the notion of disagreement, the degree to\nwhich two models trained with different randomness differ on the same input, is\na key to tackle this problem. Experimentally, disagreement and prediction error\nhave been shown to be strongly connected, which has been used to estimate model\nperformance. Experiments have led to the discovery of the\ndisagreement-on-the-line phenomenon, whereby the classification error under the\ntarget domain is often a linear function of the classification error under the\nsource domain; and whenever this property holds, disagreement under the source\nand target domain follow the same linear relation. In this work, we develop a\ntheoretical foundation for analyzing disagreement in high-dimensional random\nfeatures regression; and study under what conditions the\ndisagreement-on-the-line phenomenon occurs in our setting. Experiments on\nCIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and\nsupport the universality of the theoretical findings.\n","authors":["Donghwan Lee","Behrad Moniri","Xinmeng Huang","Edgar Dobriban","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2301.13371v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12360v2","updated":"2023-03-01T18:28:36Z","published":"2023-02-23T22:53:02Z","title":"Practical Knowledge Distillation: Using DNNs to Beat DNNs","summary":"  For tabular data sets, we explore data and model distillation, as well as\ndata denoising. These techniques improve both gradient-boosting models and a\nspecialized DNN architecture. While gradient boosting is known to outperform\nDNNs on tabular data, we close the gap for datasets with 100K+ rows and give\nDNNs an advantage on small data sets. We extend these results with input-data\ndistillation and optimized ensembling to help DNN performance match or exceed\nthat of gradient boosting. As a theoretical justification of our practical\nmethod, we prove its equivalence to classical cross-entropy knowledge\ndistillation. We also qualitatively explain the superiority of DNN ensembles\nover XGBoost on small data sets. For an industry end-to-end real-time ML\nplatform with 4M production inferences per second, we develop a model-training\nworkflow based on data sampling that distills ensembles of models into a single\ngradient-boosting model favored for high-performance real-time inference,\nwithout performance loss. Empirical evaluation shows that the proposed\ncombination of methods consistently improves model accuracy over prior best\nmodels across several production applications deployed worldwide.\n","authors":["Chung-Wei Lee","Pavlos Athanasios Apostolopulos","Igor L. Markov"],"pdf_url":"https://arxiv.org/pdf/2302.12360v2.pdf","comment":"11 pages, 1 figure, 17 tables"},{"id":"http://arxiv.org/abs/2303.00721v1","updated":"2023-03-01T18:26:44Z","published":"2023-03-01T18:26:44Z","title":"Bootstrapping Parallel Anchors for Relative Representations","summary":"  The use of relative representations for latent embeddings has shown potential\nin enabling latent space communication and zero-shot model stitching across a\nwide range of applications. Nevertheless, relative representations rely on a\ncertain amount of parallel anchors to be given as input, which can be\nimpractical to obtain in certain scenarios. To overcome this limitation, we\npropose an optimization-based method to discover new parallel anchors from a\nlimited number of seeds. Our approach can be used to find semantic\ncorrespondence between different domains, align their relative spaces, and\nachieve competitive results in several tasks.\n","authors":["Irene Cannistraci","Luca Moschella","Valentino Maiorca","Marco Fumero","Antonio Norelli","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2303.00721v1.pdf","comment":"9 pages, 7 tables"},{"id":"http://arxiv.org/abs/2303.00720v1","updated":"2023-03-01T18:26:14Z","published":"2023-03-01T18:26:14Z","title":"Cross-Modal Entity Matching for Visually Rich Documents","summary":"  Visually rich documents (VRD) are physical/digital documents that utilize\nvisual cues to augment their semantics. The information contained in these\ndocuments are often incomplete. Existing works that enable automated querying\non VRDs do not take this aspect into account. Consequently, they support a\nlimited set of queries. In this paper, we describe Juno -- a multimodal\nframework that identifies a set of tuples from a relational database to augment\nan incomplete VRD with supplementary information. Our main contribution in this\nis an end-to-end-trainable neural network with bi-directional attention that\nexecutes this cross-modal entity matching task without any prior knowledge\nabout the document type or the underlying database-schema. Exhaustive\nexperiments on two heteroegeneous datasets show that Juno outperforms\nstate-of-the-art baselines by more than 6% in F1-score, while reducing the\namount of human-effort in its workflow by more than 80%. To the best of our\nknowledge, ours is the first work that investigates the incompleteness of VRDs\nand proposes a robust framework to address it in a seamless way.\n","authors":["Ritesh Sarkhel","Arnab Nandi"],"pdf_url":"https://arxiv.org/pdf/2303.00720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02912v2","updated":"2023-03-01T18:22:47Z","published":"2022-10-06T13:30:16Z","title":"CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated\n  Learning","summary":"  Federated Learning (FL) is a setting for training machine learning models in\ndistributed environments where the clients do not share their raw data but\ninstead send model updates to a server. However, model updates can be subject\nto attacks and leak private information. Differential Privacy (DP) is a leading\nmitigation strategy which involves adding noise to clipped model updates,\ntrading off performance for strong theoretical privacy guarantees. Previous\nwork has shown that the threat model of DP is conservative and that the\nobtained guarantees may be vacuous or may overestimate information leakage in\npractice. In this paper, we aim to achieve a tighter measurement of the model\nexposure by considering a realistic threat model. We propose a novel method,\nCANIFE, that uses canaries - carefully crafted samples by a strong adversary to\nevaluate the empirical privacy of a training round. We apply this attack to\nvision models trained on CIFAR-10 and CelebA and to language models trained on\nSent140 and Shakespeare. In particular, in realistic FL scenarios, we\ndemonstrate that the empirical per-round epsilon obtained with CANIFE is 4-5x\nlower than the theoretical bound.\n","authors":["Samuel Maddock","Alexandre Sablayrolles","Pierre Stock"],"pdf_url":"https://arxiv.org/pdf/2210.02912v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00716v1","updated":"2023-03-01T18:20:24Z","published":"2023-03-01T18:20:24Z","title":"Aligning benchmark datasets for table structure recognition","summary":"  Benchmark datasets for table structure recognition (TSR) must be carefully\nprocessed to ensure they are annotated consistently. However, even if a\ndataset's annotations are self-consistent, there may be significant\ninconsistency across datasets, which can harm the performance of models trained\nand evaluated on them. In this work, we show that aligning these\nbenchmarks$\\unicode{x2014}$removing both errors and inconsistency between\nthem$\\unicode{x2014}$improves model performance significantly. We demonstrate\nthis through a data-centric approach where we adopt a single model\narchitecture, the Table Transformer (TATR), that we hold fixed throughout.\nBaseline exact match accuracy for TATR evaluated on the ICDAR-2013 benchmark is\n65% when trained on PubTables-1M, 42% when trained on FinTabNet, and 69%\ncombined. After reducing annotation mistakes and inter-dataset inconsistency,\nperformance of TATR evaluated on ICDAR-2013 increases substantially to 75% when\ntrained on PubTables-1M, 65% when trained on FinTabNet, and 81% combined. We\nshow through ablations over the modification steps that canonicalization of the\ntable annotations has a significantly positive effect on performance, while\nother choices balance necessary trade-offs that arise when deciding a benchmark\ndataset's final composition. Overall we believe our work has significant\nimplications for benchmark design for TSR and potentially other tasks as well.\nAll dataset processing and training code will be released.\n","authors":["Brandon Smock","Rohith Pesala","Robin Abraham"],"pdf_url":"https://arxiv.org/pdf/2303.00716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02742v6","updated":"2023-03-01T18:19:45Z","published":"2022-12-06T04:15:24Z","title":"A Learning Based Hypothesis Test for Harmful Covariate Shift","summary":"  The ability to quickly and accurately identify covariate shift at test time\nis a critical and often overlooked component of safe machine learning systems\ndeployed in high-risk domains. While methods exist for detecting when\npredictions should not be made on out-of-distribution test examples,\nidentifying distributional level differences between training and test time can\nhelp determine when a model should be removed from the deployment setting and\nretrained. In this work, we define harmful covariate shift (HCS) as a change in\ndistribution that may weaken the generalization of a predictive model. To\ndetect HCS, we use the discordance between an ensemble of classifiers trained\nto agree on training data and disagree on test data. We derive a loss function\nfor training this ensemble and show that the disagreement rate and entropy\nrepresent powerful discriminative statistics for HCS. Empirically, we\ndemonstrate the ability of our method to detect harmful covariate shift with\nstatistical certainty on a variety of high-dimensional datasets. Across\nnumerous domains and modalities, we show state-of-the-art performance compared\nto existing methods, particularly when the number of observed test samples is\nsmall.\n","authors":["Tom Ginsberg","Zhongyuan Liang","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2212.02742v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09329v2","updated":"2023-03-01T18:06:44Z","published":"2022-09-19T20:13:29Z","title":"MAN: Multi-Action Networks Learning","summary":"  Learning control policies with large discrete action spaces is a challenging\nproblem in the field of reinforcement learning due to present inefficiencies in\nexploration. With high dimensional action spaces, there are a large number of\npotential actions in each individual dimension over which policies would be\nlearned. In this work, we introduce a Deep Reinforcement Learning (DRL)\nalgorithm call Multi-Action Networks (MAN) Learning that addresses the\nchallenge of high-dimensional large discrete action spaces. We propose\nfactorizing the N-dimension action space into N 1-dimensional components, known\nas sub-actions, creating a Value Neural Network for each sub-action. Then, MAN\nuses temporal-difference learning to train the networks synchronously, which is\nsimpler than training a single network with a large action output directly. To\nevaluate the proposed method, we test MAN on three scenarios: an n-dimension\nmaze task, a block stacking task, and then extend MAN to handle 12 games from\nthe Atari Arcade Learning environment with 18 action spaces. Our results\nindicate that MAN learns faster than both Deep Q-Learning and Double Deep\nQ-Learning, implying our method is a better performing synchronous temporal\ndifference algorithm than those currently available for large discrete action\nspaces.\n","authors":["Keqin Wang","Alison Bartsch","Amir Barati Farimani"],"pdf_url":"https://arxiv.org/pdf/2209.09329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14935v2","updated":"2023-03-01T18:01:09Z","published":"2022-09-29T16:54:05Z","title":"Does Zero-Shot Reinforcement Learning Exist?","summary":"  A zero-shot RL agent is an agent that can solve any RL task in a given\nenvironment, instantly with no additional planning or learning, after an\ninitial reward-free learning phase. This marks a shift from the reward-centric\nRL paradigm towards \"controllable\" agents that can follow arbitrary\ninstructions in an environment. Current RL agents can solve families of related\ntasks at best, or require planning anew for each task. Strategies for\napproximate zero-shot RL ave been suggested using successor features (SFs)\n[BBQ+ 18] or forward-backward (FB) representations [TO21], but testing has been\nlimited.\n  After clarifying the relationships between these schemes, we introduce\nimproved losses and new SF models, and test the viability of zero-shot RL\nschemes systematically on tasks from the Unsupervised RL benchmark [LYL+21]. To\ndisentangle universal representation learning from exploration, we work in an\noffline setting and repeat the tests on several existing replay buffers.\n  SFs appear to suffer from the choice of the elementary state features. SFs\nwith Laplacian eigenfunctions do well, while SFs based on auto-encoders,\ninverse curiosity, transition models, low-rank transition matrix, contrastive\nlearning, or diversity (APS), perform unconsistently. In contrast, FB\nrepresentations jointly learn the elementary and successor features from a\nsingle, principled criterion. They perform best and consistently across the\nboard, reaching 85% of supervised RL performance with a good replay buffer, in\na zero-shot manner.\n","authors":["Ahmed Touati","Jérémy Rapin","Yann Ollivier"],"pdf_url":"https://arxiv.org/pdf/2209.14935v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04368v2","updated":"2023-03-01T17:51:40Z","published":"2023-01-11T09:26:16Z","title":"On the functional form of the radial acceleration relation","summary":"  We apply a new method for learning equations from data -- Exhaustive Symbolic\nRegression (ESR) -- to late-type galaxy dynamics as encapsulated in the radial\nacceleration relation (RAR). Relating the centripetal acceleration due to\nbaryons, $g_\\text{bar}$, to the total dynamical acceleration, $g_\\text{obs}$,\nthe RAR has been claimed to manifest a new law of nature due to its regularity\nand tightness, in agreement with Modified Newtonian Dynamics (MOND). Fits to\nthis relation have been restricted by prior expectations to particular\nfunctional forms, while ESR affords an exhaustive and nearly prior-free search\nthrough functional parameter space to identify the equations optimally trading\naccuracy with simplicity. Working with the SPARC data, we find the best\nfunctions typically satisfy $g_\\text{obs} \\propto g_\\text{bar}$ at high\n$g_\\text{bar}$, although the coefficient of proportionality is not clearly\nunity and the deep-MOND limit $g_\\text{obs} \\propto \\sqrt{g_\\text{bar}}$ as\n$g_\\text{bar} \\to 0$ is little evident at all. By generating mock data\naccording to MOND with or without the external field effect, we find that\nsymbolic regression would not be expected to identify the generating function\nor reconstruct successfully the asymptotic slopes. We conclude that the limited\ndynamical range and significant uncertainties of the SPARC RAR preclude a\ndefinitive statement of its functional form, and hence that this data alone can\nneither demonstrate nor rule out law-like gravitational behaviour.\n","authors":["Harry Desmond","Deaglan J. Bartlett","Pedro G. Ferreira"],"pdf_url":"https://arxiv.org/pdf/2301.04368v2.pdf","comment":"12+4 pages, 4 figures, 3 tables; minor revision to match MNRAS\n  published version"},{"id":"http://arxiv.org/abs/2303.00694v1","updated":"2023-03-01T17:42:26Z","published":"2023-03-01T17:42:26Z","title":"The Virtues of Laziness in Model-based RL: A Unified Objective and\n  Algorithms","summary":"  We propose a novel approach to addressing two fundamental challenges in\nModel-based Reinforcement Learning (MBRL): the computational expense of\nrepeatedly finding a good policy in the learned model, and the objective\nmismatch between model fitting and policy computation. Our \"lazy\" method\nleverages a novel unified objective, Performance Difference via Advantage in\nModel, to capture the performance difference between the learned policy and\nexpert policy under the true dynamics. This objective demonstrates that\noptimizing the expected policy advantage in the learned model under an\nexploration distribution is sufficient for policy computation, resulting in a\nsignificant boost in computational efficiency compared to traditional planning\nmethods. Additionally, the unified objective uses a value moment matching term\nfor model fitting, which is aligned with the model's usage during policy\ncomputation. We present two no-regret algorithms to optimize the proposed\nobjective, and demonstrate their statistical and computational gains compared\nto existing MBRL methods through simulated benchmarks.\n","authors":["Anirudh Vemula","Yuda Song","Aarti Singh","J. Andrew Bagnell","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2303.00694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.17028v2","updated":"2023-03-01T17:41:25Z","published":"2022-10-31T03:00:11Z","title":"Improved Learning-augmented Algorithms for k-means and k-medians\n  Clustering","summary":"  We consider the problem of clustering in the learning-augmented setting,\nwhere we are given a data set in $d$-dimensional Euclidean space, and a label\nfor each data point given by an oracle indicating what subsets of points should\nbe clustered together. This setting captures situations where we have access to\nsome auxiliary information about the data set relevant for our clustering\nobjective, for instance the labels output by a neural network. Following prior\nwork, we assume that there are at most an $\\alpha \\in (0,c)$ for some $c<1$\nfraction of false positives and false negatives in each predicted cluster, in\nthe absence of which the labels would attain the optimal clustering cost\n$\\mathrm{OPT}$.\n  For a dataset of size $m$, we propose a deterministic $k$-means algorithm\nthat produces centers with improved bound on clustering cost compared to the\nprevious randomized algorithm while preserving the $O( d m \\log m)$ runtime.\nFurthermore, our algorithm works even when the predictions are not very\naccurate, i.e. our bound holds for $\\alpha$ up to $1/2$, an improvement over\n$\\alpha$ being at most $1/7$ in the previous work. For the $k$-medians problem\nwe improve upon prior work by achieving a biquadratic improvement in the\ndependence of the approximation factor on the accuracy parameter $\\alpha$ to\nget a cost of $(1+O(\\alpha))\\mathrm{OPT}$, while requiring essentially just\n$O(md \\log^3 m/\\alpha)$ runtime.\n","authors":["Thy Nguyen","Anamay Chaturvedi","Huy Lê Nguyen"],"pdf_url":"https://arxiv.org/pdf/2210.17028v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00691v1","updated":"2023-03-01T17:39:08Z","published":"2023-03-01T17:39:08Z","title":"On the Importance of Feature Representation for Flood Mapping using\n  Classical Machine Learning Approaches","summary":"  Climate change has increased the severity and frequency of weather disasters\nall around the world. Flood inundation mapping based on earth observation data\ncan help in this context, by providing cheap and accurate maps depicting the\narea affected by a flood event to emergency-relief units in near-real-time.\nBuilding upon the recent development of the Sen1Floods11 dataset, which\nprovides a limited amount of hand-labeled high-quality training data, this\npaper evaluates the potential of five traditional machine learning approaches\nsuch as gradient boosted decision trees, support vector machines or quadratic\ndiscriminant analysis. By performing a grid-search-based hyperparameter\noptimization on 23 feature spaces we can show that all considered classifiers\nare capable of outperforming the current state-of-the-art neural network-based\napproaches in terms of total IoU on their best-performing feature spaces. With\ntotal and mean IoU values of 0.8751 and 0.7031 compared to 0.70 and 0.5873 as\nthe previous best-reported results, we show that a simple gradient boosting\nclassifier can significantly improve over deep neural network based approaches,\ndespite using less training data. Furthermore, an analysis of the regional\ndistribution of the Sen1Floods11 dataset reveals a problem of spatial\nimbalance. We show that traditional machine learning models can learn this bias\nand argue that modified metric evaluations are required to counter artifacts\ndue to spatial imbalance. Lastly, a qualitative analysis shows that this\npixel-wise classifier provides highly-precise surface water classifications\nindicating that a good choice of a feature space and pixel-wise classification\ncan generate high-quality flood maps using optical and SAR data. We make our\ncode publicly available at:\nhttps://github.com/DFKI-Earth-And-Space-Applications/Flood_Mapping_Feature_Space_Importance\n","authors":["Kevin Iselborn","Marco Stricker","Takashi Miyamoto","Marlon Nuske","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2303.00691v1.pdf","comment":"24 pages, 9 figures, submitted to Remote Sensing of Environment and\n  code is available at\n  https://github.com/DFKI-Earth-And-Space-Applications/Flood_Mapping_Feature_Space_Importance"},{"id":"http://arxiv.org/abs/2303.00673v1","updated":"2023-03-01T17:12:49Z","published":"2023-03-01T17:12:49Z","title":"Fairness Evaluation in Text Classification: Machine Learning\n  Practitioner Perspectives of Individual and Group Fairness","summary":"  Mitigating algorithmic bias is a critical task in the development and\ndeployment of machine learning models. While several toolkits exist to aid\nmachine learning practitioners in addressing fairness issues, little is known\nabout the strategies practitioners employ to evaluate model fairness and what\nfactors influence their assessment, particularly in the context of text\nclassification. Two common approaches of evaluating the fairness of a model are\ngroup fairness and individual fairness. We run a study with Machine Learning\npractitioners (n=24) to understand the strategies used to evaluate models.\nMetrics presented to practitioners (group vs. individual fairness) impact which\nmodels they consider fair. Participants focused on risks associated with\nunderpredicting/overpredicting and model sensitivity relative to identity token\nmanipulations. We discover fairness assessment strategies involving personal\nexperiences or how users form groups of identity tokens to test model fairness.\nWe provide recommendations for interactive tools for evaluating fairness in\ntext classification.\n","authors":["Zahra Ashktorab","Benjamin Hoover","Mayank Agarwal","Casey Dugan","Werner Geyer","Hao Bang Yang","Mikhail Yurochkin"],"pdf_url":"https://arxiv.org/pdf/2303.00673v1.pdf","comment":"To appear in Proceedings of the 2023 CHI Conference on Human Factors\n  in Computing Systems (CHI '23)"},{"id":"http://arxiv.org/abs/2303.00654v1","updated":"2023-03-01T16:56:39Z","published":"2023-03-01T16:56:39Z","title":"How to DP-fy ML: A Practical Guide to Machine Learning with Differential\n  Privacy","summary":"  ML models are ubiquitous in real world applications and are a constant focus\nof research. At the same time, the community has started to realize the\nimportance of protecting the privacy of ML training data.\n  Differential Privacy (DP) has become a gold standard for making formal\nstatements about data anonymization. However, while some adoption of DP has\nhappened in industry, attempts to apply DP to real world complex ML models are\nstill few and far between. The adoption of DP is hindered by limited practical\nguidance of what DP protection entails, what privacy guarantees to aim for, and\nthe difficulty of achieving good privacy-utility-computation trade-offs for ML\nmodels. Tricks for tuning and maximizing performance are scattered among papers\nor stored in the heads of practitioners. Furthermore, the literature seems to\npresent conflicting evidence on how and whether to apply architectural\nadjustments and which components are ``safe'' to use with DP.\n  This work is a self-contained guide that gives an in-depth overview of the\nfield of DP ML and presents information about achieving the best possible DP ML\nmodel with rigorous privacy guarantees. Our target audience is both researchers\nand practitioners. Researchers interested in DP for ML will benefit from a\nclear overview of current advances and areas for improvement. We include\ntheory-focused sections that highlight important topics such as privacy\naccounting and its assumptions, and convergence. For a practitioner, we provide\na background in DP theory and a clear step-by-step guide for choosing an\nappropriate privacy definition and approach, implementing DP training,\npotentially updating the model architecture, and tuning hyperparameters. For\nboth researchers and practitioners, consistently and fully reporting privacy\nguarantees is critical, and so we propose a set of specific best practices for\nstating guarantees.\n","authors":["Natalia Ponomareva","Hussein Hazimeh","Alex Kurakin","Zheng Xu","Carson Denison","H. Brendan McMahan","Sergei Vassilvitskii","Steve Chien","Abhradeep Thakurta"],"pdf_url":"https://arxiv.org/pdf/2303.00654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00652v1","updated":"2023-03-01T16:54:48Z","published":"2023-03-01T16:54:48Z","title":"Finding the right XAI method -- A Guide for the Evaluation and Ranking\n  of Explainable AI Methods in Climate Science","summary":"  Explainable artificial intelligence (XAI) methods shed light on the\npredictions of deep neural networks (DNNs). Several different approaches exist\nand have partly already been successfully applied in climate science. However,\nthe often missing ground truth explanations complicate their evaluation and\nvalidation, subsequently compounding the choice of the XAI method. Therefore,\nin this work, we introduce XAI evaluation in the context of climate research\nand assess different desired explanation properties, namely, robustness,\nfaithfulness, randomization, complexity, and localization. To this end we build\nupon previous work and train a multi-layer perceptron (MLP) and a convolutional\nneural network (CNN) to predict the decade based on annual-mean temperature\nmaps. Next, multiple local XAI methods are applied and their performance is\nquantified for each evaluation property and compared against a baseline test.\nIndependent of the network type, we find that the XAI methods Integrated\nGradients, Layer-wise relevance propagation, and InputGradients exhibit\nconsiderable robustness, faithfulness, and complexity while sacrificing\nrandomization. The opposite is true for Gradient, SmoothGrad, NoiseGrad, and\nFusionGrad. Notably, explanations using input perturbations, such as SmoothGrad\nand Integrated Gradients, do not improve robustness and faithfulness, contrary\nto previous claims. Overall, our experiments offer a comprehensive overview of\ndifferent properties of explanation methods in the climate science context and\nsupports users in the selection of a suitable XAI method.\n","authors":["Philine Bommer","Marlene Kretschmer","Anna Hedström","Dilyara Bareeva","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2303.00652v1.pdf","comment":"17 pages, 8 figure, under review"},{"id":"http://arxiv.org/abs/2302.08973v2","updated":"2023-03-01T16:47:49Z","published":"2023-02-17T16:19:26Z","title":"Measuring Equality in Machine Learning Security Defenses","summary":"  The machine learning security community has developed myriad defenses for\nevasion attacks over the past decade. An understudied question in that\ncommunity is: for whom do these defenses defend? In this work, we consider some\ncommon approaches to defending learned systems and whether those approaches may\noffer unexpected performance inequities when used by different sub-populations.\nWe outline simple parity metrics and a framework for analysis that can begin to\nanswer this question through empirical results of the fairness implications of\nmachine learning security methods. Many methods have been proposed that can\ncause direct harm, which we describe as biased vulnerability and biased\nrejection. Our framework and metric can be applied to robustly trained models,\npreprocessing-based methods, and rejection methods to capture behavior over\nsecurity budgets. We identify a realistic dataset with a reasonable\ncomputational cost suitable for measuring the equality of defenses. Through a\ncase study in speech command recognition, we show how such defenses do not\noffer equal protection for social subgroups and how to perform such analyses\nfor robustness training, and we present a comparison of fairness between two\nrejection-based defenses: randomized smoothing and neural rejection. We offer\nfurther analysis of factors that correlate to equitable defenses to stimulate\nthe future investigation of how to assist in building such defenses. To the\nbest of our knowledge, this is the first work that examines the fairness\ndisparity in the accuracy-robustness trade-off in speech data and addresses\nfairness evaluation for rejection-based defenses.\n","authors":["Luke E. Richards","Edward Raff","Cynthia Matuszek"],"pdf_url":"https://arxiv.org/pdf/2302.08973v2.pdf","comment":"In Submission"},{"id":"http://arxiv.org/abs/2112.07110v9","updated":"2023-03-01T16:44:09Z","published":"2021-12-14T02:25:43Z","title":"Non-Asymptotic Analysis of Online Multiplicative Stochastic Gradient\n  Descent","summary":"  Past research has indicated that the covariance of the Stochastic Gradient\nDescent (SGD) error done via minibatching plays a critical role in determining\nits regularization and escape from low potential points. Motivated by some new\nresearch in this area, we prove universality results by showing that noise\nclasses that have the same mean and covariance structure of SGD via\nminibatching have similar properties. We mainly consider the Multiplicative\nStochastic Gradient Descent (M-SGD) algorithm as introduced in previous work,\nwhich has a much more general noise class than the SGD algorithm done via\nminibatching. We establish non asymptotic bounds for the M-SGD algorithm in the\nWasserstein distance. We also show that the M-SGD error is approximately a\nscaled Gaussian distribution with mean $0$ at any fixed point of the M-SGD\nalgorithm.\n","authors":["Riddhiman Bhattacharya","Tiefeng Jiang"],"pdf_url":"https://arxiv.org/pdf/2112.07110v9.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00638v1","updated":"2023-03-01T16:40:54Z","published":"2023-03-01T16:40:54Z","title":"MEGA-DAgger: Imitation Learning with Multiple Imperfect Experts","summary":"  Imitation learning has been widely applied to various autonomous systems\nthanks to recent development in interactive algorithms that address covariate\nshift and compounding errors induced by traditional approaches like behavior\ncloning. However, existing interactive imitation learning methods assume access\nto one perfect expert. Whereas in reality, it is more likely to have multiple\nimperfect experts instead. In this paper, we propose MEGA-DAgger, a new DAgger\nvariant that is suitable for interactive learning with multiple imperfect\nexperts. First, unsafe demonstrations are filtered while aggregating the\ntraining data, so the imperfect demonstrations have little influence when\ntraining the novice policy. Next, experts are evaluated and compared on\nscenarios-specific metrics to resolve the conflicted labels among experts.\nThrough experiments in autonomous racing scenarios, we demonstrate that policy\nlearned using MEGA-DAgger can outperform both experts and policies learned\nusing the state-of-the-art interactive imitation learning algorithm. The\nsupplementary video can be found at https://youtu.be/pYQiPSHk6dU.\n","authors":["Xiatao Sun","Shuo Yang","Rahul Mangharam"],"pdf_url":"https://arxiv.org/pdf/2303.00638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15466v6","updated":"2023-03-01T16:31:13Z","published":"2022-05-30T23:44:09Z","title":"Data Banzhaf: A Robust Data Valuation Framework for Machine Learning","summary":"  Data valuation has wide use cases in machine learning, including improving\ndata quality and creating economic incentives for data sharing. This paper\nstudies the robustness of data valuation to noisy model performance scores.\nParticularly, we find that the inherent randomness of the widely used\nstochastic gradient descent can cause existing data value notions (e.g., the\nShapley value and the Leave-one-out error) to produce inconsistent data value\nrankings across different runs. To address this challenge, we introduce the\nconcept of safety margin, which measures the robustness of a data value notion.\nWe show that the Banzhaf value, a famous value notion that originated from\ncooperative game theory literature, achieves the largest safety margin among\nall semivalues (a class of value notions that satisfy crucial properties\nentailed by ML applications and include the famous Shapley value and\nLeave-one-out error). We propose an algorithm to efficiently estimate the\nBanzhaf value based on the Maximum Sample Reuse (MSR) principle. Our evaluation\ndemonstrates that the Banzhaf value outperforms the existing semivalue-based\ndata value notions on several ML tasks such as learning with weighted samples\nand noisy label detection. Overall, our study suggests that when the underlying\nML algorithm is stochastic, the Banzhaf value is a promising alternative to the\nother semivalue-based data value schemes given its computational advantage and\nability to robustly differentiate data quality.\n","authors":["Jiachen T. Wang","Ruoxi Jia"],"pdf_url":"https://arxiv.org/pdf/2205.15466v6.pdf","comment":"AISTATS 2023 Oral"},{"id":"http://arxiv.org/abs/2211.02093v2","updated":"2023-03-01T16:31:04Z","published":"2022-11-03T18:49:38Z","title":"Domain Adaptation under Missingness Shift","summary":"  Rates of missing data often depend on record-keeping policies and thus may\nchange across times and locations, even when the underlying features are\ncomparatively stable. In this paper, we introduce the problem of Domain\nAdaptation under Missingness Shift (DAMS). Here, (labeled) source data and\n(unlabeled) target data would be exchangeable but for different missing data\nmechanisms. We show that if missing data indicators are available, DAMS reduces\nto covariate shift. Addressing cases where such indicators are absent, we\nestablish the following theoretical results for underreporting completely at\nrandom: (i) covariate shift is violated (adaptation is required); (ii) the\noptimal linear source predictor can perform arbitrarily worse on the target\ndomain than always predicting the mean; (iii) the optimal target predictor can\nbe identified, even when the missingness rates themselves are not; and (iv) for\nlinear models, a simple analytic adjustment yields consistent estimates of the\noptimal target parameters. In experiments on synthetic and semi-synthetic data,\nwe demonstrate the promise of our methods when assumptions hold. Finally, we\ndiscuss a rich family of future extensions.\n","authors":["Helen Zhou","Sivaraman Balakrishnan","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2211.02093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00620v1","updated":"2023-03-01T16:22:22Z","published":"2023-03-01T16:22:22Z","title":"Multi-Armed Bandits with Generalized Temporally-Partitioned Rewards","summary":"  Decision-making problems of sequential nature, where decisions made in the\npast may have an impact on the future, are used to model many practically\nimportant applications. In some real-world applications, feedback about a\ndecision is delayed and may arrive via partial rewards that are observed with\ndifferent delays. Motivated by such scenarios, we propose a novel problem\nformulation called multi-armed bandits with generalized temporally-partitioned\nrewards. To formalize how feedback about a decision is partitioned across\nseveral time steps, we introduce $\\beta$-spread property. We derive a lower\nbound on the performance of any uniformly efficient algorithm for the\nconsidered problem. Moreover, we provide an algorithm called TP-UCB-FR-G and\nprove an upper bound on its performance measure. In some scenarios, our upper\nbound improves upon the state of the art. We provide experimental results\nvalidating the proposed algorithm and our theoretical results.\n","authors":["Ronald C. van den Broek","Rik Litjens","Tobias Sagis","Luc Siecker","Nina Verbeeke","Pratik Gajane"],"pdf_url":"https://arxiv.org/pdf/2303.00620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13259v2","updated":"2023-03-01T16:18:34Z","published":"2023-02-26T08:12:28Z","title":"Dodging the Double Descent in Deep Neural Networks","summary":"  Finding the optimal size of deep learning models is very actual and of broad\nimpact, especially in energy-saving schemes. Very recently, an unexpected\nphenomenon, the ``double descent'', has caught the attention of the deep\nlearning community. As the model's size grows, the performance gets first\nworse, and then goes back to improving. It raises serious questions about the\noptimal model's size to maintain high generalization: the model needs to be\nsufficiently over-parametrized, but adding too many parameters wastes training\nresources. Is it possible to find, in an efficient way, the best trade-off? Our\nwork shows that the double descent phenomenon is potentially avoidable with\nproper conditioning of the learning problem, but a final answer is yet to be\nfound. We empirically observe that there is hope to dodge the double descent in\ncomplex scenarios with proper regularization, as a simple $\\ell_2$\nregularization is already positively contributing to such a perspective.\n","authors":["Victor Quétu","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2302.13259v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11300v2","updated":"2023-03-01T16:13:33Z","published":"2023-01-26T18:38:56Z","title":"ZiCo: Zero-shot NAS via Inverse Coefficient of Variation on Gradients","summary":"  Neural Architecture Search (NAS) is widely used to automatically obtain the\nneural network with the best performance among a large number of candidate\narchitectures. To reduce the search time, zero-shot NAS aims at designing\ntraining-free proxies that can predict the test performance of a given\narchitecture. However, as shown recently, none of the zero-shot proxies\nproposed to date can actually work consistently better than a naive proxy,\nnamely, the number of network parameters (#Params). To improve this state of\naffairs, as the main theoretical contribution, we first reveal how some\nspecific gradient properties across different samples impact the convergence\nrate and generalization capacity of neural networks. Based on this theoretical\nanalysis, we propose a new zero-shot proxy, ZiCo, the first proxy that works\nconsistently better than #Params. We demonstrate that ZiCo works better than\nState-Of-The-Art (SOTA) proxies on several popular NAS-Benchmarks (NASBench101,\nNATSBench-SSS/TSS, TransNASBench-101) for multiple applications (e.g., image\nclassification/reconstruction and pixel-level prediction). Finally, we\ndemonstrate that the optimal architectures found via ZiCo are as competitive as\nthe ones found by one-shot and multi-shot NAS methods, but with much less\nsearch time. For example, ZiCo-based NAS can find optimal architectures with\n78.1%, 79.4%, and 80.4% test accuracy under inference budgets of 450M, 600M,\nand 1000M FLOPs, respectively, on ImageNet within 0.4 GPU days. Our code is\navailable at https://github.com/SLDGroup/ZiCo.\n","authors":["Guihong Li","Yuedong Yang","Kartikeya Bhardwaj","Radu Marculescu"],"pdf_url":"https://arxiv.org/pdf/2301.11300v2.pdf","comment":"ICLR 2023 Spotlight"},{"id":"http://arxiv.org/abs/2303.00613v1","updated":"2023-03-01T16:11:05Z","published":"2023-03-01T16:11:05Z","title":"Diffusing Graph Attention","summary":"  The dominant paradigm for machine learning on graphs uses Message Passing\nGraph Neural Networks (MP-GNNs), in which node representations are updated by\naggregating information in their local neighborhood. Recently, there have been\nincreasingly more attempts to adapt the Transformer architecture to graphs in\nan effort to solve some known limitations of MP-GNN. A challenging aspect of\ndesigning Graph Transformers is integrating the arbitrary graph structure into\nthe architecture. We propose Graph Diffuser (GD) to address this challenge. GD\nlearns to extract structural and positional relationships between distant nodes\nin the graph, which it then uses to direct the Transformer's attention and node\nrepresentation. We demonstrate that existing GNNs and Graph Transformers\nstruggle to capture long-range interactions and how Graph Diffuser does so\nwhile admitting intuitive visualizations. Experiments on eight benchmarks show\nGraph Diffuser to be a highly competitive model, outperforming the\nstate-of-the-art in a diverse set of domains.\n","authors":["Daniel Glickman","Eran Yahav"],"pdf_url":"https://arxiv.org/pdf/2303.00613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00609v1","updated":"2023-03-01T16:03:25Z","published":"2023-03-01T16:03:25Z","title":"Unsupervised Pathology Detection: A Deep Dive Into the State of the Art","summary":"  Deep unsupervised approaches are gathering increased attention for\napplications such as pathology detection and segmentation in medical images\nsince they promise to alleviate the need for large labeled datasets and are\nmore generalizable than their supervised counterparts in detecting any kind of\nrare pathology. As the Unsupervised Anomaly Detection (UAD) literature\ncontinuously grows and new paradigms emerge, it is vital to continuously\nevaluate and benchmark new methods in a common framework, in order to reassess\nthe state-of-the-art (SOTA) and identify promising research directions. To this\nend, we evaluate a diverse selection of cutting-edge UAD methods on multiple\nmedical datasets, comparing them against the established SOTA in UAD for brain\nMRI. Our experiments demonstrate that newly developed feature-modeling methods\nfrom the industrial and medical literature achieve increased performance\ncompared to previous work and set the new SOTA in a variety of modalities and\ndatasets. Additionally, we show that such methods are capable of benefiting\nfrom recently developed self-supervised pre-training algorithms, further\nincreasing their performance. Finally, we perform a series of experiments in\norder to gain further insights into some unique characteristics of selected\nmodels and datasets. Our code can be found under\nhttps://github.com/iolag/UPD_study/.\n","authors":["Ioannis Lagogiannis","Felix Meissen","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2303.00609v1.pdf","comment":"12 pages, 4 figures, under review for IEEE Transactions on Medical\n  Imaging"},{"id":"http://arxiv.org/abs/2303.00599v1","updated":"2023-03-01T15:46:12Z","published":"2023-03-01T15:46:12Z","title":"LS-IQ: Implicit Reward Regularization for Inverse Reinforcement Learning","summary":"  Recent methods for imitation learning directly learn a $Q$-function using an\nimplicit reward formulation rather than an explicit reward function. However,\nthese methods generally require implicit reward regularization to improve\nstability and often mistreat absorbing states. Previous works show that a\nsquared norm regularization on the implicit reward function is effective, but\ndo not provide a theoretical analysis of the resulting properties of the\nalgorithms. In this work, we show that using this regularizer under a mixture\ndistribution of the policy and the expert provides a particularly illuminating\nperspective: the original objective can be understood as squared Bellman error\nminimization, and the corresponding optimization problem minimizes a bounded\n$\\chi^2$-Divergence between the expert and the mixture distribution. This\nperspective allows us to address instabilities and properly treat absorbing\nstates. We show that our method, Least Squares Inverse Q-Learning (LS-IQ),\noutperforms state-of-the-art algorithms, particularly in environments with\nabsorbing states. Finally, we propose to use an inverse dynamics model to learn\nfrom observations only. Using this approach, we retain performance in settings\nwhere no expert actions are available.\n","authors":["Firas Al-Hafez","Davide Tateo","Oleg Arenz","Guoping Zhao","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2303.00599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12240v3","updated":"2023-03-01T15:38:54Z","published":"2022-01-28T16:51:54Z","title":"Continuous Deep Equilibrium Models: Training Neural ODEs faster by\n  integrating them to Infinity","summary":"  Implicit models separate the definition of a layer from the description of\nits solution process. While implicit layers allow features such as depth to\nadapt to new scenarios and inputs automatically, this adaptivity makes its\ncomputational expense challenging to predict. In this manuscript, we\n\\textit{increase the ``implicitness\" of the DEQ by redefining the method in\nterms of an infinite time neural ODE}, which paradoxically decreases the\ntraining cost over a standard neural ODE by $\\mathit{2} - \\mathit{4 \\times}$.\nAdditionally, we address the question: \\textit{is there a way to simultaneously\nachieve the robustness of implicit layers while allowing the reduced\ncomputational expense of an explicit layer?} To solve this, we develop Skip and\nSkip Reg. DEQ, an implicit-explicit (IMEX) layer that simultaneously trains an\nexplicit prediction followed by an implicit correction. We show that training\nthis explicit predictor is free and even decreases the training time by\n$\\mathit{1.11} - \\mathit{3.19 \\times}$. Together, this manuscript shows how\nbridging the dichotomy of implicit and explicit deep learning can combine the\nadvantages of both techniques.\n","authors":["Avik Pal","Alan Edelman","Christopher Rackauckas"],"pdf_url":"https://arxiv.org/pdf/2201.12240v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00589v1","updated":"2023-03-01T15:30:29Z","published":"2023-03-01T15:30:29Z","title":"Composite Optimization Algorithms for Sigmoid Networks","summary":"  In this paper, we use composite optimization algorithms to solve sigmoid\nnetworks. We equivalently transfer the sigmoid networks to a convex composite\noptimization and propose the composite optimization algorithms based on the\nlinearized proximal algorithms and the alternating direction method of\nmultipliers. Under the assumptions of the weak sharp minima and the regularity\ncondition, the algorithm is guaranteed to converge to a globally optimal\nsolution of the objective function even in the case of non-convex and\nnon-smooth problems. Furthermore, the convergence results can be directly\nrelated to the amount of training data and provide a general guide for setting\nthe size of sigmoid networks. Numerical experiments on Franke's function\nfitting and handwritten digit recognition show that the proposed algorithms\nperform satisfactorily and robustly.\n","authors":["Huixiong Chen","Qi Ye"],"pdf_url":"https://arxiv.org/pdf/2303.00589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00586v1","updated":"2023-03-01T15:28:26Z","published":"2023-03-01T15:28:26Z","title":"FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling","summary":"  Ensembling independent deep neural networks (DNNs) is a simple and effective\nway to improve top-line metrics and to outperform larger single models. In this\nwork, we go beyond top-line metrics and instead explore the impact of\nensembling on subgroup performances. Surprisingly, even with a simple\nhomogenous ensemble -- all the individual models share the same training set,\narchitecture, and design choices -- we find compelling and powerful gains in\nworst-k and minority group performance, i.e. fairness naturally emerges from\nensembling. We show that the gains in performance from ensembling for the\nminority group continue for far longer than for the majority group as more\nmodels are added. Our work establishes that simple DNN ensembles can be a\npowerful tool for alleviating disparate impact from DNN classifiers, thus\ncurbing algorithmic harm. We also explore why this is the case. We find that\neven in homogeneous ensembles, varying the sources of stochasticity through\nparameter initialization, mini-batch sampling, and the data-augmentation\nrealizations, results in different fairness outcomes.\n","authors":["Wei-Yin Ko","Daniel D'souza","Karina Nguyen","Randall Balestriero","Sara Hooker"],"pdf_url":"https://arxiv.org/pdf/2303.00586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00120v2","updated":"2023-03-01T15:23:49Z","published":"2022-09-30T22:34:54Z","title":"NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning","summary":"  Neural Motion Planners (NMPs) have emerged as a promising tool for solving\nrobot navigation tasks in complex environments. However, these methods often\nrequire expert data for learning, which limits their application to scenarios\nwhere data generation is time-consuming. Recent developments have also led to\nphysics-informed deep neural models capable of representing complex dynamical\nPartial Differential Equations (PDEs). Inspired by these developments, we\npropose Neural Time Fields (NTFields) for robot motion planning in cluttered\nscenarios. Our framework represents a wave propagation model generating\ncontinuous arrival time to find path solutions informed by a nonlinear\nfirst-order PDE called Eikonal Equation. We evaluate our method in various\ncluttered 3D environments, including the Gibson dataset, and demonstrate its\nability to solve motion planning problems for 4-DOF and 6-DOF robot\nmanipulators where the traditional grid-based Eikonal planners often face the\ncurse of dimensionality. Furthermore, the results show that our method exhibits\nhigh success rates and significantly lower computational times than the\nstate-of-the-art methods, including NMPs that require training data from\nclassical planners.\n","authors":["Ruiqi Ni","Ahmed H. Qureshi"],"pdf_url":"https://arxiv.org/pdf/2210.00120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00858v2","updated":"2023-03-01T15:22:56Z","published":"2023-01-02T19:51:55Z","title":"Robust Average-Reward Markov Decision Processes","summary":"  In robust Markov decision processes (MDPs), the uncertainty in the transition\nkernel is addressed by finding a policy that optimizes the worst-case\nperformance over an uncertainty set of MDPs. While much of the literature has\nfocused on discounted MDPs, robust average-reward MDPs remain largely\nunexplored. In this paper, we focus on robust average-reward MDPs, where the\ngoal is to find a policy that optimizes the worst-case average reward over an\nuncertainty set. We first take an approach that approximates average-reward\nMDPs using discounted MDPs. We prove that the robust discounted value function\nconverges to the robust average-reward as the discount factor $\\gamma$ goes to\n$1$, and moreover, when $\\gamma$ is large, any optimal policy of the robust\ndiscounted MDP is also an optimal policy of the robust average-reward. We\nfurther design a robust dynamic programming approach, and theoretically\ncharacterize its convergence to the optimum. Then, we investigate robust\naverage-reward MDPs directly without using discounted MDPs as an intermediate\nstep. We derive the robust Bellman equation for robust average-reward MDPs,\nprove that the optimal policy can be derived from its solution, and further\ndesign a robust relative value iteration algorithm that provably finds its\nsolution, or equivalently, the optimal robust policy.\n","authors":["Yue Wang","Alvaro Velasquez","George Atia","Ashley Prater-Bennette","Shaofeng Zou"],"pdf_url":"https://arxiv.org/pdf/2301.00858v2.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2303.00579v1","updated":"2023-03-01T15:22:40Z","published":"2023-03-01T15:22:40Z","title":"Are More Layers Beneficial to Graph Transformers?","summary":"  Despite that going deep has proven successful in many neural architectures,\nthe existing graph transformers are relatively shallow. In this work, we\nexplore whether more layers are beneficial to graph transformers, and find that\ncurrent graph transformers suffer from the bottleneck of improving performance\nby increasing depth. Our further analysis reveals the reason is that deep graph\ntransformers are limited by the vanishing capacity of global attention,\nrestricting the graph transformer from focusing on the critical substructure\nand obtaining expressive features. To this end, we propose a novel graph\ntransformer model named DeepGraph that explicitly employs substructure tokens\nin the encoded representation, and applies local attention on related nodes to\nobtain substructure based attention encoding. Our model enhances the ability of\nthe global attention to focus on substructures and promotes the expressiveness\nof the representations, addressing the limitation of self-attention as the\ngraph transformer deepens. Experiments show that our method unblocks the depth\nlimitation of graph transformers and results in state-of-the-art performance\nacross various graph benchmarks with deeper models.\n","authors":["Haiteng Zhao","Shuming Ma","Dongdong Zhang","Zhi-Hong Deng","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2303.00579v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00573v1","updated":"2023-03-01T15:16:27Z","published":"2023-03-01T15:16:27Z","title":"Dimension-reduced KRnet maps for high-dimensional inverse problems","summary":"  We present a dimension-reduced KRnet map approach (DR-KRnet) for\nhigh-dimensional inverse problems, which is based on an explicit construction\nof a map that pushes forward the prior measure to the posterior measure in the\nlatent space. Our approach consists of two main components: data-driven VAE\nprior and density approximation of the posterior of the latent variable. In\nreality, it may not be trivial to initialize a prior distribution that is\nconsistent with available prior data; in other words, the complex prior\ninformation is often beyond simple hand-crafted priors. We employ variational\nautoencoder (VAE) to approximate the underlying distribution of the prior\ndataset, which is achieved through a latent variable and a decoder. Using the\ndecoder provided by the VAE prior, we reformulate the problem in a\nlow-dimensional latent space. In particular, we seek an invertible transport\nmap given by KRnet to approximate the posterior distribution of the latent\nvariable. Moreover, an efficient physics-constrained surrogate model without\nany labeled data is constructed to reduce the computational cost of solving\nboth forward and adjoint problems involved in likelihood computation. Numerical\nexperiments are implemented to demonstrate the validity, accuracy, and\nefficiency of DR-KRnet.\n","authors":["Yani Feng","Kejun Tang","Xiaoliang Wan","Qifeng Liao"],"pdf_url":"https://arxiv.org/pdf/2303.00573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06605v2","updated":"2023-03-01T15:16:15Z","published":"2022-11-12T08:03:57Z","title":"Comprehensive Analysis of Over-smoothing in Graph Neural Networks from\n  Markov Chains Perspective","summary":"  The over-smoothing problem is an obstacle of developing deep graph neural\nnetwork (GNN). Although many approaches to improve the over-smoothing problem\nhave been proposed, there is still a lack of comprehensive understanding and\nconclusion of this problem. In this work, we analyze the over-smoothing problem\nfrom the Markov chain perspective. We focus on message passing of GNN and first\nestablish a connection between GNNs and Markov chains on the graph. GNNs are\ndivided into two classes of operator-consistent and operator-inconsistent based\non whether the corresponding Markov chains are time-homogeneous. Next we\nattribute the over-smoothing problem to the convergence of an arbitrary initial\ndistribution to a stationary distribution. Based on this, we prove that\nalthough the previously proposed methods can alleviate over-smoothing, but\nthese methods cannot avoid the over-smoothing problem. In addition, we give the\nconclusion of the over-smoothing problem in two types of GNNs in the Markovian\nsense. On the one hand, operator-consistent GNN cannot avoid over-smoothing at\nan exponential rate. On the other hand, operator-inconsistent GNN is not always\nover-smoothing. Further, we investigate the existence of the limiting\ndistribution of the time-inhomogeneous Markov chain, from which we derive a\nsufficient condition for operator-inconsistent GNN to avoid over-smoothing.\nFinally, we design experiments to verify our findings. Results show that our\nproposed sufficient condition can effectively improve over-smoothing problem in\noperator-inconsistent GNN and enhance the performance of the model.\n","authors":["Weichen Zhao","Chenguang Wang","Congying Han","Tiande Guo"],"pdf_url":"https://arxiv.org/pdf/2211.06605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00565v1","updated":"2023-03-01T15:12:42Z","published":"2023-03-01T15:12:42Z","title":"AdaSAM: Boosting Sharpness-Aware Minimization with Adaptive Learning\n  Rate and Momentum for Training Deep Neural Networks","summary":"  Sharpness aware minimization (SAM) optimizer has been extensively explored as\nit can generalize better for training deep neural networks via introducing\nextra perturbation steps to flatten the landscape of deep learning models.\nIntegrating SAM with adaptive learning rate and momentum acceleration, dubbed\nAdaSAM, has already been explored empirically to train large-scale deep neural\nnetworks without theoretical guarantee due to the triple difficulties in\nanalyzing the coupled perturbation step, adaptive learning rate and momentum\nstep. In this paper, we try to analyze the convergence rate of AdaSAM in the\nstochastic non-convex setting. We theoretically show that AdaSAM admits a\n$\\mathcal{O}(1/\\sqrt{bT})$ convergence rate, which achieves linear speedup\nproperty with respect to mini-batch size $b$. Specifically, to decouple the\nstochastic gradient steps with the adaptive learning rate and perturbed\ngradient, we introduce the delayed second-order momentum term to decompose them\nto make them independent while taking an expectation during the analysis. Then\nwe bound them by showing the adaptive learning rate has a limited range, which\nmakes our analysis feasible. To the best of our knowledge, we are the first to\nprovide the non-trivial convergence rate of SAM with an adaptive learning rate\nand momentum acceleration. At last, we conduct several experiments on several\nNLP tasks, which show that AdaSAM could achieve superior performance compared\nwith SGD, AMSGrad, and SAM optimizers.\n","authors":["Hao Sun","Li Shen","Qihuang Zhong","Liang Ding","Shixiang Chen","Jingwei Sun","Jing Li","Guangzhong Sun","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.00565v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2303.00564v1","updated":"2023-03-01T15:11:23Z","published":"2023-03-01T15:11:23Z","title":"Learning curves for deep structured Gaussian feature models","summary":"  In recent years, significant attention in deep learning theory has been\ndevoted to analyzing the generalization performance of models with multiple\nlayers of Gaussian random features. However, few works have considered the\neffect of feature anisotropy; most assume that features are generated using\nindependent and identically distributed Gaussian weights. Here, we derive\nlearning curves for models with many layers of structured Gaussian features. We\nshow that allowing correlations between the rows of the first layer of features\ncan aid generalization, while structure in later layers is generally\ndetrimental. Our results shed light on how weight structure affects\ngeneralization in a simple class of solvable models.\n","authors":["Jacob A. Zavatone-Veth","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2303.00564v1.pdf","comment":"9+12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.10763v2","updated":"2023-03-01T14:58:09Z","published":"2023-02-12T12:19:57Z","title":"Contrastive Learning and the Emergence of Attributes Associations","summary":"  In response to an object presentation, supervised learning schemes generally\nrespond with a parsimonious label. Upon a similar presentation we humans\nrespond again with a label, but are flooded, in addition, by a myriad of\nassociations. A significant portion of these consist of the presented object\nattributes. Contrastive learning is a semi-supervised learning scheme based on\nthe application of identity preserving transformations on the object input\nrepresentations. It is conjectured in this work that these same applied\ntransformations preserve, in addition to the identity of the presented object,\nalso the identity of its semantically meaningful attributes. The corollary of\nthis is that the output representations of such a contrastive learning scheme\ncontain valuable information not only for the classification of the presented\nobject, but also for the presence or absence decision of any attribute of\ninterest. Simulation results which demonstrate this idea and the feasibility of\nthis conjecture are presented.\n","authors":["Daniel N. Nissani"],"pdf_url":"https://arxiv.org/pdf/2302.10763v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2112.02089v3","updated":"2023-03-01T14:49:01Z","published":"2021-12-03T18:55:50Z","title":"Regularized Newton Method with Global $O(1/k^2)$ Convergence","summary":"  We present a Newton-type method that converges fast from any initialization\nand for arbitrary convex objectives with Lipschitz Hessians. We achieve this by\nmerging the ideas of cubic regularization with a certain adaptive\nLevenberg--Marquardt penalty. In particular, we show that the iterates given by\n$x^{k+1}=x^k - \\bigl(\\nabla^2 f(x^k) + \\sqrt{H\\|\\nabla f(x^k)\\|}\n\\mathbf{I}\\bigr)^{-1}\\nabla f(x^k)$, where $H>0$ is a constant, converge\nglobally with a $\\mathcal{O}(\\frac{1}{k^2})$ rate. Our method is the first\nvariant of Newton's method that has both cheap iterations and provably fast\nglobal convergence. Moreover, we prove that locally our method converges\nsuperlinearly when the objective is strongly convex. To boost the method's\nperformance, we present a line search procedure that does not need prior\nknowledge of $H$ and is provably efficient.\n","authors":["Konstantin Mishchenko"],"pdf_url":"https://arxiv.org/pdf/2112.02089v3.pdf","comment":"Accepted for publication at SIOPT. 22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2211.15612v2","updated":"2023-03-01T14:48:03Z","published":"2022-11-28T18:11:26Z","title":"Learning from Good Trajectories in Offline Multi-Agent Reinforcement\n  Learning","summary":"  Offline multi-agent reinforcement learning (MARL) aims to learn effective\nmulti-agent policies from pre-collected datasets, which is an important step\ntoward the deployment of multi-agent systems in real-world applications.\nHowever, in practice, each individual behavior policy that generates\nmulti-agent joint trajectories usually has a different level of how well it\nperforms. e.g., an agent is a random policy while other agents are medium\npolicies. In the cooperative game with global reward, one agent learned by\nexisting offline MARL often inherits this random policy, jeopardizing the\nperformance of the entire team. In this paper, we investigate offline MARL with\nexplicit consideration on the diversity of agent-wise trajectories and propose\na novel framework called Shared Individual Trajectories (SIT) to address this\nproblem. Specifically, an attention-based reward decomposition network assigns\nthe credit to each agent through a differentiable key-value memory mechanism in\nan offline manner. These decomposed credits are then used to reconstruct the\njoint offline datasets into prioritized experience replay with individual\ntrajectories, thereafter agents can share their good trajectories and\nconservatively train their policies with a graph attention network (GAT) based\ncritic. We evaluate our method in both discrete control (i.e., StarCraft II and\nmulti-agent particle environment) and continuous control (i.e, multi-agent\nmujoco). The results indicate that our method achieves significantly better\nresults in complex and mixed offline multi-agent datasets, especially when the\ndifference of data quality between individual trajectories is large.\n","authors":["Qi Tian","Kun Kuang","Furui Liu","Baoxiang Wang"],"pdf_url":"https://arxiv.org/pdf/2211.15612v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15987v2","updated":"2023-03-01T14:39:06Z","published":"2022-10-28T08:37:13Z","title":"NNSVS: A Neural Network-Based Singing Voice Synthesis Toolkit","summary":"  This paper describes the design of NNSVS, an open-source software for neural\nnetwork-based singing voice synthesis research. NNSVS is inspired by Sinsy, an\nopen-source pioneer in singing voice synthesis research, and provides many\nadditional features such as multi-stream models, autoregressive fundamental\nfrequency models, and neural vocoders. Furthermore, NNSVS provides extensive\ndocumentation and numerous scripts to build complete singing voice synthesis\nsystems. Experimental results demonstrate that our best system significantly\noutperforms our reproduction of Sinsy and other baseline systems. The toolkit\nis available at https://github.com/nnsvs/nnsvs.\n","authors":["Ryuichi Yamamoto","Reo Yoneyama","Tomoki Toda"],"pdf_url":"https://arxiv.org/pdf/2210.15987v2.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.03459v2","updated":"2023-03-01T14:36:30Z","published":"2023-02-07T13:29:06Z","title":"On the relationship between multivariate splines and infinitely-wide\n  neural networks","summary":"  We consider multivariate splines and show that they have a random feature\nexpansion as infinitely wide neural networks with one-hidden layer and a\nhomogeneous activation function which is the power of the rectified linear\nunit. We show that the associated function space is a Sobolev space on a\nEuclidean ball, with an explicit bound on the norms of derivatives. This link\nprovides a new random feature expansion for multivariate splines that allow\nefficient algorithms. This random feature expansion is numerically better\nbehaved than usual random Fourier features, both in theory and practice. In\nparticular, in dimension one, we compare the associated leverage scores to\ncompare the two random expansions and show a better scaling for the neural\nnetwork expansion.\n","authors":["Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2302.03459v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13754v2","updated":"2023-03-01T14:29:48Z","published":"2023-02-27T13:32:47Z","title":"Combining Slow and Fast: Complementary Filtering for Dynamics Learning","summary":"  Modeling an unknown dynamical system is crucial in order to predict the\nfuture behavior of the system. A standard approach is training recurrent models\non measurement data. While these models typically provide exact short-term\npredictions, accumulating errors yield deteriorated long-term behavior. In\ncontrast, models with reliable long-term predictions can often be obtained,\neither by training a robust but less detailed model, or by leveraging\nphysics-based simulations. In both cases, inaccuracies in the models yield a\nlack of short-time details. Thus, different models with contrastive properties\non different time horizons are available. This observation immediately raises\nthe question: Can we obtain predictions that combine the best of both worlds?\nInspired by sensor fusion tasks, we interpret the problem in the frequency\ndomain and leverage classical methods from signal processing, in particular\ncomplementary filters. This filtering technique combines two signals by\napplying a high-pass filter to one signal, and low-pass filtering the other.\nEssentially, the high-pass filter extracts high-frequencies, whereas the\nlow-pass filter extracts low frequencies. Applying this concept to dynamics\nmodel learning enables the construction of models that yield accurate long- and\nshort-term predictions. Here, we propose two methods, one being purely\nlearning-based and the other one being a hybrid model that requires an\nadditional physics-based simulator.\n","authors":["Katharina Ensinger","Sebastian Ziesche","Barbara Rakitsch","Michael Tiemann","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2302.13754v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00529v1","updated":"2023-03-01T14:10:21Z","published":"2023-03-01T14:10:21Z","title":"Extending DNN-based Multiplicative Masking to Deep Subband Filtering for\n  Improved Dereverberation","summary":"  In this paper, we present a scheme for extending deep neural network-based\nmultiplicative maskers to deep subband filters for speech restoration in the\ntime-frequency domain. The resulting method can be generically applied to any\ndeep neural network providing masks in the time-frequency domain, while\nrequiring only few more trainable parameters and a computational overhead that\nis negligible for state-of-the-art neural networks. We demonstrate that the\nresulting deep subband filtering scheme outperforms multiplicative masking for\ndereverberation, while leaving the denoising performance virtually the same. We\nargue that this is because deep subband filtering in the time-frequency domain\nfits the subband approximation often assumed in the dereverberation literature,\nwhereas multiplicative masking corresponds to the narrowband approximation\ngenerally employed in denoising.\n","authors":["Jean-Marie Lemercier","Julian Tobergte","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2303.00529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14709v2","updated":"2023-03-01T14:09:04Z","published":"2022-10-26T13:40:57Z","title":"Learning on Large-scale Text-attributed Graphs via Variational Inference","summary":"  This paper studies learning on text-attributed graphs (TAGs), where each node\nis associated with a text description. An ideal solution for such a problem\nwould be integrating both the text and graph structure information with large\nlanguage models and graph neural networks (GNNs). However, the problem becomes\nvery challenging when graphs are large due to the high computational complexity\nbrought by training large language models and GNNs together. In this paper, we\npropose an efficient and effective solution to learning on large\ntext-attributed graphs by fusing graph structure and language learning with a\nvariational Expectation-Maximization (EM) framework, called GLEM. Instead of\nsimultaneously training large language models and GNNs on big graphs, GLEM\nproposes to alternatively update the two modules in the E-step and M-step. Such\na procedure allows training the two modules separately while simultaneously\nallowing the two modules to interact and mutually enhance each other. Extensive\nexperiments on multiple data sets demonstrate the efficiency and effectiveness\nof the proposed approach.\n","authors":["Jianan Zhao","Meng Qu","Chaozhuo Li","Hao Yan","Qian Liu","Rui Li","Xing Xie","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2210.14709v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2211.05641v2","updated":"2023-03-01T13:50:09Z","published":"2022-11-10T15:13:23Z","title":"Regression as Classification: Influence of Task Formulation on Neural\n  Network Features","summary":"  Neural networks can be trained to solve regression problems by using\ngradient-based methods to minimize the square loss. However, practitioners\noften prefer to reformulate regression as a classification problem, observing\nthat training on the cross entropy loss results in better performance. By\nfocusing on two-layer ReLU networks, which can be fully characterized by\nmeasures over their feature space, we explore how the implicit bias induced by\ngradient-based optimization could partly explain the above phenomenon. We\nprovide theoretical evidence that the regression formulation yields a measure\nwhose support can differ greatly from that for classification, in the case of\none-dimensional data. Our proposed optimal supports correspond directly to the\nfeatures learned by the input layer of the network. The different nature of\nthese supports sheds light on possible optimization difficulties the square\nloss could encounter during training, and we present empirical results\nillustrating this phenomenon.\n","authors":["Lawrence Stewart","Francis Bach","Quentin Berthet","Jean-Philippe Vert"],"pdf_url":"https://arxiv.org/pdf/2211.05641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13602v2","updated":"2023-03-01T13:48:55Z","published":"2023-02-27T09:10:08Z","title":"The Role of Pre-training Data in Transfer Learning","summary":"  The transfer learning paradigm of model pre-training and subsequent\nfine-tuning produces high-accuracy models. While most studies recommend scaling\nthe pre-training size to benefit most from transfer learning, a question\nremains: what data and method should be used for pre-training? We investigate\nthe impact of pre-training data distribution on the few-shot and full\nfine-tuning performance using 3 pre-training methods (supervised, contrastive\nlanguage-image and image-image), 7 pre-training datasets, and 9 downstream\ndatasets. Through extensive controlled experiments, we find that the choice of\nthe pre-training data source is essential for the few-shot transfer, but its\nrole decreases as more data is made available for fine-tuning. Additionally, we\nexplore the role of data curation and examine the trade-offs between label\nnoise and the size of the pre-training dataset. We find that using 2000X more\npre-training data from LAION can match the performance of supervised ImageNet\npre-training. Furthermore, we investigate the effect of pre-training methods,\ncomparing language-image contrastive vs. image-image contrastive, and find that\nthe latter leads to better downstream accuracy\n","authors":["Rahim Entezari","Mitchell Wortsman","Olga Saukh","M. Moein Shariatnia","Hanie Sedghi","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2302.13602v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15269v2","updated":"2023-03-01T13:46:20Z","published":"2022-05-30T17:26:06Z","title":"Kernel Neural Optimal Transport","summary":"  We study the Neural Optimal Transport (NOT) algorithm which uses the general\noptimal transport formulation and learns stochastic transport plans. We show\nthat NOT with the weak quadratic cost might learn fake plans which are not\noptimal. To resolve this issue, we introduce kernel weak quadratic costs. We\nshow that they provide improved theoretical guarantees and practical\nperformance. We test NOT with kernel costs on the unpaired image-to-image\ntranslation task.\n","authors":["Alexander Korotin","Daniil Selikhanovych","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2205.15269v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01130v3","updated":"2023-03-01T13:43:18Z","published":"2022-12-02T12:19:12Z","title":"Improving Pareto Front Learning via Multi-Sample Hypernetworks","summary":"  Pareto Front Learning (PFL) was recently introduced as an effective approach\nto obtain a mapping function from a given trade-off vector to a solution on the\nPareto front, which solves the multi-objective optimization (MOO) problem. Due\nto the inherent trade-off between conflicting objectives, PFL offers a flexible\napproach in many scenarios in which the decision makers can not specify the\npreference of one Pareto solution over another, and must switch between them\ndepending on the situation. However, existing PFL methods ignore the\nrelationship between the solutions during the optimization process, which\nhinders the quality of the obtained front. To overcome this issue, we propose a\nnovel PFL framework namely PHN-HVI, which employs a hypernetwork to generate\nmultiple solutions from a set of diverse trade-off preferences and enhance the\nquality of the Pareto front by maximizing the Hypervolume indicator defined by\nthese solutions. The experimental results on several MOO machine learning tasks\nshow that the proposed framework significantly outperforms the baselines in\nproducing the trade-off Pareto front.\n","authors":["Long P. Hoang","Dung D. Le","Tran Anh Tuan","Tran Ngoc Thang"],"pdf_url":"https://arxiv.org/pdf/2212.01130v3.pdf","comment":"Accepted to AAAI-23"},{"id":"http://arxiv.org/abs/2201.12220v3","updated":"2023-03-01T13:38:35Z","published":"2022-01-28T16:24:13Z","title":"Neural Optimal Transport","summary":"  We present a novel neural-networks-based algorithm to compute optimal\ntransport maps and plans for strong and weak transport costs. To justify the\nusage of neural networks, we prove that they are universal approximators of\ntransport plans between probability distributions. We evaluate the performance\nof our optimal transport algorithm on toy examples and on the unpaired\nimage-to-image translation.\n","authors":["Alexander Korotin","Daniil Selikhanovych","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2201.12220v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15512v2","updated":"2023-03-01T13:37:28Z","published":"2022-05-31T02:50:17Z","title":"Nearly Minimax Optimal Offline Reinforcement Learning with Linear\n  Function Approximation: Single-Agent MDP and Markov Game","summary":"  Offline reinforcement learning (RL) aims at learning an optimal strategy\nusing a pre-collected dataset without further interactions with the\nenvironment. While various algorithms have been proposed for offline RL in the\nprevious literature, the minimax optimality has only been (nearly) established\nfor tabular Markov decision processes (MDPs). In this paper, we focus on\noffline RL with linear function approximation and propose a new pessimism-based\nalgorithm for offline linear MDP. At the core of our algorithm is the\nuncertainty decomposition via a reference function, which is new in the\nliterature of offline RL under linear function approximation. Theoretical\nanalysis demonstrates that our algorithm can match the performance lower bound\nup to logarithmic factors. We also extend our techniques to the two-player\nzero-sum Markov games (MGs), and establish a new performance lower bound for\nMGs, which tightens the existing result, and verifies the nearly minimax\noptimality of the proposed algorithm. To the best of our knowledge, these are\nthe first computationally efficient and nearly minimax optimal algorithms for\noffline single-agent MDPs and MGs with linear function approximation.\n","authors":["Wei Xiong","Han Zhong","Chengshuai Shi","Cong Shen","Liwei Wang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.15512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00501v1","updated":"2023-03-01T13:35:22Z","published":"2023-03-01T13:35:22Z","title":"OmniForce: On Human-Centered, Large Model Empowered and Cloud-Edge\n  Collaborative AutoML System","summary":"  Automated machine learning (AutoML) seeks to build ML models with minimal\nhuman effort. While considerable research has been conducted in the area of\nAutoML in general, aiming to take humans out of the loop when building\nartificial intelligence (AI) applications, scant literature has focused on how\nAutoML works well in open-environment scenarios such as the process of training\nand updating large models, industrial supply chains or the industrial\nmetaverse, where people often face open-loop problems during the search\nprocess: they must continuously collect data, update data and models, satisfy\nthe requirements of the development and deployment environment, support massive\ndevices, modify evaluation metrics, etc. Addressing the open-environment issue\nwith pure data-driven approaches requires considerable data, computing\nresources, and effort from dedicated data engineers, making current AutoML\nsystems and platforms inefficient and computationally intractable.\nHuman-computer interaction is a practical and feasible way to tackle the\nproblem of open-environment AI. In this paper, we introduce OmniForce, a\nhuman-centered AutoML (HAML) system that yields both human-assisted ML and\nML-assisted human techniques, to put an AutoML system into practice and build\nadaptive AI in open-environment scenarios. Specifically, we present OmniForce\nin terms of ML version management; pipeline-driven development and deployment\ncollaborations; a flexible search strategy framework; and widely provisioned\nand crowdsourced application algorithms, including large models. Furthermore,\nthe (large) models constructed by OmniForce can be automatically turned into\nremote services in a few minutes; this process is dubbed model as a service\n(MaaS). Experimental results obtained in multiple search spaces and real-world\nuse cases demonstrate the efficacy and efficiency of OmniForce.\n","authors":["Chao Xue","Wei Liu","Shuai Xie","Zhenfang Wang","Jiaxing Li","Xuyang Peng","Liang Ding","Shanshan Zhao","Qiong Cao","Yibo Yang","Fengxiang He","Bohua Cai","Rongcheng Bian","Yiyan Zhao","Heliang Zheng","Xiangyang Liu","Dongkai Liu","Daqing Liu","Li Shen","Chang Li","Shijin Zhang","Yukang Zhang","Guanpu Chen","Shixiang Chen","Yibing Zhan","Jing Zhang","Chaoyue Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.00501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00500v1","updated":"2023-03-01T13:32:55Z","published":"2023-03-01T13:32:55Z","title":"Inherently Interpretable Multi-Label Classification Using Class-Specific\n  Counterfactuals","summary":"  Interpretability is essential for machine learning algorithms in high-stakes\napplication fields such as medical image analysis. However, high-performing\nblack-box neural networks do not provide explanations for their predictions,\nwhich can lead to mistrust and suboptimal human-ML collaboration. Post-hoc\nexplanation techniques, which are widely used in practice, have been shown to\nsuffer from severe conceptual problems. Furthermore, as we show in this paper,\ncurrent explanation techniques do not perform adequately in the multi-label\nscenario, in which multiple medical findings may co-occur in a single image. We\npropose Attri-Net, an inherently interpretable model for multi-label\nclassification. Attri-Net is a powerful classifier that provides transparent,\ntrustworthy, and human-understandable explanations. The model first generates\nclass-specific attribution maps based on counterfactuals to identify which\nimage regions correspond to certain medical findings. Then a simple logistic\nregression classifier is used to make predictions based solely on these\nattribution maps. We compare Attri-Net to five post-hoc explanation techniques\nand one inherently interpretable classifier on three chest X-ray datasets. We\nfind that Attri-Net produces high-quality multi-label explanations consistent\nwith clinical knowledge and has comparable classification performance to\nstate-of-the-art classification models.\n","authors":["Susu Sun","Stefano Woerner","Andreas Maier","Lisa M. Koch","Christian F. Baumgartner"],"pdf_url":"https://arxiv.org/pdf/2303.00500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13308v2","updated":"2023-03-01T13:27:24Z","published":"2022-09-27T11:23:49Z","title":"Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks:\n  Navigation, Manipulation, Interaction","summary":"  Safety is a crucial property of every robotic platform: any control policy\nshould always comply with actuator limits and avoid collisions with the\nenvironment and humans. In reinforcement learning, safety is even more\nfundamental for exploring an environment without causing any damage. While\nthere are many proposed solutions to the safe exploration problem, only a few\nof them can deal with the complexity of the real world. This paper introduces a\nnew formulation of safe exploration for reinforcement learning of various\nrobotic tasks. Our approach applies to a wide class of robotic platforms and\nenforces safety even under complex collision constraints learned from data by\nexploring the tangent space of the constraint manifold. Our proposed approach\nachieves state-of-the-art performance in simulated high-dimensional and dynamic\ntasks while avoiding collisions with the environment. We show safe real-world\ndeployment of our learned controller on a TIAGo++ robot, achieving remarkable\nperformance in manipulation and human-robot interaction tasks.\n","authors":["Puze Liu","Kuo Zhang","Davide Tateo","Snehal Jauhri","Zhiyuan Hu","Jan Peters","Georgia Chalvatzaki"],"pdf_url":"https://arxiv.org/pdf/2209.13308v2.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2303.00492v1","updated":"2023-03-01T13:27:06Z","published":"2023-03-01T13:27:06Z","title":"Lumos: Heterogeneity-aware Federated Graph Learning over Decentralized\n  Devices","summary":"  Graph neural networks (GNN) have been widely deployed in real-world networked\napplications and systems due to their capability to handle graph-structured\ndata. However, the growing awareness of data privacy severely challenges the\ntraditional centralized model training paradigm, where a server holds all the\ngraph information. Federated learning is an emerging collaborative computing\nparadigm that allows model training without data centralization. Existing\nfederated GNN studies mainly focus on systems where clients hold distinctive\ngraphs or sub-graphs. The practical node-level federated situation, where each\nclient is only aware of its direct neighbors, has yet to be studied. In this\npaper, we propose the first federated GNN framework called Lumos that supports\nsupervised and unsupervised learning with feature and degree protection on\nnode-level federated graphs. We first design a tree constructor to improve the\nrepresentation capability given the limited structural information. We further\npresent a Monte Carlo Markov Chain-based algorithm to mitigate the workload\nimbalance caused by degree heterogeneity with theoretically-guaranteed\nperformance. Based on the constructed tree for each client, a decentralized\ntree-based GNN trainer is proposed to support versatile training. Extensive\nexperiments demonstrate that Lumos outperforms the baseline with significantly\nhigher accuracy and greatly reduced communication cost and training time.\n","authors":["Qiying Pan","Yifei Zhu","Lingyang Chu"],"pdf_url":"https://arxiv.org/pdf/2303.00492v1.pdf","comment":"13 pages, 7 figures, to be published in the Proceedings of the 39th\n  IEEE International Conference on Data Engineering (ICDE 2023)"},{"id":"http://arxiv.org/abs/1910.02684v4","updated":"2023-03-01T13:12:23Z","published":"2019-10-07T09:21:49Z","title":"Effective Stabilized Self-Training on Few-Labeled Graph Data","summary":"  Graph neural networks (GNNs) are designed for semi-supervised node\nclassification on graphs where only a subset of nodes have class labels.\nHowever, under extreme cases when very few labels are available (e.g., 1\nlabeled node per class), GNNs suffer from severe performance degradation.\nSpecifically, we observe that existing GNNs suffer from unstable training\nprocess on few-labeled graphs, resulting to inferior performance on node\nclassification. Therefore, we propose an effective framework, Stabilized\nSelf-Training (SST), which is applicable to existing GNNs to handle the\nscarcity of labeled data, and consequently, boost classification accuracy. We\nconduct thorough empirical and theoretical analysis to support our findings and\nmotivate the algorithmic designs in SST. We apply SST to two popular GNN models\nGCN and DAGNN, to get SSTGCN and SSTDA methods respectively, and evaluate the\ntwo methods against 10 competitors over 5 benchmarking datasets. Extensive\nexperiments show that the proposed SST framework is highly effective,\nespecially when few labeled data are available. Our methods achieve superior\nperformance under almost all settings over all datasets. For instance, on a\nCora dataset with only 1 labeled node per class, the accuracy of SSTGCN is\n62.5%, 17.9% higher than GCN, and the accuracy of SSTDA is 66.4%, which\noutperforms DAGNN by 6.6%.\n","authors":["Ziang Zhou","Jieming Shi","Shengzhong Zhang","Zengfeng Huang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/1910.02684v4.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2102.10343v4","updated":"2023-03-01T13:05:43Z","published":"2021-02-20T13:19:31Z","title":"Measuring the Transferability of $\\ell_\\infty$ Attacks by the $\\ell_2$\n  Norm","summary":"  Deep neural networks could be fooled by adversarial examples with trivial\ndifferences to original samples. To keep the difference imperceptible in human\neyes, researchers bound the adversarial perturbations by the $\\ell_\\infty$\nnorm, which is now commonly served as the standard to align the strength of\ndifferent attacks for a fair comparison. However, we propose that using the\n$\\ell_\\infty$ norm alone is not sufficient in measuring the attack strength,\nbecause even with a fixed $\\ell_\\infty$ distance, the $\\ell_2$ distance also\ngreatly affects the attack transferability between models. Through the\ndiscovery, we reach more in-depth understandings towards the attack mechanism,\ni.e., several existing methods attack black-box models better partly because\nthey craft perturbations with 70% to 130% larger $\\ell_2$ distances. Since\nlarger perturbations naturally lead to better transferability, we thereby\nadvocate that the strength of attacks should be simultaneously measured by both\nthe $\\ell_\\infty$ and $\\ell_2$ norm. Our proposal is firmly supported by\nextensive experiments on ImageNet dataset from 7 attacks, 4 white-box models,\nand 9 black-box models.\n","authors":["Sizhe Chen","Qinghua Tao","Zhixing Ye","Xiaolin Huang"],"pdf_url":"https://arxiv.org/pdf/2102.10343v4.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00466v1","updated":"2023-03-01T12:47:14Z","published":"2023-03-01T12:47:14Z","title":"ASP: Learn a Universal Neural Solver!","summary":"  Applying machine learning to combinatorial optimization problems has the\npotential to improve both efficiency and accuracy. However, existing\nlearning-based solvers often struggle with generalization when faced with\nchanges in problem distributions and scales. In this paper, we propose a new\napproach called ASP: Adaptive Staircase Policy Space Response Oracle to address\nthese generalization issues and learn a universal neural solver. ASP consists\nof two components: Distributional Exploration, which enhances the solver's\nability to handle unknown distributions using Policy Space Response Oracles,\nand Persistent Scale Adaption, which improves scalability through curriculum\nlearning. We have tested ASP on several challenging COPs, including the\ntraveling salesman problem, the vehicle routing problem, and the prize\ncollecting TSP, as well as the real-world instances from TSPLib and CVRPLib.\nOur results show that even with the same model size and weak training signal,\nASP can help neural solvers explore and adapt to unseen distributions and\nvarying scales, achieving superior performance. In particular, compared with\nthe same neural solvers under a standard training pipeline, ASP produces a\nremarkable decrease in terms of the optimality gap with 90.9% and 47.43% on\ngenerated instances and real-world instances for TSP, and a decrease of 19% and\n45.57% for CVRP.\n","authors":["Chenguang Wang","Zhouliang Yu","Stephen McAleer","Tianshu Yu","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2303.00466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12000v2","updated":"2023-03-01T12:43:16Z","published":"2023-02-22T12:02:23Z","title":"Graph Construction using Principal Axis Trees for Simple Graph\n  Convolution","summary":"  Graph Neural Networks (GNNs) are increasingly becoming the favorite method\nfor graph learning. They exploit the semi-supervised nature of deep learning,\nand they bypass computational bottlenecks associated with traditional graph\nlearning methods. In addition to the feature matrix $X$, GNNs need an adjacency\nmatrix $A$ to perform feature propagation. In many cases the adjacency matrix\n$A$ is missing. We introduce a graph construction scheme that construct the\nadjacency matrix $A$ using unsupervised and supervised information.\nUnsupervised information characterize the neighborhood around points. We used\nPrincipal Axis trees (PA-trees) as a source of unsupervised information, where\nwe create edges between points falling onto the same leaf node. For supervised\ninformation, we used the concept of penalty and intrinsic graphs. A penalty\ngraph connects points with different class labels, whereas intrinsic graph\nconnects points with the same class label. We used the penalty and intrinsic\ngraphs to remove or add edges to the graph constructed via PA-tree. This graph\nconstruction scheme was tested on two well-known GNNs: 1) Graph Convolutional\nNetwork (GCN) and 2) Simple Graph Convolution (SGC). The experiments show that\nit is better to use SGC because it is faster and delivers better or the same\nresults as GCN. We also test the effect of oversmoothing on both GCN and SGC.\nWe found out that the level of smoothing has to be selected carefully for SGC\nto avoid oversmoothing.\n","authors":["Mashaan Alshammari","John Stavrakakis","Adel F. Ahmed","Masahiro Takatsuka"],"pdf_url":"https://arxiv.org/pdf/2302.12000v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00462v1","updated":"2023-03-01T12:41:12Z","published":"2023-03-01T12:41:12Z","title":"Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision","summary":"  This work proposes a novel approach to 4D radar-based scene flow estimation\nvia cross-modal learning. Our approach is motivated by the co-located sensing\nredundancy in modern autonomous vehicles. Such redundancy implicitly provides\nvarious forms of supervision cues to the radar scene flow estimation.\nSpecifically, we introduce a multi-task model architecture for the identified\ncross-modal learning problem and propose loss functions to opportunistically\nengage scene flow estimation using multiple cross-modal constraints for\neffective model training. Extensive experiments show the state-of-the-art\nperformance of our method and demonstrate the effectiveness of cross-modal\nsupervised learning to infer more accurate 4D radar scene flow. We also show\nits usefulness to two subtasks - motion segmentation and ego-motion estimation.\nOur source code will be available on \\url{https://github.com/Toytiny/CMFlow.}\n","authors":["Fangqiang Ding","Andras Palffy","Dariu M. Gavrila","Chris Xiaoxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2303.00462v1.pdf","comment":"10 pages, 7 figures. Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2210.14103v2","updated":"2023-03-01T12:37:46Z","published":"2022-10-25T15:41:21Z","title":"Bit Error and Block Error Rate Training for ML-Assisted Communication","summary":"  Even though machine learning (ML) techniques are being widely used in\ncommunications, the question of how to train communication systems has received\nsurprisingly little attention. In this paper, we show that the commonly used\nbinary cross-entropy (BCE) loss is a sensible choice in uncoded systems, e.g.,\nfor training ML-assisted data detectors, but may not be optimal in coded\nsystems. We propose new loss functions targeted at minimizing the block error\nrate and SNR deweighting, a novel method that trains communication systems for\noptimal performance over a range of signal-to-noise ratios. The utility of the\nproposed loss functions as well as of SNR deweighting is shown through\nsimulations in NVIDIA Sionna.\n","authors":["Reinhard Wiesmayr","Gian Marti","Chris Dick","Haochuan Song","Christoph Studer"],"pdf_url":"https://arxiv.org/pdf/2210.14103v2.pdf","comment":"A shorter version of this paper will be presented at the 2023 IEEE\n  International Conference on Acoustics, Speech, and Signal Processing (ICASSP)"},{"id":"http://arxiv.org/abs/2012.01805v2","updated":"2023-03-01T12:31:39Z","published":"2020-12-03T10:11:52Z","title":"Interpretability and Explainability: A Machine Learning Zoo Mini-tour","summary":"  In this review, we examine the problem of designing interpretable and\nexplainable machine learning models. Interpretability and explainability lie at\nthe core of many machine learning and statistical applications in medicine,\neconomics, law, and natural sciences. Although interpretability and\nexplainability have escaped a clear universal definition, many techniques\nmotivated by these properties have been developed over the recent 30 years with\nthe focus currently shifting towards deep learning methods. In this review, we\nemphasise the divide between interpretability and explainability and illustrate\nthese two different research directions with concrete examples of the\nstate-of-the-art. The review is intended for a general machine learning\naudience with interest in exploring the problems of interpretation and\nexplanation beyond logistic regression or random forest variable importance.\nThis work is not an exhaustive literature survey, but rather a primer focusing\nselectively on certain lines of research which the authors found interesting or\ninformative.\n","authors":["Ričards Marcinkevičs","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2012.01805v2.pdf","comment":"A preprint version of the 2023 WIREs Data Mining and Knowledge\n  Discovery article"},{"id":"http://arxiv.org/abs/2110.14468v3","updated":"2023-03-01T12:25:12Z","published":"2021-10-27T14:35:00Z","title":"DESTA: A Framework for Safe Reinforcement Learning with Markov Games of\n  Intervention","summary":"  Reinforcement learning (RL) involves performing exploratory actions in an\nunknown system. This can place a learning agent in dangerous and potentially\ncatastrophic system states. Current approaches for tackling safe learning in RL\nsimultaneously trade-off safe exploration and task fulfillment. In this paper,\nwe introduce a new generation of RL solvers that learn to minimise safety\nviolations while maximising the task reward to the extent that can be tolerated\nby the safe policy. Our approach introduces a novel two-player framework for\nsafe RL called Distributive Exploration Safety Training Algorithm (DESTA). The\ncore of DESTA is a game between two adaptive agents: Safety Agent that is\ndelegated the task of minimising safety violations and Task Agent whose goal is\nto maximise the environment reward. Specifically, Safety Agent can selectively\ntake control of the system at any given point to prevent safety violations\nwhile Task Agent is free to execute its policy at any other states. This\nframework enables Safety Agent to learn to take actions at certain states that\nminimise future safety violations, both during training and testing time, while\nTask Agent performs actions that maximise the task performance everywhere else.\nTheoretically, we prove that DESTA converges to stable points enabling safety\nviolations of pretrained policies to be minimised. Empirically, we show DESTA's\nability to augment the safety of existing policies and secondly, construct safe\nRL policies when the Task Agent and Safety Agent are trained concurrently. We\ndemonstrate DESTA's superior performance against leading RL methods in Lunar\nLander and Frozen Lake from OpenAI gym.\n","authors":["David Mguni","Usman Islam","Yaqi Sun","Xiuling Zhang","Joel Jennings","Aivar Sootla","Changmin Yu","Ziyan Wang","Jun Wang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2110.14468v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2103.09159"},{"id":"http://arxiv.org/abs/2209.07529v2","updated":"2023-03-01T12:21:06Z","published":"2022-09-15T04:54:02Z","title":"On the Soft-Subnetwork for Few-shot Class Incremental Learning","summary":"  Inspired by Regularized Lottery Ticket Hypothesis (RLTH), which hypothesizes\nthat there exist smooth (non-binary) subnetworks within a dense network that\nachieve the competitive performance of the dense network, we propose a few-shot\nclass incremental learning (FSCIL) method referred to as \\emph{Soft-SubNetworks\n(SoftNet)}. Our objective is to learn a sequence of sessions incrementally,\nwhere each session only includes a few training instances per class while\npreserving the knowledge of the previously learned ones. SoftNet jointly learns\nthe model weights and adaptive non-binary soft masks at a base training session\nin which each mask consists of the major and minor subnetwork; the former aims\nto minimize catastrophic forgetting during training, and the latter aims to\navoid overfitting to a few samples in each new training session. We provide\ncomprehensive empirical validations demonstrating that our SoftNet effectively\ntackles the few-shot incremental learning problem by surpassing the performance\nof state-of-the-art baselines over benchmark datasets.\n","authors":["Haeyong Kang","Jaehong Yoon","Sultan Rizky Hikmawan Madjid","Sung Ju Hwang","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2209.07529v2.pdf","comment":"The Eleventh International Conference on Learning Representations\n  (ICLR, 2023)"},{"id":"http://arxiv.org/abs/2303.00450v1","updated":"2023-03-01T12:21:00Z","published":"2023-03-01T12:21:00Z","title":"Federated Learning based Hierarchical 3D Indoor Localization","summary":"  The proliferation of connected devices in indoor environments opens the floor\nto a myriad of indoor applications with positioning services as key enablers.\nHowever, as privacy issues and resource constraints arise, it becomes more\nchallenging to design accurate positioning systems as required by most\napplications. To overcome the latter challenges, we present in this paper, a\nfederated learning (FL) framework for hierarchical 3D indoor localization using\na deep neural network. Indeed, we firstly shed light on the prominence of\nexploiting the hierarchy between floors and buildings in a multi-building and\nmulti-floor indoor environment. Then, we propose an FL framework to train the\ndesigned hierarchical model. The performance evaluation shows that by adopting\na hierarchical learning scheme, we can improve the localization accuracy by up\nto 24.06% compared to the non-hierarchical approach. We also obtain a building\nand floor prediction accuracy of 99.90% and 94.87% respectively. With the\nproposed FL framework, we can achieve a near-performance characteristic as of\nthe central training with an increase of only 7.69% in the localization error.\nMoreover, the conducted scalability study reveals that the FL system accuracy\nis improved when more devices join the training.\n","authors":["Yaya Etiabi","Wafa Njima","El Mehdi Amhoud"],"pdf_url":"https://arxiv.org/pdf/2303.00450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2008.04267v2","updated":"2023-03-01T12:14:52Z","published":"2020-08-10T17:09:16Z","title":"Robust Validation: Confident Predictions Even When Distributions Shift","summary":"  While the traditional viewpoint in machine learning and statistics assumes\ntraining and testing samples come from the same population, practice belies\nthis fiction. One strategy -- coming from robust statistics and optimization --\nis thus to build a model robust to distributional perturbations. In this paper,\nwe take a different approach to describe procedures for robust predictive\ninference, where a model provides uncertainty estimates on its predictions\nrather than point predictions. We present a method that produces prediction\nsets (almost exactly) giving the right coverage level for any test distribution\nin an $f$-divergence ball around the training population. The method, based on\nconformal inference, achieves (nearly) valid coverage in finite samples, under\nonly the condition that the training data be exchangeable. An essential\ncomponent of our methodology is to estimate the amount of expected future data\nshift and build robustness to it; we develop estimators and prove their\nconsistency for protection and validity of uncertainty estimates under shifts.\nBy experimenting on several large-scale benchmark datasets, including Recht et\nal.'s CIFAR-v4 and ImageNet-V2 datasets, we provide complementary empirical\nresults that highlight the importance of robust predictive validity.\n","authors":["Maxime Cauchois","Suyash Gupta","Alnur Ali","John C. Duchi"],"pdf_url":"https://arxiv.org/pdf/2008.04267v2.pdf","comment":"58 pages, 10 figures"},{"id":"http://arxiv.org/abs/2303.00442v1","updated":"2023-03-01T12:00:37Z","published":"2023-03-01T12:00:37Z","title":"Re-weighting Based Group Fairness Regularization via Classwise Robust\n  Optimization","summary":"  Many existing group fairness-aware training methods aim to achieve the group\nfairness by either re-weighting underrepresented groups based on certain rules\nor using weakly approximated surrogates for the fairness metrics in the\nobjective as regularization terms. Although each of the learning schemes has\nits own strength in terms of applicability or performance, respectively, it is\ndifficult for any method in the either category to be considered as a gold\nstandard since their successful performances are typically limited to specific\ncases. To that end, we propose a principled method, dubbed as \\ours, which\nunifies the two learning schemes by incorporating a well-justified group\nfairness metric into the training objective using a class wise distributionally\nrobust optimization (DRO) framework. We then develop an iterative optimization\nalgorithm that minimizes the resulting objective by automatically producing the\ncorrect re-weights for each group. Our experiments show that FairDRO is\nscalable and easily adaptable to diverse applications, and consistently\nachieves the state-of-the-art performance on several benchmark datasets in\nterms of the accuracy-fairness trade-off, compared to recent strong baselines.\n","authors":["Sangwon Jung","Taeeon Park","Sanghyuk Chun","Taesup Moon"],"pdf_url":"https://arxiv.org/pdf/2303.00442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00438v1","updated":"2023-03-01T11:54:22Z","published":"2023-03-01T11:54:22Z","title":"A Framework to Generate Neurosymbolic PDDL-compliant Planners","summary":"  The problem of integrating high-level task planning in the execution loop of\na real-world robot architecture remains challenging, as the planning times of\ntraditional symbolic planners explode combinatorially with the number of\nsymbols to plan upon. In this paper, we present Teriyaki, a framework for\ntraining Large Language Models (LLMs), and in particular the now well-known\nGPT-3 model, into neurosymbolic planners compatible with the Planning Domain\nDefinition Language (PDDL). Unlike symbolic approaches, LLMs require a training\nprocess. However, their response time scales with the combined length of the\ninput and the output. Hence, LLM-based planners can potentially provide\nsignificant performance gains on complex planning problems as the technology\nmatures and becomes more accessible. In this preliminary work, which to our\nknowledge is the first using LLMs for planning in robotics, we (i) outline a\nmethodology for training LLMs as PDDL solvers, (ii) generate PDDL-compliant\nplanners for two challenging PDDL domains, and (iii) test the planning times\nand the plan quality associated with the obtained planners, while also\ncomparing them to a state-of-the-art PDDL planner, namely Probe. Results\nconfirm the viability of the approach, with Teriyaki-based planners being able\nto solve 95.5% of problems in a test data set of 1000 samples, and even\ngenerating plans up to 13.5% shorter on average than the employed traditional\nplanner, depending on the domain.\n","authors":["Alessio Capitanelli","Fulvio Mastrogiovanni"],"pdf_url":"https://arxiv.org/pdf/2303.00438v1.pdf","comment":"Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems. 7 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.00431v1","updated":"2023-03-01T11:39:54Z","published":"2023-03-01T11:39:54Z","title":"OliVaR: Improving Olive Variety Recognition using Deep Neural Networks","summary":"  The easy and accurate identification of varieties is fundamental in\nagriculture, especially in the olive sector, where more than 1200 olive\nvarieties are currently known worldwide. Varietal misidentification leads to\nmany potential problems for all the actors in the sector: farmers and nursery\nworkers may establish the wrong variety, leading to its maladaptation in the\nfield; olive oil and table olive producers may label and sell a non-authentic\nproduct; consumers may be misled; and breeders may commit errors during\ntargeted crossings between different varieties. To date, the standard for\nvarietal identification and certification consists of two methods:\nmorphological classification and genetic analysis. The morphological\nclassification consists of the visual pairwise comparison of different organs\nof the olive tree, where the most important organ is considered to be the\nendocarp. In contrast, different methods for genetic classification exist\n(RAPDs, SSR, and SNP). Both classification methods present advantages and\ndisadvantages. Visual morphological classification requires highly specialized\npersonnel and is prone to human error. Genetic identification methods are more\naccurate but incur a high cost and are difficult to implement. This paper\nintroduces OliVaR, a novel approach to olive varietal identification. OliVaR\nuses a teacher-student deep learning architecture to learn the defining\ncharacteristics of the endocarp of each specific olive variety and perform\nclassification. We construct what is, to the best of our knowledge, the largest\nolive variety dataset to date, comprising image data for 131 varieties from the\nMediterranean basin. We thoroughly test OliVaR on this dataset and show that it\ncorrectly predicts olive varieties with over 86% accuracy.\n","authors":["Hristofor Miho","Giulio Pagnotta","Dorjan Hitaj","Fabio De Gaspari","Luigi V. Mancini","Georgios Koubouris","Gianluca Godino","Mehmet Hakan","Concepcion Muñoz Diez"],"pdf_url":"https://arxiv.org/pdf/2303.00431v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.00428v1","updated":"2023-03-01T11:32:59Z","published":"2023-03-01T11:32:59Z","title":"Supporting Future Electrical Utilities: Using Deep Learning Methods in\n  EMS and DMS Algorithms","summary":"  Electrical power systems are increasing in size, complexity, as well as\ndynamics due to the growing integration of renewable energy resources, which\nhave sporadic power generation. This necessitates the development of near\nreal-time power system algorithms, demanding lower computational complexity\nregarding the power system size. Considering the growing trend in the\ncollection of historical measurement data and recent advances in the rapidly\ndeveloping deep learning field, the main goal of this paper is to provide a\nreview of recent deep learning-based power system monitoring and optimization\nalgorithms. Electrical utilities can benefit from this review by\nre-implementing or enhancing the algorithms traditionally used in energy\nmanagement systems (EMS) and distribution management systems (DMS).\n","authors":["Ognjen Kundacina","Gorana Gojic","Mile Mitrovic","Dragisa Miskovic","Dejan Vukobratovic"],"pdf_url":"https://arxiv.org/pdf/2303.00428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01217v2","updated":"2023-03-01T11:23:58Z","published":"2022-12-31T04:26:25Z","title":"Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples","summary":"  There is a growing interest in developing unlearnable examples (UEs) against\nvisual privacy leaks on the Internet. UEs are training samples added with\ninvisible but unlearnable noise, which have been found can prevent unauthorized\ntraining of machine learning models. UEs typically are generated via a bilevel\noptimization framework with a surrogate model to remove (minimize) errors from\nthe original samples, and then applied to protect the data against unknown\ntarget models. However, existing UE generation methods all rely on an ideal\nassumption called label-consistency, where the hackers and protectors are\nassumed to hold the same label for a given sample. In this work, we propose and\npromote a more practical label-agnostic setting, where the hackers may exploit\nthe protected data quite differently from the protectors. E.g., a m-class\nunlearnable dataset held by the protector may be exploited by the hacker as a\nn-class dataset. Existing UE generation methods are rendered ineffective in\nthis challenging setting. To tackle this challenge, we present a novel\ntechnique called Unlearnable Clusters (UCs) to generate label-agnostic\nunlearnable examples with cluster-wise perturbations. Furthermore, we propose\nto leverage VisionandLanguage Pre-trained Models (VLPMs) like CLIP as the\nsurrogate model to improve the transferability of the crafted UCs to diverse\ndomains. We empirically verify the effectiveness of our proposed approach under\na variety of settings with different datasets, target models, and even\ncommercial platforms Microsoft Azure and Baidu PaddlePaddle. Code is available\nat \\url{https://github.com/jiamingzhang94/Unlearnable-Clusters}.\n","authors":["Jiaming Zhang","Xingjun Ma","Qi Yi","Jitao Sang","Yugang Jiang","Yaowei Wang","Changsheng Xu"],"pdf_url":"https://arxiv.org/pdf/2301.01217v2.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2303.00413v1","updated":"2023-03-01T11:09:06Z","published":"2023-03-01T11:09:06Z","title":"Automated Task-Time Interventions to Improve Teamwork using Imitation\n  Learning","summary":"  Effective human-human and human-autonomy teamwork is critical but often\nchallenging to perfect. The challenge is particularly relevant in time-critical\ndomains, such as healthcare and disaster response, where the time pressures can\nmake coordination increasingly difficult to achieve and the consequences of\nimperfect coordination can be severe. To improve teamwork in these and other\ndomains, we present TIC: an automated intervention approach for improving\ncoordination between team members. Using BTIL, a multi-agent imitation learning\nalgorithm, our approach first learns a generative model of team behavior from\npast task execution data. Next, it utilizes the learned generative model and\nteam's task objective (shared reward) to algorithmically generate\nexecution-time interventions. We evaluate our approach in synthetic multi-agent\nteaming scenarios, where team members make decentralized decisions without full\nobservability of the environment. The experiments demonstrate that the\nautomated interventions can successfully improve team performance and shed\nlight on the design of autonomous agents for improving teamwork.\n","authors":["Sangwon Seo","Bing Han","Vaibhav Unhelkar"],"pdf_url":"https://arxiv.org/pdf/2303.00413v1.pdf","comment":"Extended version of an identically-titled paper accepted at AAMAS\n  2023"},{"id":"http://arxiv.org/abs/2303.00409v1","updated":"2023-03-01T11:00:20Z","published":"2023-03-01T11:00:20Z","title":"RePAD2: Real-Time, Lightweight, and Adaptive Anomaly Detection for\n  Open-Ended Time Series","summary":"  An open-ended time series refers to a series of data points indexed in time\norder without an end. Such a time series can be found everywhere due to the\nprevalence of Internet of Things. Providing lightweight and real-time anomaly\ndetection for open-ended time series is highly desirable to industry and\norganizations since it allows immediate response and avoids potential financial\nloss. In the last few years, several real-time time series anomaly detection\napproaches have been introduced. However, they might exhaust system resources\nwhen they are applied to open-ended time series for a long time. To address\nthis issue, in this paper we propose RePAD2, a lightweight real-time anomaly\ndetection approach for open-ended time series by improving its predecessor\nRePAD, which is one of the state-of-the-art anomaly detection approaches. We\nconducted a series of experiments to compare RePAD2 with RePAD and another\nsimilar detection approach based on real-world time series datasets, and\ndemonstrated that RePAD2 can address the mentioned resource exhaustion issue\nwhile offering comparable detection accuracy and slightly less time\nconsumption.\n","authors":["Ming-Chang Lee","Jia-Chun Lin"],"pdf_url":"https://arxiv.org/pdf/2303.00409v1.pdf","comment":"10 pages, 11 figures, and 10 tables, 8th International Conference on\n  Internet of Things, Big Data and Security (IoTBDS 2023)"},{"id":"http://arxiv.org/abs/2303.00403v1","updated":"2023-03-01T10:51:27Z","published":"2023-03-01T10:51:27Z","title":"Can representation learning for multimodal image registration be\n  improved by supervision of intermediate layers?","summary":"  Multimodal imaging and correlative analysis typically require image\nalignment. Contrastive learning can generate representations of multimodal\nimages, reducing the challenging task of multimodal image registration to a\nmonomodal one. Previously, additional supervision on intermediate layers in\ncontrastive learning has improved biomedical image classification. We evaluate\nif a similar approach improves representations learned for registration to\nboost registration performance. We explore three approaches to add contrastive\nsupervision to the latent features of the bottleneck layer in the U-Nets\nencoding the multimodal images and evaluate three different critic functions.\nOur results show that representations learned without additional supervision on\nlatent features perform best in the downstream task of registration on two\npublic biomedical datasets. We investigate the performance drop by exploiting\nrecent insights in contrastive learning in classification and self-supervised\nlearning. We visualize the spatial relations of the learned representations by\nmeans of multidimensional scaling, and show that additional supervision on the\nbottleneck layer can lead to partial dimensional collapse of the intermediate\nembedding space.\n","authors":["Elisabeth Wetzer","Joakim Lindblad","Nataša Sladoje"],"pdf_url":"https://arxiv.org/pdf/2303.00403v1.pdf","comment":"15 Pages + 9 Pages Appendix, 10 Figures"},{"id":"http://arxiv.org/abs/2303.00400v1","updated":"2023-03-01T10:39:58Z","published":"2023-03-01T10:39:58Z","title":"A Study on Accuracy, Miscalibration, and Popularity Bias in\n  Recommendations","summary":"  Recent research has suggested different metrics to measure the inconsistency\nof recommendation performance, including the accuracy difference between user\ngroups, miscalibration, and popularity lift. However, a study that relates\nmiscalibration and popularity lift to recommendation accuracy across different\nuser groups is still missing. Additionally, it is unclear if particular genres\ncontribute to the emergence of inconsistency in recommendation performance\nacross user groups. In this paper, we present an analysis of these three\naspects of five well-known recommendation algorithms for user groups that\ndiffer in their preference for popular content. Additionally, we study how\ndifferent genres affect the inconsistency of recommendation performance, and\nhow this is aligned with the popularity of the genres. Using data from LastFm,\nMovieLens, and MyAnimeList, we present two key findings. First, we find that\nusers with little interest in popular content receive the worst recommendation\naccuracy, and that this is aligned with miscalibration and popularity lift.\nSecond, our experiments show that particular genres contribute to a different\nextent to the inconsistency of recommendation performance, especially in terms\nof miscalibration in the case of the MyAnimeList dataset.\n","authors":["Dominik Kowald","Gregor Mayr","Markus Schedl","Elisabeth Lex"],"pdf_url":"https://arxiv.org/pdf/2303.00400v1.pdf","comment":"Accepted at BIAS@ECIR WS 2023"},{"id":"http://arxiv.org/abs/2303.00399v1","updated":"2023-03-01T10:38:10Z","published":"2023-03-01T10:38:10Z","title":"D4FT: A Deep Learning Approach to Kohn-Sham Density Functional Theory","summary":"  Kohn-Sham Density Functional Theory (KS-DFT) has been traditionally solved by\nthe Self-Consistent Field (SCF) method. Behind the SCF loop is the physics\nintuition of solving a system of non-interactive single-electron wave functions\nunder an effective potential. In this work, we propose a deep learning approach\nto KS-DFT. First, in contrast to the conventional SCF loop, we propose to\ndirectly minimize the total energy by reparameterizing the orthogonal\nconstraint as a feed-forward computation. We prove that such an approach has\nthe same expressivity as the SCF method, yet reduces the computational\ncomplexity from O(N^4) to O(N^3). Second, the numerical integration which\ninvolves a summation over the quadrature grids can be amortized to the\noptimization steps. At each step, stochastic gradient descent (SGD) is\nperformed with a sampled minibatch of the grids. Extensive experiments are\ncarried out to demonstrate the advantage of our approach in terms of efficiency\nand stability. In addition, we show that our approach enables us to explore\nmore complex neural-based wave functions.\n","authors":["Tianbo Li","Min Lin","Zheyuan Hu","Kunhao Zheng","Giovanni Vignale","Kenji Kawaguchi","A. H. Castro Neto","Kostya S. Novoselov","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2303.00399v1.pdf","comment":"Accepted by The Eleventh International Conference on Learning\n  Representations (ICLR 2023, notable-top-25%)"},{"id":"http://arxiv.org/abs/2204.02678v2","updated":"2023-03-01T10:14:50Z","published":"2022-04-06T08:59:38Z","title":"Random Features Model with General Convex Regularization: A Fine Grained\n  Analysis with Precise Asymptotic Learning Curves","summary":"  We compute precise asymptotic expressions for the learning curves of least\nsquares random feature (RF) models with either a separable strongly convex\nregularization or the $\\ell_1$ regularization. We propose a novel multi-level\napplication of the convex Gaussian min max theorem (CGMT) to overcome the\ntraditional difficulty of finding computable expressions for random features\nmodels with correlated data. Our result takes the form of a computable\n4-dimensional scalar optimization. In contrast to previous results, our\napproach does not require solving an often intractable proximal operator, which\nscales with the number of model parameters. Furthermore, we extend the\nuniversality results for the training and generalization errors for RF models\nto $\\ell_1$ regularization. In particular, we demonstrate that under mild\nconditions, random feature models with elastic net or $\\ell_1$ regularization\nare asymptotically equivalent to a surrogate Gaussian model with the same first\nand second moments. We numerically demonstrate the predictive capacity of our\nresults, and show experimentally that the predicted test error is accurate even\nin the non-asymptotic regime.\n","authors":["David Bosch","Ashkan Panahi","Ayca Özcelikkale","Devdatt Dubhash"],"pdf_url":"https://arxiv.org/pdf/2204.02678v2.pdf","comment":"52 pages, 3 figures"},{"id":"http://arxiv.org/abs/2203.00162v3","updated":"2023-03-01T10:01:16Z","published":"2022-02-19T09:56:38Z","title":"Do Transformers know symbolic rules, and would we know if they did?","summary":"  To improve the explainability of leading Transformer networks used in NLP, it\nis important to tease apart genuine symbolic rules from merely associative\ninput-output patterns. However, we identify several inconsistencies in how\n``symbolicity'' has been construed in recent NLP literature. To mitigate this\nproblem, we propose two criteria to be the most relevant, one pertaining to a\nsystem's internal architecture and the other to the dissociation between\nabstract rules and specific input identities. From this perspective, we\ncritically examine prior work on the symbolic capacities of Transformers, and\ndeem the results to be fundamentally inconclusive for reasons inherent in\nexperiment design. We further maintain that there is no simple fix to this\nproblem, since it arises -- to an extent -- in all end-to-end settings.\nNonetheless, we emphasize the need for more robust evaluation of whether\nnon-symbolic explanations exist for success in seemingly symbolic tasks. To\nfacilitate this, we experiment on four sequence modelling tasks on the T5\nTransformer in two experiment settings: zero-shot generalization, and\ngeneralization across class-specific vocabularies flipped between the training\nand test set. We observe that T5's generalization is markedly stronger in\nsequence-to-sequence tasks than in comparable classification tasks. Based on\nthis, we propose a thus far overlooked analysis, where the Transformer itself\ndoes not need to be symbolic to be part of a symbolic architecture as the\nprocessor, operating on the input and output as external memory components.\n","authors":["Tommi Gröndahl","Yujia Guo","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2203.00162v3.pdf","comment":"15 pages, 1 figure"},{"id":"http://arxiv.org/abs/2303.00364v1","updated":"2023-03-01T09:45:17Z","published":"2023-03-01T09:45:17Z","title":"Lessons Learned Report: Super-Resolution for Detection Tasks in\n  Engineering Problem-Solving","summary":"  We describe the lessons learned from targeting agricultural detection\nproblem-solving, when subject to low resolution input maps, by means of Machine\nLearning-based super-resolution approaches. The underlying domain is the\nso-called agro-detection class of problems, and the specific objective is to\nlearn a complementary ensemble of sporadic input maps. While super-resolution\nalgorithms are branded with the capacity to enhance various attractive features\nin generic photography, we argue that they must meet certain requirements, and\nmore importantly, that their outcome does not necessarily guarantee an\nimprovement in engineering detection problem-solving (unlike so-called\naesthetics/artistic super-resolution in ImageNet-like datasets). By presenting\nspecific data-driven case studies, we outline a set of limitations and\nrecommendations for deploying super-resolution algorithms for agro-detection\nproblems. Another conclusion states that super-resolution algorithms can be\nused for learning missing spectral channels, and that their usage may result in\nsome desired side-effects such as channels' synchronization.\n","authors":["Martin Feder","Michal Horovitz","Assaf Chen","Raphael Linker","Ofer M. Shir"],"pdf_url":"https://arxiv.org/pdf/2303.00364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00356v1","updated":"2023-03-01T09:34:52Z","published":"2023-03-01T09:34:52Z","title":"A Deep Reinforcement Learning Trader without Offline Training","summary":"  In this paper we pursue the question of a fully online trading algorithm\n(i.e. one that does not need offline training on previously gathered data). For\nthis task we use Double Deep $Q$-learning in the episodic setting with Fast\nLearning Networks approximating the expected reward $Q$. Additionally, we\ndefine the possible terminal states of an episode in such a way as to introduce\na mechanism to conserve some of the money in the trading pool when market\nconditions are seen as unfavourable. Some of these money are taken as profit\nand some are reused at a later time according to certain criteria. After\ndescribing the algorithm, we test it using the 1-minute-tick data for Cardano's\nprice on Binance. We see that the agent performs better than trading with\nrandomly chosen actions on each timestep. And it does so when tested on the\nwhole dataset as well as on different subsets, capturing different market\ntrends.\n","authors":["Boian Lazov"],"pdf_url":"https://arxiv.org/pdf/2303.00356v1.pdf","comment":"17 pages, 5 figures, full Mathematica code included"},{"id":"http://arxiv.org/abs/2302.10747v2","updated":"2023-03-01T09:29:29Z","published":"2023-02-17T07:11:02Z","title":"Clustered Data Sharing for Non-IID Federated Learning over Wireless\n  Networks","summary":"  Federated Learning (FL) is a novel distributed machine learning approach to\nleverage data from Internet of Things (IoT) devices while maintaining data\nprivacy. However, the current FL algorithms face the challenges of\nnon-independent and identically distributed (non-IID) data, which causes high\ncommunication costs and model accuracy declines. To address the statistical\nimbalances in FL, we propose a clustered data sharing framework which spares\nthe partial data from cluster heads to credible associates through\ndevice-to-device (D2D) communication. Moreover, aiming at diluting the data\nskew on nodes, we formulate the joint clustering and data sharing problem based\non the privacy-preserving constrained graph. To tackle the serious coupling of\ndecisions on the graph, we devise a distribution-based adaptive clustering\nalgorithm (DACA) basing on three deductive cluster-forming conditions, which\nensures the maximum yield of data sharing. The experiments show that the\nproposed framework facilitates FL on non-IID datasets with better convergence\nand model accuracy under a limited communication environment.\n","authors":["Gang Hu","Yinglei Teng","Nan Wang","F. Richard Yu"],"pdf_url":"https://arxiv.org/pdf/2302.10747v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00351v1","updated":"2023-03-01T09:27:08Z","published":"2023-03-01T09:27:08Z","title":"An end-to-end SE(3)-equivariant segmentation network","summary":"  Convolutional neural networks (CNNs) allow for parameter sharing and\ntranslational equivariance by using convolutional kernels in their linear\nlayers. By restricting these kernels to be SO(3)-steerable, CNNs can further\nimprove parameter sharing and equivariance. These equivariant convolutional\nlayers have several advantages over standard convolutional layers, including\nincreased robustness to unseen poses, smaller network size, and improved sample\nefficiency. Despite this, most segmentation networks used in medical image\nanalysis continue to rely on standard convolutional kernels. In this paper, we\npresent a new family of segmentation networks that use equivariant voxel\nconvolutions based on spherical harmonics, as well as equivariant pooling and\nnormalization operations. These SE(3)-equivariant volumetric segmentation\nnetworks, which are robust to data poses not seen during training, do not\nrequire rotation-based data augmentation during training. In addition, we\ndemonstrate improved segmentation performance in MRI brain tumor and healthy\nbrain structure segmentation tasks, with enhanced robustness to reduced amounts\nof training data and improved parameter efficiency. Code to reproduce our\nresults, and to implement the equivariant segmentation networks for other tasks\nis available at~\\url{http://github.com/SCAN-NRAD/e3nn_Unet}.\n","authors":["Ivan Diaz","Mario Geiger","Richard Iain McKinley"],"pdf_url":"https://arxiv.org/pdf/2303.00351v1.pdf","comment":"19 pages, 10 figures, submitted to the Journal of Machine Learning\n  for Biomedical Imaging"},{"id":"http://arxiv.org/abs/2209.00588v2","updated":"2023-03-01T09:21:14Z","published":"2022-09-01T17:03:07Z","title":"Transformers are Sample-Efficient World Models","summary":"  Deep reinforcement learning agents are notoriously sample inefficient, which\nconsiderably limits their application to real-world problems. Recently, many\nmodel-based methods have been designed to address this issue, with learning in\nthe imagination of a world model being one of the most prominent approaches.\nHowever, while virtually unlimited interaction with a simulated environment\nsounds appealing, the world model has to be accurate over extended periods of\ntime. Motivated by the success of Transformers in sequence modeling tasks, we\nintroduce IRIS, a data-efficient agent that learns in a world model composed of\na discrete autoencoder and an autoregressive Transformer. With the equivalent\nof only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean\nhuman normalized score of 1.046, and outperforms humans on 10 out of 26 games,\nsetting a new state of the art for methods without lookahead search. To foster\nfuture research on Transformers and world models for sample-efficient\nreinforcement learning, we release our code and models at\nhttps://github.com/eloialonso/iris.\n","authors":["Vincent Micheli","Eloi Alonso","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2209.00588v2.pdf","comment":"ICLR 2023 (notable top 5%)"},{"id":"http://arxiv.org/abs/2303.00340v1","updated":"2023-03-01T09:07:27Z","published":"2023-03-01T09:07:27Z","title":"A Practical Upper Bound for the Worst-Case Attribution Deviations","summary":"  Model attribution is a critical component of deep neural networks (DNNs) for\nits interpretability to complex models. Recent studies bring up attention to\nthe security of attribution methods as they are vulnerable to attribution\nattacks that generate similar images with dramatically different attributions.\nExisting works have been investigating empirically improving the robustness of\nDNNs against those attacks; however, none of them explicitly quantifies the\nactual deviations of attributions. In this work, for the first time, a\nconstrained optimization problem is formulated to derive an upper bound that\nmeasures the largest dissimilarity of attributions after the samples are\nperturbed by any noises within a certain region while the classification\nresults remain the same. Based on the formulation, different practical\napproaches are introduced to bound the attributions above using Euclidean\ndistance and cosine similarity under both $\\ell_2$ and $\\ell_\\infty$-norm\nperturbations constraints. The bounds developed by our theoretical study are\nvalidated on various datasets and two different types of attacks (PGD attack\nand IFIA attribution attack). Over 10 million attacks in the experiments\nindicate that the proposed upper bounds effectively quantify the robustness of\nmodels based on the worst-case attribution dissimilarities.\n","authors":["Fan Wang","Adams Wai-Kin Kong"],"pdf_url":"https://arxiv.org/pdf/2303.00340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.05534v4","updated":"2023-03-01T09:03:21Z","published":"2020-06-09T22:34:27Z","title":"Novelty Detection via Robust Variational Autoencoding","summary":"  We propose a new method for novelty detection that can tolerate high\ncorruption of the training points, whereas previous works assumed either no or\nvery low corruption. Our method trains a robust variational autoencoder (VAE),\nwhich aims to generate a model for the uncorrupted training points. To gain\nrobustness to high corruption, we incorporate the following four changes to the\ncommon VAE: 1. Extracting crucial features of the latent code by a carefully\ndesigned dimension reduction component for distributions; 2. Modeling the\nlatent distribution as a mixture of Gaussian low-rank inliers and full-rank\noutliers, where the testing only uses the inlier model; 3. Applying the\nWasserstein-1 metric for regularization, instead of the Kullback-Leibler (KL)\ndivergence; and 4. Using a robust error for reconstruction. We establish both\nrobustness to outliers and suitability to low-rank modeling of the Wasserstein\nmetric as opposed to the KL divergence. We illustrate state-of-the-art results\non standard benchmarks.\n","authors":["Chieh-Hsin Lai","Dongmian Zou","Gilad Lerman"],"pdf_url":"https://arxiv.org/pdf/2006.05534v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12840v2","updated":"2023-03-01T08:43:13Z","published":"2023-02-24T18:17:38Z","title":"HULAT at SemEval-2023 Task 10: Data augmentation for pre-trained\n  transformers applied to the detection of sexism in social media","summary":"  This paper describes our participation in SemEval-2023 Task 10, whose goal is\nthe detection of sexism in social media. We explore some of the most popular\ntransformer models such as BERT, DistilBERT, RoBERTa, and XLNet. We also study\ndifferent data augmentation techniques to increase the training dataset. During\nthe development phase, our best results were obtained by using RoBERTa and data\naugmentation for tasks B and C. However, the use of synthetic data does not\nimprove the results for task C. We participated in the three subtasks. Our\napproach still has much room for improvement, especially in the two\nfine-grained classifications. All our code is available in the repository\nhttps://github.com/isegura/hulat_edos.\n","authors":["Isabel Segura-Bedmar"],"pdf_url":"https://arxiv.org/pdf/2302.12840v2.pdf","comment":"The experiments are not reproducible because I did not use a seed for\n  replicability"},{"id":"http://arxiv.org/abs/2303.00326v1","updated":"2023-03-01T08:43:05Z","published":"2023-03-01T08:43:05Z","title":"Empowering Networks With Scale and Rotation Equivariance Using A\n  Similarity Convolution","summary":"  The translational equivariant nature of Convolutional Neural Networks (CNNs)\nis a reason for its great success in computer vision. However, networks do not\nenjoy more general equivariance properties such as rotation or scaling,\nultimately limiting their generalization performance. To address this\nlimitation, we devise a method that endows CNNs with simultaneous equivariance\nwith respect to translation, rotation, and scaling. Our approach defines a\nconvolution-like operation and ensures equivariance based on our proposed\nscalable Fourier-Argand representation. The method maintains similar efficiency\nas a traditional network and hardly introduces any additional learnable\nparameters, since it does not face the computational issue that often occurs in\ngroup-convolution operators. We validate the efficacy of our approach in the\nimage classification task, demonstrating its robustness and the generalization\nability to both scaled and rotated inputs.\n","authors":["Zikai Sun","Thierry Blu"],"pdf_url":"https://arxiv.org/pdf/2303.00326v1.pdf","comment":"Accepted for ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00320v1","updated":"2023-03-01T08:33:16Z","published":"2023-03-01T08:33:16Z","title":"TimeMAE: Self-Supervised Representations of Time Series with Decoupled\n  Masked Autoencoders","summary":"  Enhancing the expressive capacity of deep learning-based time series models\nwith self-supervised pre-training has become ever-increasingly prevalent in\ntime series classification. Even though numerous efforts have been devoted to\ndeveloping self-supervised models for time series data, we argue that the\ncurrent methods are not sufficient to learn optimal time series representations\ndue to solely unidirectional encoding over sparse point-wise input units. In\nthis work, we propose TimeMAE, a novel self-supervised paradigm for learning\ntransferrable time series representations based on transformer networks. The\ndistinct characteristics of the TimeMAE lie in processing each time series into\na sequence of non-overlapping sub-series via window-slicing partitioning,\nfollowed by random masking strategies over the semantic units of localized\nsub-series. Such a simple yet effective setting can help us achieve the goal of\nkilling three birds with one stone, i.e., (1) learning enriched contextual\nrepresentations of time series with a bidirectional encoding scheme; (2)\nincreasing the information density of basic semantic units; (3) efficiently\nencoding representations of time series using transformer networks.\nNevertheless, it is a non-trivial to perform reconstructing task over such a\nnovel formulated modeling paradigm. To solve the discrepancy issue incurred by\nnewly injected masked embeddings, we design a decoupled autoencoder\narchitecture, which learns the representations of visible (unmasked) positions\nand masked ones with two different encoder modules, respectively. Furthermore,\nwe construct two types of informative targets to accomplish the corresponding\npretext tasks. One is to create a tokenizer module that assigns a codeword to\neach masked region, allowing the masked codeword classification (MCC) task to\nbe completed effectively...\n","authors":["Mingyue Cheng","Qi Liu","Zhiding Liu","Hao Zhang","Rujiao Zhang","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00320v1.pdf","comment":"Submitted to IEEE TRANSACTIONS ON KNOWLEDGE AND DATA\n  ENGINEERING(TKDE), under review"},{"id":"http://arxiv.org/abs/2209.15420v2","updated":"2023-03-01T08:32:28Z","published":"2022-09-23T09:21:35Z","title":"Ensemble-based gradient inference for particle methods in optimization\n  and sampling","summary":"  We propose an approach based on function evaluations and Bayesian inference\nto extract higher-order differential information of objective functions {from a\ngiven ensemble of particles}. Pointwise evaluation $\\{V(x^i)\\}_i$ of some\npotential $V$ in an ensemble $\\{x^i\\}_i$ contains implicit information about\nfirst or higher order derivatives, which can be made explicit with little\ncomputational effort (ensemble-based gradient inference -- EGI). We suggest to\nuse this information for the improvement of established ensemble-based\nnumerical methods for optimization and sampling such as Consensus-based\noptimization and Langevin-based samplers. Numerical studies indicate that the\naugmented algorithms are often superior to their gradient-free variants, in\nparticular the augmented methods help the ensembles to escape their initial\ndomain, to explore multimodal, non-Gaussian settings and to speed up the\ncollapse at the end of optimization dynamics.}\n  The code for the numerical examples in this manuscript can be found in the\npaper's Github repository\n(https://github.com/MercuryBench/ensemble-based-gradient.git).\n","authors":["Claudia Schillings","Claudia Totzeck","Philipp Wacker"],"pdf_url":"https://arxiv.org/pdf/2209.15420v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00315v1","updated":"2023-03-01T08:24:54Z","published":"2023-03-01T08:24:54Z","title":"Efficient Explorative Key-term Selection Strategies for Conversational\n  Contextual Bandits","summary":"  Conversational contextual bandits elicit user preferences by occasionally\nquerying for explicit feedback on key-terms to accelerate learning. However,\nthere are aspects of existing approaches which limit their performance. First,\ninformation gained from key-term-level conversations and arm-level\nrecommendations is not appropriately incorporated to speed up learning. Second,\nit is important to ask explorative key-terms to quickly elicit the user's\npotential interests in various domains to accelerate the convergence of user\npreference estimation, which has never been considered in existing works. To\ntackle these issues, we first propose ``ConLinUCB\", a general framework for\nconversational bandits with better information incorporation, combining\narm-level and key-term-level feedback to estimate user preference in one step\nat each time. Based on this framework, we further design two bandit algorithms\nwith explorative key-term selection strategies, ConLinUCB-BS and ConLinUCB-MCR.\nWe prove tighter regret upper bounds of our proposed algorithms. Particularly,\nConLinUCB-BS achieves a regret bound of $O(\\sqrt{dT\\log T})$, better than the\nprevious result $O(d\\sqrt{T}\\log T)$. Extensive experiments on synthetic and\nreal-world data show significant advantages of our algorithms in learning\naccuracy (up to 54\\% improvement) and computational efficiency (up to 72\\%\nimprovement), compared to the classic ConUCB algorithm, showing the potential\nbenefit to recommender systems.\n","authors":["Zhiyong Wang","Xutong Liu","Shuai Li","John C. S. Lui"],"pdf_url":"https://arxiv.org/pdf/2303.00315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12886v2","updated":"2023-03-01T08:18:42Z","published":"2022-11-23T11:44:35Z","title":"OReX: Object Reconstruction from Planar Cross-sections Using Neural\n  Fields","summary":"  Reconstructing 3D shapes from planar cross-sections is a challenge inspired\nby downstream applications like medical imaging and geographic informatics. The\ninput is an in/out indicator function fully defined on a sparse collection of\nplanes in space, and the output is an interpolation of the indicator function\nto the entire volume. Previous works addressing this sparse and ill-posed\nproblem either produce low quality results, or rely on additional priors such\nas target topology, appearance information, or input normal directions. In this\npaper, we present OReX, a method for 3D shape reconstruction from slices alone,\nfeaturing a Neural Field as the interpolation prior. A simple neural network is\ntrained on the input planes to receive a 3D coordinate and return an\ninside/outside estimate for the query point. This prior is powerful in inducing\nsmoothness and self-similarities. The main challenge for this approach is\nhigh-frequency details, as the neural prior is overly smoothing. To alleviate\nthis, we offer an iterative estimation architecture and a hierarchical input\nsampling scheme that encourage coarse-to-fine training, allowing focusing on\nhigh frequencies at later stages. In addition, we identify and analyze a common\nripple-like effect stemming from the mesh extraction step. We mitigate it by\nregularizing the spatial gradients of the indicator function around input\nin/out boundaries, cutting the problem at the root.\n  Through extensive qualitative and quantitative experimentation, we\ndemonstrate our method is robust, accurate, and scales well with the size of\nthe input. We report state-of-the-art results compared to previous approaches\nand recent potential solutions, and demonstrate the benefit of our individual\ncontributions through analysis and ablation studies.\n","authors":["Haim Sawdayee","Amir Vaxman","Amit H. Bermano"],"pdf_url":"https://arxiv.org/pdf/2211.12886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00313v1","updated":"2023-03-01T08:16:38Z","published":"2023-03-01T08:16:38Z","title":"Deep Learning Methods for Small Molecule Drug Discovery: A Survey","summary":"  With the development of computer-assisted techniques, research communities\nincluding biochemistry and deep learning have been devoted into the drug\ndiscovery field for over a decade. Various applications of deep learning have\ndrawn great attention in drug discovery, such as molecule generation, molecular\nproperty prediction, retrosynthesis prediction, and reaction prediction. While\nmost existing surveys only focus on one of the applications, limiting the view\nof researchers in the community. In this paper, we present a comprehensive\nreview on the aforementioned four aspects, and discuss the relationships among\ndifferent applications. The latest literature and classical benchmarks are\npresented for better understanding the development of variety of approaches.\n  We commence by summarizing the molecule representation format in these works,\nfollowed by an introduction of recent proposed approaches for each of the four\ntasks. Furthermore, we review a variety of commonly used datasets and\nevaluation metrics and compare the performance of deep learning-based models.\nFinally, we conclude by identifying remaining challenges and discussing the\nfuture trend for deep learning methods in drug discovery.\n","authors":["Wenhao Hu","Yingying Liu","Xuanyu Chen","Wenhao Chai","Hangyue Chen","Hongwei Wang","Gaoang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01303v2","updated":"2023-03-01T08:13:11Z","published":"2022-03-02T18:41:22Z","title":"An Analysis of Ensemble Sampling","summary":"  Ensemble sampling serves as a practical approximation to Thompson sampling\nwhen maintaining an exact posterior distribution over model parameters is\ncomputationally intractable. In this paper, we establish a regret bound that\nensures desirable behavior when ensemble sampling is applied to the linear\nbandit problem. This represents the first rigorous regret analysis of ensemble\nsampling and is made possible by leveraging information-theoretic concepts and\nnovel analytic techniques that may prove useful beyond the scope of this paper.\n","authors":["Chao Qin","Zheng Wen","Xiuyuan Lu","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2203.01303v2.pdf","comment":"[NeurIPS 2022 camera-ready\n  version](https://openreview.net/forum?id=c6ibx0yl-aG) with improved regret\n  bounds"},{"id":"http://arxiv.org/abs/2210.07494v2","updated":"2023-03-01T08:02:27Z","published":"2022-10-14T03:43:05Z","title":"A Comprehensive Study on Large-Scale Graph Training: Benchmarking and\n  Rethinking","summary":"  Large-scale graph training is a notoriously challenging problem for graph\nneural networks (GNNs). Due to the nature of evolving graph structures into the\ntraining process, vanilla GNNs usually fail to scale up, limited by the GPU\nmemory space. Up to now, though numerous scalable GNN architectures have been\nproposed, we still lack a comprehensive survey and fair benchmark of this\nreservoir to find the rationale for designing scalable GNNs. To this end, we\nfirst systematically formulate the representative methods of large-scale graph\ntraining into several branches and further establish a fair and consistent\nbenchmark for them by a greedy hyperparameter searching. In addition, regarding\nefficiency, we theoretically evaluate the time and space complexity of various\nbranches and empirically compare them w.r.t GPU memory usage, throughput, and\nconvergence. Furthermore, We analyze the pros and cons for various branches of\nscalable GNNs and then present a new ensembling training manner, named EnGCN,\nto address the existing issues. Our code is available at\nhttps://github.com/VITA-Group/Large_Scale_GCN_Benchmarking.\n","authors":["Keyu Duan","Zirui Liu","Peihao Wang","Wenqing Zheng","Kaixiong Zhou","Tianlong Chen","Xia Hu","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2210.07494v2.pdf","comment":"Accepted by NeurIPS 2022 Dataset and Benchmark Track"},{"id":"http://arxiv.org/abs/2303.00302v1","updated":"2023-03-01T07:54:54Z","published":"2023-03-01T07:54:54Z","title":"Mitigating Backdoors in Federated Learning with FLD","summary":"  Federated learning allows clients to collaboratively train a global model\nwithout uploading raw data for privacy preservation. This feature, i.e., the\ninability to review participants' datasets, has recently been found responsible\nfor federated learning's vulnerability in the face of backdoor attacks.\nExisting defense methods fall short from two perspectives: 1) they consider\nonly very specific and limited attacker models and unable to cope with advanced\nbackdoor attacks, such as distributed backdoor attacks, which break down the\nglobal trigger into multiple distributed triggers. 2) they conduct detection\nbased on model granularity thus the performance gets impacted by the model\ndimension. To address these challenges, we propose Federated Layer Detection\n(FLD), a novel model filtering approach for effectively defending against\nbackdoor attacks. FLD examines the models based on layer granularity to capture\nthe complete model details and effectively detect potential backdoor models\nregardless of model dimension. We provide theoretical analysis and proof for\nthe convergence of FLD. Extensive experiments demonstrate that FLD effectively\nmitigates state-of-the-art backdoor attacks with negligible impact on the\naccuracy of the primary task.\n","authors":["Yihang Lin","Pengyuan Zhou","Zhiqian Wu","Yong Liao"],"pdf_url":"https://arxiv.org/pdf/2303.00302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00295v1","updated":"2023-03-01T07:42:48Z","published":"2023-03-01T07:42:48Z","title":"Region Prediction for Efficient Robot Localization on Large Maps","summary":"  Recognizing already explored places (a.k.a. place recognition) is a\nfundamental task in Simultaneous Localization and Mapping (SLAM) to enable\nrobot relocalization and loop closure detection. In topological SLAM the\nrecognition takes place by comparing a signature (or feature vector) associated\nto the current node with the signatures of the nodes in the known map. However,\nas the number of nodes increases, matching the current node signature against\nall the existing ones becomes inefficient and thwarts real-time navigation. In\nthis paper we propose a novel approach to pre-select a subset of map nodes for\nplace recognition. The map nodes are clustered during exploration and each\ncluster is associated with a region. The region labels become the prediction\ntargets of a deep neural network and, during navigation, only the nodes\nassociated with the regions predicted with high probability are considered for\nmatching. While the proposed technique can be integrated in different SLAM\napproaches, in this work we describe an effective integration with RTAB-Map (a\npopular framework for real-time topological SLAM) which allowed us to design\nand run several experiments to demonstrate its effectiveness. All the code and\nmaterial from the experiments will be available online at\nhttps://github.com/MI-BioLab/region-learner.\n","authors":["Matteo Scucchia","Davide Maltoni"],"pdf_url":"https://arxiv.org/pdf/2303.00295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07817v2","updated":"2023-03-01T07:38:13Z","published":"2022-09-16T09:33:09Z","title":"SPGP: Structure Prototype Guided Graph Pooling","summary":"  While graph neural networks (GNNs) have been successful for node\nclassification tasks and link prediction tasks in graph, learning graph-level\nrepresentations still remains a challenge. For the graph-level representation,\nit is important to learn both representation of neighboring nodes, i.e.,\naggregation, and graph structural information. A number of graph pooling\nmethods have been developed for this goal. However, most of the existing\npooling methods utilize k-hop neighborhood without considering explicit\nstructural information in a graph. In this paper, we propose Structure\nPrototype Guided Pooling (SPGP) that utilizes prior graph structures to\novercome the limitation. SPGP formulates graph structures as learnable\nprototype vectors and computes the affinity between nodes and prototype\nvectors. This leads to a novel node scoring scheme that prioritizes informative\nnodes while encapsulating the useful structures of the graph. Our experimental\nresults show that SPGP outperforms state-of-the-art graph pooling methods on\ngraph classification benchmark datasets in both accuracy and scalability.\n","authors":["Sangseon Lee","Dohoon Lee","Yinhua Piao","Sun Kim"],"pdf_url":"https://arxiv.org/pdf/2209.07817v2.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2012.08950v5","updated":"2023-03-01T07:35:43Z","published":"2020-12-16T13:48:48Z","title":"Revocable Deep Reinforcement Learning with Affinity Regularization for\n  Outlier-Robust Graph Matching","summary":"  Graph matching (GM) has been a building block in various areas including\ncomputer vision and pattern recognition. Despite recent impressive progress,\nexisting deep GM methods often have obvious difficulty in handling outliers,\nwhich are ubiquitous in practice. We propose a deep reinforcement learning\nbased approach RGM, whose sequential node matching scheme naturally fits the\nstrategy for selective inlier matching against outliers. A revocable action\nframework is devised to improve the agent's flexibility against the complex\nconstrained GM. Moreover, we propose a quadratic approximation technique to\nregularize the affinity score, in the presence of outliers. As such, the agent\ncan finish inlier matching timely when the affinity score stops growing, for\nwhich otherwise an additional parameter i.e. the number of inliers is needed to\navoid matching outliers. In this paper, we focus on learning the back-end\nsolver under the most general form of GM: the Lawler's QAP, whose input is the\naffinity matrix. Especially, our approach can also boost existing GM methods\nthat use such input. Experiments on multiple real-world datasets demonstrate\nits performance regarding both accuracy and robustness.\n","authors":["Chang Liu","Zetian Jiang","Runzhong Wang","Junchi Yan","Lingxiao Huang","Pinyan Lu"],"pdf_url":"https://arxiv.org/pdf/2012.08950v5.pdf","comment":"Proceedings of The Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2303.00286v1","updated":"2023-03-01T07:25:28Z","published":"2023-03-01T07:25:28Z","title":"Enhancing Knowledge Graph Embedding Models with Semantic-driven Loss\n  Functions","summary":"  Knowledge graph embedding models (KGEMs) are used for various tasks related\nto knowledge graphs (KGs), including link prediction. They are trained with\nloss functions that are computed considering a batch of scored triples and\ntheir corresponding labels. Traditional approaches consider the label of a\ntriple to be either true or false. However, recent works suggest that all\nnegative triples should not be valued equally. In line with this commonly\nadopted assumption, we posit that semantically valid negative triples might be\nhigh-quality negative triples. As such, loss functions should treat them\ndifferently from semantically invalid negative ones. To this aim, we propose\nsemantic-driven versions for the three mostly used loss functions for link\nprediction. In particular, we treat the scores of negative triples differently\nby injecting background knowledge about relation domains and ranges into the\nloss functions. In an extensive and controlled experimental setting, we show\nthat the proposed loss functions systematically provide satisfying results on\nthree public benchmark KGs underpinned with different schemas, which\ndemonstrates both the generality and superiority of our proposed approach. In\nfact, the proposed loss functions do not only lead to better MRR and Hits@10\nvalues, but also drive KGEMs towards better semantic awareness. This highlights\nthat semantic information globally improves KGEMs, and thus should be\nincorporated into loss functions whenever such information is available.\n","authors":["Nicolas Hubert","Pierre Monnin","Armelle Brun","Davy Monticolo"],"pdf_url":"https://arxiv.org/pdf/2303.00286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00282v1","updated":"2023-03-01T07:12:33Z","published":"2023-03-01T07:12:33Z","title":"FedScore: A privacy-preserving framework for federated scoring system\n  development","summary":"  We propose FedScore, a privacy-preserving federated learning framework for\nscoring system generation across multiple sites to facilitate\ncross-institutional collaborations. The FedScore framework includes five\nmodules: federated variable ranking, federated variable transformation,\nfederated score derivation, federated model selection and federated model\nevaluation. To illustrate usage and assess FedScore's performance, we built a\nhypothetical global scoring system for mortality prediction within 30 days\nafter a visit to an emergency department using 10 simulated sites divided from\na tertiary hospital in Singapore. We employed a pre-existing score generator to\nconstruct 10 local scoring systems independently at each site and we also\ndeveloped a scoring system using centralized data for comparison. We compared\nthe acquired FedScore model's performance with that of other scoring models\nusing the receiver operating characteristic (ROC) analysis. The FedScore model\nachieved an average area under the curve (AUC) value of 0.763 across all sites,\nwith a standard deviation (SD) of 0.020. We also calculated the average AUC\nvalues and SDs for each local model, and the FedScore model showed promising\naccuracy and stability with a high average AUC value which was closest to the\none of the pooled model and SD which was lower than that of most local models.\nThis study demonstrates that FedScore is a privacy-preserving scoring system\ngenerator with potentially good generalizability.\n","authors":["Siqi Li","Yilin Ning","Marcus Eng Hock Ong","Bibhas Chakraborty","Chuan Hong","Feng Xie","Han Yuan","Mingxuan Liu","Daniel M. Buckland","Yong Chen","Nan Liu"],"pdf_url":"https://arxiv.org/pdf/2303.00282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12172v3","updated":"2023-03-01T07:11:16Z","published":"2023-02-23T17:13:25Z","title":"Unified Chest X-ray and Radiology Report Generation Model with\n  Multi-view Chest X-rays","summary":"  Generated synthetic data in medical research can substitute privacy and\nsecurity-sensitive data with a large-scale curated dataset, reducing data\ncollection and annotation costs. As part of this effort, we propose UniXGen, a\nunified chest X-ray and report generation model, with the following\ncontributions. First, we design a unified model for bidirectional chest X-ray\nand report generation by adopting a vector quantization method to discretize\nchest X-rays into discrete visual tokens and formulating both tasks as sequence\ngeneration tasks. Second, we introduce several special tokens to generate chest\nX-rays with specific views that can be useful when the desired views are\nunavailable. Furthermore, UniXGen can flexibly take various inputs from single\nto multiple views to take advantage of the additional findings available in\nother X-ray views. We adopt an efficient transformer for computational and\nmemory efficiency to handle the long-range input sequence of multi-view chest\nX-rays with high resolution and long paragraph reports. In extensive\nexperiments, we show that our unified model has a synergistic effect on both\ngeneration tasks, as opposed to training only the task-specific models. We also\nfind that view-specific special tokens can distinguish between different views\nand properly generate specific views even if they do not exist in the dataset,\nand utilizing multi-view chest X-rays can faithfully capture the abnormal\nfindings in the additional X-rays. The source code is publicly available at:\nhttps://github.com/ttumyche/UniXGen.\n","authors":["Hyungyung Lee","Da Young Lee","Wonjae Kim","Jin-Hwa Kim","Tackeun Kim","Jihang Kim","Leonard Sunwoo","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2302.12172v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00280v1","updated":"2023-03-01T07:02:09Z","published":"2023-03-01T07:02:09Z","title":"Label Attention Network for sequential multi-label classification","summary":"  Multi-label classification is a natural problem statement for sequential\ndata. We might be interested in the items of the next order by a customer, or\ntypes of financial transactions that will occur tomorrow. Most modern\napproaches focus on transformer architecture for multi-label classification,\nintroducing self-attention for the elements of a sequence with each element\nbeing a multi-label vector and supplementary information. However, in this way\nwe loose local information related to interconnections between particular\nlabels. We propose instead to use a self-attention mechanism over labels\npreceding the predicted step. Conducted experiments suggest that such\narchitecture improves the model performance and provides meaningful attention\nbetween labels. The metric such as micro-AUC of our label attention network is\n$0.9847$ compared to $0.7390$ for vanilla transformers benchmark.\n","authors":["Elizaveta Kovtun","Galina Boeva","Artem Zabolotnyi","Evgeny Burnaev","Martin Spindler","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2303.00280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00518v5","updated":"2023-03-01T06:47:38Z","published":"2022-06-01T14:28:35Z","title":"Efficient Scheduling of Data Augmentation for Deep Reinforcement\n  Learning","summary":"  In deep reinforcement learning (RL), data augmentation is widely considered\nas a tool to induce a set of useful priors about semantic consistency and\nimprove sample efficiency and generalization performance. However, even when\nthe prior is useful for generalization, distilling it to RL agent often\ninterferes with RL training and degenerates sample efficiency. Meanwhile, the\nagent is forgetful of the prior due to the non-stationary nature of RL. These\nobservations suggest two extreme schedules of distillation: (i) over the entire\ntraining; or (ii) only at the end. Hence, we devise a stand-alone network\ndistillation method to inject the consistency prior at any time (even after\nRL), and a simple yet efficient framework to automatically schedule the\ndistillation. Specifically, the proposed framework first focuses on mastering\ntrain environments regardless of generalization by adaptively deciding which\n{\\it or no} augmentation to be used for the training. After this, we add the\ndistillation to extract the remaining benefits for generalization from all the\naugmentations, which requires no additional new samples. In our experiments, we\ndemonstrate the utility of the proposed framework, in particular, that\nconsiders postponing the augmentation to the end of RL training.\n","authors":["Byungchan Ko","Jungseul Ok"],"pdf_url":"https://arxiv.org/pdf/2206.00518v5.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2102.08581"},{"id":"http://arxiv.org/abs/2303.00262v1","updated":"2023-03-01T06:35:42Z","published":"2023-03-01T06:35:42Z","title":"Collage Diffusion","summary":"  Text-conditional diffusion models generate high-quality, diverse images.\nHowever, text is often an ambiguous specification for a desired target image,\ncreating the need for additional user-friendly controls for diffusion-based\nimage generation. We focus on having precise control over image output for\nscenes with several objects. Users control image generation by defining a\ncollage: a text prompt paired with an ordered sequence of layers, where each\nlayer is an RGBA image and a corresponding text prompt. We introduce Collage\nDiffusion, a collage-conditional diffusion algorithm that allows users to\ncontrol both the spatial arrangement and visual attributes of objects in the\nscene, and also enables users to edit individual components of generated\nimages. To ensure that different parts of the input text correspond to the\nvarious locations specified in the input collage layers, Collage Diffusion\nmodifies text-image cross-attention with the layers' alpha masks. To maintain\ncharacteristics of individual collage layers that are not specified in text,\nCollage Diffusion learns specialized text representations per layer. Collage\ninput also enables layer-based controls that provide fine-grained control over\nthe final output: users can control image harmonization on a layer-by-layer\nbasis, and they can edit individual objects in generated images while keeping\nother objects fixed. Collage-conditional image generation requires harmonizing\nthe input collage to make objects fit together--the key challenge involves\nminimizing changes in the positions and key visual attributes of objects in the\ninput collage while allowing other attributes of the collage to change in the\nharmonization process. By leveraging the rich information present in layer\ninput, Collage Diffusion generates globally harmonized images that maintain\ndesired object locations and visual characteristics better than prior\napproaches.\n","authors":["Vishnu Sarukkai","Linden Li","Arden Ma","Christopher Ré","Kayvon Fatahalian"],"pdf_url":"https://arxiv.org/pdf/2303.00262v1.pdf","comment":"26 pages, 20 figures"},{"id":"http://arxiv.org/abs/2303.00261v1","updated":"2023-03-01T06:35:29Z","published":"2023-03-01T06:35:29Z","title":"Speeding Up EfficientNet: Selecting Update Blocks of Convolutional\n  Neural Networks using Genetic Algorithm in Transfer Learning","summary":"  The performance of convolutional neural networks (CNN) depends heavily on\ntheir architectures. Transfer learning performance of a CNN relies quite\nstrongly on selection of its trainable layers. Selecting the most effective\nupdate layers for a certain target dataset often requires expert knowledge on\nCNN architecture which many practitioners do not posses. General users prefer\nto use an available architecture (e.g. GoogleNet, ResNet, EfficientNet etc.)\nthat is developed by domain experts. With the ever-growing number of layers, it\nis increasingly becoming quite difficult and cumbersome to handpick the update\nlayers. Therefore, in this paper we explore the application of genetic\nalgorithm to mitigate this problem. The convolutional layers of popular\npretrained networks are often grouped into modules that constitute their\nbuilding blocks. We devise a genetic algorithm to select blocks of layers for\nupdating the parameters. By experimenting with EfficientNetB0 pre-trained on\nImageNet and using Food-101, CIFAR-100 and MangoLeafBD as target datasets, we\nshow that our algorithm yields similar or better results than the baseline in\nterms of accuracy, and requires lower training and evaluation time due to\nlearning less number of parameters. We also devise a metric called block\nimportance to measure efficacy of each block as update block and analyze the\nimportance of the blocks selected by our algorithm.\n","authors":["Md. Mehedi Hasana","Muhammad Ibrahim","Md. Sawkat Ali"],"pdf_url":"https://arxiv.org/pdf/2303.00261v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2303.00250v1","updated":"2023-03-01T06:16:15Z","published":"2023-03-01T06:16:15Z","title":"Combating Exacerbated Heterogeneity for Robust Models in Federated\n  Learning","summary":"  Privacy and security concerns in real-world applications have led to the\ndevelopment of adversarially robust federated models. However, the\nstraightforward combination between adversarial training and federated learning\nin one framework can lead to the undesired robustness deterioration. We\ndiscover that the attribution behind this phenomenon is that the generated\nadversarial data could exacerbate the data heterogeneity among local clients,\nmaking the wrapped federated learning perform poorly. To deal with this\nproblem, we propose a novel framework called Slack Federated Adversarial\nTraining (SFAT), assigning the client-wise slack during aggregation to combat\nthe intensified heterogeneity. Theoretically, we analyze the convergence of the\nproposed method to properly relax the objective when combining federated\nlearning and adversarial training. Experimentally, we verify the rationality\nand effectiveness of SFAT on various benchmarked and real-world datasets with\ndifferent adversarial training and federated optimization methods. The code is\npublicly available at https://github.com/ZFancy/SFAT.\n","authors":["Jianing Zhu","Jiangchao Yao","Tongliang Liu","Quanming Yao","Jianliang Xu","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2303.00250v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2210.01302v2","updated":"2023-03-01T06:00:47Z","published":"2022-10-04T01:40:31Z","title":"Nuisances via Negativa: Adjusting for Spurious Correlations via Data\n  Augmentation","summary":"  In prediction tasks, there exist features that are related to the label in\nthe same way across different settings for that task; these are semantic\nfeatures or semantics. Features with varying relationships to the label are\nnuisances. For example, in detecting cows from natural images, the shape of the\nhead is a semantic but because images of cows often have grass backgrounds but\nnot always, the background is a nuisance. Relationships between a nuisance and\nthe label are unstable across settings and, consequently, models that exploit\nnuisance-label relationships face performance degradation when these\nrelationships change. Direct knowledge of a nuisance helps build models that\nare robust to such changes, but requires extra annotations beyond labels and\ncovariates. In this paper, we develop an alternative way to produce robust\nmodels by data augmentation. These data augmentations corrupt semantic\ninformation to produce models that identify and adjust for where nuisances\ndrive predictions. We study semantic corruptions in powering different\nspurious-correlation avoiding methods on multiple out-of distribution (OOD)\ntasks like classifying waterbirds, natural language inference (NLI), and\ndetecting cardiomegaly in chest X-rays.\n","authors":["Aahlad Puli","Nitish Joshi","He He","Rajesh Ranganath"],"pdf_url":"https://arxiv.org/pdf/2210.01302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14499v2","updated":"2023-03-01T05:45:02Z","published":"2022-09-29T01:30:34Z","title":"NVRadarNet: Real-Time Radar Obstacle and Free Space Detection for\n  Autonomous Driving","summary":"  Detecting obstacles is crucial for safe and efficient autonomous driving. To\nthis end, we present NVRadarNet, a deep neural network (DNN) that detects\ndynamic obstacles and drivable free space using automotive RADAR sensors. The\nnetwork utilizes temporally accumulated data from multiple RADAR sensors to\ndetect dynamic obstacles and compute their orientation in a top-down bird's-eye\nview (BEV). The network also regresses drivable free space to detect\nunclassified obstacles. Our DNN is the first of its kind to utilize sparse\nRADAR signals in order to perform obstacle and free space detection in real\ntime from RADAR data only. The network has been successfully used for\nperception on our autonomous vehicles in real self-driving scenarios. The\nnetwork runs faster than real time on an embedded GPU and shows good\ngeneralization across geographic regions.\n","authors":["Alexander Popov","Patrik Gebhardt","Ke Chen","Ryan Oldja","Heeseok Lee","Shane Murray","Ruchi Bhargava","Nikolai Smolyanskiy"],"pdf_url":"https://arxiv.org/pdf/2209.14499v2.pdf","comment":"7 pages, 6 figures, ICRA 2023 conference, for associated video file,\n  see https://youtu.be/WlwJJMltoJY"},{"id":"http://arxiv.org/abs/2302.10238v2","updated":"2023-03-01T05:22:32Z","published":"2023-02-20T19:07:42Z","title":"Multiagent Inverse Reinforcement Learning via Theory of Mind Reasoning","summary":"  We approach the problem of understanding how people interact with each other\nin collaborative settings, especially when individuals know little about their\nteammates, via Multiagent Inverse Reinforcement Learning (MIRL), where the goal\nis to infer the reward functions guiding the behavior of each individual given\ntrajectories of a team's behavior during some task. Unlike current MIRL\napproaches, we do not assume that team members know each other's goals a\npriori; rather, that they collaborate by adapting to the goals of others\nperceived by observing their behavior, all while jointly performing a task. To\naddress this problem, we propose a novel approach to MIRL via Theory of Mind\n(MIRL-ToM). For each agent, we first use ToM reasoning to estimate a posterior\ndistribution over baseline reward profiles given their demonstrated behavior.\nWe then perform MIRL via decentralized equilibrium by employing single-agent\nMaximum Entropy IRL to infer a reward function for each agent, where we\nsimulate the behavior of other teammates according to the time-varying\ndistribution over profiles. We evaluate our approach in a simulated 2-player\nsearch-and-rescue operation where the goal of the agents, playing different\nroles, is to search for and evacuate victims in the environment. Our results\nshow that the choice of baseline profiles is paramount to the recovery of the\nground-truth rewards, and that MIRL-ToM is able to recover the rewards used by\nagents interacting both with known and unknown teammates.\n","authors":["Haochen Wu","Pedro Sequeira","David V. Pynadath"],"pdf_url":"https://arxiv.org/pdf/2302.10238v2.pdf","comment":"Accepted as a full paper at AAMAS2023"},{"id":"http://arxiv.org/abs/2204.10414v3","updated":"2023-03-01T05:07:42Z","published":"2022-04-21T21:32:28Z","title":"Dirichlet Proportions Model for Hierarchically Coherent Probabilistic\n  Forecasting","summary":"  Probabilistic, hierarchically coherent forecasting is a key problem in many\npractical forecasting applications -- the goal is to obtain coherent\nprobabilistic predictions for a large number of time series arranged in a\npre-specified tree hierarchy. In this paper, we present an end-to-end deep\nprobabilistic model for hierarchical forecasting that is motivated by a\nclassical top-down strategy. It jointly learns the distribution of the root\ntime series, and the (dirichlet) proportions according to which each parent\ntime-series is split among its children at any point in time. The resulting\nforecasts are naturally coherent, and provide probabilistic predictions over\nall time series in the hierarchy. We experiment on several public datasets and\ndemonstrate significant improvements of up to 26% on most datasets compared to\nstate-of-the-art baselines. Finally, we also provide theoretical justification\nfor the superiority of our top-down approach compared to the more traditional\nbottom-up modeling.\n","authors":["Abhimanyu Das","Weihao Kong","Biswajit Paria","Rajat Sen"],"pdf_url":"https://arxiv.org/pdf/2204.10414v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00233v1","updated":"2023-03-01T05:03:23Z","published":"2023-03-01T05:03:23Z","title":"Single-Cell Multimodal Prediction via Transformers","summary":"  The recent development of multimodal single-cell technology has made the\npossibility of acquiring multiple omics data from individual cells, thereby\nenabling a deeper understanding of cellular states and dynamics. Nevertheless,\nthe proliferation of multimodal single-cell data also introduces tremendous\nchallenges in modeling the complex interactions among different modalities. The\nrecently advanced methods focus on constructing static interaction graphs and\napplying graph neural networks (GNNs) to learn from multimodal data. However,\nsuch static graphs can be suboptimal as they do not take advantage of the\ndownstream task information; meanwhile GNNs also have some inherent limitations\nwhen deeply stacking GNN layers. To tackle these issues, in this work, we\ninvestigate how to leverage transformers for multimodal single-cell data in an\nend-to-end manner while exploiting downstream task information. In particular,\nwe propose a scMoFormer framework which can readily incorporate external domain\nknowledge and model the interactions within each modality and cross modalities.\nExtensive experiments demonstrate that scMoFormer achieves superior performance\non various benchmark datasets. Note that scMoFormer won a Kaggle silver medal\nwith the rank of $24\\ /\\ 1221$ (Top 2%) without ensemble in a NeurIPS 2022\ncompetition. Our implementation is publicly available at Github.\n","authors":["Wenzhuo Tang","Hongzhi Wen","Renming Liu","Jiayuan Ding","Wei Jin","Yuying Xie","Hui Liu","Jiliang Tang"],"pdf_url":"https://arxiv.org/pdf/2303.00233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.05833v2","updated":"2023-03-01T04:40:21Z","published":"2022-07-12T20:52:26Z","title":"Earthformer: Exploring Space-Time Transformers for Earth System\n  Forecasting","summary":"  Conventionally, Earth system (e.g., weather and climate) forecasting relies\non numerical simulation with complex physical models and are hence both\nexpensive in computation and demanding on domain expertise. With the explosive\ngrowth of the spatiotemporal Earth observation data in the past decade,\ndata-driven models that apply Deep Learning (DL) are demonstrating impressive\npotential for various Earth system forecasting tasks. The Transformer as an\nemerging DL architecture, despite its broad success in other domains, has\nlimited adoption in this area. In this paper, we propose Earthformer, a\nspace-time Transformer for Earth system forecasting. Earthformer is based on a\ngeneric, flexible and efficient space-time attention block, named Cuboid\nAttention. The idea is to decompose the data into cuboids and apply\ncuboid-level self-attention in parallel. These cuboids are further connected\nwith a collection of global vectors. We conduct experiments on the MovingMNIST\ndataset and a newly proposed chaotic N-body MNIST dataset to verify the\neffectiveness of cuboid attention and figure out the best design of\nEarthformer. Experiments on two real-world benchmarks about precipitation\nnowcasting and El Nino/Southern Oscillation (ENSO) forecasting show Earthformer\nachieves state-of-the-art performance. Code is available:\nhttps://github.com/amazon-science/earth-forecasting-transformer .\n","authors":["Zhihan Gao","Xingjian Shi","Hao Wang","Yi Zhu","Yuyang Wang","Mu Li","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2207.05833v2.pdf","comment":"Published at NeurIPS 2022. Camera-ready version"},{"id":"http://arxiv.org/abs/2303.00228v1","updated":"2023-03-01T04:37:14Z","published":"2023-03-01T04:37:14Z","title":"Two Views of Constrained Differential Privacy: Belief Revision and\n  Update","summary":"  In this paper, we provide two views of constrained differential private (DP)\nmechanisms. The first one is as belief revision. A constrained DP mechanism is\nobtained by standard probabilistic conditioning, and hence can be naturally\nimplemented by Monte Carlo algorithms. The other is as belief update. A\nconstrained DP is defined according to l2-distance minimization postprocessing\nor projection and hence can be naturally implemented by optimization\nalgorithms. The main advantage of these two perspectives is that we can make\nfull use of the machinery of belief revision and update to show basic\nproperties for constrained differential privacy especially some important new\ncomposition properties. Within the framework established in this paper,\nconstrained DP algorithms in the literature can be classified either as belief\nrevision or belief update. At the end of the paper, we demonstrate their\ndifferences especially in utility in a couple of scenarios.\n","authors":["Likang Liu","Keke Sun","Chunlai Zhou","Yuan Feng"],"pdf_url":"https://arxiv.org/pdf/2303.00228v1.pdf","comment":"23 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.10701v2","updated":"2023-03-01T04:22:54Z","published":"2022-12-21T00:33:59Z","title":"A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks","summary":"  Oversmoothing is a central challenge of building more powerful Graph Neural\nNetworks (GNNs). While previous works have only demonstrated that oversmoothing\nis inevitable when the number of graph convolutions tends to infinity, in this\npaper, we precisely characterize the mechanism behind the phenomenon via a\nnon-asymptotic analysis. Specifically, we distinguish between two different\neffects when applying graph convolutions -- an undesirable mixing effect that\nhomogenizes node representations in different classes, and a desirable\ndenoising effect that homogenizes node representations in the same class. By\nquantifying these two effects on random graphs sampled from the Contextual\nStochastic Block Model (CSBM), we show that oversmoothing happens once the\nmixing effect starts to dominate the denoising effect, and the number of layers\nrequired for this transition is $O(\\log N/\\log (\\log N))$ for sufficiently\ndense graphs with $N$ nodes. We also extend our analysis to study the effects\nof Personalized PageRank (PPR), or equivalently, the effects of initial\nresidual connections on oversmoothing. Our results suggest that while PPR\nmitigates oversmoothing at deeper layers, PPR-based architectures still achieve\ntheir best performance at a shallow depth and are outperformed by the graph\nconvolution approach on certain graphs. Finally, we support our theoretical\nresults with numerical experiments, which further suggest that the\noversmoothing phenomenon observed in practice can be magnified by the\ndifficulty of optimizing deep GNN models.\n","authors":["Xinyi Wu","Zhengdao Chen","William Wang","Ali Jadbabaie"],"pdf_url":"https://arxiv.org/pdf/2212.10701v2.pdf","comment":"Accepted by the 11th International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2209.06983v2","updated":"2023-03-01T04:01:40Z","published":"2022-09-15T00:20:38Z","title":"Double Doubly Robust Thompson Sampling for Generalized Linear Contextual\n  Bandits","summary":"  We propose a novel contextual bandit algorithm for generalized linear rewards\nwith an $\\tilde{O}(\\sqrt{\\kappa^{-1} \\phi T})$ regret over $T$ rounds where\n$\\phi$ is the minimum eigenvalue of the covariance of contexts and $\\kappa$ is\na lower bound of the variance of rewards. In several practical cases where\n$\\phi=O(d)$, our result is the first regret bound for generalized linear model\n(GLM) bandits with the order $\\sqrt{d}$ without relying on the approach of Auer\n[2002]. We achieve this bound using a novel estimator called double\ndoubly-robust (DDR) estimator, a subclass of doubly-robust (DR) estimator but\nwith a tighter error bound. The approach of Auer [2002] achieves independence\nby discarding the observed rewards, whereas our algorithm achieves independence\nconsidering all contexts using our DDR estimator. We also provide an\n$O(\\kappa^{-1} \\phi \\log (NT) \\log T)$ regret bound for $N$ arms under a\nprobabilistic margin condition. Regret bounds under the margin condition are\ngiven by Bastani and Bayati [2020] and Bastani et al. [2021] under the setting\nthat contexts are common to all arms but coefficients are arm-specific. When\ncontexts are different for all arms but coefficients are common, ours is the\nfirst regret bound under the margin condition for linear models or GLMs. We\nconduct empirical studies using synthetic data and real examples, demonstrating\nthe effectiveness of our algorithm.\n","authors":["Wonyoung Kim","Kyungbok Lee","Myunghee Cho Paik"],"pdf_url":"https://arxiv.org/pdf/2209.06983v2.pdf","comment":"2023 AAAI Press Proceedings (Full paper including Appendix) Selected\n  as an oral presentation at the 2023 AAAI conference"},{"id":"http://arxiv.org/abs/2206.09311v3","updated":"2023-03-01T03:56:51Z","published":"2022-06-19T02:33:14Z","title":"Primal Estimated Subgradient Solver for SVM for Imbalanced\n  Classification","summary":"  We aim to demonstrate in experiments that our cost sensitive PEGASOS SVM\n(without synthetic majority oversampling/under sampling (SMOTE) ) achieves good\nperformance on imbalanced data sets with a Majority to Minority Ratio ranging\nfrom 8.6:1 to 130:1. Although many resort to SMOTE methods, we aim for a less\ncomputationally intensive method. We evaluate the performance by examining the\nlearning curves. These curves diagnose whether we overfit or underfit or we\nchoose over-representive or under representative training/test data. We will\nalso examine the effect of varying the hyperparameters via validation curves.\nWe compare our PEGASOS Cost-Sensitive SVM's results on three of the datasets\nDing analyzed using his LINEAR SVM DECIDL method. He obtained an ROC-AUC of .5\nin one dataset. We consider that dataset the most promising use of kernel\nSupport Vector Machine. Our work will extend the work of Ding by incorporating\nkernels into Support Vector Machine. We will use Python rather than MatLab as\npython has dictionaries for storing mixed data types during multi-parameter\ncross-validation.\n","authors":["John Sun"],"pdf_url":"https://arxiv.org/pdf/2206.09311v3.pdf","comment":"10 pages, 4 tables, 3 figures"},{"id":"http://arxiv.org/abs/2302.09369v2","updated":"2023-03-01T03:48:17Z","published":"2023-02-18T15:53:55Z","title":"Calibrating the Rigged Lottery: Making All Tickets Reliable","summary":"  Although sparse training has been successfully used in various\nresource-limited deep learning tasks to save memory, accelerate training, and\nreduce inference time, the reliability of the produced sparse models remains\nunexplored. Previous research has shown that deep neural networks tend to be\nover-confident, and we find that sparse training exacerbates this problem.\nTherefore, calibrating the sparse models is crucial for reliable prediction and\ndecision-making. In this paper, we propose a new sparse training method to\nproduce sparse models with improved confidence calibration. In contrast to\nprevious research that uses only one mask to control the sparse topology, our\nmethod utilizes two masks, including a deterministic mask and a random mask.\nThe former efficiently searches and activates important weights by exploiting\nthe magnitude of weights and gradients. While the latter brings better\nexploration and finds more appropriate weight values by random updates.\nTheoretically, we prove our method can be viewed as a hierarchical variational\napproximation of a probabilistic deep Gaussian process. Extensive experiments\non multiple datasets, model architectures, and sparsities show that our method\nreduces ECE values by up to 47.8\\% and simultaneously maintains or even\nimproves accuracy with only a slight increase in computation and storage\nburden.\n","authors":["Bowen Lei","Ruqi Zhang","Dongkuan Xu","Bani Mallick"],"pdf_url":"https://arxiv.org/pdf/2302.09369v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.13602v2","updated":"2023-03-01T03:29:24Z","published":"2022-06-27T19:30:53Z","title":"Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance\n  Matching","summary":"  Molecular representation pretraining is critical in various applications for\ndrug and material discovery due to the limited number of labeled molecules, and\nmost existing work focuses on pretraining on 2D molecular graphs. However, the\npower of pretraining on 3D geometric structures has been less explored. This is\nowing to the difficulty of finding a sufficient proxy task that can empower the\npretraining to effectively extract essential features from the geometric\nstructures. Motivated by the dynamic nature of 3D molecules, where the\ncontinuous motion of a molecule in the 3D Euclidean space forms a smooth\npotential energy surface, we propose GeoSSL, a 3D coordinate denoising\npretraining framework to model such an energy landscape. Further by leveraging\nan SE(3)-invariant score matching method, we propose GeoSSL-DDM in which the\ncoordinate denoising proxy task is effectively boiled down to denoising the\npairwise atomic distances in a molecule. Our comprehensive experiments confirm\nthe effectiveness and robustness of our proposed method.\n","authors":["Shengchao Liu","Hongyu Guo","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2206.13602v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15408v3","updated":"2023-03-01T03:23:32Z","published":"2022-09-30T12:10:15Z","title":"Equivariant Energy-Guided SDE for Inverse Molecular Design","summary":"  Inverse molecular design is critical in material science and drug discovery,\nwhere the generated molecules should satisfy certain desirable properties. In\nthis paper, we propose equivariant energy-guided stochastic differential\nequations (EEGSDE), a flexible framework for controllable 3D molecule\ngeneration under the guidance of an energy function in diffusion models.\nFormally, we show that EEGSDE naturally exploits the geometric symmetry in 3D\nmolecular conformation, as long as the energy function is invariant to\northogonal transformations. Empirically, under the guidance of designed energy\nfunctions, EEGSDE significantly improves the baseline on QM9, in inverse\nmolecular design targeted to quantum properties and molecular structures.\nFurthermore, EEGSDE is able to generate molecules with multiple target\nproperties by combining the corresponding energy functions linearly.\n","authors":["Fan Bao","Min Zhao","Zhongkai Hao","Peiyao Li","Chongxuan Li","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.15408v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00198v1","updated":"2023-03-01T03:06:29Z","published":"2023-03-01T03:06:29Z","title":"Self-Supervised Convolutional Visual Prompts","summary":"  Machine learning models often fail on out-of-distribution (OOD) samples.\nVisual prompts emerge as a light-weight adaptation method in input space for\nlarge-scale vision models. Existing vision prompts optimize a high-dimensional\nadditive vector and require labeled data on training. However, we find this\nparadigm fails on test-time adaptation when labeled data is unavailable, where\nthe high-dimensional visual prompt overfits to the self-supervised objective.\nWe present convolutional visual prompts for test-time adaptation without\nlabels. Our convolutional prompt is structured and requires fewer trainable\nparameters (less than 1 % parameters of standard visual prompts). Extensive\nexperiments on a wide variety of OOD recognition tasks show that our approach\nis effective, improving robustness by up to 5.87 % over a number of large-scale\nmodel architectures.\n","authors":["Yun-Yun Tsai","Chengzhi Mao","Yow-Kuan Lin","Junfeng Yang"],"pdf_url":"https://arxiv.org/pdf/2303.00198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00196v1","updated":"2023-03-01T03:05:40Z","published":"2023-03-01T03:05:40Z","title":"Transformed Low-Rank Parameterization Can Help Robust Generalization for\n  Tensor Neural Networks","summary":"  Achieving efficient and robust multi-channel data learning is a challenging\ntask in data science. By exploiting low-rankness in the transformed domain,\ni.e., transformed low-rankness, tensor Singular Value Decomposition (t-SVD) has\nachieved extensive success in multi-channel data representation and has\nrecently been extended to function representation such as Neural Networks with\nt-product layers (t-NNs). However, it still remains unclear how t-SVD\ntheoretically affects the learning behavior of t-NNs. This paper is the first\nto answer this question by deriving the upper bounds of the generalization\nerror of both standard and adversarially trained t-NNs. It reveals that the\nt-NNs compressed by exact transformed low-rank parameterization can achieve a\nsharper adversarial generalization bound. In practice, although t-NNs rarely\nhave exactly transformed low-rank weights, our analysis further shows that by\nadversarial training with gradient flow (GF), the over-parameterized t-NNs with\nReLU activations are trained with implicit regularization towards transformed\nlow-rank parameterization under certain conditions. We also establish\nadversarial generalization bounds for t-NNs with approximately transformed\nlow-rank weights. Our analysis indicates that the transformed low-rank\nparameterization can promisingly enhance robust generalization for t-NNs.\n","authors":["Andong Wang","Chao Li","Mingyuan Bai","Zhong Jin","Guoxu Zhou","Qibin Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.00196v1.pdf","comment":"55 pages, submitted for peer review"},{"id":"http://arxiv.org/abs/2205.14309v2","updated":"2023-03-01T02:54:36Z","published":"2022-05-28T02:58:37Z","title":"Federated Neural Bandits","summary":"  Recent works on neural contextual bandits have achieved compelling\nperformances due to their ability to leverage the strong representation power\nof neural networks (NNs) for reward prediction. Many applications of contextual\nbandits involve multiple agents who collaborate without sharing raw\nobservations, thus giving rise to the setting of federated contextual bandits.\nExisting works on federated contextual bandits rely on linear or kernelized\nbandits, which may fall short when modeling complex real-world reward\nfunctions. So, this paper introduces the federated neural-upper confidence\nbound (FN-UCB) algorithm. To better exploit the federated setting, FN-UCB\nadopts a weighted combination of two UCBs: $\\text{UCB}^{a}$ allows every agent\nto additionally use the observations from the other agents to accelerate\nexploration (without sharing raw observations), while $\\text{UCB}^{b}$ uses an\nNN with aggregated parameters for reward prediction in a similar way to\nfederated averaging for supervised learning. Notably, the weight between the\ntwo UCBs required by our theoretical analysis is amenable to an interesting\ninterpretation, which emphasizes $\\text{UCB}^{a}$ initially for accelerated\nexploration and relies more on $\\text{UCB}^{b}$ later after enough observations\nhave been collected to train the NNs for accurate reward prediction (i.e.,\nreliable exploitation). We prove sub-linear upper bounds on both the cumulative\nregret and the number of communication rounds of FN-UCB, and empirically\ndemonstrate its competitive performance.\n","authors":["Zhongxiang Dai","Yao Shu","Arun Verma","Flint Xiaofeng Fan","Bryan Kian Hsiang Low","Patrick Jaillet"],"pdf_url":"https://arxiv.org/pdf/2205.14309v2.pdf","comment":"ICLR 2023. Code:\n  https://github.com/daizhongxiang/Federated-Neural-Bandits"},{"id":"http://arxiv.org/abs/2210.00312v4","updated":"2023-03-01T02:51:12Z","published":"2022-10-01T16:24:15Z","title":"Multimodal Analogical Reasoning over Knowledge Graphs","summary":"  Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.\n","authors":["Ningyu Zhang","Lei Li","Xiang Chen","Xiaozhuan Liang","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00312v4.pdf","comment":"Accepted by ICLR 2023. The project website is\n  https://zjunlp.github.io/project/MKG_Analogy/introduction.html"},{"id":"http://arxiv.org/abs/2303.00191v1","updated":"2023-03-01T02:48:55Z","published":"2023-03-01T02:48:55Z","title":"pyribs: A Bare-Bones Python Library for Quality Diversity Optimization","summary":"  Recent years have seen a rise in the popularity of quality diversity (QD)\noptimization, a branch of optimization that seeks to find a collection of\ndiverse, high-performing solutions to a given problem. To grow further, we\nbelieve the QD community faces two challenges: developing a framework to\nrepresent the field's growing array of algorithms, and implementing that\nframework in software that supports a range of researchers and practitioners.\nTo address these challenges, we have developed pyribs, a library built on a\nhighly modular conceptual QD framework. By replacing components in the\nconceptual framework, and hence in pyribs, users can compose algorithms from\nacross the QD literature; equally important, they can identify unexplored\nalgorithm variations. Furthermore, pyribs makes this framework simple,\nflexible, and accessible, with a user-friendly API supported by extensive\ndocumentation and tutorials. This paper overviews the creation of pyribs,\nfocusing on the conceptual framework that it implements and the design\nprinciples that have guided the library's development.\n","authors":["Bryon Tjanaka","Matthew C. Fontaine","David H. Lee","Yulun Zhang","Nivedit Reddy Balam","Nathaniel Dennler","Sujay S. Garlanka","Nikitas Dimitri Klapsis","Stefanos Nikolaidis"],"pdf_url":"https://arxiv.org/pdf/2303.00191v1.pdf","comment":"Pyribs is available at https://pyribs.org; supplemental material for\n  this paper is available at https://pyribs.org/paper"},{"id":"http://arxiv.org/abs/2210.10946v3","updated":"2023-03-01T02:41:41Z","published":"2022-10-20T01:29:10Z","title":"Causally-guided Regularization of Graph Attention Improves\n  Generalizability","summary":"  Graph attention networks estimate the relational importance of node neighbors\nto aggregate relevant information over local neighborhoods for a prediction\ntask. However, the inferred attentions are vulnerable to spurious correlations\nand connectivity in the training data, hampering the generalizability of the\nmodel. We introduce CAR, a general-purpose regularization framework for graph\nattention networks. Embodying a causal inference approach, CAR aligns the\nattention mechanism with the causal effects of active interventions on graph\nconnectivity in a scalable manner. CAR is compatible with a variety of graph\nattention architectures, and we show that it systematically improves\ngeneralizability on various node classification tasks. Our ablation studies\nindicate that CAR hones in on the aspects of graph structure most pertinent to\nthe prediction (e.g., homophily), and does so more effectively than alternative\napproaches. Finally, we also show that CAR enhances interpretability of\nattention weights by accentuating node-neighbor relations that point to causal\nhypotheses. For social media network-sized graphs, a CAR-guided graph rewiring\napproach could allow us to combine the scalability of graph convolutional\nmethods with the higher performance of graph attention.\n","authors":["Alexander P. Wu","Thomas Markovich","Bonnie Berger","Nils Hammerla","Rohit Singh"],"pdf_url":"https://arxiv.org/pdf/2210.10946v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00187v1","updated":"2023-03-01T02:29:41Z","published":"2023-03-01T02:29:41Z","title":"On the Integration of Physics-Based Machine Learning with Hierarchical\n  Bayesian Modeling Techniques","summary":"  Machine Learning (ML) has widely been used for modeling and predicting\nphysical systems. These techniques offer high expressive power and good\ngeneralizability for interpolation within observed data sets. However, the\ndisadvantage of black-box models is that they underperform under blind\nconditions since no physical knowledge is incorporated. Physics-based ML aims\nto address this problem by retaining the mathematical flexibility of ML\ntechniques while incorporating physics. In accord, this paper proposes to embed\nmechanics-based models into the mean function of a Gaussian Process (GP) model\nand characterize potential discrepancies through kernel machines. A specific\nclass of kernel function is promoted, which has a connection with the gradient\nof the physics-based model with respect to the input and parameters and shares\nsimilarity with the exact Autocovariance function of linear dynamical systems.\nThe spectral properties of the kernel function enable considering dominant\nperiodic processes originating from physics misspecification. Nevertheless, the\nstationarity of the kernel function is a difficult hurdle in the sequential\nprocessing of long data sets, resolved through hierarchical Bayesian\ntechniques. This implementation is also advantageous to mitigate computational\ncosts, alleviating the scalability of GPs when dealing with sequential data.\nUsing numerical and experimental examples, potential applications of the\nproposed method to structural dynamics inverse problems are demonstrated.\n","authors":["Omid Sedehi","Antonina M. Kosikova","Costas Papadimitriou","Lambros S. Katafygiotis"],"pdf_url":"https://arxiv.org/pdf/2303.00187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00186v1","updated":"2023-03-01T02:29:30Z","published":"2023-03-01T02:29:30Z","title":"Towards a real-time demand response framework for smart communities\n  using clustering techniques","summary":"  The present study explores the use of clustering techniques for the design\nand implementation of a demand response (DR) program for commercial and\nresidential prosumers. The goal of the program is to shift the participants'\nconsumption behavior to mitigate two issues a) the reverse power flow at the\nprimary substation, that occurs when generation from solar panels in the local\ngrid exceeds consumption and b) the system wide peak demand, that typically\noccurs during hours of the late afternoon. For the clustering stage, three\npopular algorithms for electrical load clustering are employed -- namely\nk-means, k-medoids and a hierarchical clustering algorithm -- alongside two\ndifferent distance metrics -- namely euclidean and constrained Dynamic Time\nWarping (DTW). We evaluate the methods using different validation metrics\nincluding a novel metric -- namely peak performance score (PPS) -- that we\npropose in the context of this study. The best setup is employed to divide\ndaily prosumer load profiles into clusters and each cluster is analyzed in\nterms of load shape, mean entropy and distribution of load profiles from each\nload type. These characteristics are then used to distinguish the clusters that\nwould be most likely to aid with the DR schemes would fit each cluster.\nFinally, we conceptualize a DR system that combines forecasting, clustering and\na price-based demand projection engine to produce daily individualized DR\nrecommendations and pricing policies for prosumers participating in the\nprogram. The results of this study can be useful for network operators and\nutilities that aim to develop targeted DR programs for groups of prosumers\nwithin flexible energy communities.\n","authors":["Sotiris Pelekis","Angelos Pipergias","Evangelos Karakolis","Spiros Mouzakitis","Francesca Santori","Mohammad Ghoreishi","Dimitris Askounis"],"pdf_url":"https://arxiv.org/pdf/2303.00186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06545v4","updated":"2023-03-01T02:27:46Z","published":"2022-11-12T02:01:46Z","title":"Self-Supervised Graph Structure Refinement for Graph Neural Networks","summary":"  Graph structure learning (GSL), which aims to learn the adjacency matrix for\ngraph neural networks (GNNs), has shown great potential in boosting the\nperformance of GNNs. Most existing GSL works apply a joint learning framework\nwhere the estimated adjacency matrix and GNN parameters are optimized for\ndownstream tasks. However, as GSL is essentially a link prediction task, whose\ngoal may largely differ from the goal of the downstream task. The inconsistency\nof these two goals limits the GSL methods to learn the potential optimal graph\nstructure. Moreover, the joint learning framework suffers from scalability\nissues in terms of time and space during the process of estimation and\noptimization of the adjacency matrix. To mitigate these issues, we propose a\ngraph structure refinement (GSR) framework with a pretrain-finetune pipeline.\nSpecifically, The pre-training phase aims to comprehensively estimate the\nunderlying graph structure by a multi-view contrastive learning framework with\nboth intra- and inter-view link prediction tasks. Then, the graph structure is\nrefined by adding and removing edges according to the edge probabilities\nestimated by the pre-trained model. Finally, the fine-tuning GNN is initialized\nby the pre-trained model and optimized toward downstream tasks. With the\nrefined graph structure remaining static in the fine-tuning space, GSR avoids\nestimating and optimizing graph structure in the fine-tuning phase which enjoys\ngreat scalability and efficiency. Moreover, the fine-tuning GNN is boosted by\nboth migrating knowledge and refining graphs. Extensive experiments are\nconducted to evaluate the effectiveness (best performance on six benchmark\ndatasets), efficiency, and scalability (13.8x faster using 32.8% GPU memory\ncompared to the best GSL baseline on Cora) of the proposed model.\n","authors":["Jianan Zhao","Qianlong Wen","Mingxuan Ju","Chuxu Zhang","Yanfang Ye"],"pdf_url":"https://arxiv.org/pdf/2211.06545v4.pdf","comment":"WSDM 2023"},{"id":"http://arxiv.org/abs/2206.01729v2","updated":"2023-03-01T02:27:10Z","published":"2022-06-01T04:30:41Z","title":"Torsional Diffusion for Molecular Conformer Generation","summary":"  Molecular conformer generation is a fundamental task in computational\nchemistry. Several machine learning approaches have been developed, but none\nhave outperformed state-of-the-art cheminformatics methods. We propose\ntorsional diffusion, a novel diffusion framework that operates on the space of\ntorsion angles via a diffusion process on the hypertorus and an\nextrinsic-to-intrinsic score model. On a standard benchmark of drug-like\nmolecules, torsional diffusion generates superior conformer ensembles compared\nto machine learning and cheminformatics methods in terms of both RMSD and\nchemical properties, and is orders of magnitude faster than previous\ndiffusion-based models. Moreover, our model provides exact likelihoods, which\nwe employ to build the first generalizable Boltzmann generator. Code is\navailable at https://github.com/gcorso/torsional-diffusion.\n","authors":["Bowen Jing","Gabriele Corso","Jeffrey Chang","Regina Barzilay","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2206.01729v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.00180v1","updated":"2023-03-01T02:14:20Z","published":"2023-03-01T02:14:20Z","title":"FaceRNET: a Facial Expression Intensity Estimation Network","summary":"  This paper presents our approach for Facial Expression Intensity Estimation\nfrom videos. It includes two components: i) a representation extractor network\nthat extracts various emotion descriptors (valence-arousal, action units and\nbasic expressions) from each videoframe; ii) a RNN that captures temporal\ninformation in the data, followed by a mask layer which enables handling\nvarying input video lengths through dynamic routing. This approach has been\ntested on the Hume-Reaction dataset yielding excellent results.\n","authors":["Dimitrios Kollias","Andreas Psaroudakis","Anastasios Arsenos","Paraskeui Theofilou"],"pdf_url":"https://arxiv.org/pdf/2303.00180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00179v1","updated":"2023-03-01T02:13:22Z","published":"2023-03-01T02:13:22Z","title":"A Unified Momentum-based Paradigm of Decentralized SGD for Non-Convex\n  Models and Heterogeneous Data","summary":"  Emerging distributed applications recently boosted the development of\ndecentralized machine learning, especially in IoT and edge computing fields. In\nreal-world scenarios, the common problems of non-convexity and data\nheterogeneity result in inefficiency, performance degradation, and development\nstagnation. The bulk of studies concentrates on one of the issues mentioned\nabove without having a more general framework that has been proven optimal. To\nthis end, we propose a unified paradigm called UMP, which comprises two\nalgorithms, D-SUM and GT-DSUM, based on the momentum technique with\ndecentralized stochastic gradient descent(SGD). The former provides a\nconvergence guarantee for general non-convex objectives. At the same time, the\nlatter is extended by introducing gradient tracking, which estimates the global\noptimization direction to mitigate data heterogeneity(i.e., distribution\ndrift). We can cover most momentum-based variants based on the classical heavy\nball or Nesterov's acceleration with different parameters in UMP. In theory, we\nrigorously provide the convergence analysis of these two approaches for\nnon-convex objectives and conduct extensive experiments, demonstrating a\nsignificant improvement in model accuracy by up to 57.6% compared to other\nmethods in practice.\n","authors":["Haizhou Du","Chengdong Ni"],"pdf_url":"https://arxiv.org/pdf/2303.00179v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2303.00177v1","updated":"2023-03-01T02:09:49Z","published":"2023-03-01T02:09:49Z","title":"Finite-sample Guarantees for Nash Q-learning with Linear Function\n  Approximation","summary":"  Nash Q-learning may be considered one of the first and most known algorithms\nin multi-agent reinforcement learning (MARL) for learning policies that\nconstitute a Nash equilibrium of an underlying general-sum Markov game. Its\noriginal proof provided asymptotic guarantees and was for the tabular case.\nRecently, finite-sample guarantees have been provided using more modern RL\ntechniques for the tabular case. Our work analyzes Nash Q-learning using linear\nfunction approximation -- a representation regime introduced when the state\nspace is large or continuous -- and provides finite-sample guarantees that\nindicate its sample efficiency. We find that the obtained performance nearly\nmatches an existing efficient result for single-agent RL under the same\nrepresentation and has a polynomial gap when compared to the best-known result\nfor the tabular case.\n","authors":["Pedro Cisneros-Velarde","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2303.00177v1.pdf","comment":"25 pages. arXiv admin note: text overlap with arXiv:2205.15891"},{"id":"http://arxiv.org/abs/2303.00175v1","updated":"2023-03-01T02:07:48Z","published":"2023-03-01T02:07:48Z","title":"A Deep Neural Architecture for Harmonizing 3-D Input Data Analysis and\n  Decision Making in Medical Imaging","summary":"  Harmonizing the analysis of data, especially of 3-D image volumes, consisting\nof different number of slices and annotated per volume, is a significant\nproblem in training and using deep neural networks in various applications,\nincluding medical imaging. Moreover, unifying the decision making of the\nnetworks over different input datasets is crucial for the generation of rich\ndata-driven knowledge and for trusted usage in the applications. This paper\npresents a new deep neural architecture, named RACNet, which includes routing\nand feature alignment steps and effectively handles different input lengths and\nsingle annotations of the 3-D image inputs, whilst providing highly accurate\ndecisions. In addition, through latent variable extraction from the trained\nRACNet, a set of anchors are generated providing further insight on the\nnetwork's decision making. These can be used to enrich and unify data-driven\nknowledge extracted from different datasets. An extensive experimental study\nillustrates the above developments, focusing on COVID-19 diagnosis through\nanalysis of 3-D chest CT scans from databases generated in different countries\nand medical centers.\n","authors":["Dimitrios Kollias","Anastasios Arsenos","Stefanos Kollias"],"pdf_url":"https://arxiv.org/pdf/2303.00175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07924v3","updated":"2023-03-01T01:59:08Z","published":"2022-09-15T07:45:35Z","title":"GNNInterpreter: A Probabilistic Generative Model-Level Explanation for\n  Graph Neural Networks","summary":"  Recently, Graph Neural Networks (GNNs) have significantly advanced the\nperformance of machine learning tasks on graphs. However, this technological\nbreakthrough makes people wonder: how does a GNN make such decisions, and can\nwe trust its prediction with high confidence? When it comes to some critical\nfields, such as biomedicine, where making wrong decisions can have severe\nconsequences, it is crucial to interpret the inner working mechanisms of GNNs\nbefore applying them. In this paper, we propose a model-agnostic model-level\nexplanation method for different GNNs that follow the message passing scheme,\nGNNInterpreter, to explain the high-level decision-making process of the GNN\nmodel. More specifically, GNNInterpreter learns a probabilistic generative\ngraph distribution that produces the most discriminative graph pattern the GNN\ntries to detect when making a certain prediction by optimizing a novel\nobjective function specifically designed for the model-level explanation for\nGNNs. Compared to existing works, GNNInterpreter is more flexible and\ncomputationally efficient in generating explanation graphs with different types\nof node and edge features, without introducing another blackbox or requiring\nmanually specified domain-specific rules. In addition, the experimental studies\nconducted on four different datasets demonstrate that the explanation graphs\ngenerated by GNNInterpreter match the desired graph pattern if the model is\nideal; otherwise, potential model pitfalls can be revealed by the explanation.\n","authors":["Xiaoqi Wang","Han-Wei Shen"],"pdf_url":"https://arxiv.org/pdf/2209.07924v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00171v1","updated":"2023-03-01T01:53:11Z","published":"2023-03-01T01:53:11Z","title":"DTW-SiameseNet: Dynamic Time Warped Siamese Network for Mispronunciation\n  Detection and Correction","summary":"  Personal Digital Assistants (PDAs) - such as Siri, Alexa and Google\nAssistant, to name a few - play an increasingly important role to access\ninformation and complete tasks spanning multiple domains, and by diverse groups\nof users. A text-to-speech (TTS) module allows PDAs to interact in a natural,\nhuman-like manner, and play a vital role when the interaction involves people\nwith visual impairments or other disabilities. To cater to the needs of a\ndiverse set of users, inclusive TTS is important to recognize and pronounce\ncorrectly text in different languages and dialects. Despite great progress in\nspeech synthesis, the pronunciation accuracy of named entities in a\nmulti-lingual setting still has a large room for improvement. Existing\napproaches to correct named entity (NE) mispronunciations, like retraining\nGrapheme-to-Phoneme (G2P) models, or maintaining a TTS pronunciation\ndictionary, require expensive annotation of the ground truth pronunciation,\nwhich is also time consuming. In this work, we present a highly-precise,\nPDA-compatible pronunciation learning framework for the task of TTS\nmispronunciation detection and correction. In addition, we also propose a novel\nmispronunciation detection model called DTW-SiameseNet, which employs metric\nlearning with a Siamese architecture for Dynamic Time Warping (DTW) with\ntriplet loss. We demonstrate that a locale-agnostic, privacy-preserving\nsolution to the problem of TTS mispronunciation detection is feasible. We\nevaluate our approach on a real-world dataset, and a corpus of NE\npronunciations of an anonymized audio dataset of person names recorded by\nparticipants from 10 different locales. Human evaluation shows our proposed\napproach improves pronunciation accuracy on average by ~6% compared to strong\nphoneme-based and audio-based baselines.\n","authors":["Raviteja Anantha","Kriti Bhasin","Daniela de la Parra Aguilar","Prabal Vashisht","Becci Williamson","Srinivas Chappidi"],"pdf_url":"https://arxiv.org/pdf/2303.00171v1.pdf","comment":"Preprint version"},{"id":"http://arxiv.org/abs/2303.00170v1","updated":"2023-03-01T01:48:20Z","published":"2023-03-01T01:48:20Z","title":"Asymmetric Learning for Graph Neural Network based Link Prediction","summary":"  Link prediction is a fundamental problem in many graph based applications,\nsuch as protein-protein interaction prediction. Graph neural network (GNN) has\nrecently been widely used for link prediction. However, existing GNN based link\nprediction (GNN-LP) methods suffer from scalability problem during training for\nlarge-scale graphs, which has received little attention by researchers. In this\npaper, we first give computation complexity analysis of existing GNN-LP\nmethods, which reveals that the scalability problem stems from their symmetric\nlearning strategy adopting the same class of GNN models to learn representation\nfor both head and tail nodes. Then we propose a novel method, called asymmetric\nlearning (AML), for GNN-LP. The main idea of AML is to adopt a GNN model for\nlearning head node representation while using a multi-layer perceptron (MLP)\nmodel for learning tail node representation. Furthermore, AML proposes a\nrow-wise sampling strategy to generate mini-batch for training, which is a\nnecessary component to make the asymmetric learning strategy work for training\nspeedup. To the best of our knowledge, AML is the first GNN-LP method adopting\nan asymmetric learning strategy for node representation learning. Experiments\non three real large-scale datasets show that AML is 1.7X~7.3X faster in\ntraining than baselines with a symmetric learning strategy, while having almost\nno accuracy loss.\n","authors":["Kai-Lang Yao","Wu-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2303.00170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14165v2","updated":"2023-03-01T01:36:37Z","published":"2023-02-27T21:57:42Z","title":"GAM Coach: Towards Interactive and User-centered Algorithmic Recourse","summary":"  Machine learning (ML) recourse techniques are increasingly used in\nhigh-stakes domains, providing end users with actions to alter ML predictions,\nbut they assume ML developers understand what input variables can be changed.\nHowever, a recourse plan's actionability is subjective and unlikely to match\ndevelopers' expectations completely. We present GAM Coach, a novel open-source\nsystem that adapts integer linear programming to generate customizable\ncounterfactual explanations for Generalized Additive Models (GAMs), and\nleverages interactive visualizations to enable end users to iteratively\ngenerate recourse plans meeting their needs. A quantitative user study with 41\nparticipants shows our tool is usable and useful, and users prefer personalized\nrecourse plans over generic plans. Through a log analysis, we explore how users\ndiscover satisfactory recourse plans, and provide empirical evidence that\ntransparency can lead to more opportunities for everyday users to discover\ncounterintuitive patterns in ML models. GAM Coach is available at:\nhttps://poloclub.github.io/gam-coach/.\n","authors":["Zijie J. Wang","Jennifer Wortman Vaughan","Rich Caruana","Duen Horng Chau"],"pdf_url":"https://arxiv.org/pdf/2302.14165v2.pdf","comment":"Accepted to CHI 2023. 20 pages, 12 figures. For a demo video, see\n  https://youtu.be/ubacP34H9XE. For a live demo, visit\n  https://poloclub.github.io/gam-coach/"},{"id":"http://arxiv.org/abs/2210.01241v3","updated":"2023-03-01T01:31:17Z","published":"2022-10-03T21:38:29Z","title":"Is Reinforcement Learning (Not) for Natural Language Processing:\n  Benchmarks, Baselines, and Building Blocks for Natural Language Policy\n  Optimization","summary":"  We tackle the problem of aligning pre-trained large language models (LMs)\nwith human preferences. If we view text generation as a sequential\ndecision-making problem, reinforcement learning (RL) appears to be a natural\nconceptual framework. However, using RL for LM-based generation faces empirical\nchallenges, including training instability due to the combinatorial action\nspace, as well as a lack of open-source libraries and benchmarks customized for\nLM alignment. Thus, a question rises in the research community: is RL a\npractical paradigm for NLP?\n  To help answer this, we first introduce an open-source modular library,\nRL4LMs (Reinforcement Learning for Language Models), for optimizing language\ngenerators with RL. The library consists of on-policy RL algorithms that can be\nused to train any encoder or encoder-decoder LM in the HuggingFace library\n(Wolf et al. 2020) with an arbitrary reward function. Next, we present the GRUE\n(General Reinforced-language Understanding Evaluation) benchmark, a set of 6\nlanguage generation tasks which are supervised not by target strings, but by\nreward functions which capture automated measures of human preference.GRUE is\nthe first leaderboard-style evaluation of RL algorithms for NLP tasks. Finally,\nwe introduce an easy-to-use, performant RL algorithm, NLPO (Natural Language\nPolicy Optimization)} that learns to effectively reduce the combinatorial\naction space in language generation. We show 1) that RL techniques are\ngenerally better than supervised methods at aligning LMs to human preferences;\nand 2) that NLPO exhibits greater stability and performance than previous\npolicy gradient methods (e.g., PPO (Schulman et al. 2017)), based on both\nautomatic and human evaluations.\n","authors":["Rajkumar Ramamurthy","Prithviraj Ammanabrolu","Kianté Brantley","Jack Hessel","Rafet Sifa","Christian Bauckhage","Hannaneh Hajishirzi","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2210.01241v3.pdf","comment":"In Proceedings of ICLR 2023. Code found at\n  https://github.com/allenai/rl4lms and Project website at\n  https://rl4lms.apps.allenai.org/"},{"id":"http://arxiv.org/abs/2210.11780v2","updated":"2023-03-01T01:14:55Z","published":"2022-10-21T07:25:57Z","title":"Correlating sparse sensing for large-scale traffic speed estimation: A\n  Laplacian enhanced low-rank tensor kriging approach","summary":"  Traffic speed is central to characterizing the fluidity of the road network.\nMany transportation applications rely on it, such as real-time navigation,\ndynamic route planning, and congestion management. Rapid advances in sensing\nand communication techniques make traffic speed detection easier than ever.\nHowever, due to sparse deployment of static sensors or low penetration of\nmobile sensors, speeds detected are incomplete and far from network-wide use.\nIn addition, sensors are prone to error or missing data due to various kinds of\nreasons, speeds from these sensors can become highly noisy. These drawbacks\ncall for effective techniques to recover credible estimates from the incomplete\ndata. In this work, we first identify the issue as a spatiotemporal kriging\nproblem and propose a Laplacian enhanced low-rank tensor completion (LETC)\nframework featuring both lowrankness and multi-dimensional correlations for\nlarge-scale traffic speed kriging under limited observations. To be specific,\nthree types of speed correlation including temporal continuity, temporal\nperiodicity, and spatial proximity are carefully chosen and simultaneously\nmodeled by three different forms of graph Laplacian, named temporal graph\nFourier transform, generalized temporal consistency regularization, and\ndiffusion graph regularization. We then design an efficient solution algorithm\nvia several effective numeric techniques to scale up the proposed model to\nnetwork-wide kriging. By performing experiments on two public million-level\ntraffic speed datasets, we finally draw the conclusion and find our proposed\nLETC achieves the state-of-the-art kriging performance even under low\nobservation rates, while at the same time saving more than half computing time\ncompared with baseline methods. Some insights into spatiotemporal traffic data\nmodeling and kriging at the network level are provided as well.\n","authors":["Tong Nie","Guoyang Qin","Yunpeng Wang","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2210.11780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04980v2","updated":"2023-03-01T01:02:23Z","published":"2022-07-23T15:24:07Z","title":"An NLP-Assisted Bayesian Time Series Analysis for Prevalence of Twitter\n  Cyberbullying During the COVID-19 Pandemic","summary":"  COVID-19 has brought about many changes in social dynamics. Stay-at-home\norders and disruptions in school teaching can influence bullying behavior\nin-person and online, both of which leading to negative outcomes in victims. To\nstudy cyberbullying specifically, 1 million tweets containing keywords\nassociated with abuse were collected from the beginning of 2019 to the end of\n2021 with the Twitter API search endpoint. A natural language processing model\npre-trained on a Twitter corpus generated probabilities for the tweets being\noffensive and hateful. To overcome limitations of sampling, data was also\ncollected using the count endpoint. The fraction of tweets from a given daily\nsample marked as abusive is multiplied to the number reported by the count\nendpoint. Once these adjusted counts are assembled, a Bayesian autoregressive\nPoisson model allows one to study the mean trend and lag functions of the data\nand how they vary over time. The results reveal strong weekly and yearly\nseasonality in hateful speech but with slight differences across years that may\nbe attributed to COVID-19.\n","authors":["Christopher Perez","Sayar Karmakar"],"pdf_url":"https://arxiv.org/pdf/2208.04980v2.pdf","comment":"22 pages, 15 figures"},{"id":"http://arxiv.org/abs/2208.04202v2","updated":"2023-03-01T00:18:33Z","published":"2022-08-08T15:08:40Z","title":"Analog Bits: Generating Discrete Data using Diffusion Models with\n  Self-Conditioning","summary":"  We present Bit Diffusion: a simple and generic approach for generating\ndiscrete data with continuous state and continuous time diffusion models. The\nmain idea behind our approach is to first represent the discrete data as binary\nbits, and then train a continuous diffusion model to model these bits as real\nnumbers which we call analog bits. To generate samples, the model first\ngenerates the analog bits, which are then thresholded to obtain the bits that\nrepresent the discrete variables. We further propose two simple techniques,\nnamely Self-Conditioning and Asymmetric Time Intervals, which lead to a\nsignificant improvement in sample quality. Despite its simplicity, the proposed\napproach can achieve strong performance in both discrete image generation and\nimage captioning tasks. For discrete image generation, we significantly improve\nprevious state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens)\nand ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the\nbest autoregressive model in both sample quality (measured by FID) and\nefficiency. For image captioning on MS-COCO dataset, our approach achieves\ncompetitive results compared to autoregressive models.\n","authors":["Ting Chen","Ruixiang Zhang","Geoffrey Hinton"],"pdf_url":"https://arxiv.org/pdf/2208.04202v2.pdf","comment":"ICLR'23"},{"id":"http://arxiv.org/abs/2303.00141v1","updated":"2023-03-01T00:13:52Z","published":"2023-03-01T00:13:52Z","title":"Containing a spread through sequential learning: to exploit or to\n  explore?","summary":"  The spread of an undesirable contact process, such as an infectious disease\n(e.g. COVID-19), is contained through testing and isolation of infected nodes.\nThe temporal and spatial evolution of the process (along with containment\nthrough isolation) render such detection as fundamentally different from active\nsearch detection strategies. In this work, through an active learning approach,\nwe design testing and isolation strategies to contain the spread and minimize\nthe cumulative infections under a given test budget. We prove that the\nobjective can be optimized, with performance guarantees, by greedily selecting\nthe nodes to test. We further design reward-based methodologies that\neffectively minimize an upper bound on the cumulative infections and are\ncomputationally more tractable in large networks. These policies, however, need\nknowledge about the nodes' infection probabilities which are dynamically\nchanging and have to be learned by sequential testing. We develop a\nmessage-passing framework for this purpose and, building on that, show novel\ntradeoffs between exploitation of knowledge through reward-based heuristics and\nexploration of the unknown through a carefully designed probabilistic testing.\nThe tradeoffs are fundamentally distinct from the classical counterparts under\nactive search or multi-armed bandit problems (MABs). We provably show the\nnecessity of exploration in a stylized network and show through simulations\nthat exploration can outperform exploitation in various synthetic and real-data\nnetworks depending on the parameters of the network and the spread.\n","authors":["Xingran Chen","Hesam Nikpey","Jungyeol Kim","Saswati Sarkar","Shirin Saeedi-Bidokhti"],"pdf_url":"https://arxiv.org/pdf/2303.00141v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2206.00089v2","updated":"2023-03-01T13:33:47Z","published":"2022-05-31T19:59:00Z","title":"Defining Quantum Games","summary":"  In this article, we explore the concept of quantum games and define quantum\ngames as any type of playable games that are related to or reference quantum\nphysics through any of three proposed aspects. The rise of the quantum\ncomputers has made it possible to think about a new wave of computer games,\nnamely quantum computer games, games on quantum computers. But at the same\ntime, there are also various games that are exploring quantum mechanics and\nrelated topics through digital, analogue and hybrid means. In this article we\ngo through the emerging body of quantum games, the history of quantum games and\nthe different ways a game may be considered a quantum game. For this we propose\nthree dimensions for analysing and defining the phenomenon of quantum games:\nthe perceivable dimension of quantum physics, the dimension of quantum\ntechnologies and the dimension of scientific purposes.\n","authors":["Laura Piispanen","Marcel Pfaffhauser","Annakaisa Kultima","James R. Wootton"],"pdf_url":"https://arxiv.org/pdf/2206.00089v2.pdf","comment":"13 pages + references, 34 figures. Update on the previous version\n  with some typos"},{"id":"http://arxiv.org/abs/2303.00448v1","updated":"2023-03-01T12:17:33Z","published":"2023-03-01T12:17:33Z","title":"The style transformer with common knowledge optimization for image-text\n  retrieval","summary":"  Image-text retrieval which associates different modalities has drawn broad\nattention due to its excellent research value and broad real-world application.\nWhile the algorithms keep updated, most of them haven't taken the high-level\nsemantic relationships (\"style embedding\") and common knowledge from\nmulti-modalities into full consideration. To this end, we propose a novel style\ntransformer network with common knowledge optimization (CKSTN) for image-text\nretrieval. The main module is the common knowledge adaptor (CKA) with both the\nstyle embedding extractor (SEE) and the common knowledge optimization (CKO)\nmodules. Specifically, the SEE is designed to effectively extract high-level\nfeatures. The CKO module is introduced to dynamically capture the latent\nconcepts of common knowledge from different modalities. Together, they could\nassist in the formation of item representations in lightweight transformers.\nBesides, to get generalized temporal common knowledge, we propose a sequential\nupdate strategy to effectively integrate the features of different layers in\nSEE with previous common feature units. CKSTN outperforms the results of\nstate-of-the-art methods in image-text retrieval on MSCOCO and Flickr30K\ndatasets. Moreover, CKSTN is more convenient and practical for the application\nof real scenes, due to the better performance and lower parameters.\n","authors":["Wenrui Li","Zhengyu Ma","Xiaopeng Fan"],"pdf_url":"https://arxiv.org/pdf/2303.00448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14472v2","updated":"2023-03-01T03:38:11Z","published":"2023-02-28T10:30:16Z","title":"TV-watching partner robot: Analysis of User's Experience","summary":"  Watching TV not only provides news information but also gives an opportunity\nfor different generations to communicate. With the proliferation of\nsmartphones, PC, and the Internet, increase the opportunities for communication\nin front of the television is also likely to diminish. This has led to some\nproblems further from face-to-face such as a lack of self-control and\ninsufficient development of communication skills. This paper proposes a\nTV-watching companion robot with open-domain chat ability. The robot contains\ntwo modes: TV-watching mode and conversation mode. In TV-watching mode, the\nrobot first extracts keywords from the TV program and then generates the\ndisclosure utterances based on the extracted keywords as if enjoying the TV\nprogram. In the conversation mode, the robot generates question utterances with\nkeywords in the same way and then employs a topics-based dialog management\nmethod consisting of multiple dialog engines for rich conversations related to\nthe TV program. We conduct the initial experiments and the result shows that\nall participants from the three groups enjoyed talking with the robot, and the\nquestion about their interests in the robot was rated 6.5/7-levels. This\nindicates that the proposed conversational features of TV-watching Companion\nRobot have the potential to make our daily lives more enjoyable. Under the\nanalysis of the initial experiments, we achieve further experiments with more\nparticipants by dividing them into two groups: a control group without a robot\nand an intervention group with a robot. The results show that people prefer to\ntalk to robots because the robot will bring more enjoyable, relaxed, and\ninteresting.\n","authors":["Donghuo Zeng","Jianming Wu","Gen Hattori","Yasuhiro Takishima"],"pdf_url":"https://arxiv.org/pdf/2302.14472v2.pdf","comment":"15 pages, 3 figures, 11 tables"},{"id":"http://arxiv.org/abs/2210.00312v4","updated":"2023-03-01T02:51:12Z","published":"2022-10-01T16:24:15Z","title":"Multimodal Analogical Reasoning over Knowledge Graphs","summary":"  Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.\n","authors":["Ningyu Zhang","Lei Li","Xiang Chen","Xiaozhuan Liang","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00312v4.pdf","comment":"Accepted by ICLR 2023. The project website is\n  https://zjunlp.github.io/project/MKG_Analogy/introduction.html"},{"id":"http://arxiv.org/abs/2303.00181v1","updated":"2023-03-01T02:15:07Z","published":"2023-03-01T02:15:07Z","title":"Selectively Hard Negative Mining for Alleviating Gradient Vanishing in\n  Image-Text Matching","summary":"  Recently, a series of Image-Text Matching (ITM) methods achieve impressive\nperformance. However, we observe that most existing ITM models suffer from\ngradients vanishing at the beginning of training, which makes these models\nprone to falling into local minima. Most ITM models adopt triplet loss with\nHard Negative mining (HN) as the optimization objective. We find that\noptimizing an ITM model using only the hard negative samples can easily lead to\ngradient vanishing. In this paper, we derive the condition under which the\ngradient vanishes during training. When the difference between the positive\npair similarity and the negative pair similarity is close to 0, the gradients\non both the image and text encoders will approach 0. To alleviate the gradient\nvanishing problem, we propose a Selectively Hard Negative Mining (SelHN)\nstrategy, which chooses whether to mine hard negative samples according to the\ngradient vanishing condition. SelHN can be plug-and-play applied to existing\nITM models to give them better training behavior. To further ensure the\nback-propagation of gradients, we construct a Residual Visual Semantic\nEmbedding model with SelHN, denoted as RVSE++. Extensive experiments on two ITM\nbenchmarks demonstrate the strength of RVSE++, achieving state-of-the-art\nperformance.\n","authors":["Zheng Li","Caili Guo","Xin Wang","Zerun Feng","Zhongtian Du"],"pdf_url":"https://arxiv.org/pdf/2303.00181v1.pdf","comment":null}]},"2023-03-02T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.01502v1","updated":"2023-03-02T18:59:46Z","published":"2023-03-02T18:59:46Z","title":"Computational Language Acquisition with Theory of Mind","summary":"  Unlike current state-of-the-art language models, young children actively\nacquire language through interactions with their surrounding environment and\ncaretakers. One mechanism that has been argued to be critical to language\nlearning is the ability to infer the mental states of other agents in social\nenvironments, coined Theory of Mind (ToM) by Premack & Woodruff (1978). Drawing\ninspiration from the modern operationalized versions of ToM implemented in\nRabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning\nagents equipped with ToM, and measure its effects on the learning process. We\nmodel ToM by giving the speaker agent an internal listener model that is\ntrained alongside the speaker and used to rerank potential utterances. We\nexperiment with varying task difficulty, hypothesizing that models will acquire\nmore complex language to adapt to stronger environmental pressures. We find\nthat training speakers with a highly weighted ToM listener component leads to\nperformance gains in our image referential game setting. We also find some\nevidence that increasing task difficulty in the training process results in\nmore fluent and precise utterances in evaluation. This suggests the potential\nutility of further incorporating ToM, as well as other insights from child\nlanguage acquisition, into computational models of language acquisition.\n","authors":["Andy Liu","Hao Zhu","Emmy Liu","Yonatan Bisk","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2303.01502v1.pdf","comment":"9 pages, 3 figures. To be published in the 11th International\n  Conference on Learning Representations, ICLR 2023, Conference Track\n  Proceedings"},{"id":"http://arxiv.org/abs/2303.01490v1","updated":"2023-03-02T18:51:58Z","published":"2023-03-02T18:51:58Z","title":"Language Variety Identification with True Labels","summary":"  Language identification is an important first step in many IR and NLP\napplications. Most publicly available language identification datasets,\nhowever, are compiled under the assumption that the gold label of each instance\nis determined by where texts are retrieved from. Research has shown that this\nis a problematic assumption, particularly in the case of very similar languages\n(e.g., Croatian and Serbian) and national language varieties (e.g., Brazilian\nand European Portuguese), where texts may contain no distinctive marker of the\nparticular language or variety. To overcome this important limitation, this\npaper presents DSL True Labels (DSL-TL), the first human-annotated multilingual\ndataset for language variety identification. DSL-TL contains a total of 12,900\ninstances in Portuguese, split between European Portuguese and Brazilian\nPortuguese; Spanish, split between Argentine Spanish and Castilian Spanish; and\nEnglish, split between American English and British English. We trained\nmultiple models to discriminate between these language varieties, and we\npresent the results in detail. The data and models presented in this paper\nprovide a reliable benchmark toward the development of robust and fairer\nlanguage variety identification systems. We make DSL-TL freely available to the\nresearch community.\n","authors":["Marcos Zampieri","Kai North","Tommi Jauhiainen","Mariano Felice","Neha Kumari","Nishant Nair","Yash Bangera"],"pdf_url":"https://arxiv.org/pdf/2303.01490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13817v2","updated":"2023-03-02T18:27:43Z","published":"2023-02-27T14:26:29Z","title":"Let's have a chat! A Conversation with ChatGPT: Technology,\n  Applications, and Limitations","summary":"  The emergence of an AI-powered chatbot that can generate human-like sentences\nand write coherent essays has caught the world's attention. This paper\ndiscusses the historical overview of chatbots and the technology behind Chat\nGenerative Pre-trained Transformer, better known as ChatGPT. Moreover,\npotential applications of ChatGPT in various domains, including healthcare,\neducation, and research, are highlighted. Despite promising results, there are\nseveral privacy and ethical concerns surrounding ChatGPT. In addition, we\nhighlight some of the important limitations of the current version of ChatGPT.\nWe also ask ChatGPT to provide its point of view and present its responses to\nseveral questions we attempt to answer.\n","authors":["Sakib Shahriar","Kadhim Hayawi"],"pdf_url":"https://arxiv.org/pdf/2302.13817v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01432v1","updated":"2023-03-02T17:45:32Z","published":"2023-03-02T17:45:32Z","title":"WiCE: Real-World Entailment for Claims in Wikipedia","summary":"  Models for textual entailment have increasingly been applied to settings like\nfact-checking, presupposition verification in question answering, and\nvalidating that generation models' outputs are faithful to a source. However,\nsuch applications are quite far from the settings that existing datasets are\nconstructed in. We propose WiCE, a new textual entailment dataset centered\naround verifying claims in text, built on real-world claims and evidence in\nWikipedia with fine-grained annotations. We collect sentences in Wikipedia that\ncite one or more webpages and annotate whether the content on those pages\nentails those sentences. Negative examples arise naturally, from slight\nmisinterpretation of text to minor aspects of the sentence that are not\nattested in the evidence. Our annotations are over sub-sentence units of the\nhypothesis, decomposed automatically by GPT-3, each of which is labeled with a\nsubset of evidence sentences from the source document. We show that real claims\nin our dataset involve challenging verification problems, and we benchmark\nexisting approaches on this dataset. In addition, we show that reducing the\ncomplexity of claims by decomposing them by GPT-3 can improve entailment\nmodels' performance on various domains.\n","authors":["Ryo Kamoi","Tanya Goyal","Juan Diego Rodriguez","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2303.01432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01421v1","updated":"2023-03-02T17:15:02Z","published":"2023-03-02T17:15:02Z","title":"Semiparametric Language Models Are Scalable Continual Learners","summary":"  Semiparametric language models (LMs) have shown promise in continuously\nlearning from new text data by combining a parameterized neural LM with a\ngrowable non-parametric memory for memorizing new content. However,\nconventional semiparametric LMs will finally become prohibitive for computing\nand storing if they are applied to continual learning over streaming data,\nbecause the non-parametric memory grows linearly with the amount of data they\nlearn from over time. To address the issue of scalability, we present a simple\nand intuitive approach called Selective Memorization (SeMem), which only\nmemorizes difficult samples that the model is likely to struggle with. We\ndemonstrate that SeMem improves the scalability of semiparametric LMs for\ncontinual learning over streaming data in two ways: (1) data-wise scalability:\nas the model becomes stronger through continual learning, it will encounter\nfewer difficult cases that need to be memorized, causing the growth of the\nnon-parametric memory to slow down over time rather than growing at a linear\nrate with the size of training data; (2) model-wise scalability: SeMem allows a\nlarger model to memorize fewer samples than its smaller counterpart because it\nis rarer for a larger model to encounter incomprehensible cases, resulting in a\nnon-parametric memory that does not scale linearly with model size. We conduct\nextensive experiments in language modeling and downstream tasks to test SeMem's\nresults, showing SeMem enables a semiparametric LM to be a scalable continual\nlearner with little forgetting.\n","authors":["Guangyue Peng","Tao Ge","Si-Qing Chen","Furu Wei","Houfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01421v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2303.01410v1","updated":"2023-03-02T16:59:31Z","published":"2023-03-02T16:59:31Z","title":"NLP Workbench: Efficient and Extensible Integration of State-of-the-art\n  Text Mining Tools","summary":"  NLP Workbench is a web-based platform for text mining that allows non-expert\nusers to obtain semantic understanding of large-scale corpora using\nstate-of-the-art text mining models. The platform is built upon latest\npre-trained models and open source systems from academia that provide semantic\nanalysis functionalities, including but not limited to entity linking,\nsentiment analysis, semantic parsing, and relation extraction. Its extensible\ndesign enables researchers and developers to smoothly replace an existing model\nor integrate a new one. To improve efficiency, we employ a microservice\narchitecture that facilitates allocation of acceleration hardware and\nparallelization of computation. This paper presents the architecture of NLP\nWorkbench and discusses the challenges we faced in designing it. We also\ndiscuss diverse use cases of NLP Workbench and the benefits of using it over\nother approaches. The platform is under active development, with its source\ncode released under the MIT license. A website and a short video demonstrating\nour platform are also available.\n","authors":["Peiran Yao","Matej Kosmajac","Abeer Waheed","Kostyantyn Guzhva","Natalie Hervieux","Denilson Barbosa"],"pdf_url":"https://arxiv.org/pdf/2303.01410v1.pdf","comment":"Camera-ready version for EACL 2023: System Demonstrations"},{"id":"http://arxiv.org/abs/2303.01396v1","updated":"2023-03-02T16:26:14Z","published":"2023-03-02T16:26:14Z","title":"MLANet: Multi-Level Attention Network with Sub-instruction for\n  Continuous Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) aims to develop intelligent agents to\nnavigate in unseen environments only through language and vision supervision.\nIn the recently proposed continuous settings (continuous VLN), the agent must\nact in a free 3D space and faces tougher challenges like real-time execution,\ncomplex instruction understanding, and long action sequence prediction. For a\nbetter performance in continuous VLN, we design a multi-level instruction\nunderstanding procedure and propose a novel model, Multi-Level Attention\nNetwork (MLANet). The first step of MLANet is to generate sub-instructions\nefficiently. We design a Fast Sub-instruction Algorithm (FSA) to segment the\nraw instruction into sub-instructions and generate a new sub-instruction\ndataset named ``FSASub\". FSA is annotation-free and faster than the current\nmethod by 70 times, thus fitting the real-time requirement in continuous VLN.\nTo solve the complex instruction understanding problem, MLANet needs a global\nperception of the instruction and observations. We propose a Multi-Level\nAttention (MLA) module to fuse vision, low-level semantics, and high-level\nsemantics, which produce features containing a dynamic and global comprehension\nof the task. MLA also mitigates the adverse effects of noise words, thus\nensuring a robust understanding of the instruction. To correctly predict\nactions in long trajectories, MLANet needs to focus on what sub-instruction is\nbeing executed every step. We propose a Peak Attention Loss (PAL) to improve\nthe flexible and adaptive selection of the current sub-instruction. PAL\nbenefits the navigation agent by concentrating its attention on the local\ninformation, thus helping the agent predict the most appropriate actions. We\ntrain and test MLANet in the standard benchmark. Experiment results show MLANet\noutperforms baselines by a significant margin.\n","authors":["Zongtao He","Liuyi Wang","Shu Li","Qingqing Yan","Chengju Liu","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.10314v6","updated":"2023-03-02T15:56:26Z","published":"2021-07-21T19:23:56Z","title":"Small-Text: Active Learning for Text Classification in Python","summary":"  We introduce small-text, an easy-to-use active learning library, which offers\npool-based active learning for single- and multi-label text classification in\nPython. It features numerous pre-implemented state-of-the-art query strategies,\nincluding some that leverage the GPU. Standardized interfaces allow the\ncombination of a variety of classifiers, query strategies, and stopping\ncriteria, facilitating a quick mix and match, and enabling a rapid and\nconvenient development of both active learning experiments and applications.\nWith the objective of making various classifiers and query strategies\naccessible for active learning, small-text integrates several well-known\nmachine learning libraries, namely scikit-learn, PyTorch, and Hugging Face\ntransformers. The latter integrations are optionally installable extensions, so\nGPUs can be used but are not required. Using this new library, we investigate\nthe performance of the recently published SetFit training paradigm, which we\ncompare to vanilla transformer fine-tuning, finding that it matches the latter\nin classification accuracy while outperforming it in area under the curve. The\nlibrary is available under the MIT License at\nhttps://github.com/webis-de/small-text, in version 1.3.0 at the time of\nwriting.\n","authors":["Christopher Schröder","Lydia Müller","Andreas Niekler","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2107.10314v6.pdf","comment":"EACL 2023 System Demonstrations (camera-ready)"},{"id":"http://arxiv.org/abs/2208.01575v2","updated":"2023-03-02T15:46:26Z","published":"2022-08-02T16:21:42Z","title":"ferret: a Framework for Benchmarking Explainers on Transformers","summary":"  As Transformers are increasingly relied upon to solve complex NLP problems,\nthere is an increased need for their decisions to be humanly interpretable.\nWhile several explainable AI (XAI) techniques for interpreting the outputs of\ntransformer-based models have been proposed, there is still a lack of easy\naccess to using and comparing them. We introduce ferret, a Python library to\nsimplify the use and comparisons of XAI methods on transformer-based\nclassifiers. With ferret, users can visualize and compare transformers-based\nmodels output explanations using state-of-the-art XAI methods on any free-text\nor existing XAI corpora. Moreover, users can also evaluate ad-hoc XAI metrics\nto select the most faithful and plausible explanations. To align with the\nrecently consolidated process of sharing and using transformers-based models\nfrom Hugging Face, ferret interfaces directly with its Python library. In this\npaper, we showcase ferret to benchmark XAI methods used on transformers for\nsentiment analysis and hate speech detection. We show how specific methods\nprovide consistently better explanations and are preferable in the context of\ntransformer models.\n","authors":["Giuseppe Attanasio","Eliana Pastor","Chiara Di Bonaventura","Debora Nozza"],"pdf_url":"https://arxiv.org/pdf/2208.01575v2.pdf","comment":"11 pages, 3 figures. Accepted to EACL 2023 (System Demonstration).\n  More details at https://github.com/g8a9/ferret"},{"id":"http://arxiv.org/abs/2303.01347v1","updated":"2023-03-02T15:26:46Z","published":"2023-03-02T15:26:46Z","title":"Letz Translate: Low-Resource Machine Translation for Luxembourgish","summary":"  Natural language processing of Low-Resource Languages (LRL) is often\nchallenged by the lack of data. Therefore, achieving accurate machine\ntranslation (MT) in a low-resource environment is a real problem that requires\npractical solutions. Research in multilingual models have shown that some LRLs\ncan be handled with such models. However, their large size and computational\nneeds make their use in constrained environments (e.g., mobile/IoT devices or\nlimited/old servers) impractical. In this paper, we address this problem by\nleveraging the power of large multilingual MT models using knowledge\ndistillation. Knowledge distillation can transfer knowledge from a large and\ncomplex teacher model to a simpler and smaller student model without losing\nmuch in performance. We also make use of high-resource languages that are\nrelated or share the same linguistic root as the target LRL. For our\nevaluation, we consider Luxembourgish as the LRL that shares some roots and\nproperties with German. We build multiple resource-efficient models based on\nGerman, knowledge distillation from the multilingual No Language Left Behind\n(NLLB) model, and pseudo-translation. We find that our efficient models are\nmore than 30\\% faster and perform only 4\\% lower compared to the large\nstate-of-the-art NLLB model.\n","authors":["Yewei Song","Saad Ezzini","Jacques Klein","Tegawende Bissyande","Clément Lefebvre","Anne Goujon"],"pdf_url":"https://arxiv.org/pdf/2303.01347v1.pdf","comment":"The associated model is published on HuggingFace:\n  https://huggingface.co/etamin/Letz-Translate-OPUS-LB-EN The Dictionary used\n  in this paper is available in Github:\n  https://github.com/Etamin/Ltz_dictionary"},{"id":"http://arxiv.org/abs/2303.01341v1","updated":"2023-03-02T15:17:38Z","published":"2023-03-02T15:17:38Z","title":"Matching-based Term Semantics Pre-training for Spoken Patient Query\n  Understanding","summary":"  Medical Slot Filling (MSF) task aims to convert medical queries into\nstructured information, playing an essential role in diagnosis dialogue\nsystems. However, the lack of sufficient term semantics learning makes existing\napproaches hard to capture semantically identical but colloquial expressions of\nterms in medical conversations. In this work, we formalize MSF into a matching\nproblem and propose a Term Semantics Pre-trained Matching Network (TSPMN) that\ntakes both terms and queries as input to model their semantic interaction. To\nlearn term semantics better, we further design two self-supervised objectives,\nincluding Contrastive Term Discrimination (CTD) and Matching-based Mask Term\nModeling (MMTM). CTD determines whether it is the masked term in the dialogue\nfor each given term, while MMTM directly predicts the masked ones. Experimental\nresults on two Chinese benchmarks show that TSPMN outperforms strong baselines,\nespecially in few-shot settings.\n","authors":["Zefa Hu","Xiuyi Chen","Haoran Wu","Minglun Han","Ziyi Ni","Jing Shi","Shuang Xu","Bo Xu"],"pdf_url":"https://arxiv.org/pdf/2303.01341v1.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.10198v2","updated":"2023-03-02T14:33:12Z","published":"2023-02-19T12:29:33Z","title":"Can ChatGPT Understand Too? A Comparative Study on ChatGPT and\n  Fine-tuned BERT","summary":"  Recently, ChatGPT has attracted great attention, as it can generate fluent\nand high-quality responses to human inquiries. Several prior studies have shown\nthat ChatGPT attains remarkable generation ability compared with existing\nmodels. However, the quantitative analysis of ChatGPT's understanding ability\nhas been given little attention. In this report, we explore the understanding\nability of ChatGPT by evaluating it on the most popular GLUE benchmark, and\ncomparing it with 4 representative fine-tuned BERT-style models. We find that:\n1) ChatGPT falls short in handling paraphrase and similarity tasks; 2) ChatGPT\noutperforms all BERT models on inference tasks by a large margin; 3) ChatGPT\nachieves comparable performance compared with BERT on sentiment analysis and\nquestion-answering tasks. Additionally, by combining some advanced prompting\nstrategies, we show that the understanding ability of ChatGPT can be further\nimproved.\n","authors":["Qihuang Zhong","Liang Ding","Juhua Liu","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.10198v2.pdf","comment":"Work in progress. Added results of advanced prompting strategies,\n  e.g., CoT. (19 pages)"},{"id":"http://arxiv.org/abs/2302.08957v2","updated":"2023-03-02T14:23:39Z","published":"2023-02-17T15:43:29Z","title":"Like a Good Nearest Neighbor: Practical Content Moderation with Sentence\n  Transformers","summary":"  Modern text classification systems have impressive capabilities but are\ninfeasible to deploy and use reliably due to their dependence on prompting and\nbillion-parameter language models. SetFit (Tunstall et al., 2022) is a recent,\npractical approach that fine-tunes a Sentence Transformer under a contrastive\nlearning paradigm and achieves similar results to more unwieldy systems. Text\nclassification is important for addressing the problem of domain drift in\ndetecting harmful content, which plagues all social media platforms. Here, we\npropose Like a Good Nearest Neighbor (LaGoNN), an inexpensive modification to\nSetFit that requires no additional parameters or hyperparameters but modifies\ninput with information about its nearest neighbor, for example, the label and\ntext, in the training data, making novel data appear similar to an instance on\nwhich the model was optimized. LaGoNN is effective at the task of detecting\nharmful content and generally improves performance compared to SetFit. To\ndemonstrate the value of our system, we conduct a thorough study of text\nclassification systems in the context of content moderation under four label\ndistributions.\n","authors":["Luke Bates","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2302.08957v2.pdf","comment":"8 pages, 4 figures, 13 supplemental pages, 15 supplemental figures"},{"id":"http://arxiv.org/abs/2209.13877v2","updated":"2023-03-02T13:06:10Z","published":"2022-09-28T07:25:04Z","title":"YATO: Yet Another deep learning based Text analysis Open toolkit","summary":"  We introduce YATO, an open-source toolkit for text analysis with deep\nlearning. It focuses on fundamental sequence labeling and sequence\nclassification tasks on text. Designed in a hierarchical structure, YATO\nsupports free combinations of three types of features including 1) traditional\nneural networks (CNN, RNN, etc.); 2) pre-trained language models (BERT,\nRoBERTa, ELECTRA, etc.); and 3) user-customed neural features via a simple\nconfigurable file. Benefiting from the advantages of flexibility and ease of\nuse, YATO can facilitate reproducing and refinement of state-of-the-art NLP\nmodels, and promote the cross-disciplinary applications of NLP techniques.\nSource code, examples, and documentation are publicly available at\nhttps://github.com/jiesutd/YATO. A demo video is also available at\nhttps://youtu.be/tSjjf5BzfQg.\n","authors":["Zeqiang Wang","Yile Wang","Jiageng Wu","Zhiyang Teng","Jie Yang"],"pdf_url":"https://arxiv.org/pdf/2209.13877v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01217v1","updated":"2023-03-02T12:59:01Z","published":"2023-03-02T12:59:01Z","title":"Synthetic Misinformers: Generating and Combating Multimodal\n  Misinformation","summary":"  With the expansion of social media and the increasing dissemination of\nmultimedia content, the spread of misinformation has become a major concern.\nThis necessitates effective strategies for multimodal misinformation detection\n(MMD) that detect whether the combination of an image and its accompanying text\ncould mislead or misinform. Due to the data-intensive nature of deep neural\nnetworks and the labor-intensive process of manual annotation, researchers have\nbeen exploring various methods for automatically generating synthetic\nmultimodal misinformation - which we refer to as Synthetic Misinformers - in\norder to train MMD models. However, limited evaluation on real-world\nmisinformation and a lack of comparisons with other Synthetic Misinformers\nmakes difficult to assess progress in the field. To address this, we perform a\ncomparative study on existing and new Synthetic Misinformers that involves (1)\nout-of-context (OOC) image-caption pairs, (2) cross-modal named entity\ninconsistency (NEI) as well as (3) hybrid approaches and we evaluate them\nagainst real-world misinformation; using the COSMOS benchmark. The comparative\nstudy showed that our proposed CLIP-based Named Entity Swapping can lead to MMD\nmodels that surpass other OOC and NEI Misinformers in terms of multimodal\naccuracy and that hybrid approaches can lead to even higher detection accuracy.\nNevertheless, after alleviating information leakage from the COSMOS evaluation\nprotocol, low Sensitivity scores indicate that the task is significantly more\nchallenging than previous studies suggested. Finally, our findings showed that\nNEI-based Synthetic Misinformers tend to suffer from a unimodal bias, where\ntext-only MMDs can outperform multimodal ones.\n","authors":["Stefanos-Iordanis Papadopoulos","Christos Koutlis","Symeon Papadopoulos","Panagiotis C. Petrantonakis"],"pdf_url":"https://arxiv.org/pdf/2303.01217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12502v2","updated":"2023-03-02T12:33:10Z","published":"2022-05-25T05:40:00Z","title":"The Dialog Must Go On: Improving Visual Dialog via Generative\n  Self-Training","summary":"  Visual dialog (VisDial) is a task of answering a sequence of questions\ngrounded in an image, using the dialog history as context. Prior work has\ntrained the dialog agents solely on VisDial data via supervised learning or\nleveraged pre-training on related vision-and-language datasets. This paper\npresents a semi-supervised learning approach for visually-grounded dialog,\ncalled Generative Self-Training (GST), to leverage unlabeled images on the Web.\nSpecifically, GST first retrieves in-domain images through out-of-distribution\ndetection and generates synthetic dialogs regarding the images via multimodal\nconditional text generation. GST then trains a dialog agent on the synthetic\nand the original VisDial data. As a result, GST scales the amount of training\ndata up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For\nrobust training of the synthetic dialogs, we also propose perplexity-based data\nselection and multimodal consistency regularization. Evaluation on VisDial v1.0\nand v0.9 datasets shows that GST achieves new state-of-the-art results on both\ndatasets. We further observe the robustness of GST against both visual and\ntextual adversarial attacks. Finally, GST yields strong performance gains in\nthe low-data regime. Code is available at\nhttps://github.com/gicheonkang/gst-visdial.\n","authors":["Gi-Cheon Kang","Sungdong Kim","Jin-Hwa Kim","Donghyun Kwak","Byoung-Tak Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.12502v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01197v1","updated":"2023-03-02T12:26:03Z","published":"2023-03-02T12:26:03Z","title":"Document Provenance and Authentication through Authorship Classification","summary":"  Style analysis, which is relatively a less explored topic, enables several\ninteresting applications. For instance, it allows authors to adjust their\nwriting style to produce a more coherent document in collaboration. Similarly,\nstyle analysis can also be used for document provenance and authentication as a\nprimary step. In this paper, we propose an ensemble-based text-processing\nframework for the classification of single and multi-authored documents, which\nis one of the key tasks in style analysis. The proposed framework incorporates\nseveral state-of-the-art text classification algorithms including classical\nMachine Learning (ML) algorithms, transformers, and deep learning algorithms\nboth individually and in merit-based late fusion. For the merit-based late\nfusion, we employed several weight optimization and selection methods to assign\nmerit-based weights to the individual text classification algorithms. We also\nanalyze the impact of the characters on the task that are usually excluded in\nNLP applications during pre-processing by conducting experiments on both clean\nand un-clean data. The proposed framework is evaluated on a large-scale\nbenchmark dataset, significantly improving performance over the existing\nsolutions.\n","authors":["Muhammad Tayyab Zamir","Muhammad Asif Ayub","Jebran Khan","Muhammad Jawad Ikram","Nasir Ahmad","Kashif Ahmad"],"pdf_url":"https://arxiv.org/pdf/2303.01197v1.pdf","comment":"7 pages; 3 tables; 1 figure"},{"id":"http://arxiv.org/abs/2303.01194v1","updated":"2023-03-02T12:18:53Z","published":"2023-03-02T12:18:53Z","title":"UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data\n  Generation for Cross-Lingual Learning in Tweet Intimacy Prediction","summary":"  This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9\n\"Multilingual Tweet Intimacy Analysis\". We achieved second-best results in all\n10 languages according to the official Pearson's correlation regression\nevaluation measure. Our cross-lingual transfer learning approach explores the\nbenefits of using a Head-First Fine-Tuning method (HeFiT) that first updates\nonly the regression head parameters and then also updates the pre-trained\ntransformer encoder parameters at a reduced learning rate. Additionally, we\nstudy the impact of using a small set of automatically generated examples (in\nour case, from ChatGPT) for low-resource settings where no human-labeled data\nis available. Our study shows that HeFiT stabilizes training and consistently\nimproves results for pre-trained models that lack domain adaptation to tweets.\nOur study also shows a noticeable performance increase in cross-lingual\nlearning when synthetic data is used, confirming the usefulness of current text\ngeneration systems to improve zero-shot baseline results. Finally, we examine\nhow possible inconsistencies in the annotated data contribute to cross-lingual\ninterference issues.\n","authors":["Andrianos Michail","Stefanos Konstantinou","Simon Clematide"],"pdf_url":"https://arxiv.org/pdf/2303.01194v1.pdf","comment":"Submitted for peer-review at SemEval-2023"},{"id":"http://arxiv.org/abs/2303.01191v1","updated":"2023-03-02T12:11:58Z","published":"2023-03-02T12:11:58Z","title":"Denoising-based UNMT is more robust to word-order divergence than\n  MASS-based UNMT","summary":"  We aim to investigate whether UNMT approaches with self-supervised\npre-training are robust to word-order divergence between language pairs. We\nachieve this by comparing two models pre-trained with the same self-supervised\npre-training objective. The first model is trained on language pairs with\ndifferent word-orders, and the second model is trained on the same language\npairs with source language re-ordered to match the word-order of the target\nlanguage. Ideally, UNMT approaches which are robust to word-order divergence\nshould exhibit no visible performance difference between the two\nconfigurations. In this paper, we investigate two such self-supervised\npre-training based UNMT approaches, namely Masked Sequence-to-Sequence\nPre-Training, (MASS) (which does not have shuffling noise) and Denoising\nAutoEncoder (DAE), (which has shuffling noise).\n  We experiment with five English$\\rightarrow$Indic language pairs, i.e.,\nen-hi, en-bn, en-gu, en-kn, and en-ta) where word-order of the source language\nis SVO (Subject-Verb-Object), and the word-order of the target languages is SOV\n(Subject-Object-Verb). We observed that for these language pairs, DAE-based\nUNMT approach consistently outperforms MASS in terms of translation accuracies.\nMoreover, bridging the word-order gap using reordering improves the translation\naccuracy of MASS-based UNMT models, while it cannot improve the translation\naccuracy of DAE-based UNMT models. This observation indicates that DAE-based\nUNMT is more robust to word-order divergence than MASS-based UNMT.\nWord-shuffling noise in DAE approach could be the possible reason for the\napproach being robust to word-order divergence.\n","authors":["Tamali Banerjee","Rudra Murthy V","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2303.01191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.00968v2","updated":"2023-03-02T11:51:48Z","published":"2022-11-02T09:15:20Z","title":"Internal Language Model Estimation based Adaptive Language Model Fusion\n  for Domain Adaptation","summary":"  ASR model deployment environment is ever-changing, and the incoming speech\ncan be switched across different domains during a session. This brings a\nchallenge for effective domain adaptation when only target domain text data is\navailable, and our objective is to obtain obviously improved performance on the\ntarget domain while the performance on the general domain is less undermined.\nIn this paper, we propose an adaptive LM fusion approach called internal\nlanguage model estimation based adaptive domain adaptation (ILME-ADA). To\nrealize such an ILME-ADA, an interpolated log-likelihood score is calculated\nbased on the maximum of the scores from the internal LM and the external LM\n(ELM) respectively. We demonstrate the efficacy of the proposed ILME-ADA method\nwith both RNN-T and LAS modeling frameworks employing neural network and n-gram\nLMs as ELMs respectively on two domain specific (target) test sets. The\nproposed method can achieve significantly better performance on the target test\nsets while it gets minimal performance degradation on the general test set,\ncompared with both shallow and ILME-based LM fusion methods.\n","authors":["Rao Ma","Xiaobo Wu","Jin Qiu","Yanan Qin","Haihua Xu","Peihao Wu","Zejun Ma"],"pdf_url":"https://arxiv.org/pdf/2211.00968v2.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.01094v1","updated":"2023-03-02T09:27:11Z","published":"2023-03-02T09:27:11Z","title":"CTRLStruct: Dialogue Structure Learning for Open-Domain Response\n  Generation","summary":"  Dialogue structure discovery is essential in dialogue generation.\nWell-structured topic flow can leverage background information and predict\nfuture topics to help generate controllable and explainable responses. However,\nmost previous work focused on dialogue structure learning in task-oriented\ndialogue other than open-domain dialogue which is more complicated and\nchallenging. In this paper, we present a new framework CTRLStruct for dialogue\nstructure learning to effectively explore topic-level dialogue clusters as well\nas their transitions with unlabelled information. Precisely, dialogue\nutterances encoded by bi-directional Transformer are further trained through a\nspecial designed contrastive learning task to improve representation. Then we\nperform clustering to utterance-level representations and form topic-level\nclusters that can be considered as vertices in dialogue structure graph. The\nedges in the graph indicating transition probability between vertices are\ncalculated by mimicking expert behavior in datasets. Finally, dialogue\nstructure graph is integrated into dialogue model to perform controlled\nresponse generation. Experiments on two popular open-domain dialogue datasets\nshow our model can generate more coherent responses compared to some excellent\ndialogue models, as well as outperform some typical sentence embedding methods\nin dialogue utterance representation. Code is available in GitHub.\n","authors":["Congchi Yin","Piji Li","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2303.01094v1.pdf","comment":"12 pages, to be published in The Web Conference 2023"},{"id":"http://arxiv.org/abs/2205.12523v2","updated":"2023-03-02T09:17:01Z","published":"2022-05-25T06:34:14Z","title":"TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation","summary":"  Direct speech-to-speech translation (S2ST) with discrete units leverages\nrecent progress in speech representation learning. Specifically, a sequence of\ndiscrete representations derived in a self-supervised manner are predicted from\nthe model and passed to a vocoder for speech reconstruction, while still facing\nthe following challenges: 1) Acoustic multimodality: the discrete units derived\nfrom speech with same content could be indeterministic due to the acoustic\nproperty (e.g., rhythm, pitch, and energy), which causes deterioration of\ntranslation accuracy; 2) high latency: current S2ST systems utilize\nautoregressive models which predict each unit conditioned on the sequence\npreviously generated, failing to take full advantage of parallelism. In this\nwork, we propose TranSpeech, a speech-to-speech translation model with\nbilateral perturbation. To alleviate the acoustic multimodal problem, we\npropose bilateral perturbation (BiP), which consists of the style normalization\nand information enhancement stages, to learn only the linguistic information\nfrom speech samples and generate more deterministic representations. With\nreduced multimodality, we step forward and become the first to establish a\nnon-autoregressive S2ST technique, which repeatedly masks and predicts unit\nchoices and produces high-accuracy results in just a few cycles. Experimental\nresults on three language pairs demonstrate that BiP yields an improvement of\n2.9 BLEU on average compared with a baseline textless S2ST model. Moreover, our\nparallel decoding shows a significant reduction of inference latency, enabling\nspeedup up to 21.4x than autoregressive technique. Audio samples are available\nat \\url{https://TranSpeech.github.io/}\n","authors":["Rongjie Huang","Jinglin Liu","Huadai Liu","Yi Ren","Lichao Zhang","Jinzheng He","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2205.12523v2.pdf","comment":"Accpeted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01086v1","updated":"2023-03-02T09:16:21Z","published":"2023-03-02T09:16:21Z","title":"LiteG2P: A fast, light and high accuracy model for grapheme-to-phoneme\n  conversion","summary":"  As a key component of automated speech recognition (ASR) and the front-end in\ntext-to-speech (TTS), grapheme-to-phoneme (G2P) plays the role of converting\nletters to their corresponding pronunciations. Existing methods are either slow\nor poor in performance, and are limited in application scenarios, particularly\nin the process of on-device inference. In this paper, we integrate the\nadvantages of both expert knowledge and connectionist temporal classification\n(CTC) based neural network and propose a novel method named LiteG2P which is\nfast, light and theoretically parallel. With the carefully leading design,\nLiteG2P can be applied both on cloud and on device. Experimental results on the\nCMU dataset show that the performance of the proposed method is superior to the\nstate-of-the-art CTC based method with 10 times fewer parameters, and even\ncomparable to the state-of-the-art Transformer-based sequence-to-sequence model\nwith less parameters and 33 times less computation.\n","authors":["Chunfeng Wang","Peisong Huang","Yuxiang Zou","Haoyu Zhang","Shichao Liu","Xiang Yin","Zejun Ma"],"pdf_url":"https://arxiv.org/pdf/2303.01086v1.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2206.04624v3","updated":"2023-03-02T09:11:34Z","published":"2022-06-09T17:16:43Z","title":"Factuality Enhanced Language Models for Open-Ended Text Generation","summary":"  Pretrained language models (LMs) are susceptible to generate text with\nnonfactual information. In this work, we measure and improve the factual\naccuracy of large-scale LMs for open-ended text generation. We design the\nFactualityPrompts test set and metrics to measure the factuality of LM\ngenerations. Based on that, we study the factual accuracy of LMs with parameter\nsizes ranging from 126M to 530B. Interestingly, we find that larger LMs are\nmore factual than smaller ones, although a previous study suggests that larger\nLMs can be less truthful in terms of misconceptions. In addition, popular\nsampling algorithms (e.g., top-p) in open-ended text generation can harm the\nfactuality due to the ''uniform randomness'' introduced at every sampling step.\nWe propose the factual-nucleus sampling algorithm that dynamically adapts the\nrandomness to improve the factuality of generation while maintaining quality.\nFurthermore, we analyze the inefficiencies of the standard training method in\nlearning correct associations between entities from factual text corpus (e.g.,\nWikipedia). We propose a factuality-enhanced training method that uses\nTopicPrefix for better awareness of facts and sentence completion as the\ntraining objective, which can vastly reduce the factual errors. We release our\ncode and FactualityPrompts benchmark at:\nhttps://github.com/nayeon7lee/FactualityPrompt.\n","authors":["Nayeon Lee","Wei Ping","Peng Xu","Mostofa Patwary","Pascale Fung","Mohammad Shoeybi","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2206.04624v3.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2210.05193v2","updated":"2023-03-02T09:04:57Z","published":"2022-10-11T06:53:34Z","title":"Viterbi Decoding of Directed Acyclic Transformer for Non-Autoregressive\n  Machine Translation","summary":"  Non-autoregressive models achieve significant decoding speedup in neural\nmachine translation but lack the ability to capture sequential dependency.\nDirected Acyclic Transformer (DA-Transformer) was recently proposed to model\nsequential dependency with a directed acyclic graph. Consequently, it has to\napply a sequential decision process at inference time, which harms the global\ntranslation accuracy. In this paper, we present a Viterbi decoding framework\nfor DA-Transformer, which guarantees to find the joint optimal solution for the\ntranslation and decoding path under any length constraint. Experimental results\ndemonstrate that our approach consistently improves the performance of\nDA-Transformer while maintaining a similar decoding speedup.\n","authors":["Chenze Shao","Zhengrui Ma","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2210.05193v2.pdf","comment":"Findings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2303.01081v1","updated":"2023-03-02T09:03:43Z","published":"2023-03-02T09:03:43Z","title":"Can BERT Refrain from Forgetting on Sequential Tasks? A Probing Study","summary":"  Large pre-trained language models help to achieve state of the art on a\nvariety of natural language processing (NLP) tasks, nevertheless, they still\nsuffer from forgetting when incrementally learning a sequence of tasks. To\nalleviate this problem, recent works enhance existing models by sparse\nexperience replay and local adaption, which yield satisfactory performance.\nHowever, in this paper we find that pre-trained language models like BERT have\na potential ability to learn sequentially, even without any sparse memory\nreplay. To verify the ability of BERT to maintain old knowledge, we adopt and\nre-finetune single-layer probe networks with the parameters of BERT fixed. We\ninvestigate the models on two types of NLP tasks, text classification and\nextractive question answering. Our experiments reveal that BERT can actually\ngenerate high quality representations for previously learned tasks in a long\nterm, under extremely sparse replay or even no replay. We further introduce a\nseries of novel methods to interpret the mechanism of forgetting and how memory\nrehearsal plays a significant role in task incremental learning, which bridges\nthe gap between our new discovery and previous studies about catastrophic\nforgetting.\n","authors":["Mingxu Tao","Yansong Feng","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.01081v1.pdf","comment":"Accepted by ICLR 2023. URL:\n  https://openreview.net/forum?id=UazgYBMS9-W"},{"id":"http://arxiv.org/abs/2303.01080v1","updated":"2023-03-02T09:03:11Z","published":"2023-03-02T09:03:11Z","title":"LANDMARK: Language-guided Representation Enhancement Framework for Scene\n  Graph Generation","summary":"  Scene graph generation (SGG) is a sophisticated task that suffers from both\ncomplex visual features and dataset long-tail problem. Recently, various\nunbiased strategies have been proposed by designing novel loss functions and\ndata balancing strategies. Unfortunately, these unbiased methods fail to\nemphasize language priors in feature refinement perspective. Inspired by the\nfact that predicates are highly correlated with semantics hidden in\nsubject-object pair and global context, we propose LANDMARK (LANguage-guiDed\nrepresentationenhanceMent frAmewoRK) that learns predicate-relevant\nrepresentations from language-vision interactive patterns, global language\ncontext and pair-predicate correlation. Specifically, we first project object\nlabels to three distinctive semantic embeddings for different representation\nlearning. Then, Language Attention Module (LAM) and Experience Estimation\nModule (EEM) process subject-object word embeddings to attention vector and\npredicate distribution, respectively. Language Context Module (LCM) encodes\nglobal context from each word embed-ding, which avoids isolated learning from\nlocal information. Finally, modules outputs are used to update visual\nrepresentations and SGG model's prediction. All language representations are\npurely generated from object categories so that no extra knowledge is needed.\nThis framework is model-agnostic and consistently improves performance on\nexisting SGG models. Besides, representation-level unbiased strategies endow\nLANDMARK the advantage of compatibility with other methods. Code is available\nat https://github.com/rafa-cxg/PySGG-cxg.\n","authors":["Xiaoguang Chang","Teng Wang","Shaowei Cai","Changyin Sun"],"pdf_url":"https://arxiv.org/pdf/2303.01080v1.pdf","comment":"Revision period in Applied Intelligence (APIN)"},{"id":"http://arxiv.org/abs/2303.01068v1","updated":"2023-03-02T08:43:30Z","published":"2023-03-02T08:43:30Z","title":"Targeted Adversarial Attacks against Neural Machine Translation","summary":"  Neural Machine Translation (NMT) systems are used in various applications.\nHowever, it has been shown that they are vulnerable to very small perturbations\nof their inputs, known as adversarial attacks. In this paper, we propose a new\ntargeted adversarial attack against NMT models. In particular, our goal is to\ninsert a predefined target keyword into the translation of the adversarial\nsentence while maintaining similarity between the original sentence and the\nperturbed one in the source domain. To this aim, we propose an optimization\nproblem, including an adversarial loss term and a similarity term. We use\ngradient projection in the embedding space to craft an adversarial sentence.\nExperimental results show that our attack outperforms Seq2Sick, the other\ntargeted adversarial attack against NMT models, in terms of success rate and\ndecrease in translation quality. Our attack succeeds in inserting a keyword\ninto the translation for more than 75% of sentences while similarity with the\noriginal sentence stays preserved.\n","authors":["Sahar Sadrizadeh","AmirHossein Dabiri Aghdam","Ljiljana Dolamic","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2303.01068v1.pdf","comment":"ICASSP 2023, Code available at:\n  http://github.com/sssadrizadeh/NMT-targeted-attack"},{"id":"http://arxiv.org/abs/2303.01064v1","updated":"2023-03-02T08:40:31Z","published":"2023-03-02T08:40:31Z","title":"Adopting the Multi-answer Questioning Task with an Auxiliary Metric for\n  Extreme Multi-label Text Classification Utilizing the Label Hierarchy","summary":"  Extreme multi-label text classification utilizes the label hierarchy to\npartition extreme labels into multiple label groups, turning the task into\nsimple multi-group multi-label classification tasks. Current research encodes\nlabels as a vector with fixed length which needs establish multiple classifiers\nfor different label groups. The problem is how to build only one classifier\nwithout sacrificing the label relationship in the hierarchy. This paper adopts\nthe multi-answer questioning task for extreme multi-label classification. This\npaper also proposes an auxiliary classification evaluation metric. This study\nadopts the proposed method and the evaluation metric to the legal domain. The\nutilization of legal Berts and the study on task distribution are discussed.\nThe experiment results show that the proposed hierarchy and multi-answer\nquestioning task can do extreme multi-label classification for EURLEX dataset.\nAnd in minor/fine-tuning the multi-label classification task, the domain\nadapted BERT models could not show apparent advantages in this experiment. The\nmethod is also theoretically applicable to zero-shot learning.\n","authors":["Li Wang","Ying Wah Teh","Mohammed Ali Al-Garadi"],"pdf_url":"https://arxiv.org/pdf/2303.01064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12095v3","updated":"2023-03-02T08:33:04Z","published":"2023-02-22T11:01:20Z","title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution\n  Perspective","summary":"  ChatGPT is a recent chatbot service released by OpenAI and is receiving\nincreasing attention over the past few months. While evaluations of various\naspects of ChatGPT have been done, its robustness, i.e., the performance to\nunexpected inputs, is still unclear to the public. Robustness is of particular\nconcern in responsible AI, especially for safety-critical applications. In this\npaper, we conduct a thorough evaluation of the robustness of ChatGPT from the\nadversarial and out-of-distribution (OOD) perspective. To do so, we employ the\nAdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart\nreview and DDXPlus medical diagnosis datasets for OOD evaluation. We select\nseveral popular foundation models as baselines. Results show that ChatGPT shows\nconsistent advantages on most adversarial and OOD classification and\ntranslation tasks. However, the absolute performance is far from perfection,\nwhich suggests that adversarial and OOD robustness remains a significant threat\nto foundation models. Moreover, ChatGPT shows astounding performance in\nunderstanding dialogue-related texts and we find that it tends to provide\ninformal suggestions for medical tasks instead of definitive answers. Finally,\nwe present in-depth discussions of possible research directions.\n","authors":["Jindong Wang","Xixu Hu","Wenxin Hou","Hao Chen","Runkai Zheng","Yidong Wang","Linyi Yang","Haojun Huang","Wei Ye","Xiubo Geng","Binxin Jiao","Yue Zhang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2302.12095v3.pdf","comment":"Technical report; code is at:\n  https://github.com/microsoft/robustlearn"},{"id":"http://arxiv.org/abs/2303.01037v1","updated":"2023-03-02T07:47:18Z","published":"2023-03-02T07:47:18Z","title":"Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages","summary":"  We introduce the Universal Speech Model (USM), a single large model that\nperforms automatic speech recognition (ASR) across 100+ languages. This is\nachieved by pre-training the encoder of the model on a large unlabeled\nmultilingual dataset of 12 million (M) hours spanning over 300 languages, and\nfine-tuning on a smaller labeled dataset. We use multilingual pre-training with\nrandom-projection quantization and speech-text modality matching to achieve\nstate-of-the-art performance on downstream multilingual ASR and speech-to-text\ntranslation tasks. We also demonstrate that despite using a labeled training\nset 1/7-th the size of that used for the Whisper model, our model exhibits\ncomparable or better performance on both in-domain and out-of-domain speech\nrecognition tasks across many languages.\n","authors":["Yu Zhang","Wei Han","James Qin","Yongqiang Wang","Ankur Bapna","Zhehuai Chen","Nanxin Chen","Bo Li","Vera Axelrod","Gary Wang","Zhong Meng","Ke Hu","Andrew Rosenberg","Rohit Prabhavalkar","Daniel S. Park","Parisa Haghani","Jason Riesa","Ginger Perng","Hagen Soltau","Trevor Strohman","Bhuvana Ramabhadran","Tara Sainath","Pedro Moreno","Chung-Cheng Chiu","Johan Schalkwyk","Françoise Beaufays","Yonghui Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01037v1.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2209.14610v3","updated":"2023-03-02T07:41:55Z","published":"2022-09-29T08:01:04Z","title":"Dynamic Prompt Learning via Policy Gradient for Semi-structured\n  Mathematical Reasoning","summary":"  Mathematical reasoning, a core ability of human intelligence, presents unique\nchallenges for machines in abstract thinking and logical reasoning. Recent\nlarge pre-trained language models such as GPT-3 have achieved remarkable\nprogress on mathematical reasoning tasks written in text form, such as math\nword problems (MWP). However, it is unknown if the models can handle more\ncomplex problems that involve math reasoning over heterogeneous information,\nsuch as tabular data. To fill the gap, we present Tabular Math Word Problems\n(TabMWP), a new dataset containing 38,431 open-domain grade-level problems that\nrequire mathematical reasoning on both textual and tabular data. Each question\nin TabMWP is aligned with a tabular context, which is presented as an image,\nsemi-structured text, and a structured table. There are two types of questions:\nfree-text and multi-choice, and each problem is annotated with gold solutions\nto reveal the multi-step reasoning process. We evaluate different pre-trained\nmodels on TabMWP, including the GPT-3 model in a few-shot setting. As earlier\nstudies suggest, since few-shot GPT-3 relies on the selection of in-context\nexamples, its performance is unstable and can degrade to near chance. The\nunstable issue is more severe when handling complex problems like TabMWP. To\nmitigate this, we further propose a novel approach, PromptPG, which utilizes\npolicy gradient to learn to select in-context examples from a small amount of\ntraining data and then constructs the corresponding prompt for the test\nexample. Experimental results show that our method outperforms the best\nbaseline by 5.31% on the accuracy metric and reduces the prediction variance\nsignificantly compared to random selection, which verifies its effectiveness in\nselecting in-context examples.\n","authors":["Pan Lu","Liang Qiu","Kai-Wei Chang","Ying Nian Wu","Song-Chun Zhu","Tanmay Rajpurohit","Peter Clark","Ashwin Kalyan"],"pdf_url":"https://arxiv.org/pdf/2209.14610v3.pdf","comment":"ICLR 2023. 26 pages and 18 figures. The data and code are available\n  at https://promptpg.github.io"},{"id":"http://arxiv.org/abs/2208.01174v2","updated":"2023-03-02T06:11:49Z","published":"2022-08-01T23:43:48Z","title":"TextWorldExpress: Simulating Text Games at One Million Steps Per Second","summary":"  Text-based games offer a challenging test bed to evaluate virtual agents at\nlanguage understanding, multi-step problem-solving, and common-sense reasoning.\nHowever, speed is a major limitation of current text-based games, capping at\n300 steps per second, mainly due to the use of legacy tooling. In this work we\npresent TextWorldExpress, a high-performance simulator that includes\nimplementations of three common text game benchmarks that increases simulation\nthroughput by approximately three orders of magnitude, reaching over one\nmillion steps per second on common desktop hardware. This significantly reduces\nexperiment runtime, enabling billion-step-scale experiments in about one day.\n","authors":["Peter A. Jansen","Marc-Alexandre Côté"],"pdf_url":"https://arxiv.org/pdf/2208.01174v2.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2303.00978v1","updated":"2023-03-02T05:19:49Z","published":"2023-03-02T05:19:49Z","title":"Leveraging Large Text Corpora for End-to-End Speech Summarization","summary":"  End-to-end speech summarization (E2E SSum) is a technique to directly\ngenerate summary sentences from speech. Compared with the cascade approach,\nwhich combines automatic speech recognition (ASR) and text summarization\nmodels, the E2E approach is more promising because it mitigates ASR errors,\nincorporates nonverbal information, and simplifies the overall system. However,\nsince collecting a large amount of paired data (i.e., speech and summary) is\ndifficult, the training data is usually insufficient to train a robust E2E SSum\nsystem. In this paper, we present two novel methods that leverage a large\namount of external text summarization data for E2E SSum training. The first\ntechnique is to utilize a text-to-speech (TTS) system to generate synthesized\nspeech, which is used for E2E SSum training with the text summary. The second\nis a TTS-free method that directly inputs phoneme sequence instead of\nsynthesized speech to the E2E SSum model. Experiments show that our proposed\nTTS- and phoneme-based methods improve several metrics on the How2 dataset. In\nparticular, our best system outperforms a previous state-of-the-art one by a\nlarge margin (i.e., METEOR score improvements of more than 6 points). To the\nbest of our knowledge, this is the first work to use external language\nresources for E2E SSum. Moreover, we report a detailed analysis of the How2\ndataset to confirm the validity of our proposed E2E SSum system.\n","authors":["Kohei Matsuura","Takanori Ashihara","Takafumi Moriya","Tomohiro Tanaka","Atsunori Ogawa","Marc Delcroix","Ryo Masumura"],"pdf_url":"https://arxiv.org/pdf/2303.00978v1.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00969v1","updated":"2023-03-02T05:06:44Z","published":"2023-03-02T05:06:44Z","title":"Rethinking the Reasonability of the Test Set for Simultaneous Machine\n  Translation","summary":"  Simultaneous machine translation (SimulMT) models start translation before\nthe end of the source sentence, making the translation monotonically aligned\nwith the source sentence. However, the general full-sentence translation test\nset is acquired by offline translation of the entire source sentence, which is\nnot designed for SimulMT evaluation, making us rethink whether this will\nunderestimate the performance of SimulMT models. In this paper, we manually\nannotate a monotonic test set based on the MuST-C English-Chinese test set,\ndenoted as SiMuST-C. Our human evaluation confirms the acceptability of our\nannotated test set. Evaluations on three different SimulMT models verify that\nthe underestimation problem can be alleviated on our test set. Further\nexperiments show that finetuning on an automatically extracted monotonic\ntraining set improves SimulMT models by up to 3 BLEU points.\n","authors":["Mengge Liu","Wen Zhang","Xiang Li","Jian Luan","Bin Wang","Yuhang Guo","Shuoying Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00969v1.pdf","comment":"Accepted by 48th IEEE International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2023)"},{"id":"http://arxiv.org/abs/2210.01240v4","updated":"2023-03-02T03:54:28Z","published":"2022-10-03T21:34:32Z","title":"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of\n  Chain-of-Thought","summary":"  Large language models (LLMs) have shown remarkable reasoning capabilities\ngiven chain-of-thought prompts (examples with intermediate reasoning steps).\nExisting benchmarks measure reasoning ability indirectly, by evaluating\naccuracy on downstream tasks such as mathematical reasoning. However, it is\nunclear how these models obtain the answers and whether they rely on simple\nheuristics rather than the generated chain-of-thought. To enable systematic\nexploration of the reasoning ability of LLMs, we present a new synthetic\nquestion-answering dataset called PrOntoQA, where each example is generated\nfrom a synthetic world model represented in first-order logic. This allows us\nto parse the generated chain-of-thought into symbolic proofs for formal\nanalysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quite\ncapable of making correct individual deduction steps, and so are generally\ncapable of reasoning, even in fictional contexts. However, they have difficulty\nwith proof planning: When multiple valid deduction steps are available, they\nare not able to systematically explore the different options.\n","authors":["Abulhair Saparov","He He"],"pdf_url":"https://arxiv.org/pdf/2210.01240v4.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00915v1","updated":"2023-03-02T02:20:04Z","published":"2023-03-02T02:20:04Z","title":"Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language\n  Processing","summary":"  Contrastive pretraining on parallel image-text data has attained great\nsuccess in vision-language processing (VLP), as exemplified by CLIP and related\nmethods. However, prior explorations tend to focus on general domains in the\nweb. Biomedical images and text are rather different, but publicly available\ndatasets are small and skew toward chest X-ray, thus severely limiting\nprogress. In this paper, we conducted by far the largest study on biomedical\nVLP, using 15 million figure-caption pairs extracted from biomedical research\narticles in PubMed Central. Our dataset (PMC-15M) is two orders of magnitude\nlarger than existing biomedical image-text datasets such as MIMIC-CXR, and\nspans a diverse range of biomedical images. The standard CLIP method is\nsuboptimal for the biomedical domain. We propose BiomedCLIP with\ndomain-specific adaptations tailored to biomedical VLP. We conducted extensive\nexperiments and ablation studies on standard biomedical imaging tasks from\nretrieval to classification to visual question-answering (VQA). BiomedCLIP\nestablished new state of the art in a wide range of standard datasets,\nsubstantially outperformed prior VLP approaches. Surprisingly, BiomedCLIP even\noutperformed radiology-specific state-of-the-art models such as BioViL on\nradiology-specific tasks such as RSNA pneumonia detection, thus highlighting\nthe utility in large-scale pretraining across all biomedical image types. We\nwill release our models at https://aka.ms/biomedclip to facilitate future\nresearch in biomedical VLP.\n","authors":["Sheng Zhang","Yanbo Xu","Naoto Usuyama","Jaspreet Bagga","Robert Tinn","Sam Preston","Rajesh Rao","Mu Wei","Naveen Valluri","Cliff Wong","Matthew P. Lungren","Tristan Naumann","Hoifung Poon"],"pdf_url":"https://arxiv.org/pdf/2303.00915v1.pdf","comment":"The models will be released soon at https://aka.ms/biomedclip"},{"id":"http://arxiv.org/abs/2303.00908v1","updated":"2023-03-02T01:57:17Z","published":"2023-03-02T01:57:17Z","title":"Interactive Text Generation","summary":"  Users interact with text, image, code, or other editors on a daily basis.\nHowever, machine learning models are rarely trained in the settings that\nreflect the interactivity between users and their editor. This is\nunderstandable as training AI models with real users is not only slow and\ncostly, but what these models learn may be specific to user interface design\nchoices. Unfortunately, this means most of the research on text, code, and\nimage generation has focused on non-interactive settings, whereby the model is\nexpected to get everything right without accounting for any input from a user\nwho may be willing to help.\n  We introduce a new Interactive Text Generation task that allows training\ngeneration models interactively without the costs of involving real users, by\nusing user simulators that provide edits that guide the model towards a given\ntarget text. We train our interactive models using Imitation Learning, and our\nexperiments against competitive non-interactive generation models show that\nmodels trained interactively are superior to their non-interactive\ncounterparts, even when all models are given the same budget of user inputs or\nedits.\n","authors":["Felix Faltings","Michel Galley","Baolin Peng","Kianté Brantley","Weixin Cai","Yizhe Zhang","Jianfeng Gao","Bill Dolan"],"pdf_url":"https://arxiv.org/pdf/2303.00908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05423v4","updated":"2023-03-02T01:52:48Z","published":"2022-10-11T13:04:59Z","title":"Learning to Locate Visual Answer in Video Corpus Using Question","summary":"  We introduce a new task, named video corpus visual answer localization\n(VCVAL), which aims to locate the visual answer in a large collection of\nuntrimmed instructional videos using a natural language question. This task\nrequires a range of skills - the interaction between vision and language, video\nretrieval, passage comprehension, and visual answer localization. In this\npaper, we propose a cross-modal contrastive global-span (CCGS) method for the\nVCVAL, jointly training the video corpus retrieval and visual answer\nlocalization subtasks with the global-span matrix. We have reconstructed a\ndataset named MedVidCQA, on which the VCVAL task is benchmarked. Experimental\nresults show that the proposed method outperforms other competitive methods\nboth in the video corpus retrieval and visual answer localization subtasks.\nMost importantly, we perform detailed analyses on extensive experiments, paving\na new path for understanding the instructional videos, which ushers in further\nresearch.\n","authors":["Bin Li","Yixuan Weng","Bin Sun","Shutao Li"],"pdf_url":"https://arxiv.org/pdf/2210.05423v4.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2205.12636v2","updated":"2023-03-02T01:49:09Z","published":"2022-05-25T10:22:14Z","title":"A Zipf's Law-Driven Method for Extracting Entities from Documents","summary":"  Entity extraction is critical to the intelligent development of various\ndomains and the construction of knowledge agents. Yet, there is category\nimbalance problem in documents in some specific domains that some categories of\nentities are common, while some are rare and scattered. This paper proposes to\nuse Zipf's law to tackle this problem and to promote the performance of entity\nextraction from documents. Using two forms of Zipf's law, words in the\ndocuments are classified into common and rare ones, and then sentences are\nclassified into common and rare ones, and are further processed by text\ngeneration models respectively. Rare entities in the generated sentences are\nlabeled with human-designed rules, and serve as a supplement to the raw dataset\nso as to alleviate the category imbalance problem. A case of extracting\nentities from technical documents on industrial safety is given and the\nexperiments results on two datasets show the effectiveness of the proposed\nmethod.\n","authors":["Zhenhua Wang","Ming Ren","Dong Gao","Zhuang Li"],"pdf_url":"https://arxiv.org/pdf/2205.12636v2.pdf","comment":"Journal of Informetrics"},{"id":"http://arxiv.org/abs/2303.00897v1","updated":"2023-03-02T01:39:16Z","published":"2023-03-02T01:39:16Z","title":"Stochastic Clustered Federated Learning","summary":"  Federated learning is a distributed learning framework that takes full\nadvantage of private data samples kept on edge devices. In real-world federated\nlearning systems, these data samples are often decentralized and\nNon-Independently Identically Distributed (Non-IID), causing divergence and\nperformance degradation in the federated learning process. As a new solution,\nclustered federated learning groups federated clients with similar data\ndistributions to impair the Non-IID effects and train a better model for every\ncluster. This paper proposes StoCFL, a novel clustered federated learning\napproach for generic Non-IID issues. In detail, StoCFL implements a flexible\nCFL framework that supports an arbitrary proportion of client participation and\nnewly joined clients for a varying FL system, while maintaining a great\nimprovement in model performance. The intensive experiments are conducted by\nusing four basic Non-IID settings and a real-world dataset. The results show\nthat StoCFL could obtain promising cluster results even when the number of\nclusters is unknown. Based on the client clustering results, models trained\nwith StoCFL outperform baseline approaches in a variety of contexts.\n","authors":["Dun Zeng","Xiangjing Hu","Shiyu Liu","Yue Yu","Qifan Wang","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2303.00897v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.01503v1","updated":"2023-03-02T18:59:48Z","published":"2023-03-02T18:59:48Z","title":"FeatAug-DETR: Enriching One-to-Many Matching for DETRs with Feature\n  Augmentation","summary":"  One-to-one matching is a crucial design in DETR-like object detection\nframeworks. It enables the DETR to perform end-to-end detection. However, it\nalso faces challenges of lacking positive sample supervision and slow\nconvergence speed. Several recent works proposed the one-to-many matching\nmechanism to accelerate training and boost detection performance. We revisit\nthese methods and model them in a unified format of augmenting the object\nqueries. In this paper, we propose two methods that realize one-to-many\nmatching from a different perspective of augmenting images or image features.\nThe first method is One-to-many Matching via Data Augmentation (denoted as\nDataAug-DETR). It spatially transforms the images and includes multiple\naugmented versions of each image in the same training batch. Such a simple\naugmentation strategy already achieves one-to-many matching and surprisingly\nimproves DETR's performance. The second method is One-to-many matching via\nFeature Augmentation (denoted as FeatAug-DETR). Unlike DataAug-DETR, it\naugments the image features instead of the original images and includes\nmultiple augmented features in the same batch to realize one-to-many matching.\nFeatAug-DETR significantly accelerates DETR training and boosts detection\nperformance while keeping the inference speed unchanged. We conduct extensive\nexperiments to evaluate the effectiveness of the proposed approach on DETR\nvariants, including DAB-DETR, Deformable-DETR, and H-Deformable-DETR. Without\nextra training data, FeatAug-DETR shortens the training convergence periods of\nDeformable-DETR to 24 epochs and achieves 58.3 AP on COCO val2017 set with\nSwin-L as the backbone.\n","authors":["Rongyao Fang","Peng Gao","Aojun Zhou","Yingjie Cai","Si Liu","Jifeng Dai","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2303.01503v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.01500v1","updated":"2023-03-02T18:59:15Z","published":"2023-03-02T18:59:15Z","title":"Dropout Reduces Underfitting","summary":"  Introduced by Hinton et al. in 2012, dropout has stood the test of time as a\nregularizer for preventing overfitting in neural networks. In this study, we\ndemonstrate that dropout can also mitigate underfitting when used at the start\nof training. During the early phase, we find dropout reduces the directional\nvariance of gradients across mini-batches and helps align the mini-batch\ngradients with the entire dataset's gradient. This helps counteract the\nstochasticity of SGD and limit the influence of individual batches on model\ntraining. Our findings lead us to a solution for improving performance in\nunderfitting models - early dropout: dropout is applied only during the initial\nphases of training, and turned off afterwards. Models equipped with early\ndropout achieve lower final training loss compared to their counterparts\nwithout dropout. Additionally, we explore a symmetric technique for\nregularizing overfitting models - late dropout, where dropout is not used in\nthe early iterations and is only activated later in training. Experiments on\nImageNet and various vision tasks demonstrate that our methods consistently\nimprove generalization accuracy. Our results encourage more research on\nunderstanding regularization in deep learning and our methods can be useful\ntools for future neural network training, especially in the era of large data.\nCode is available at https://github.com/facebookresearch/dropout .\n","authors":["Zhuang Liu","Zhiqiu Xu","Joseph Jin","Zhiqiang Shen","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2303.01500v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2303.01498v1","updated":"2023-03-02T18:58:15Z","published":"2023-03-02T18:58:15Z","title":"ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit\n  Detection & Emotional Reaction Intensity Estimation Challenges","summary":"  The fifth Affective Behavior Analysis in-the-wild (ABAW) Competition is part\nof the respective ABAW Workshop which will be held in conjunction with IEEE\nComputer Vision and Pattern Recognition Conference (CVPR), 2023. The 5th ABAW\nCompetition is a continuation of the Competitions held at ECCV 2022, IEEE CVPR\n2022, ICCV 2021, IEEE FG 2020 and CVPR 2017 Conferences, and is dedicated at\nautomatically analyzing affect. For this year's Competition, we feature two\ncorpora: i) an extended version of the Aff-Wild2 database and ii) the\nHume-Reaction dataset. The former database is an audiovisual one of around 600\nvideos of around 3M frames and is annotated with respect to:a) two continuous\naffect dimensions -valence (how positive/negative a person is) and arousal (how\nactive/passive a person is)-; b) basic expressions (e.g. happiness, sadness,\nneutral state); and c) atomic facial muscle actions (i.e., action units). The\nlatter dataset is an audiovisual one in which reactions of individuals to\nemotional stimuli have been annotated with respect to seven emotional\nexpression intensities. Thus the 5th ABAW Competition encompasses four\nChallenges: i) uni-task Valence-Arousal Estimation, ii) uni-task Expression\nClassification, iii) uni-task Action Unit Detection, and iv) Emotional Reaction\nIntensity Estimation. In this paper, we present these Challenges, along with\ntheir corpora, we outline the evaluation metrics, we present the baseline\nsystems and illustrate their obtained performance.\n","authors":["Dimitrios Kollias","Panagiotis Tzirakis","Alice Baird","Alan Cowen","Stefanos Zafeiriou"],"pdf_url":"https://arxiv.org/pdf/2303.01498v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.10659"},{"id":"http://arxiv.org/abs/2202.00182v2","updated":"2023-03-02T18:57:56Z","published":"2022-02-01T02:06:54Z","title":"Semi-supervised 3D Object Detection via Temporal Graph Neural Networks","summary":"  3D object detection plays an important role in autonomous driving and other\nrobotics applications. However, these detectors usually require training on\nlarge amounts of annotated data that is expensive and time-consuming to\ncollect. Instead, we propose leveraging large amounts of unlabeled point cloud\nvideos by semi-supervised learning of 3D object detectors via temporal graph\nneural networks. Our insight is that temporal smoothing can create more\naccurate detection results on unlabeled data, and these smoothed detections can\nthen be used to retrain the detector. We learn to perform this temporal\nreasoning with a graph neural network, where edges represent the relationship\nbetween candidate detections in different time frames. After semi-supervised\nlearning, our method achieves state-of-the-art detection performance on the\nchallenging nuScenes and H3D benchmarks, compared to baselines trained on the\nsame amount of labeled data. Project and code are released at\nhttps://www.jianrenw.com/SOD-TGNN/.\n","authors":["Jianren Wang","Haiming Gang","Siddarth Ancha","Yi-Ting Chen","David Held"],"pdf_url":"https://arxiv.org/pdf/2202.00182v2.pdf","comment":"3DV 2021"},{"id":"http://arxiv.org/abs/2303.01497v1","updated":"2023-03-02T18:57:38Z","published":"2023-03-02T18:57:38Z","title":"Teach a Robot to FISH: Versatile Imitation from One Minute of\n  Demonstrations","summary":"  While imitation learning provides us with an efficient toolkit to train\nrobots, learning skills that are robust to environment variations remains a\nsignificant challenge. Current approaches address this challenge by relying\neither on large amounts of demonstrations that span environment variations or\non handcrafted reward functions that require state estimates. Both directions\nare not scalable to fast imitation. In this work, we present Fast Imitation of\nSkills from Humans (FISH), a new imitation learning approach that can learn\nrobust visual skills with less than a minute of human demonstrations. Given a\nweak base-policy trained by offline imitation of demonstrations, FISH computes\nrewards that correspond to the \"match\" between the robot's behavior and the\ndemonstrations. These rewards are then used to adaptively update a residual\npolicy that adds on to the base-policy. Across all tasks, FISH requires at most\ntwenty minutes of interactive learning to imitate demonstrations on object\nconfigurations that were not seen in the demonstrations. Importantly, FISH is\nconstructed to be versatile, which allows it to be used across robot\nmorphologies (e.g. xArm, Allegro, Stretch) and camera configurations (e.g.\nthird-person, eye-in-hand). Our experimental evaluations on 9 different tasks\nshow that FISH achieves an average success rate of 93%, which is around 3.8x\nhigher than prior state-of-the-art methods.\n","authors":["Siddhant Haldar","Jyothish Pari","Anant Rai","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2303.01497v1.pdf","comment":"Code and robot videos are available at\n  https://fast-imitation.github.io/"},{"id":"http://arxiv.org/abs/2303.01494v1","updated":"2023-03-02T18:56:39Z","published":"2023-03-02T18:56:39Z","title":"Image as Set of Points","summary":"  What is an image and how to extract latent features? Convolutional Networks\n(ConvNets) consider an image as organized pixels in a rectangular shape and\nextract features via convolutional operation in local region; Vision\nTransformers (ViTs) treat an image as a sequence of patches and extract\nfeatures via attention mechanism in a global range. In this work, we introduce\na straightforward and promising paradigm for visual representation, which is\ncalled Context Clusters. Context clusters (CoCs) view an image as a set of\nunorganized points and extract features via simplified clustering algorithm. In\ndetail, each point includes the raw feature (e.g., color) and positional\ninformation (e.g., coordinates), and a simplified clustering algorithm is\nemployed to group and extract deep features hierarchically. Our CoCs are\nconvolution- and attention-free, and only rely on clustering algorithm for\nspatial interaction. Owing to the simple design, we show CoCs endow gratifying\ninterpretability via the visualization of clustering process. Our CoCs aim at\nproviding a new perspective on image and visual representation, which may enjoy\nbroad applications in different domains and exhibit profound insights. Even\nthough we are not targeting SOTA performance, COCs still achieve comparable or\neven better results than ConvNets or ViTs on several benchmarks. Codes are\navailable at: https://github.com/ma-xu/Context-Cluster.\n","authors":["Xu Ma","Yuqian Zhou","Huan Wang","Can Qin","Bin Sun","Chang Liu","Yun Fu"],"pdf_url":"https://arxiv.org/pdf/2303.01494v1.pdf","comment":"ICLR'23 Oral (top 5%); Codes:\n  https://github.com/ma-xu/Context-Cluster"},{"id":"http://arxiv.org/abs/2301.08965v2","updated":"2023-03-02T18:50:45Z","published":"2023-01-21T15:42:53Z","title":"Raw or Cooked? Object Detection on RAW Images","summary":"  Images fed to a deep neural network have in general undergone several\nhandcrafted image signal processing (ISP) operations, all of which have been\noptimized to produce visually pleasing images. In this work, we investigate the\nhypothesis that the intermediate representation of visually pleasing images is\nsub-optimal for downstream computer vision tasks compared to the RAW image\nrepresentation. We suggest that the operations of the ISP instead should be\noptimized towards the end task, by learning the parameters of the operations\njointly during training. We extend previous works on this topic and propose a\nnew learnable operation that enables an object detector to achieve superior\nperformance when compared to both previous works and traditional RGB images. In\nexperiments on the open PASCALRAW dataset, we empirically confirm our\nhypothesis.\n","authors":["William Ljungbergh","Joakim Johnander","Christoffer Petersson","Michael Felsberg"],"pdf_url":"https://arxiv.org/pdf/2301.08965v2.pdf","comment":"SCIA 2023"},{"id":"http://arxiv.org/abs/2206.12370v2","updated":"2023-03-02T18:45:57Z","published":"2022-06-24T16:44:06Z","title":"Mixed Sample Augmentation for Online Distillation","summary":"  Mixed Sample Regularization (MSR), such as MixUp or CutMix, is a powerful\ndata augmentation strategy to generalize convolutional neural networks.\nPrevious empirical analysis has illustrated an orthogonal performance gain\nbetween MSR and conventional offline Knowledge Distillation (KD). To be more\nspecific, student networks can be enhanced with the involvement of MSR in the\ntraining stage of sequential distillation. Yet, the interplay between MSR and\nonline knowledge distillation, where an ensemble of peer students learn\nmutually from each other, remains unexplored. To bridge the gap, we make the\nfirst attempt at incorporating CutMix into online distillation, where we\nempirically observe a significant improvement. Encouraged by this fact, we\npropose an even stronger MSR specifically for online distillation, named as\nCut\\textsuperscript{n}Mix. Furthermore, a novel online distillation framework\nis designed upon Cut\\textsuperscript{n}Mix, to enhance the distillation with\nfeature level mutual learning and a self-ensemble teacher. Comprehensive\nevaluations on CIFAR10 and CIFAR100 with six network architectures show that\nour approach can consistently outperform state-of-the-art distillation methods.\n","authors":["Yiqing Shen","Liwu Xu","Yuzhe Yang","Yaqian Li","Yandong Guo"],"pdf_url":"https://arxiv.org/pdf/2206.12370v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2303.01484v1","updated":"2023-03-02T18:45:02Z","published":"2023-03-02T18:45:02Z","title":"Predicting Motion Plans for Articulating Everyday Objects","summary":"  Mobile manipulation tasks such as opening a door, pulling open a drawer, or\nlifting a toilet lid require constrained motion of the end-effector under\nenvironmental and task constraints. This, coupled with partial information in\nnovel environments, makes it challenging to employ classical motion planning\napproaches at test time. Our key insight is to cast it as a learning problem to\nleverage past experience of solving similar planning problems to directly\npredict motion plans for mobile manipulation tasks in novel situations at test\ntime. To enable this, we develop a simulator, ArtObjSim, that simulates\narticulated objects placed in real scenes. We then introduce SeqIK+$\\theta_0$,\na fast and flexible representation for motion plans. Finally, we learn models\nthat use SeqIK+$\\theta_0$ to quickly predict motion plans for articulating\nnovel objects at test time. Experimental evaluation shows improved speed and\naccuracy at generating motion plans than pure search-based methods and pure\nlearning methods.\n","authors":["Arjun Gupta","Max E. Shepherd","Saurabh Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.01484v1.pdf","comment":"To Appear in ICRA 2023. Project webpage:\n  https://arjung128.github.io/mpao/"},{"id":"http://arxiv.org/abs/2303.01480v1","updated":"2023-03-02T18:41:41Z","published":"2023-03-02T18:41:41Z","title":"Delivering Arbitrary-Modal Semantic Segmentation","summary":"  Multimodal fusion can make semantic segmentation more robust. However, fusing\nan arbitrary number of modalities remains underexplored. To delve into this\nproblem, we create the DeLiVER arbitrary-modal segmentation benchmark, covering\nDepth, LiDAR, multiple Views, Events, and RGB. Aside from this, we provide this\ndataset in four severe weather conditions as well as five sensor failure cases\nto exploit modal complementarity and resolve partial outages. To make this\npossible, we present the arbitrary cross-modal segmentation model CMNeXt. It\nencompasses a Self-Query Hub (SQ-Hub) designed to extract effective information\nfrom any modality for subsequent fusion with the RGB representation and adds\nonly negligible amounts of parameters (~0.01M) per additional modality. On top,\nto efficiently and flexibly harvest discriminative cues from the auxiliary\nmodalities, we introduce the simple Parallel Pooling Mixer (PPX). With\nextensive experiments on a total of six benchmarks, our CMNeXt achieves\nstate-of-the-art performance on the DeLiVER, KITTI-360, MFNet, NYU Depth V2,\nUrbanLF, and MCubeS datasets, allowing to scale from 1 to 81 modalities. On the\nfreshly collected DeLiVER, the quad-modal CMNeXt reaches up to 66.30% in mIoU\nwith a +9.10% gain as compared to the mono-modal baseline. The DeLiVER dataset\nand our code are at: https://jamycheung.github.io/DELIVER.html.\n","authors":["Jiaming Zhang","Ruiping Liu","Hao Shi","Kailun Yang","Simon Reiß","Kunyu Peng","Haodong Fu","Kaiwei Wang","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2303.01480v1.pdf","comment":"Accepted by CVPR 2023. Dataset and our code are at:\n  https://jamycheung.github.io/DELIVER.html"},{"id":"http://arxiv.org/abs/2303.01469v1","updated":"2023-03-02T18:30:16Z","published":"2023-03-02T18:30:16Z","title":"Consistency Models","summary":"  Diffusion models have made significant breakthroughs in image, audio, and\nvideo generation, but they depend on an iterative generation process that\ncauses slow sampling speed and caps their potential for real-time applications.\nTo overcome this limitation, we propose consistency models, a new family of\ngenerative models that achieve high sample quality without adversarial\ntraining. They support fast one-step generation by design, while still allowing\nfor few-step sampling to trade compute for sample quality. They also support\nzero-shot data editing, like image inpainting, colorization, and\nsuper-resolution, without requiring explicit training on these tasks.\nConsistency models can be trained either as a way to distill pre-trained\ndiffusion models, or as standalone generative models. Through extensive\nexperiments, we demonstrate that they outperform existing distillation\ntechniques for diffusion models in one- and few-step generation. For example,\nwe achieve the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on\nImageNet 64x64 for one-step generation. When trained as standalone generative\nmodels, consistency models also outperform single-step, non-adversarial\ngenerative models on standard benchmarks like CIFAR-10, ImageNet 64x64 and LSUN\n256x256.\n","authors":["Yang Song","Prafulla Dhariwal","Mark Chen","Ilya Sutskever"],"pdf_url":"https://arxiv.org/pdf/2303.01469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03992v2","updated":"2023-03-02T18:29:24Z","published":"2023-02-08T11:01:19Z","title":"Convolutional Neural Networks Trained to Identify Words Provide a Good\n  Account of Visual Form Priming Effects","summary":"  A wide variety of orthographic coding schemes and models of visual word\nidentification have been developed to account for masked priming data that\nprovide a measure of orthographic similarity between letter strings. These\nmodels tend to include hand-coded orthographic representations with single unit\ncoding for specific forms of knowledge (e.g., units coding for a letter in a\ngiven position). Here we assess how well a range of these coding schemes and\nmodels account for the pattern of form priming effects taken from the Form\nPriming Project and compare these findings to results observed with 11 standard\ndeep neural network models (DNNs) developed in computer science. We find that\ndeep convolutional networks (CNNs) perform as well or better than the coding\nschemes and word recognition models, whereas transformer networks did less\nwell. The success of CNNs is remarkable as their architectures were not\ndeveloped to support word recognition (they were designed to perform well on\nobject recognition), they classify pixel images of words (rather than\nartificial encodings of letter strings), and their training was highly\nsimplified (not respecting many key aspects of human experience). In addition\nto these form priming effects, we find that the DNNs can account for visual\nsimilarity effects on priming that are beyond all current psychological models\nof priming. The findings add to the recent work of (Hannagan et al., 2021) and\nsuggest that CNNs should be given more attention in psychology as models of\nhuman visual word recognition.\n","authors":["Dong Yin","Valerio Biscione","Jeffrey Bowers"],"pdf_url":"https://arxiv.org/pdf/2302.03992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01468v1","updated":"2023-03-02T18:28:29Z","published":"2023-03-02T18:28:29Z","title":"Dataset Creation Pipeline for Camera-Based Heart Rate Estimation","summary":"  Heart rate is one of the most vital health metrics which can be utilized to\ninvestigate and gain intuitions into various human physiological and\npsychological information. Estimating heart rate without the constraints of\ncontact-based sensors thus presents itself as a very attractive field of\nresearch as it enables well-being monitoring in a wider variety of scenarios.\nConsequently, various techniques for camera-based heart rate estimation have\nbeen developed ranging from classical image processing to convoluted deep\nlearning models and architectures. At the heart of such research efforts lies\nhealth and visual data acquisition, cleaning, transformation, and annotation.\nIn this paper, we discuss how to prepare data for the task of developing or\ntesting an algorithm or machine learning model for heart rate estimation from\nimages of facial regions. The data prepared is to include camera frames as well\nas sensor readings from an electrocardiograph sensor. The proposed pipeline is\ndivided into four main steps, namely removal of faulty data, frame and\nelectrocardiograph timestamp de-jittering, signal denoising and filtering, and\nframe annotation creation. Our main contributions are a novel technique of\neliminating jitter from health sensor and camera timestamps and a method to\naccurately time align both visual frame and electrocardiogram sensor data which\nis also applicable to other sensor types.\n","authors":["Mohamed Moustafa","Amr Elrasad","Joseph Lemley","Peter Corcoran"],"pdf_url":"https://arxiv.org/pdf/2303.01468v1.pdf","comment":"Presented at the International Conference on Machine Vision 2022,\n  Rome, Italy. Paper is 8 pages long and includes 7 figures (including table)"},{"id":"http://arxiv.org/abs/2303.01465v1","updated":"2023-03-02T18:27:48Z","published":"2023-03-02T18:27:48Z","title":"MoSFPAD: An end-to-end Ensemble of MobileNet and Support Vector\n  Classifier for Fingerprint Presentation Attack Detection","summary":"  Automatic fingerprint recognition systems are the most extensively used\nsystems for person authentication although they are vulnerable to Presentation\nattacks. Artificial artifacts created with the help of various materials are\nused to deceive these systems causing a threat to the security of\nfingerprint-based applications. This paper proposes a novel end-to-end model to\ndetect fingerprint Presentation attacks. The proposed model incorporates\nMobileNet as a feature extractor and a Support Vector Classifier as a\nclassifier to detect presentation attacks in cross-material and cross-sensor\nparadigms. The feature extractor's parameters are learned with the loss\ngenerated by the support vector classifier. The proposed model eliminates the\nneed for intermediary data preparation procedures, unlike other static hybrid\narchitectures. The performance of the proposed model has been validated on\nbenchmark LivDet 2011, 2013, 2015, 2017, and 2019 databases, and overall\naccuracy of 98.64%, 99.50%, 97.23%, 95.06%, and 95.20% is achieved on these\ndatabases, respectively. The performance of the proposed model is compared with\nstate-of-the-art methods and the proposed method outperforms in cross-material\nand cross-sensor paradigms in terms of average classification error.\n","authors":["Anuj Rai","Somnath Dey","Pradeep Patidar","Prakhar Rai"],"pdf_url":"https://arxiv.org/pdf/2303.01465v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2211.05778v3","updated":"2023-03-02T18:13:33Z","published":"2022-11-10T18:59:04Z","title":"InternImage: Exploring Large-Scale Vision Foundation Models with\n  Deformable Convolutions","summary":"  Compared to the great progress of large-scale vision transformers (ViTs) in\nrecent years, large-scale models based on convolutional neural networks (CNNs)\nare still in an early state. This work presents a new large-scale CNN-based\nfoundation model, termed InternImage, which can obtain the gain from increasing\nparameters and training data like ViTs. Different from the recent CNNs that\nfocus on large dense kernels, InternImage takes deformable convolution as the\ncore operator, so that our model not only has the large effective receptive\nfield required for downstream tasks such as detection and segmentation, but\nalso has the adaptive spatial aggregation conditioned by input and task\ninformation. As a result, the proposed InternImage reduces the strict inductive\nbias of traditional CNNs and makes it possible to learn stronger and more\nrobust patterns with large-scale parameters from massive data like ViTs. The\neffectiveness of our model is proven on challenging benchmarks including\nImageNet, COCO, and ADE20K. It is worth mentioning that InternImage-H achieved\na new record 65.4 mAP on COCO test-dev and 62.9 mIoU on ADE20K, outperforming\ncurrent leading CNNs and ViTs. The code will be released at\nhttps://github.com/OpenGVLab/InternImage.\n","authors":["Wenhai Wang","Jifeng Dai","Zhe Chen","Zhenhang Huang","Zhiqi Li","Xizhou Zhu","Xiaowei Hu","Tong Lu","Lewei Lu","Hongsheng Li","Xiaogang Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2211.05778v3.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2208.11870v2","updated":"2023-03-02T17:27:13Z","published":"2022-08-25T04:52:21Z","title":"Fix-A-Step: Semi-supervised Learning from Uncurated Unlabeled Data","summary":"  Semi-supervised learning (SSL) promises improved accuracy compared to\ntraining classifiers on small labeled datasets by also training on many\nunlabeled images. In real applications like medical imaging, unlabeled data\nwill be collected for expediency and thus uncurated: possibly different from\nthe labeled set in classes or features. Unfortunately, modern deep SSL often\nmakes accuracy worse when given uncurated unlabeled data. Recent complex\nremedies try to detect out-of-distribution unlabeled images and then discard or\ndownweight them. Instead, we introduce Fix-A-Step, a simpler procedure that\nviews all uncurated unlabeled images as potentially helpful. Our first insight\nis that even uncurated images can yield useful augmentations of labeled data.\nSecond, we modify gradient descent updates to prevent optimizing a multi-task\nSSL loss from hurting labeled-set accuracy. Fix-A-Step can repair many common\ndeep SSL methods, improving accuracy on CIFAR benchmarks across all tested\nmethods and levels of artificial class mismatch. On a new medical SSL benchmark\ncalled Heart2Heart, Fix-A-Step can learn from 353,500 truly uncurated\nultrasound images to deliver gains that generalize across hospitals.\n","authors":["Zhe Huang","Mary-Joy Sidhom","Benjamin S. Wessler","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2208.11870v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.01418v1","updated":"2023-03-02T17:09:27Z","published":"2023-03-02T17:09:27Z","title":"Human Motion Diffusion as a Generative Prior","summary":"  In recent months, we witness a leap forward as denoising diffusion models\nwere introduced to Motion Generation. Yet, the main gap in this field remains\nthe low availability of data. Furthermore, the expensive acquisition process of\nmotion biases the already modest data towards short single-person sequences.\nWith such a shortage, more elaborate generative tasks are left behind. In this\npaper, we show that this gap can be mitigated using a pre-trained\ndiffusion-based model as a generative prior. We demonstrate the prior is\neffective for fine-tuning, in a few-, and even a zero-shot manner. For the\nzero-shot setting, we tackle the challenge of long sequence generation. We\nintroduce DoubleTake, an inference-time method with which we demonstrate up to\n10-minute long animations of prompted intervals and their meaningful and\ncontrolled transition, using the prior that was trained for 10-second\ngenerations. For the few-shot setting, we consider two-person generation. Using\ntwo fixed priors and as few as a dozen training examples, we learn a slim\ncommunication block, ComMDM, to infuse interaction between the two resulting\nmotions. Finally, using fine-tuning, we train the prior to semantically\ncomplete motions from a single prescribed joint. Then, we use our\nDiffusionBlending to blend a few such models into a single one that responds\nwell to the combination of the individual control signals, enabling\nfine-grained joint- and trajectory-level control and editing. Using an\noff-the-shelf state-of-the-art (SOTA) motion diffusion model as a prior, we\nevaluate our approach for the three mentioned cases and show that we\nconsistently outperform SOTA models that were designed and trained for those\ntasks.\n","authors":["Yonatan Shafir","Guy Tevet","Roy Kapon","Amit H. Bermano"],"pdf_url":"https://arxiv.org/pdf/2303.01418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01416v1","updated":"2023-03-02T17:06:57Z","published":"2023-03-02T17:06:57Z","title":"3D generation on ImageNet","summary":"  Existing 3D-from-2D generators are typically designed for well-curated\nsingle-category datasets, where all the objects have (approximately) the same\nscale, 3D location, and orientation, and the camera always points to the center\nof the scene. This makes them inapplicable to diverse, in-the-wild datasets of\nnon-alignable scenes rendered from arbitrary camera poses. In this work, we\ndevelop a 3D generator with Generic Priors (3DGP): a 3D synthesis framework\nwith more general assumptions about the training data, and show that it scales\nto very challenging datasets, like ImageNet. Our model is based on three new\nideas. First, we incorporate an inaccurate off-the-shelf depth estimator into\n3D GAN training via a special depth adaptation module to handle the\nimprecision. Then, we create a flexible camera model and a regularization\nstrategy for it to learn its distribution parameters during training. Finally,\nwe extend the recent ideas of transferring knowledge from pre-trained\nclassifiers into GANs for patch-wise trained models by employing a simple\ndistillation-based technique on top of the discriminator. It achieves more\nstable training than the existing methods and speeds up the convergence by at\nleast 40%. We explore our model on four datasets: SDIP Dogs 256x256, SDIP\nElephants 256x256, LSUN Horses 256x256, and ImageNet 256x256, and demonstrate\nthat 3DGP outperforms the recent state-of-the-art in terms of both texture and\ngeometry quality. Code and visualizations:\nhttps://snap-research.github.io/3dgp.\n","authors":["Ivan Skorokhodov","Aliaksandr Siarohin","Yinghao Xu","Jian Ren","Hsin-Ying Lee","Peter Wonka","Sergey Tulyakov"],"pdf_url":"https://arxiv.org/pdf/2303.01416v1.pdf","comment":"ICLR 2023 (Oral)"},{"id":"http://arxiv.org/abs/2301.02830v3","updated":"2023-03-02T16:49:52Z","published":"2023-01-07T11:37:32Z","title":"Advanced Data Augmentation Approaches: A Comprehensive Survey and Future\n  directions","summary":"  Deep learning (DL) algorithms have shown significant performance in various\ncomputer vision tasks. However, having limited labelled data lead to a network\noverfitting problem, where network performance is bad on unseen data as\ncompared to training data. Consequently, it limits performance improvement. To\ncope with this problem, various techniques have been proposed such as dropout,\nnormalization and advanced data augmentation. Among these, data augmentation,\nwhich aims to enlarge the dataset size by including sample diversity, has been\na hot topic in recent times. In this article, we focus on advanced data\naugmentation techniques. we provide a background of data augmentation, a novel\nand comprehensive taxonomy of reviewed data augmentation techniques, and the\nstrengths and weaknesses (wherever possible) of each technique. We also provide\ncomprehensive results of the data augmentation effect on three popular computer\nvision tasks, such as image classification, object detection and semantic\nsegmentation. For results reproducibility, we compiled available codes of all\ndata augmentation techniques. Finally, we discuss the challenges and\ndifficulties, and possible future direction for the research community. We\nbelieve, this survey provides several benefits i) readers will understand the\ndata augmentation working mechanism to fix overfitting problems ii) results\nwill save the searching time of the researcher for comparison purposes. iii)\nCodes of the mentioned data augmentation techniques are available at\nhttps://github.com/kmr2017/Advanced-Data-augmentation-codes iv) Future work\nwill spark interest in research community.\n","authors":["Teerath Kumar","Alessandra Mileo","Rob Brennan","Malika Bendechache"],"pdf_url":"https://arxiv.org/pdf/2301.02830v3.pdf","comment":"We need to make a lot changes to make its quality better"},{"id":"http://arxiv.org/abs/2302.07817v2","updated":"2023-03-02T16:41:45Z","published":"2023-02-15T17:58:10Z","title":"Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction","summary":"  Modern methods for vision-centric autonomous driving perception widely adopt\nthe bird's-eye-view (BEV) representation to describe a 3D scene. Despite its\nbetter efficiency than voxel representation, it has difficulty describing the\nfine-grained 3D structure of a scene with a single plane. To address this, we\npropose a tri-perspective view (TPV) representation which accompanies BEV with\ntwo additional perpendicular planes. We model each point in the 3D space by\nsumming its projected features on the three planes. To lift image features to\nthe 3D TPV space, we further propose a transformer-based TPV encoder\n(TPVFormer) to obtain the TPV features effectively. We employ the attention\nmechanism to aggregate the image features corresponding to each query in each\nTPV plane. Experiments show that our model trained with sparse supervision\neffectively predicts the semantic occupancy for all voxels. We demonstrate for\nthe first time that using only camera inputs can achieve comparable performance\nwith LiDAR-based methods on the LiDAR segmentation task on nuScenes. Code:\nhttps://github.com/wzzheng/TPVFormer.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Yunpeng Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2302.07817v2.pdf","comment":"Accepted to CVPR 2023. Code is available at\n  https://github.com/wzzheng/TPVFormer"},{"id":"http://arxiv.org/abs/2303.01396v1","updated":"2023-03-02T16:26:14Z","published":"2023-03-02T16:26:14Z","title":"MLANet: Multi-Level Attention Network with Sub-instruction for\n  Continuous Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) aims to develop intelligent agents to\nnavigate in unseen environments only through language and vision supervision.\nIn the recently proposed continuous settings (continuous VLN), the agent must\nact in a free 3D space and faces tougher challenges like real-time execution,\ncomplex instruction understanding, and long action sequence prediction. For a\nbetter performance in continuous VLN, we design a multi-level instruction\nunderstanding procedure and propose a novel model, Multi-Level Attention\nNetwork (MLANet). The first step of MLANet is to generate sub-instructions\nefficiently. We design a Fast Sub-instruction Algorithm (FSA) to segment the\nraw instruction into sub-instructions and generate a new sub-instruction\ndataset named ``FSASub\". FSA is annotation-free and faster than the current\nmethod by 70 times, thus fitting the real-time requirement in continuous VLN.\nTo solve the complex instruction understanding problem, MLANet needs a global\nperception of the instruction and observations. We propose a Multi-Level\nAttention (MLA) module to fuse vision, low-level semantics, and high-level\nsemantics, which produce features containing a dynamic and global comprehension\nof the task. MLA also mitigates the adverse effects of noise words, thus\nensuring a robust understanding of the instruction. To correctly predict\nactions in long trajectories, MLANet needs to focus on what sub-instruction is\nbeing executed every step. We propose a Peak Attention Loss (PAL) to improve\nthe flexible and adaptive selection of the current sub-instruction. PAL\nbenefits the navigation agent by concentrating its attention on the local\ninformation, thus helping the agent predict the most appropriate actions. We\ntrain and test MLANet in the standard benchmark. Experiment results show MLANet\noutperforms baselines by a significant margin.\n","authors":["Zongtao He","Liuyi Wang","Shu Li","Qingqing Yan","Chengju Liu","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01384v1","updated":"2023-03-02T16:08:23Z","published":"2023-03-02T16:08:23Z","title":"DAVA: Disentangling Adversarial Variational Autoencoder","summary":"  The use of well-disentangled representations offers many advantages for\ndownstream tasks, e.g. an increased sample efficiency, or better\ninterpretability. However, the quality of disentangled interpretations is often\nhighly dependent on the choice of dataset-specific hyperparameters, in\nparticular the regularization strength. To address this issue, we introduce\nDAVA, a novel training procedure for variational auto-encoders. DAVA completely\nalleviates the problem of hyperparameter selection. We compare DAVA to models\nwith optimal hyperparameters. Without any hyperparameter tuning, DAVA is\ncompetitive on a diverse range of commonly used datasets. Underlying DAVA, we\ndiscover a necessary condition for unsupervised disentanglement, which we call\nPIPE. We demonstrate the ability of PIPE to positively predict the performance\nof downstream models in abstract reasoning. We also thoroughly investigate\ncorrelations with existing supervised and unsupervised metrics. The code is\navailable at https://github.com/besterma/dava.\n","authors":["Benjamin Estermann","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.01384v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01377v1","updated":"2023-03-02T16:02:55Z","published":"2023-03-02T16:02:55Z","title":"BEL: A Bag Embedding Loss for Transformer enhances Multiple Instance\n  Whole Slide Image Classification","summary":"  Multiple Instance Learning (MIL) has become the predominant approach for\nclassification tasks on gigapixel histopathology whole slide images (WSIs).\nWithin the MIL framework, single WSIs (bags) are decomposed into patches\n(instances), with only WSI-level annotation available. Recent MIL approaches\nproduce highly informative bag level representations by utilizing the\ntransformer architecture's ability to model the dependencies between instances.\nHowever, when applied to high magnification datasets, problems emerge due to\nthe large number of instances and the weak supervisory learning signal. To\naddress this problem, we propose to additionally train transformers with a\nnovel Bag Embedding Loss (BEL). BEL forces the model to learn a discriminative\nbag-level representation by minimizing the distance between bag embeddings of\nthe same class and maximizing the distance between different classes. We\nevaluate BEL with the Transformer architecture TransMIL on two publicly\navailable histopathology datasets, BRACS and CAMELYON17. We show that with BEL,\nTransMIL outperforms the baseline models on both datasets, thus contributing to\nthe clinically highly relevant AI-based tumor classification of histological\npatient material.\n","authors":["Daniel Sens","Ario Sadafi","Francesco Paolo Casale","Nassir Navab","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2303.01377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01363v1","updated":"2023-03-02T15:48:02Z","published":"2023-03-02T15:48:02Z","title":"Deep-NFA: a Deep $\\textit{a contrario}$ Framework for Small Object\n  Detection","summary":"  The detection of small objects is a challenging task in computer vision.\nConventional object detection methods have difficulty in finding the balance\nbetween high detection and low false alarm rates. In the literature, some\nmethods have addressed this issue by enhancing the feature map responses, but\nwithout guaranteeing robustness with respect to the number of false alarms\ninduced by background elements. To tackle this problem, we introduce an\n$\\textit{a contrario}$ decision criterion into the learning process to take\ninto account the unexpectedness of small objects. This statistic criterion\nenhances the feature map responses while controlling the number of false alarms\n(NFA) and can be integrated into any semantic segmentation neural network. Our\nadd-on NFA module not only allows us to obtain competitive results for small\ntarget and crack detection tasks respectively, but also leads to more robust\nand interpretable results.\n","authors":["Alina Ciocarlan","Sylvie Le Hegarat-Mascle","Sidonie Lefebvre","Arnaud Woiselle"],"pdf_url":"https://arxiv.org/pdf/2303.01363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01351v1","updated":"2023-03-02T15:31:53Z","published":"2023-03-02T15:31:53Z","title":"APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth\n  Estimation for Autonomous Navigation","summary":"  In recent years, monocular depth estimation (MDE) has witnessed a substantial\nperformance improvement due to convolutional neural networks (CNNs). However,\nCNNs are vulnerable to adversarial attacks, which pose serious concerns for\nsafety-critical and security-sensitive systems. Specifically, adversarial\nattacks can have catastrophic impact on MDE given its importance for scene\nunderstanding in applications like autonomous driving and robotic navigation.\nTo physically assess the vulnerability of CNN-based depth prediction methods,\nrecent work tries to design adversarial patches against MDE. However, these\nmethods are not powerful enough to fully fool the vision system in a\nsystemically threatening manner. In fact, their impact is partial and locally\nlimited; they mislead the depth prediction of only the overlapping region with\nthe input image regardless of the target object size, shape and location. In\nthis paper, we investigate MDE vulnerability to adversarial patches in a more\ncomprehensive manner. We propose a novel adaptive adversarial patch (APARATE)\nthat is able to selectively jeopardize MDE by either corrupting the estimated\ndistance, or simply manifesting an object as disappeared for the autonomous\nsystem. Specifically, APARATE is optimized to be shape and scale-aware, and its\nimpact adapts to the target object instead of being limited to the immediate\nneighborhood. Our proposed patch achieves more than $14~meters$ mean depth\nestimation error, with $99\\%$ of the target region being affected. We believe\nthis work highlights the threat of adversarial attacks in the context of MDE,\nand we hope it would alert the community to the real-life potential harm of\nthis attack and motivate investigating more robust and adaptive defenses for\nautonomous robots.\n","authors":["Amira Guesmi","Muhammad Abdullah Hanif","Ihsen Alouani","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.01351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02295v3","updated":"2023-03-02T15:23:11Z","published":"2022-12-05T14:19:21Z","title":"Block Selection Method for Using Feature Norm in Out-of-distribution\n  Detection","summary":"  Detecting out-of-distribution (OOD) inputs during the inference stage is\ncrucial for deploying neural networks in the real world. Previous methods\ncommonly relied on the output of a network derived from the highly activated\nfeature map. In this study, we first revealed that a norm of the feature map\nobtained from the other block than the last block can be a better indicator of\nOOD detection. Motivated by this, we propose a simple framework consisting of\nFeatureNorm: a norm of the feature map and NormRatio: a ratio of FeatureNorm\nfor ID and OOD to measure the OOD detection performance of each block. In\nparticular, to select the block that provides the largest difference between\nFeatureNorm of ID and FeatureNorm of OOD, we create Jigsaw puzzle images as\npseudo OOD from ID training samples and calculate NormRatio, and the block with\nthe largest value is selected. After the suitable block is selected, OOD\ndetection with the FeatureNorm outperforms other OOD detection methods by\nreducing FPR95 by up to 52.77% on CIFAR10 benchmark and by up to 48.53% on\nImageNet benchmark. We demonstrate that our framework can generalize to various\narchitectures and the importance of block selection, which can improve previous\nOOD detection methods as well.\n","authors":["Yeonguk Yu","Sungho Shin","Seongju Lee","Changhyun Jun","Kyoobin Lee"],"pdf_url":"https://arxiv.org/pdf/2212.02295v3.pdf","comment":"CVPR2023 accepted; Code is available in\n  https://github.com/gist-ailab/block-selection-for-OOD-detection"},{"id":"http://arxiv.org/abs/2303.01342v1","updated":"2023-03-02T15:18:58Z","published":"2023-03-02T15:18:58Z","title":"Active Learning Enhances Classification of Histopathology Whole Slide\n  Images with Attention-based Multiple Instance Learning","summary":"  In many histopathology tasks, sample classification depends on morphological\ndetails in tissue or single cells that are only visible at the highest\nmagnification. For a pathologist, this implies tedious zooming in and out,\nwhile for a computational decision support algorithm, it leads to the analysis\nof a huge number of small image patches per whole slide image (WSI).\nAttention-based multiple instance learning (MIL), where attention estimation is\nlearned in a weakly supervised manner, has been successfully applied in\ncomputational histopathology, but it is challenged by large numbers of\nirrelevant patches, reducing its accuracy. Here, we present an active learning\napproach to the problem. Querying the expert to annotate regions of interest in\na WSI guides the formation of high-attention regions for MIL. We train an\nattention-based MIL and calculate a confidence metric for every image in the\ndataset to select the most uncertain WSIs for expert annotation. We test our\napproach on the CAMELYON17 dataset classifying metastatic lymph node sections\nin breast cancer. With a novel attention guiding loss, this leads to an\naccuracy boost of the trained models with few regions annotated for each class.\nActive learning thus improves WSIs classification accuracy, leads to faster and\nmore robust convergence, and speeds up the annotation process. It may in the\nfuture serve as an important contribution to train MIL models in the clinically\nrelevant context of cancer classification in histopathology.\n","authors":["Ario Sadafi","Nassir Navab","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2303.01342v1.pdf","comment":"Accepted for publication at the 2023 IEEE International Symposium on\n  Biomedical Imaging (ISBI 2023)"},{"id":"http://arxiv.org/abs/2303.01338v1","updated":"2023-03-02T15:14:46Z","published":"2023-03-02T15:14:46Z","title":"AdvRain: Adversarial Raindrops to Attack Camera-based Smart Vision\n  Systems","summary":"  Vision-based perception modules are increasingly deployed in many\napplications, especially autonomous vehicles and intelligent robots. These\nmodules are being used to acquire information about the surroundings and\nidentify obstacles. Hence, accurate detection and classification are essential\nto reach appropriate decisions and take appropriate and safe actions at all\ntimes. Current studies have demonstrated that \"printed adversarial attacks\",\nknown as physical adversarial attacks, can successfully mislead perception\nmodels such as object detectors and image classifiers. However, most of these\nphysical attacks are based on noticeable and eye-catching patterns for\ngenerated perturbations making them identifiable/detectable by human eye or in\ntest drives. In this paper, we propose a camera-based inconspicuous adversarial\nattack (\\textbf{AdvRain}) capable of fooling camera-based perception systems\nover all objects of the same class. Unlike mask based fake-weather attacks that\nrequire access to the underlying computing hardware or image memory, our attack\nis based on emulating the effects of a natural weather condition (i.e.,\nRaindrops) that can be printed on a translucent sticker, which is externally\nplaced over the lens of a camera. To accomplish this, we provide an iterative\nprocess based on performing a random search aiming to identify critical\npositions to make sure that the performed transformation is adversarial for a\ntarget classifier. Our transformation is based on blurring predefined parts of\nthe captured image corresponding to the areas covered by the raindrop. We\nachieve a drop in average model accuracy of more than $45\\%$ and $40\\%$ on\nVGG19 for ImageNet and Resnet34 for Caltech-101, respectively, using only $20$\nraindrops.\n","authors":["Amira Guesmi","Muhammad Abdullah Hanif","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.01338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07254v2","updated":"2023-03-02T15:10:12Z","published":"2022-11-14T10:32:51Z","title":"The Role of Local Alignment and Uniformity in Image-Text Contrastive\n  Learning on Medical Images","summary":"  Image-text contrastive learning has proven effective for pretraining medical\nimage models. When targeting localized downstream tasks like semantic\nsegmentation or object detection, additional local contrastive losses that\nalign image regions with sentences have shown promising results. We study how\nlocal contrastive losses are related to global (per-sample) contrastive losses\nand which effects they have on localized medical downstream tasks. Based on a\ntheoretical comparison, we propose to remove some components of local losses\nand replace others by a novel distribution prior which enforces uniformity of\nrepresentations within each sample. We empirically study this approach on chest\nX-ray tasks and find it to be very effective, outperforming methods without\nlocal losses on 12 of 18 tasks.\n","authors":["Philip Müller","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2211.07254v2.pdf","comment":"NeurIPS 2022 Workshop: Self-Supervised Learning - Theory and Practice\n  (Reason for updated version: correction of a typo in Eq. (2) and (3))"},{"id":"http://arxiv.org/abs/2303.01332v1","updated":"2023-03-02T15:10:08Z","published":"2023-03-02T15:10:08Z","title":"Self-Supervised Few-Shot Learning for Ischemic Stroke Lesion\n  Segmentation","summary":"  Precise ischemic lesion segmentation plays an essential role in improving\ndiagnosis and treatment planning for ischemic stroke, one of the prevalent\ndiseases with the highest mortality rate. While numerous deep neural network\napproaches have recently been proposed to tackle this problem, these methods\nrequire large amounts of annotated regions during training, which can be\nimpractical in the medical domain where annotated data is scarce. As a remedy,\nwe present a prototypical few-shot segmentation approach for ischemic lesion\nsegmentation using only one annotated sample during training. The proposed\napproach leverages a novel self-supervised training mechanism that is tailored\nto the task of ischemic stroke lesion segmentation by exploiting color-coded\nparametric maps generated from Computed Tomography Perfusion scans. We\nillustrate the benefits of our proposed training mechanism, leading to\nconsiderable improvements in performance in the few-shot setting. Given a\nsingle annotated patient, an average Dice score of 0.58 is achieved for the\nsegmentation of ischemic lesions.\n","authors":["Luca Tomasetti","Stine Hansen","Mahdieh Khanmohammadi","Kjersti Engan","Liv Jorunn Høllesli","Kathinka Dæhli Kurz","Michael Kampffmeyer"],"pdf_url":"https://arxiv.org/pdf/2303.01332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01331v1","updated":"2023-03-02T15:09:25Z","published":"2023-03-02T15:09:25Z","title":"Canonical mapping as a general-purpose object descriptor for robotic\n  manipulation","summary":"  Perception is an essential part of robotic manipulation in a semi-structured\nenvironment. Traditional approaches produce a narrow task-specific prediction\n(e.g., object's 6D pose), that cannot be adapted to other tasks and is\nill-suited for deformable objects. In this paper, we propose using canonical\nmapping as a near-universal and flexible object descriptor. We demonstrate that\ncommon object representations can be derived from a single pre-trained\ncanonical mapping model, which in turn can be generated with minimal manual\neffort using an automated data generation and training pipeline. We perform a\nmulti-stage experiment using two robot arms that demonstrate the robustness of\nthe perception approach and the ways it can inform the manipulation strategy,\nthus serving as a powerful foundation for general-purpose robotic manipulation.\n","authors":["Benjamin Joffe","Konrad Ahlin"],"pdf_url":"https://arxiv.org/pdf/2303.01331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02432v2","updated":"2023-03-02T15:00:46Z","published":"2022-11-04T13:16:20Z","title":"RCDPT: Radar-Camera fusion Dense Prediction Transformer","summary":"  Recently, transformer networks have outperformed traditional deep neural\nnetworks in natural language processing and show a large potential in many\ncomputer vision tasks compared to convolutional backbones. In the original\ntransformer, readout tokens are used as designated vectors for aggregating\ninformation from other tokens. However, the performance of using readout tokens\nin a vision transformer is limited. Therefore, we propose a novel fusion\nstrategy to integrate radar data into a dense prediction transformer network by\nreassembling camera representations with radar representations. Instead of\nusing readout tokens, radar representations contribute additional depth\ninformation to a monocular depth estimation model and improve performance. We\nfurther investigate different fusion approaches that are commonly used for\nintegrating additional modality in a dense prediction transformer network. The\nexperiments are conducted on the nuScenes dataset, which includes camera\nimages, lidar, and radar data. The results show that our proposed method yields\nbetter performance than the commonly used fusion strategies and outperforms\nexisting convolutional depth estimation models that fuse camera images and\nradar.\n","authors":["Chen-Chou Lo","Patrick Vandewalle"],"pdf_url":"https://arxiv.org/pdf/2211.02432v2.pdf","comment":"5 pages, 2 figures and 1 table, accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2207.07027v2","updated":"2023-03-02T14:49:06Z","published":"2022-07-14T15:59:03Z","title":"MedFuse: Multi-modal fusion with clinical time-series data and chest\n  X-ray images","summary":"  Multi-modal fusion approaches aim to integrate information from different\ndata sources. Unlike natural datasets, such as in audio-visual applications,\nwhere samples consist of \"paired\" modalities, data in healthcare is often\ncollected asynchronously. Hence, requiring the presence of all modalities for a\ngiven sample is not realistic for clinical tasks and significantly limits the\nsize of the dataset during training. In this paper, we propose MedFuse, a\nconceptually simple yet promising LSTM-based fusion module that can accommodate\nuni-modal as well as multi-modal input. We evaluate the fusion method and\nintroduce new benchmark results for in-hospital mortality prediction and\nphenotype classification, using clinical time-series data in the MIMIC-IV\ndataset and corresponding chest X-ray images in MIMIC-CXR. Compared to more\ncomplex multi-modal fusion strategies, MedFuse provides a performance\nimprovement by a large margin on the fully paired test set. It also remains\nrobust across the partially paired test set containing samples with missing\nchest X-ray images. We release our code for reproducibility and to enable the\nevaluation of competing models in the future.\n","authors":["Nasir Hayat","Krzysztof J. Geras","Farah E. Shamout"],"pdf_url":"https://arxiv.org/pdf/2207.07027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01313v1","updated":"2023-03-02T14:41:31Z","published":"2023-03-02T14:41:31Z","title":"Weakly-supervised HOI Detection via Prior-guided Bi-level Representation\n  Learning","summary":"  Human object interaction (HOI) detection plays a crucial role in\nhuman-centric scene understanding and serves as a fundamental building-block\nfor many vision tasks. One generalizable and scalable strategy for HOI\ndetection is to use weak supervision, learning from image-level annotations\nonly. This is inherently challenging due to ambiguous human-object\nassociations, large search space of detecting HOIs and highly noisy training\nsignal. A promising strategy to address those challenges is to exploit\nknowledge from large-scale pretrained models (e.g., CLIP), but a direct\nknowledge distillation strategy~\\citep{liao2022gen} does not perform well on\nthe weakly-supervised setting. In contrast, we develop a CLIP-guided HOI\nrepresentation capable of incorporating the prior knowledge at both image level\nand HOI instance level, and adopt a self-taught mechanism to prune incorrect\nhuman-object associations. Experimental results on HICO-DET and V-COCO show\nthat our method outperforms the previous works by a sizable margin, showing the\nefficacy of our HOI representation.\n","authors":["Bo Wan","Yongfei Liu","Desen Zhou","Tinne Tuytelaars","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2303.01313v1.pdf","comment":"Accepted by ICLR2023"},{"id":"http://arxiv.org/abs/2303.01311v1","updated":"2023-03-02T14:37:17Z","published":"2023-03-02T14:37:17Z","title":"Zero-Shot Text-to-Parameter Translation for Game Character Auto-Creation","summary":"  Recent popular Role-Playing Games (RPGs) saw the great success of character\nauto-creation systems. The bone-driven face model controlled by continuous\nparameters (like the position of bones) and discrete parameters (like the\nhairstyles) makes it possible for users to personalize and customize in-game\ncharacters. Previous in-game character auto-creation systems are mostly\nimage-driven, where facial parameters are optimized so that the rendered\ncharacter looks similar to the reference face photo. This paper proposes a\nnovel text-to-parameter translation method (T2P) to achieve zero-shot\ntext-driven game character auto-creation. With our method, users can create a\nvivid in-game character with arbitrary text description without using any\nreference photo or editing hundreds of parameters manually. In our method,\ntaking the power of large-scale pre-trained multi-modal CLIP and neural\nrendering, T2P searches both continuous facial parameters and discrete facial\nparameters in a unified framework. Due to the discontinuous parameter\nrepresentation, previous methods have difficulty in effectively learning\ndiscrete facial parameters. T2P, to our best knowledge, is the first method\nthat can handle the optimization of both discrete and continuous parameters.\nExperimental results show that T2P can generate high-quality and vivid game\ncharacters with given text prompts. T2P outperforms other SOTA text-to-3D\ngeneration methods on both objective evaluations and subjective evaluations.\n","authors":["Rui Zhao","Wei Li","Zhipeng Hu","Lincheng Li","Zhengxia Zou","Zhenwei Shi","Changjie Fan"],"pdf_url":"https://arxiv.org/pdf/2303.01311v1.pdf","comment":"Accepted in CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01309v1","updated":"2023-03-02T14:33:43Z","published":"2023-03-02T14:33:43Z","title":"BIFRNet: A Brain-Inspired Feature Restoration DNN for Partially Occluded\n  Image Recognition","summary":"  The partially occluded image recognition (POIR) problem has been a challenge\nfor artificial intelligence for a long time. A common strategy to handle the\nPOIR problem is using the non-occluded features for classification.\nUnfortunately, this strategy will lose effectiveness when the image is severely\noccluded, since the visible parts can only provide limited information. Several\nstudies in neuroscience reveal that feature restoration which fills in the\noccluded information and is called amodal completion is essential for human\nbrains to recognize partially occluded images. However, feature restoration is\ncommonly ignored by CNNs, which may be the reason why CNNs are ineffective for\nthe POIR problem. Inspired by this, we propose a novel brain-inspired feature\nrestoration network (BIFRNet) to solve the POIR problem. It mimics a ventral\nvisual pathway to extract image features and a dorsal visual pathway to\ndistinguish occluded and visible image regions. In addition, it also uses a\nknowledge module to store object prior knowledge and uses a completion module\nto restore occluded features based on visible features and prior knowledge.\nThorough experiments on synthetic and real-world occluded image datasets show\nthat BIFRNet outperforms the existing methods in solving the POIR problem.\nEspecially for severely occluded images, BIRFRNet surpasses other methods by a\nlarge margin and is close to the human brain performance. Furthermore, the\nbrain-inspired design makes BIFRNet more interpretable.\n","authors":["Jiahong Zhang","Lihong Cao","Qiuxia Lai","Binyao Li","Yunxiao Qin"],"pdf_url":"https://arxiv.org/pdf/2303.01309v1.pdf","comment":"This paper has been accepted by AAAI-2023"},{"id":"http://arxiv.org/abs/2303.01295v1","updated":"2023-03-02T14:21:54Z","published":"2023-03-02T14:21:54Z","title":"Iterative Assessment and Improvement of DNN Operational Accuracy","summary":"  Deep Neural Networks (DNN) are nowadays largely adopted in many application\ndomains thanks to their human-like, or even superhuman, performance in specific\ntasks. However, due to unpredictable/unconsidered operating conditions,\nunexpected failures show up on field, making the performance of a DNN in\noperation very different from the one estimated prior to release. In the life\ncycle of DNN systems, the assessment of accuracy is typically addressed in two\nways: offline, via sampling of operational inputs, or online, via\npseudo-oracles. The former is considered more expensive due to the need for\nmanual labeling of the sampled inputs. The latter is automatic but less\naccurate. We believe that emerging iterative industrial-strength life cycle\nmodels for Machine Learning systems, like MLOps, offer the possibility to\nleverage inputs observed in operation not only to provide faithful estimates of\na DNN accuracy, but also to improve it through remodeling/retraining actions.\nWe propose DAIC (DNN Assessment and Improvement Cycle), an approach which\ncombines ''low-cost'' online pseudo-oracles and ''high-cost'' offline sampling\ntechniques to estimate and improve the operational accuracy of a DNN in the\niterations of its life cycle. Preliminary results show the benefits of\ncombining the two approaches and integrating them in the DNN life cycle.\n","authors":["Antonio Guerriero","Roberto Pietrantuono","Stefano Russo"],"pdf_url":"https://arxiv.org/pdf/2303.01295v1.pdf","comment":"Paper accepted at 45th International Conference on Software\n  Engineering (ICSE'23 NIER), May 2023"},{"id":"http://arxiv.org/abs/2111.03815v2","updated":"2023-03-02T14:18:57Z","published":"2021-11-06T06:53:40Z","title":"Order-Guided Disentangled Representation Learning for Ulcerative Colitis\n  Classification with Limited Labels","summary":"  Ulcerative colitis (UC) classification, which is an important task for\nendoscopic diagnosis, involves two main difficulties. First, endoscopic images\nwith the annotation about UC (positive or negative) are usually limited.\nSecond, they show a large variability in their appearance due to the location\nin the colon. Especially, the second difficulty prevents us from using existing\nsemi-supervised learning techniques, which are the common remedy for the first\ndifficulty. In this paper, we propose a practical semi-supervised learning\nmethod for UC classification by newly exploiting two additional features, the\nlocation in a colon (e.g., left colon) and image capturing order, both of which\nare often attached to individual images in endoscopic image sequences. The\nproposed method can extract the essential information of UC classification\nefficiently by a disentanglement process with those features. Experimental\nresults demonstrate that the proposed method outperforms several existing\nsemi-supervised learning methods in the classification task, even with a small\nnumber of annotated images.\n","authors":["Shota Harada","Ryoma Bise","Hideaki Hayashi","Kiyohito Tanaka","Seiichi Uchida"],"pdf_url":"https://arxiv.org/pdf/2111.03815v2.pdf","comment":"Accepted by MICCAI 2021"},{"id":"http://arxiv.org/abs/2205.14589v2","updated":"2023-03-02T14:10:40Z","published":"2022-05-29T07:32:00Z","title":"Masked Distillation with Receptive Tokens","summary":"  Distilling from the feature maps can be fairly effective for dense prediction\ntasks since both the feature discriminability and localization priors can be\nwell transferred. However, not every pixel contributes equally to the\nperformance, and a good student should learn from what really matters to the\nteacher. In this paper, we introduce a learnable embedding dubbed receptive\ntoken to localize those pixels of interests (PoIs) in the feature map, with a\ndistillation mask generated via pixel-wise attention. Then the distillation\nwill be performed on the mask via pixel-wise reconstruction. In this way, a\ndistillation mask actually indicates a pattern of pixel dependencies within\nfeature maps of teacher. We thus adopt multiple receptive tokens to investigate\nmore sophisticated and informative pixel dependencies to further enhance the\ndistillation. To obtain a group of masks, the receptive tokens are learned via\nthe regular task loss but with teacher fixed, and we also leverage a Dice loss\nto enrich the diversity of learned masks. Our method dubbed MasKD is simple and\npractical, and needs no priors of tasks in application. Experiments show that\nour MasKD can achieve state-of-the-art performance consistently on object\ndetection and semantic segmentation benchmarks. Code is available at:\nhttps://github.com/hunto/MasKD .\n","authors":["Tao Huang","Yuan Zhang","Shan You","Fei Wang","Chen Qian","Jian Cao","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2205.14589v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01283v1","updated":"2023-03-02T14:07:36Z","published":"2023-03-02T14:07:36Z","title":"Cluster-Guided Semi-Supervised Domain Adaptation for Imbalanced Medical\n  Image Classification","summary":"  Semi-supervised domain adaptation is a technique to build a classifier for a\ntarget domain by modifying a classifier in another (source) domain using many\nunlabeled samples and a small number of labeled samples from the target domain.\nIn this paper, we develop a semi-supervised domain adaptation method, which has\nrobustness to class-imbalanced situations, which are common in medical image\nclassification tasks. For robustness, we propose a weakly-supervised clustering\npipeline to obtain high-purity clusters and utilize the clusters in\nrepresentation learning for domain adaptation. The proposed method showed\nstate-of-the-art performance in the experiment using severely class-imbalanced\npathological image patches.\n","authors":["Shota Harada","Ryoma Bise","Kengo Araki","Akihiko Yoshizawa","Kazuhiro Terada","Mariyo Kurata","Naoki Nakajima","Hiroyuki Abe","Tetsuo Ushiku","Seiichi Uchida"],"pdf_url":"https://arxiv.org/pdf/2303.01283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10518v3","updated":"2023-03-02T14:06:01Z","published":"2023-02-21T08:48:27Z","title":"USR: Unsupervised Separated 3D Garment and Human Reconstruction via\n  Geometry and Semantic Consistency","summary":"  Dressed people reconstruction from images is a popular task with promising\napplications in the creative media and game industry. However, most existing\nmethods reconstruct the human body and garments as a whole with the supervision\nof 3D models, which hinders the downstream interaction tasks and requires\nhard-to-obtain data. To address these issues, we propose an unsupervised\nseparated 3D garments and human reconstruction model (USR), which reconstructs\nthe human body and authentic textured clothes in layers without 3D models. More\nspecifically, our method proposes a generalized surface-aware neural radiance\nfield to learn the mapping between sparse multi-view images and geometries of\nthe dressed people. Based on the full geometry, we introduce a Semantic and\nConfidence Guided Separation strategy (SCGS) to detect, segment, and\nreconstruct the clothes layer, leveraging the consistency between 2D semantic\nand 3D geometry. Moreover, we propose a Geometry Fine-tune Module to smooth\nedges. Extensive experiments on our dataset show that comparing with\nstate-of-the-art methods, USR achieves improvements on both geometry and\nappearance reconstruction while supporting generalizing to unseen people in\nreal time. Besides, we also introduce SMPL-D model to show the benefit of the\nseparated modeling of clothes and the human body that allows swapping clothes\nand virtual try-on.\n","authors":["Yue Shi","Yuxuan Xiong","Jingyi Chai","Bingbing Ni","Wenjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.10518v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01276v1","updated":"2023-03-02T14:02:16Z","published":"2023-03-02T14:02:16Z","title":"Conflict-Based Cross-View Consistency for Semi-Supervised Semantic\n  Segmentation","summary":"  Semi-supervised semantic segmentation has recently gained increasing research\ninterest as it can reduce the requirement for large-scale fully-annotated\ntraining data by effectively exploiting large amounts of unlabelled data. The\ncurrent methods often suffer from the confirmation bias from the\npseudo-labelling process, which can be alleviated by the co-training framework.\nThe current co-training-based semi-supervised semantic segmentation methods\nrely on hand-crafted perturbations to prevent the different sub-nets from\ncollapsing into each other, but these artificial perturbations cannot lead to\nthe optimal solution. In this work, we propose a new conflict-based cross-view\nconsistency (CCVC) method based on a two-branch co-training framework for\nsemi-supervised semantic segmentation. Our work aims at enforcing the two\nsub-nets to learn informative features from irrelevant views. In particular, we\nfirst propose a new cross-view consistency (CVC) strategy that encourages the\ntwo sub-nets to learn distinct features from the same input by introducing a\nfeature discrepancy loss, while these distinct features are expected to\ngenerate consistent prediction scores of the input. The CVC strategy helps to\nprevent the two sub-nets from stepping into the collapse. In addition, we\nfurther propose a conflict-based pseudo-labelling (CPL) method to guarantee the\nmodel will learn more useful information from conflicting predictions, which\nwill lead to a stable training process. We validate our new semi-supervised\nsemantic segmentation approach on the widely used benchmark datasets PASCAL VOC\n2012 and Cityscapes, where our method achieves new state-of-the-art\nperformance.\n","authors":["Zicheng Wang","Zhen Zhao","Luping Zhou","Dong Xu","Xiaoxia Xing","Xiangyu Kong"],"pdf_url":"https://arxiv.org/pdf/2303.01276v1.pdf","comment":"accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01274v1","updated":"2023-03-02T13:59:07Z","published":"2023-03-02T13:59:07Z","title":"Measuring axiomatic soundness of counterfactual image models","summary":"  We present a general framework for evaluating image counterfactuals. The\npower and flexibility of deep generative models make them valuable tools for\nlearning mechanisms in structural causal models. However, their flexibility\nmakes counterfactual identifiability impossible in the general case. Motivated\nby these issues, we revisit Pearl's axiomatic definition of counterfactuals to\ndetermine the necessary constraints of any counterfactual inference model:\ncomposition, reversibility, and effectiveness. We frame counterfactuals as\nfunctions of an input variable, its parents, and counterfactual parents and use\nthe axiomatic constraints to restrict the set of functions that could represent\nthe counterfactual, thus deriving distance metrics between the approximate and\nideal functions. We demonstrate how these metrics can be used to compare and\nchoose between different approximate counterfactual inference models and to\nprovide insight into a model's shortcomings and trade-offs.\n","authors":["Miguel Monteiro","Fabio De Sousa Ribeiro","Nick Pawlowski","Daniel C. Castro","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2303.01274v1.pdf","comment":"Counterfactual inference, Generative Models, Computer Vision,\n  Published in ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01268v1","updated":"2023-03-02T13:53:22Z","published":"2023-03-02T13:53:22Z","title":"Analyzing Effects of Fake Training Data on the Performance of Deep\n  Learning Systems","summary":"  Deep learning models frequently suffer from various problems such as class\nimbalance and lack of robustness to distribution shift. It is often difficult\nto find data suitable for training beyond the available benchmarks. This is\nespecially the case for computer vision models. However, with the advent of\nGenerative Adversarial Networks (GANs), it is now possible to generate\nhigh-quality synthetic data. This synthetic data can be used to alleviate some\nof the challenges faced by deep learning models. In this work we present a\ndetailed analysis of the effect of training computer vision models using\ndifferent proportions of synthetic data along with real (organic) data. We\nanalyze the effect that various quantities of synthetic data, when mixed with\noriginal data, can have on a model's robustness to out-of-distribution data and\nthe general quality of predictions.\n","authors":["Pratinav Seth","Akshat Bhandari","Kumud Lakara"],"pdf_url":"https://arxiv.org/pdf/2303.01268v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2303.01267v1","updated":"2023-03-02T13:51:58Z","published":"2023-03-02T13:51:58Z","title":"Token Contrast for Weakly-Supervised Semantic Segmentation","summary":"  Weakly-Supervised Semantic Segmentation (WSSS) using image-level labels\ntypically utilizes Class Activation Map (CAM) to generate the pseudo labels.\nLimited by the local structure perception of CNN, CAM usually cannot identify\nthe integral object regions. Though the recent Vision Transformer (ViT) can\nremedy this flaw, we observe it also brings the over-smoothing issue, \\ie, the\nfinal patch tokens incline to be uniform. In this work, we propose Token\nContrast (ToCo) to address this issue and further explore the virtue of ViT for\nWSSS. Firstly, motivated by the observation that intermediate layers in ViT can\nstill retain semantic diversity, we designed a Patch Token Contrast module\n(PTC). PTC supervises the final patch tokens with the pseudo token relations\nderived from intermediate layers, allowing them to align the semantic regions\nand thus yield more accurate CAM. Secondly, to further differentiate the\nlow-confidence regions in CAM, we devised a Class Token Contrast module (CTC)\ninspired by the fact that class tokens in ViT can capture high-level semantics.\nCTC facilitates the representation consistency between uncertain local regions\nand global objects by contrasting their class tokens. Experiments on the PASCAL\nVOC and MS COCO datasets show the proposed ToCo can remarkably surpass other\nsingle-stage competitors and achieve comparable performance with\nstate-of-the-art multi-stage methods. Code is available at\nhttps://github.com/rulixiang/ToCo.\n","authors":["Lixiang Ru","Heliang Zheng","Yibing Zhan","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2303.01267v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2202.13808v3","updated":"2023-03-02T13:44:43Z","published":"2022-02-28T14:12:00Z","title":"DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training","summary":"  A standard hardware bottleneck when training deep neural networks is GPU\nmemory. The bulk of memory is occupied by caching intermediate tensors for\ngradient computation in the backward pass. We propose a novel method to reduce\nthis footprint - Dropping Intermediate Tensors (DropIT). DropIT drops min-k\nelements of the intermediate tensors and approximates gradients from the\nsparsified tensors in the backward pass. Theoretically, DropIT reduces noise on\nestimated gradients and therefore has a higher rate of convergence than\nvanilla-SGD. Experiments show that we can drop up to 90\\% of the intermediate\ntensor elements in fully-connected and convolutional layers while achieving\nhigher testing accuracy for Visual Transformers and Convolutional Neural\nNetworks on various tasks (e.g., classification, object detection, instance\nsegmentation). Our code and models are available at\nhttps://github.com/chenjoya/dropit.\n","authors":["Joya Chen","Kai Xu","Yuhui Wang","Yifei Cheng","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2202.13808v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2212.10390v3","updated":"2023-03-02T13:36:47Z","published":"2022-12-20T16:17:40Z","title":"ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic\n  Segmentation","summary":"  State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.\n","authors":["Ben Fei","Siyuan Huang","Jiakang Yuan","Botian Shi","Bo Zhang","Tao Chen","Min Dou","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.10390v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12245v2","updated":"2023-03-02T13:36:28Z","published":"2023-02-23T18:58:57Z","title":"Set Features for Fine-grained Anomaly Detection","summary":"  Fine-grained anomaly detection has recently been dominated by segmentation\nbased approaches. These approaches first classify each element of the sample\n(e.g., image patch) as normal or anomalous and then classify the entire sample\nas anomalous if it contains anomalous elements. However, such approaches do not\nextend to scenarios where the anomalies are expressed by an unusual combination\nof normal elements. In this paper, we overcome this limitation by proposing set\nfeatures that model each sample by the distribution its elements. We compute\nthe anomaly score of each sample using a simple density estimation method. Our\nsimple-to-implement approach outperforms the state-of-the-art in image-level\nlogical anomaly detection (+3.4%) and sequence-level time-series anomaly\ndetection (+2.4%).\n","authors":["Niv Cohen","Issar Tzachor","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2302.12245v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01256v1","updated":"2023-03-02T13:36:28Z","published":"2023-03-02T13:36:28Z","title":"Choosing Public Datasets for Private Machine Learning via Gradient\n  Subspace Distance","summary":"  Differentially private stochastic gradient descent privatizes model training\nby injecting noise into each iteration, where the noise magnitude increases\nwith the number of model parameters. Recent works suggest that we can reduce\nthe noise by leveraging public data for private machine learning, by projecting\ngradients onto a subspace prescribed by the public data. However, given a\nchoice of public datasets, it is not a priori clear which one may be most\nappropriate for the private task. We give an algorithm for selecting a public\ndataset by measuring a low-dimensional subspace distance between gradients of\nthe public and private examples. We provide theoretical analysis demonstrating\nthat the excess risk scales with this subspace distance. This distance is easy\nto compute and robust to modifications in the setting. Empirical evaluation\nshows that trained model accuracy is monotone in this distance.\n","authors":["Xin Gu","Gautam Kamath","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01239v1","updated":"2023-03-02T13:28:50Z","published":"2023-03-02T13:28:50Z","title":"MixPHM: Redundancy-Aware Parameter-Efficient Tuning for Low-Resource\n  Visual Question Answering","summary":"  Recently, finetuning pretrained vision-language models (VLMs) has become one\nprevailing paradigm to achieve state-of-the-art performance in VQA. However, as\nVLMs scale, it becomes computationally expensive, storage inefficient, and\nprone to overfitting to tune full model parameters for a specific task in\nlow-resource settings. Although current parameter-efficient tuning methods\ndramatically reduce the number of tunable parameters, there still exists a\nsignificant performance gap with full finetuning. In this paper, we propose\n\\textbf{MixPHM}, a redundancy-aware parameter-efficient tuning method that\noutperforms full finetuning in low-resource VQA. Specifically, MixPHM is a\nlightweight module implemented by multiple PHM-experts in a mixture-of-experts\nmanner. To reduce parameter redundancy, we reparameterize expert weights in a\nlow-rank subspace and share part of the weights inside and across MixPHM.\nMoreover, based on our quantitative analysis of representation redundancy, we\npropose \\textbf{redundancy regularization}, which facilitates MixPHM to reduce\ntask-irrelevant redundancy while promoting task-relevant correlation.\nExperiments conducted on VQA v2, GQA, and OK-VQA with different low-resource\nsettings show that our MixPHM outperforms state-of-the-art parameter-efficient\nmethods and is the only one consistently surpassing full finetuning.\n","authors":["Jingjing Jiang","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.01239v1.pdf","comment":"14 pages, 6 figures, 9 tables. Accepted by CVPR 2023. Code will be\n  available at \\url{https://github.com/jingjing12110/MixPHM}"},{"id":"http://arxiv.org/abs/2303.01237v1","updated":"2023-03-02T13:28:07Z","published":"2023-03-02T13:28:07Z","title":"FlowFormer++: Masked Cost Volume Autoencoding for Pretraining Optical\n  Flow Estimation","summary":"  FlowFormer introduces a transformer architecture into optical flow estimation\nand achieves state-of-the-art performance. The core component of FlowFormer is\nthe transformer-based cost-volume encoder. Inspired by the recent success of\nmasked autoencoding (MAE) pretraining in unleashing transformers' capacity of\nencoding visual representation, we propose Masked Cost Volume Autoencoding\n(MCVA) to enhance FlowFormer by pretraining the cost-volume encoder with a\nnovel MAE scheme. Firstly, we introduce a block-sharing masking strategy to\nprevent masked information leakage, as the cost maps of neighboring source\npixels are highly correlated. Secondly, we propose a novel pre-text\nreconstruction task, which encourages the cost-volume encoder to aggregate\nlong-range information and ensures pretraining-finetuning consistency. We also\nshow how to modify the FlowFormer architecture to accommodate masks during\npretraining. Pretrained with MCVA, FlowFormer++ ranks 1st among published\nmethods on both Sintel and KITTI-2015 benchmarks. Specifically, FlowFormer++\nachieves 1.07 and 1.94 average end-point error (AEPE) on the clean and final\npass of Sintel benchmark, leading to 7.76\\% and 7.18\\% error reductions from\nFlowFormer. FlowFormer++ obtains 4.52 F1-all on the KITTI-2015 test set,\nimproving FlowFormer by 0.16.\n","authors":["Xiaoyu Shi","Zhaoyang Huang","Dasong Li","Manyuan Zhang","Ka Chun Cheung","Simon See","Hongwei Qin","Jifeng Dai","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2303.01237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01219v1","updated":"2023-03-02T13:04:33Z","published":"2023-03-02T13:04:33Z","title":"A Coarse to Fine Framework for Object Detection in High Resolution Image","summary":"  Object detection is a fundamental problem in computer vision, aiming at\nlocating and classifying objects in image. Although current devices can easily\ntake very high-resolution images, current approaches of object detection seldom\nconsider detecting tiny object or the large scale variance problem in high\nresolution images. In this paper, we introduce a simple yet efficient approach\nthat improves accuracy of object detection especially for small objects and\nlarge scale variance scene while reducing the computational cost in high\nresolution image. Inspired by observing that overall detection accuracy is\nreduced if the image is properly down-sampled but the recall rate is not\nsignificantly reduced. Besides, small objects can be better detected by\ninputting high-resolution images even if using lightweight detector. We propose\na cluster-based coarse-to-fine object detection framework to enhance the\nperformance for detecting small objects while ensure the accuracy of large\nobjects in high-resolution images. For the first stage, we perform coarse\ndetection on the down-sampled image and center localization of small objects by\nlightweight detector on high-resolution image, and then obtains image chips\nbased on cluster region generation method by coarse detection and center\nlocalization results, and further sends chips to the second stage detector for\nfine detection. Finally, we merge the coarse detection and fine detection\nresults. Our approach can make good use of the sparsity of the objects and the\ninformation in high-resolution image, thereby making the detection more\nefficient. Experiment results show that our proposed approach achieves\npromising performance compared with other state-of-the-art detectors.\n","authors":["Jinyan Liu","Jie Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11436v2","updated":"2023-03-02T12:56:46Z","published":"2022-11-21T13:23:52Z","title":"N-Gram in Swin Transformers for Efficient Lightweight Image\n  Super-Resolution","summary":"  While some studies have proven that Swin Transformer (SwinT) with window\nself-attention (WSA) is suitable for single image super-resolution (SR), SwinT\nignores the broad regions for reconstructing high-resolution images due to\nwindow and shift size. In addition, many deep learning SR methods suffer from\nintensive computations. To address these problems, we introduce the N-Gram\ncontext to the image domain for the first time in history. We define N-Gram as\nneighboring local windows in SwinT, which differs from text analysis that views\nN-Gram as consecutive characters or words. N-Grams interact with each other by\nsliding-WSA, expanding the regions seen to restore degraded pixels. Using the\nN-Gram context, we propose NGswin, an efficient SR network with SCDP bottleneck\ntaking all outputs of the hierarchical encoder. Experimental results show that\nNGswin achieves competitive performance while keeping an efficient structure,\ncompared with previous leading methods. Moreover, we also improve other\nSwinT-based SR methods with the N-Gram context, thereby building an enhanced\nmodel: SwinIR-NG. Our improved SwinIR-NG outperforms the current best\nlightweight SR approaches and establishes state-of-the-art results. Codes will\nbe available soon.\n","authors":["Haram Choi","Jeongmin Lee","Jihoon Yang"],"pdf_url":"https://arxiv.org/pdf/2211.11436v2.pdf","comment":"Accepted at CVPR 2023. Codes are available at\n  https://github.com/rami0205/NGramSwin"},{"id":"http://arxiv.org/abs/2303.01212v1","updated":"2023-03-02T12:52:46Z","published":"2023-03-02T12:52:46Z","title":"Grid-Centric Traffic Scenario Perception for Autonomous Driving: A\n  Comprehensive Review","summary":"  Grid-centric perception is a crucial field for mobile robot perception and\nnavigation. Nonetheless, grid-centric perception is less prevalent than\nobject-centric perception for autonomous driving as autonomous vehicles need to\naccurately perceive highly dynamic, large-scale outdoor traffic scenarios and\nthe complexity and computational costs of grid-centric perception are high. The\nrapid development of deep learning techniques and hardware gives fresh insights\ninto the evolution of grid-centric perception and enables the deployment of\nmany real-time algorithms. Current industrial and academic research\ndemonstrates the great advantages of grid-centric perception, such as\ncomprehensive fine-grained environmental representation, greater robustness to\nocclusion, more efficient sensor fusion, and safer planning policies. Given the\nlack of current surveys for this rapidly expanding field, we present a\nhierarchically-structured review of grid-centric perception for autonomous\nvehicles. We organize previous and current knowledge of occupancy grid\ntechniques and provide a systematic in-depth analysis of algorithms in terms of\nthree aspects: feature representation, data utility, and applications in\nautonomous driving systems. Lastly, we present a summary of the current\nresearch trend and provide some probable future outlooks.\n","authors":["Yining Shi","Kun Jiang","Jiusi Li","Junze Wen","Zelin Qian","Mengmeng Yang","Ke Wang","Diange Yang"],"pdf_url":"https://arxiv.org/pdf/2303.01212v1.pdf","comment":"The first version of the review. Comments are welcomed"},{"id":"http://arxiv.org/abs/2303.01201v1","updated":"2023-03-02T12:34:38Z","published":"2023-03-02T12:34:38Z","title":"Average of Pruning: Improving Performance and Stability of\n  Out-of-Distribution Detection","summary":"  Detecting Out-of-distribution (OOD) inputs have been a critical issue for\nneural networks in the open world. However, the unstable behavior of OOD\ndetection along the optimization trajectory during training has not been\nexplored clearly. In this paper, we first find the performance of OOD detection\nsuffers from overfitting and instability during training: 1) the performance\ncould decrease when the training error is near zero, and 2) the performance\nwould vary sharply in the final stage of training. Based on our findings, we\npropose Average of Pruning (AoP), consisting of model averaging and pruning, to\nmitigate the unstable behaviors. Specifically, model averaging can help achieve\na stable performance by smoothing the landscape, and pruning is certified to\neliminate the overfitting by eliminating redundant features. Comprehensive\nexperiments on various datasets and architectures are conducted to verify the\neffectiveness of our method.\n","authors":["Zhen Cheng","Fei Zhu","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12502v2","updated":"2023-03-02T12:33:10Z","published":"2022-05-25T05:40:00Z","title":"The Dialog Must Go On: Improving Visual Dialog via Generative\n  Self-Training","summary":"  Visual dialog (VisDial) is a task of answering a sequence of questions\ngrounded in an image, using the dialog history as context. Prior work has\ntrained the dialog agents solely on VisDial data via supervised learning or\nleveraged pre-training on related vision-and-language datasets. This paper\npresents a semi-supervised learning approach for visually-grounded dialog,\ncalled Generative Self-Training (GST), to leverage unlabeled images on the Web.\nSpecifically, GST first retrieves in-domain images through out-of-distribution\ndetection and generates synthetic dialogs regarding the images via multimodal\nconditional text generation. GST then trains a dialog agent on the synthetic\nand the original VisDial data. As a result, GST scales the amount of training\ndata up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For\nrobust training of the synthetic dialogs, we also propose perplexity-based data\nselection and multimodal consistency regularization. Evaluation on VisDial v1.0\nand v0.9 datasets shows that GST achieves new state-of-the-art results on both\ndatasets. We further observe the robustness of GST against both visual and\ntextual adversarial attacks. Finally, GST yields strong performance gains in\nthe low-data regime. Code is available at\nhttps://github.com/gicheonkang/gst-visdial.\n","authors":["Gi-Cheon Kang","Sungdong Kim","Jin-Hwa Kim","Donghyun Kwak","Byoung-Tak Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.12502v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01196v1","updated":"2023-03-02T12:22:51Z","published":"2023-03-02T12:22:51Z","title":"STDepthFormer: Predicting Spatio-temporal Depth from Video with a\n  Self-supervised Transformer Model","summary":"  In this paper, a self-supervised model that simultaneously predicts a\nsequence of future frames from video-input with a novel spatial-temporal\nattention (ST) network is proposed. The ST transformer network allows\nconstraining both temporal consistency across future frames whilst constraining\nconsistency across spatial objects in the image at different scales. This was\nnot the case in prior works for depth prediction, which focused on predicting a\nsingle frame as output. The proposed model leverages prior scene knowledge such\nas object shape and texture similar to single-image depth inference methods,\nwhilst also constraining the motion and geometry from a sequence of input\nimages. Apart from the transformer architecture, one of the main contributions\nwith respect to prior works lies in the objective function that enforces\nspatio-temporal consistency across a sequence of output frames rather than a\nsingle output frame. As will be shown, this results in more accurate and robust\ndepth sequence forecasting. The model achieves highly accurate depth\nforecasting results that outperform existing baselines on the KITTI benchmark.\nExtensive ablation studies were performed to assess the effectiveness of the\nproposed techniques. One remarkable result of the proposed model is that it is\nimplicitly capable of forecasting the motion of objects in the scene, rather\nthan requiring complex models involving multi-object detection, segmentation\nand tracking.\n","authors":["Houssem Boulahbal","Adrian Voicila","Andrew Comport"],"pdf_url":"https://arxiv.org/pdf/2303.01196v1.pdf","comment":"Submitted to IROS 2023"},{"id":"http://arxiv.org/abs/2211.11393v2","updated":"2023-03-02T12:12:12Z","published":"2022-11-21T12:07:05Z","title":"TFormer: A throughout fusion transformer for multi-modal skin lesion\n  diagnosis","summary":"  Multi-modal skin lesion diagnosis (MSLD) has achieved remarkable success by\nmodern computer-aided diagnosis (CAD) technology based on deep convolutions.\nHowever, the information aggregation across modalities in MSLD remains\nchallenging due to severity unaligned spatial resolution (e.g., dermoscopic\nimage and clinical image) and heterogeneous data (e.g., dermoscopic image and\npatients' meta-data). Limited by the intrinsic local attention, most recent\nMSLD pipelines using pure convolutions struggle to capture representative\nfeatures in shallow layers, thus the fusion across different modalities is\nusually done at the end of the pipelines, even at the last layer, leading to an\ninsufficient information aggregation. To tackle the issue, we introduce a pure\ntransformer-based method, which we refer to as ``Throughout Fusion Transformer\n(TFormer)'', for sufficient information integration in MSLD. Different from the\nexisting approaches with convolutions, the proposed network leverages\ntransformer as feature extraction backbone, bringing more representative\nshallow features. We then carefully design a stack of dual-branch hierarchical\nmulti-modal transformer (HMT) blocks to fuse information across different image\nmodalities in a stage-by-stage way. With the aggregated information of image\nmodalities, a multi-modal transformer post-fusion (MTP) block is designed to\nintegrate features across image and non-image data. Such a strategy that\ninformation of the image modalities is firstly fused then the heterogeneous\nones enables us to better divide and conquer the two major challenges while\nensuring inter-modality dynamics are effectively modeled.\n","authors":["Yilan Zhang","Fengying Xie","Jianqi Chen"],"pdf_url":"https://arxiv.org/pdf/2211.11393v2.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.01178v1","updated":"2023-03-02T11:47:55Z","published":"2023-03-02T11:47:55Z","title":"Augmenting Medical Imaging: A Comprehensive Catalogue of 65 Techniques\n  for Enhanced Data Analysis","summary":"  In the realm of medical imaging, the training of machine learning models\nnecessitates a large and varied training dataset to ensure robustness and\ninteroperability. However, acquiring such diverse and heterogeneous data can be\ndifficult due to the need for expert labeling of each image and privacy\nconcerns associated with medical data. To circumvent these challenges, data\naugmentation has emerged as a promising and cost-effective technique for\nincreasing the size and diversity of the training dataset. In this study, we\nprovide a comprehensive review of the specific data augmentation techniques\nemployed in medical imaging and explore their benefits. We conducted an\nin-depth study of all data augmentation techniques used in medical imaging,\nidentifying 11 different purposes and collecting 65 distinct techniques. The\ntechniques were operationalized into spatial transformation-based, color and\ncontrast adjustment-based, noise-based, deformation-based, data mixing-based,\nfilters and mask-based, division-based, multi-scale and multi-view-based, and\nmeta-learning-based categories. We observed that some techniques require manual\nspecification of all parameters, while others rely on automation to adjust the\ntype and magnitude of augmentation based on task requirements. The utilization\nof these techniques enables the development of more robust models that can be\napplied in domains with limited or challenging data availability. It is\nexpected that the list of available techniques will expand in the future,\nproviding researchers with additional options to consider.\n","authors":["Manuel Cossio"],"pdf_url":"https://arxiv.org/pdf/2303.01178v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2303.01166v1","updated":"2023-03-02T11:15:59Z","published":"2023-03-02T11:15:59Z","title":"BPT: Binary Point Cloud Transformer for Place Recognition","summary":"  Place recognition, an algorithm to recognize the re-visited places, plays the\nrole of back-end optimization trigger in a full SLAM system. Many works\nequipped with deep learning tools, such as MLP, CNN, and transformer, have\nachieved great improvements in this research field. Point cloud transformer is\none of the excellent frameworks for place recognition applied in robotics, but\nwith large memory consumption and expensive computation, it is adverse to\nwidely deploy the various point cloud transformer networks in mobile or\nembedded devices. To solve this issue, we propose a binary point cloud\ntransformer for place recognition. As a result, a 32-bit full-precision model\ncan be reduced to a 1-bit model with less memory occupation and faster\nbinarized bitwise operations. To our best knowledge, this is the first binary\npoint cloud transformer that can be deployed on mobile devices for online\napplications such as place recognition. Experiments on several standard\nbenchmarks demonstrate that the proposed method can get comparable results with\nthe corresponding full-precision transformer model and even outperform some\nfull-precision deep learning methods. For example, the proposed method achieves\n93.28% at the top @1% and 85.74% at the top @1% on the Oxford RobotCar dataset\nin terms of the metric of the average recall rate. Meanwhile, the size and\nfloating point operations of the model with the same transformer structure\nreduce 56.1% and 34.1% respectively from original precision to binary\nprecision.\n","authors":["Zhixing Hou","Yuzhang Shang","Tian Gao","Yan Yan"],"pdf_url":"https://arxiv.org/pdf/2303.01166v1.pdf","comment":"Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robots (IROS 2023)"},{"id":"http://arxiv.org/abs/2303.01147v1","updated":"2023-03-02T10:52:30Z","published":"2023-03-02T10:52:30Z","title":"GeoLab: Geometry-based Tractography Parcellation of Superficial White\n  Matter","summary":"  Superficial white matter (SWM) has been less studied than long-range\nconnections despite being of interest to clinical research, andfew tractography\nparcellation methods have been adapted to SWM. Here, we propose an efficient\ngeometry-based parcellation method (GeoLab) that allows high-performance\nsegmentation of hundreds of short white matter bundles from a subject. This\nmethod has been designed for the SWM atlas of EBRAINS European infrastructure,\nwhich is composed of 657 bundles. The atlas projection relies on the\nprecomputed statistics of six bundle-specific geometrical properties of atlas\nstreamlines. In the spirit of RecoBundles, a global and local streamline-based\nregistration (SBR) is used to align the subject to the atlas space. Then, the\nstreamlines are labeled taking into account the six geometrical parameters\ndescribing the similarity to the streamlines in the model bundle. Compared to\nother state-of-the-art methods, GeoLab allows the extraction of more bundles\nwith a higher number of streamlines.\n","authors":["Nabil Vindas","Nicole Labra Avila","Fan Zhang","Tengfei Xue","Lauren J. O'Donnell","Jean-François Mangin"],"pdf_url":"https://arxiv.org/pdf/2303.01147v1.pdf","comment":"Accepted by the ISBI 2023 conference, 5 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.14441v3","updated":"2023-03-02T10:48:12Z","published":"2022-12-29T19:32:20Z","title":"Fruit Ripeness Classification: a Survey","summary":"  Fruit is a key crop in worldwide agriculture feeding millions of people. The\nstandard supply chain of fruit products involves quality checks to guarantee\nfreshness, taste, and, most of all, safety. An important factor that determines\nfruit quality is its stage of ripening. This is usually manually classified by\nfield experts, making it a labor-intensive and error-prone process. Thus, there\nis an arising need for automation in fruit ripeness classification. Many\nautomatic methods have been proposed that employ a variety of feature\ndescriptors for the food item to be graded. Machine learning and deep learning\ntechniques dominate the top-performing methods. Furthermore, deep learning can\noperate on raw data and thus relieve the users from having to compute complex\nengineered features, which are often crop-specific. In this survey, we review\nthe latest methods proposed in the literature to automatize fruit ripeness\nclassification, highlighting the most common feature descriptors they operate\non.\n","authors":["Matteo Rizzo","Matteo Marcuzzo","Alessandro Zangari","Andrea Gasparetto","Andrea Albarelli"],"pdf_url":"https://arxiv.org/pdf/2212.14441v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00232v2","updated":"2023-03-02T10:02:03Z","published":"2023-03-01T04:52:49Z","title":"Towards more precise automatic analysis: a comprehensive survey of deep\n  learning-based multi-organ segmentation","summary":"  Accurate segmentation of multiple organs of the head, neck, chest, and\nabdomen from medical images is an essential step in computer-aided diagnosis,\nsurgical navigation, and radiation therapy. In the past few years, with a\ndata-driven feature extraction approach and end-to-end training, automatic deep\nlearning-based multi-organ segmentation method has far outperformed traditional\nmethods and become a new research topic. This review systematically summarizes\nthe latest research in this field. For the first time, from the perspective of\nfull and imperfect annotation, we comprehensively compile 161 studies on deep\nlearning-based multi-organ segmentation in multiple regions such as the head\nand neck, chest, and abdomen, containing a total of 214 related references. The\nmethod based on full annotation summarizes the existing methods from four\naspects: network architecture, network dimension, network dedicated modules,\nand network loss function. The method based on imperfect annotation summarizes\nthe existing methods from two aspects: weak annotation-based methods and semi\nannotation-based methods. We also summarize frequently used datasets for\nmulti-organ segmentation and discuss new challenges and new research trends in\nthis field.\n","authors":["Xiaoyu Liu","Linhao Qu","Ziyue Xie","Jiayue Zhao","Yonghong Shi","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2303.00232v2.pdf","comment":"25 pages, 9 figures, 16 tabels"},{"id":"http://arxiv.org/abs/2303.01112v1","updated":"2023-03-02T09:47:28Z","published":"2023-03-02T09:47:28Z","title":"Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves","summary":"  Formula-driven supervised learning (FDSL) has been shown to be an effective\nmethod for pre-training vision transformers, where ExFractalDB-21k was shown to\nexceed the pre-training effect of ImageNet-21k. These studies also indicate\nthat contours mattered more than textures when pre-training vision\ntransformers. However, the lack of a systematic investigation as to why these\ncontour-oriented synthetic datasets can achieve the same accuracy as real\ndatasets leaves much room for skepticism. In the present work, we develop a\nnovel methodology based on circular harmonics for systematically investigating\nthe design space of contour-oriented synthetic datasets. This allows us to\nefficiently search the optimal range of FDSL parameters and maximize the\nvariety of synthetic images in the dataset, which we found to be a critical\nfactor. When the resulting new dataset VisualAtom-21k is used for pre-training\nViT-Base, the top-1 accuracy reached 83.7% when fine-tuning on ImageNet-1k.\nThis is close to the top-1 accuracy (84.2%) achieved by JFT-300M pre-training,\nwhile the number of images is 1/14. Unlike JFT-300M which is a static dataset,\nthe quality of synthetic datasets will continue to improve, and the current\nwork is a testament to this possibility. FDSL is also free of the common issues\nassociated with real images, e.g. privacy/copyright issues, labeling\ncosts/errors, and ethical biases.\n","authors":["Sora Takashima","Ryo Hayamizu","Nakamasa Inoue","Hirokatsu Kataoka","Rio Yokota"],"pdf_url":"https://arxiv.org/pdf/2303.01112v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2210.14648v3","updated":"2023-03-02T09:42:58Z","published":"2022-10-26T11:49:30Z","title":"Masked Modeling Duo: Learning Representations by Encouraging Both\n  Networks to Model the Input","summary":"  Masked Autoencoders is a simple yet powerful self-supervised learning method.\nHowever, it learns representations indirectly by reconstructing masked input\npatches. Several methods learn representations directly by predicting\nrepresentations of masked patches; however, we think using all patches to\nencode training signal representations is suboptimal. We propose a new method,\nMasked Modeling Duo (M2D), that learns representations directly while obtaining\ntraining signals using only masked patches. In the M2D, the online network\nencodes visible patches and predicts masked patch representations, and the\ntarget network, a momentum encoder, encodes masked patches. To better predict\ntarget representations, the online network should model the input well, while\nthe target network should also model it well to agree with online predictions.\nThen the learned representations should better model the input. We validated\nthe M2D by learning general-purpose audio representations, and M2D set new\nstate-of-the-art performance on tasks such as UrbanSound8K, VoxCeleb1,\nAudioSet20K, GTZAN, and SpeechCommandsV2. We additionally validate the\neffectiveness of M2D for images using ImageNet-1K in the appendix.\n","authors":["Daisuke Niizumi","Daiki Takeuchi","Yasunori Ohishi","Noboru Harada","Kunio Kashino"],"pdf_url":"https://arxiv.org/pdf/2210.14648v3.pdf","comment":"6 pages, 3 figures, and 6 tables. To appear at ICASSP2023"},{"id":"http://arxiv.org/abs/2303.01105v1","updated":"2023-03-02T09:37:56Z","published":"2023-03-02T09:37:56Z","title":"Evidence-empowered Transfer Learning for Alzheimer's Disease","summary":"  Transfer learning has been widely utilized to mitigate the data scarcity\nproblem in the field of Alzheimer's disease (AD). Conventional transfer\nlearning relies on re-using models trained on AD-irrelevant tasks such as\nnatural image classification. However, it often leads to negative transfer due\nto the discrepancy between the non-medical source and target medical domains.\nTo address this, we present evidence-empowered transfer learning for AD\ndiagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary\ntask, namely morphological change prediction, without requiring additional MRI\ndata. In this auxiliary task, the diagnosis model learns the evidential and\ntransferable knowledge from morphological features in MRI scans. Experimental\nresults demonstrate that our framework is not only effective in improving\ndetection performance regardless of model capacity, but also more\ndata-efficient and faithful.\n","authors":["Kai Tzu-iunn Ong","Hana Kim","Minjin Kim","Jinseong Jang","Beomseok Sohn","Yoon Seong Choi","Dosik Hwang","Seong Jae Hwang","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.01105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01099v1","updated":"2023-03-02T09:32:32Z","published":"2023-03-02T09:32:32Z","title":"Multi-Head Multi-Loss Model Calibration","summary":"  Delivering meaningful uncertainty estimates is essential for a successful\ndeployment of machine learning models in the clinical practice. A central\naspect of uncertainty quantification is the ability of a model to return\npredictions that are well-aligned with the actual probability of the model\nbeing correct, also known as model calibration. Although many methods have been\nproposed to improve calibration, no technique can match the simple, but\nexpensive approach of training an ensemble of deep neural networks. In this\npaper we introduce a form of simplified ensembling that bypasses the costly\ntraining and inference of deep ensembles, yet it keeps its calibration\ncapabilities. The idea is to replace the common linear classifier at the end of\na network by a set of heads that are supervised with different loss functions\nto enforce diversity on their predictions. Specifically, each head is trained\nto minimize a weighted Cross-Entropy loss, but the weights are different among\nthe different branches. We show that the resulting averaged predictions can\nachieve excellent calibration without sacrificing accuracy in two challenging\ndatasets for histopathological and endoscopic image classification. Our\nexperiments indicate that Multi-Head Multi-Loss classifiers are inherently\nwell-calibrated, outperforming other recent calibration techniques and even\nchallenging Deep Ensembles' performance. Code to reproduce our experiments can\nbe found at \\url{https://github.com/agaldran/mhml_calibration} .\n","authors":["Adrian Galdran","Johan Verjans","Gustavo Carneiro","Miguel A. González Ballester"],"pdf_url":"https://arxiv.org/pdf/2303.01099v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2111.00743v4","updated":"2023-03-02T09:31:50Z","published":"2021-11-01T07:39:38Z","title":"Towards the Generalization of Contrastive Self-Supervised Learning","summary":"  Recently, self-supervised learning has attracted great attention, since it\nonly requires unlabeled data for model training. Contrastive learning is one\npopular method for self-supervised learning and has achieved promising\nempirical performance. However, the theoretical understanding of its\ngeneralization ability is still limited. To this end, we define a kind of\n$(\\sigma,\\delta)$-measure to mathematically quantify the data augmentation, and\nthen provide an upper bound of the downstream classification error rate based\non the measure. It reveals that the generalization ability of contrastive\nself-supervised learning is related to three key factors: alignment of positive\nsamples, divergence of class centers, and concentration of augmented data. The\nfirst two factors are properties of learned representations, while the third\none is determined by pre-defined data augmentation. We further investigate two\ncanonical contrastive losses, InfoNCE and cross-correlation, to show how they\nprovably achieve the first two factors. Moreover, we conduct experiments to\nstudy the third factor, and observe a strong correlation between downstream\nperformance and the concentration of augmented data.\n","authors":["Weiran Huang","Mingyang Yi","Xuyang Zhao","Zihao Jiang"],"pdf_url":"https://arxiv.org/pdf/2111.00743v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01092v1","updated":"2023-03-02T09:26:20Z","published":"2023-03-02T09:26:20Z","title":"ArCL: Enhancing Contrastive Learning with Augmentation-Robust\n  Representations","summary":"  Self-Supervised Learning (SSL) is a paradigm that leverages unlabeled data\nfor model training. Empirical studies show that SSL can achieve promising\nperformance in distribution shift scenarios, where the downstream and training\ndistributions differ. However, the theoretical understanding of its\ntransferability remains limited. In this paper, we develop a theoretical\nframework to analyze the transferability of self-supervised contrastive\nlearning, by investigating the impact of data augmentation on it. Our results\nreveal that the downstream performance of contrastive learning depends largely\non the choice of data augmentation. Moreover, we show that contrastive learning\nfails to learn domain-invariant features, which limits its transferability.\nBased on these theoretical insights, we propose a novel method called\nAugmentation-robust Contrastive Learning (ArCL), which guarantees to learn\ndomain-invariant features and can be easily integrated with existing\ncontrastive learning algorithms. We conduct experiments on several datasets and\nshow that ArCL significantly improves the transferability of contrastive\nlearning.\n","authors":["Xuyang Zhao","Tianqi Du","Yisen Wang","Jun Yao","Weiran Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01092v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01091v1","updated":"2023-03-02T09:26:14Z","published":"2023-03-02T09:26:14Z","title":"OPE-SR: Orthogonal Position Encoding for Designing a Parameter-free\n  Upsampling Module in Arbitrary-scale Image Super-Resolution","summary":"  Implicit neural representation (INR) is a popular approach for\narbitrary-scale image super-resolution (SR), as a key component of INR,\nposition encoding improves its representation ability. Motivated by position\nencoding, we propose orthogonal position encoding (OPE) - an extension of\nposition encoding - and an OPE-Upscale module to replace the INR-based\nupsampling module for arbitrary-scale image super-resolution. Same as INR, our\nOPE-Upscale Module takes 2D coordinates and latent code as inputs; however it\ndoes not require training parameters. This parameter-free feature allows the\nOPE-Upscale Module to directly perform linear combination operations to\nreconstruct an image in a continuous manner, achieving an arbitrary-scale image\nreconstruction. As a concise SR framework, our method has high computing\nefficiency and consumes less memory comparing to the state-of-the-art (SOTA),\nwhich has been confirmed by extensive experiments and evaluations. In addition,\nour method has comparable results with SOTA in arbitrary scale image\nsuper-resolution. Last but not the least, we show that OPE corresponds to a set\nof orthogonal basis, justifying our design principle.\n","authors":["Gaochao Song","Luo Zhang","Ran Su","Jianfeng Shi","Ying He","Qian Sun"],"pdf_url":"https://arxiv.org/pdf/2303.01091v1.pdf","comment":"Accepted by CVPR 2023. 11 pages"},{"id":"http://arxiv.org/abs/2212.09748v2","updated":"2023-03-02T09:06:55Z","published":"2022-12-19T18:59:58Z","title":"Scalable Diffusion Models with Transformers","summary":"  We explore a new class of diffusion models based on the transformer\narchitecture. We train latent diffusion models of images, replacing the\ncommonly-used U-Net backbone with a transformer that operates on latent\npatches. We analyze the scalability of our Diffusion Transformers (DiTs)\nthrough the lens of forward pass complexity as measured by Gflops. We find that\nDiTs with higher Gflops -- through increased transformer depth/width or\nincreased number of input tokens -- consistently have lower FID. In addition to\npossessing good scalability properties, our largest DiT-XL/2 models outperform\nall prior diffusion models on the class-conditional ImageNet 512x512 and\n256x256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.\n","authors":["William Peebles","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2212.09748v2.pdf","comment":"Code, project page and videos available at\n  https://www.wpeebles.com/DiT"},{"id":"http://arxiv.org/abs/2210.06031v2","updated":"2023-03-02T09:05:43Z","published":"2022-10-12T09:08:27Z","title":"Long-Form Video-Language Pre-Training with Multimodal Temporal\n  Contrastive Learning","summary":"  Large-scale video-language pre-training has shown significant improvement in\nvideo-language understanding tasks. Previous studies of video-language\npretraining mainly focus on short-form videos (i.e., within 30 seconds) and\nsentences, leaving long-form video-language pre-training rarely explored.\nDirectly learning representation from long-form videos and language may benefit\nmany long-form video-language understanding tasks. However, it is challenging\ndue to the difficulty of modeling long-range relationships and the heavy\ncomputational burden caused by more frames. In this paper, we introduce a\nLong-Form VIdeo-LAnguage pre-training model (LF-VILA) and train it on a\nlarge-scale long-form video and paragraph dataset constructed from an existing\npublic dataset. To effectively capture the rich temporal dynamics and to better\nalign video and language in an efficient end-to-end manner, we introduce two\nnovel designs in our LF-VILA model. We first propose a Multimodal Temporal\nContrastive (MTC) loss to learn the temporal relation across different\nmodalities by encouraging fine-grained alignment between long-form videos and\nparagraphs. Second, we propose a Hierarchical Temporal Window Attention (HTWA)\nmechanism to effectively capture long-range dependency while reducing\ncomputational cost in Transformer. We fine-tune the pre-trained LF-VILA model\non seven downstream long-form video-language understanding tasks of\nparagraph-to-video retrieval and long-form video question-answering, and\nachieve new state-of-the-art performances. Specifically, our model achieves\n16.1% relative improvement on ActivityNet paragraph-to-video retrieval task and\n2.4% on How2QA task, respectively. We release our code, dataset, and\npre-trained models at https://github.com/microsoft/XPretrain.\n","authors":["Yuchong Sun","Hongwei Xue","Ruihua Song","Bei Liu","Huan Yang","Jianlong Fu"],"pdf_url":"https://arxiv.org/pdf/2210.06031v2.pdf","comment":"Accepted by NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.01080v1","updated":"2023-03-02T09:03:11Z","published":"2023-03-02T09:03:11Z","title":"LANDMARK: Language-guided Representation Enhancement Framework for Scene\n  Graph Generation","summary":"  Scene graph generation (SGG) is a sophisticated task that suffers from both\ncomplex visual features and dataset long-tail problem. Recently, various\nunbiased strategies have been proposed by designing novel loss functions and\ndata balancing strategies. Unfortunately, these unbiased methods fail to\nemphasize language priors in feature refinement perspective. Inspired by the\nfact that predicates are highly correlated with semantics hidden in\nsubject-object pair and global context, we propose LANDMARK (LANguage-guiDed\nrepresentationenhanceMent frAmewoRK) that learns predicate-relevant\nrepresentations from language-vision interactive patterns, global language\ncontext and pair-predicate correlation. Specifically, we first project object\nlabels to three distinctive semantic embeddings for different representation\nlearning. Then, Language Attention Module (LAM) and Experience Estimation\nModule (EEM) process subject-object word embeddings to attention vector and\npredicate distribution, respectively. Language Context Module (LCM) encodes\nglobal context from each word embed-ding, which avoids isolated learning from\nlocal information. Finally, modules outputs are used to update visual\nrepresentations and SGG model's prediction. All language representations are\npurely generated from object categories so that no extra knowledge is needed.\nThis framework is model-agnostic and consistently improves performance on\nexisting SGG models. Besides, representation-level unbiased strategies endow\nLANDMARK the advantage of compatibility with other methods. Code is available\nat https://github.com/rafa-cxg/PySGG-cxg.\n","authors":["Xiaoguang Chang","Teng Wang","Shaowei Cai","Changyin Sun"],"pdf_url":"https://arxiv.org/pdf/2303.01080v1.pdf","comment":"Revision period in Applied Intelligence (APIN)"},{"id":"http://arxiv.org/abs/2112.01784v2","updated":"2023-03-02T08:54:48Z","published":"2021-12-03T08:37:52Z","title":"Fully automatic integration of dental CBCT images and full-arch\n  intraoral impressions with stitching error correction via individual tooth\n  segmentation and identification","summary":"  We present a fully automated method of integrating intraoral scan (IOS) and\ndental cone-beam computerized tomography (CBCT) images into one image by\ncomplementing each image's weaknesses. Dental CBCT alone may not be able to\ndelineate precise details of the tooth surface due to limited image resolution\nand various CBCT artifacts, including metal-induced artifacts. IOS is very\naccurate for the scanning of narrow areas, but it produces cumulative stitching\nerrors during full-arch scanning. The proposed method is intended not only to\ncompensate the low-quality of CBCT-derived tooth surfaces with IOS, but also to\ncorrect the cumulative stitching errors of IOS across the entire dental arch.\nMoreover, the integration provide both gingival structure of IOS and tooth\nroots of CBCT in one image. The proposed fully automated method consists of\nfour parts; (i) individual tooth segmentation and identification module for IOS\ndata (TSIM-IOS); (ii) individual tooth segmentation and identification module\nfor CBCT data (TSIM-CBCT); (iii) global-to-local tooth registration between IOS\nand CBCT; and (iv) stitching error correction of full-arch IOS. The\nexperimental results show that the proposed method achieved landmark and\nsurface distance errors of 112.4 $\\mu$m and 301.7 $\\mu$m, respectively.\n","authors":["Tae Jun Jang","Hye Sun Yun","Chang Min Hyun","Jong-Eun Kim","Sang-Hwy Lee","Jin Keun Seo"],"pdf_url":"https://arxiv.org/pdf/2112.01784v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01069v1","updated":"2023-03-02T08:43:40Z","published":"2023-03-02T08:43:40Z","title":"Implicit Neural Representations for Modeling of Abdominal Aortic\n  Aneurysm Progression","summary":"  Abdominal aortic aneurysms (AAAs) are progressive dilatations of the\nabdominal aorta that, if left untreated, can rupture with lethal consequences.\nImaging-based patient monitoring is required to select patients eligible for\nsurgical repair. In this work, we present a model based on implicit neural\nrepresentations (INRs) to model AAA progression. We represent the AAA wall over\ntime as the zero-level set of a signed distance function (SDF), estimated by a\nmultilayer perception that operates on space and time. We optimize this INR\nusing automatically extracted segmentation masks in longitudinal CT data. This\nnetwork is conditioned on spatiotemporal coordinates and represents the AAA\nsurface at any desired resolution at any moment in time. Using regularization\non spatial and temporal gradients of the SDF, we ensure proper interpolation of\nthe AAA shape. We demonstrate the network's ability to produce AAA\ninterpolations with average surface distances ranging between 0.72 and 2.52 mm\nfrom images acquired at highly irregular intervals. The results indicate that\nour model can accurately interpolate AAA shapes over time, with potential\nclinical value for a more personalised assessment of AAA progression.\n","authors":["Dieuwertje Alblas","Marieke Hofman","Christoph Brune","Kak Khee Yeung","Jelmer M. Wolterink"],"pdf_url":"https://arxiv.org/pdf/2303.01069v1.pdf","comment":"FIMH 2023 (submitted)"},{"id":"http://arxiv.org/abs/2210.15075v2","updated":"2023-03-02T08:25:37Z","published":"2022-10-26T23:11:02Z","title":"IDEAL: Improved DEnse locAL Contrastive Learning for Semi-Supervised\n  Medical Image Segmentation","summary":"  Due to the scarcity of labeled data, Contrastive Self-Supervised Learning\n(SSL) frameworks have lately shown great potential in several medical image\nanalysis tasks. However, the existing contrastive mechanisms are sub-optimal\nfor dense pixel-level segmentation tasks due to their inability to mine local\nfeatures. To this end, we extend the concept of metric learning to the\nsegmentation task, using a dense (dis)similarity learning for pre-training a\ndeep encoder network, and employing a semi-supervised paradigm to fine-tune for\nthe downstream task. Specifically, we propose a simple convolutional projection\nhead for obtaining dense pixel-level features, and a new contrastive loss to\nutilize these dense projections thereby improving the local representations. A\nbidirectional consistency regularization mechanism involving two-stream model\ntraining is devised for the downstream task. Upon comparison, our IDEAL method\noutperforms the SoTA methods by fair margins on cardiac MRI segmentation. Code\navailable: https://github.com/hritam-98/IDEAL-ICASSP23\n","authors":["Hritam Basak","Soumitri Chattopadhyay","Rohit Kundu","Sayan Nag","Rammohan Mallipeddi"],"pdf_url":"https://arxiv.org/pdf/2210.15075v2.pdf","comment":"Paper accepted for publication at IEEE ICASSP 2023"},{"id":"http://arxiv.org/abs/2209.06430v4","updated":"2023-03-02T08:24:23Z","published":"2022-09-14T05:47:02Z","title":"CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language\n  Representation Alignment","summary":"  The pre-trained image-text models, like CLIP, have demonstrated the strong\npower of vision-language representation learned from a large scale of\nweb-collected image-text data. In light of the well-learned visual features,\nsome existing works transfer image representation to video domain and achieve\ngood results. However, how to utilize image-language pre-trained model (e.g.,\nCLIP) for video-language pre-training (post-pretraining) is still under\nexplored. In this paper, we investigate two questions: 1) what are the factors\nhindering post-pretraining CLIP to further improve the performance on\nvideo-language tasks? and 2) how to mitigate the impact of these factors?\nThrough a series of comparative experiments and analyses, we find that the data\nscale and domain gap between language sources have great impacts. Motivated by\nthese, we propose a Omnisource Cross-modal Learning method equipped with a\nVideo Proxy mechanism on the basis of CLIP, namely CLIP-ViP. Extensive results\nshow that our approach improves the performance of CLIP on video-text retrieval\nby a large margin. Our model also achieves SOTA results on a variety of\ndatasets, including MSR-VTT, DiDeMo, LSMDC, and ActivityNet. We will release\nour code and pre-trained CLIP-ViP models at\nhttps://github.com/microsoft/XPretrain/tree/main/CLIP-ViP.\n","authors":["Hongwei Xue","Yuchong Sun","Bei Liu","Jianlong Fu","Ruihua Song","Houqiang Li","Jiebo Luo"],"pdf_url":"https://arxiv.org/pdf/2209.06430v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01054v1","updated":"2023-03-02T08:24:13Z","published":"2023-03-02T08:24:13Z","title":"Deep Learning based Segmentation of Optical Coherence Tomographic Images\n  of Human Saphenous Varicose Vein","summary":"  Deep-learning based segmentation model is proposed for Optical Coherence\nTomography images of human varicose vein based on the U-Net model employing\natrous convolution with residual blocks, which gives an accuracy of 0.9932.\n","authors":["Maryam Viqar","Violeta Madjarova","Amit Kumar Yadav","Desislava Pashkuleva","Alexander S. Machikhin"],"pdf_url":"https://arxiv.org/pdf/2303.01054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01052v1","updated":"2023-03-02T08:18:22Z","published":"2023-03-02T08:18:22Z","title":"Demystifying Causal Features on Adversarial Examples and Causal\n  Inoculation for Robust Network by Adversarial Instrumental Variable\n  Regression","summary":"  The origin of adversarial examples is still inexplicable in research fields,\nand it arouses arguments from various viewpoints, albeit comprehensive\ninvestigations. In this paper, we propose a way of delving into the unexpected\nvulnerability in adversarially trained networks from a causal perspective,\nnamely adversarial instrumental variable (IV) regression. By deploying it, we\nestimate the causal relation of adversarial prediction under an unbiased\nenvironment dissociated from unknown confounders. Our approach aims to\ndemystify inherent causal features on adversarial examples by leveraging a\nzero-sum optimization game between a casual feature estimator (i.e., hypothesis\nmodel) and worst-case counterfactuals (i.e., test function) disturbing to find\ncausal features. Through extensive analyses, we demonstrate that the estimated\ncausal features are highly related to the correct prediction for adversarial\nrobustness, and the counterfactuals exhibit extreme features significantly\ndeviating from the correct prediction. In addition, we present how to\neffectively inoculate CAusal FEatures (CAFE) into defense networks for\nimproving adversarial robustness.\n","authors":["Junho Kim. Byung-Kwan Lee","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2303.01052v1.pdf","comment":"Accepted in CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01047v1","updated":"2023-03-02T08:02:14Z","published":"2023-03-02T08:02:14Z","title":"Task-Specific Context Decoupling for Object Detection","summary":"  Classification and localization are two main sub-tasks in object detection.\nNonetheless, these two tasks have inconsistent preferences for feature context,\ni.e., localization expects more boundary-aware features to accurately regress\nthe bounding box, while more semantic context is preferred for object\nclassification. Exsiting methods usually leverage disentangled heads to learn\ndifferent feature context for each task. However, the heads are still applied\non the same input features, which leads to an imperfect balance between\nclassifcation and localization. In this work, we propose a novel Task-Specific\nCOntext DEcoupling (TSCODE) head which further disentangles the feature\nencoding for two tasks. For classification, we generate spatially-coarse but\nsemantically-strong feature encoding. For localization, we provide\nhigh-resolution feature map containing more edge information to better regress\nobject boundaries. TSCODE is plug-and-play and can be easily incorperated into\nexisting detection pipelines. Extensive experiments demonstrate that our method\nstably improves different detectors by over 1.0 AP with less computational\ncost. Our code and models will be publicly released.\n","authors":["Jiayuan Zhuang","Zheng Qin","Hao Yu","Xucan Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01047v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01046v1","updated":"2023-03-02T08:00:22Z","published":"2023-03-02T08:00:22Z","title":"Jointly Visual- and Semantic-Aware Graph Memory Networks for Temporal\n  Sentence Localization in Videos","summary":"  Temporal sentence localization in videos (TSLV) aims to retrieve the most\ninterested segment in an untrimmed video according to a given sentence query.\nHowever, almost of existing TSLV approaches suffer from the same limitations:\n(1) They only focus on either frame-level or object-level visual representation\nlearning and corresponding correlation reasoning, but fail to integrate them\nboth; (2) They neglect to leverage the rich semantic contexts to further\nbenefit the query reasoning. To address these issues, in this paper, we propose\na novel Hierarchical Visual- and Semantic-Aware Reasoning Network (HVSARN),\nwhich enables both visual- and semantic-aware query reasoning from object-level\nto frame-level. Specifically, we present a new graph memory mechanism to\nperform visual-semantic query reasoning: For visual reasoning, we design a\nvisual graph memory to leverage visual information of video; For semantic\nreasoning, a semantic graph memory is also introduced to explicitly leverage\nsemantic knowledge contained in the classes and attributes of video objects,\nand perform correlation reasoning in the semantic space. Experiments on three\ndatasets demonstrate that our HVSARN achieves a new state-of-the-art\nperformance.\n","authors":["Daizong Liu","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.01046v1.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2303.00351v2","updated":"2023-03-02T07:59:22Z","published":"2023-03-01T09:27:08Z","title":"An end-to-end SE(3)-equivariant segmentation network","summary":"  Convolutional neural networks (CNNs) allow for parameter sharing and\ntranslational equivariance by using convolutional kernels in their linear\nlayers. By restricting these kernels to be SO(3)-steerable, CNNs can further\nimprove parameter sharing and equivariance. These equivariant convolutional\nlayers have several advantages over standard convolutional layers, including\nincreased robustness to unseen poses, smaller network size, and improved sample\nefficiency. Despite this, most segmentation networks used in medical image\nanalysis continue to rely on standard convolutional kernels. In this paper, we\npresent a new family of segmentation networks that use equivariant voxel\nconvolutions based on spherical harmonics, as well as equivariant pooling and\nnormalization operations. These SE(3)-equivariant volumetric segmentation\nnetworks, which are robust to data poses not seen during training, do not\nrequire rotation-based data augmentation during training. In addition, we\ndemonstrate improved segmentation performance in MRI brain tumor and healthy\nbrain structure segmentation tasks, with enhanced robustness to reduced amounts\nof training data and improved parameter efficiency. Code to reproduce our\nresults, and to implement the equivariant segmentation networks for other tasks\nis available at http://github.com/SCAN-NRAD/e3nn_Unet\n","authors":["Ivan Diaz","Mario Geiger","Richard Iain McKinley"],"pdf_url":"https://arxiv.org/pdf/2303.00351v2.pdf","comment":"19 pages, 10 figures, submitted to the Journal of Machine Learning\n  for Biomedical Imaging"},{"id":"http://arxiv.org/abs/2303.01043v1","updated":"2023-03-02T07:56:04Z","published":"2023-03-02T07:56:04Z","title":"I2P-Rec: Recognizing Images on Large-scale Point Cloud Maps through\n  Bird's Eye View Projections","summary":"  Place recognition is an important technique for autonomous cars to achieve\nfull autonomy since it can provide an initial guess to online localization\nalgorithms. Although current methods based on images or point clouds have\nachieved satisfactory performance, localizing the images on a large-scale point\ncloud map remains a fairly unexplored problem. This cross-modal matching task\nis challenging due to the difficulty in extracting consistent descriptors from\nimages and point clouds. In this paper, we propose the I2P-Rec method to solve\nthe problem by transforming the cross-modal data into the same modality.\nSpecifically, we leverage on the recent success of depth estimation networks to\nrecover point clouds from images. We then project the point clouds into Bird's\nEye View (BEV) images. Using the BEV image as an intermediate representation,\nwe extract global features with a Convolutional Neural Network followed by a\nNetVLAD layer to perform matching. We evaluate our method on the KITTI dataset.\nThe experimental results show that, with only a small set of training data,\nI2P-Rec can achieve a recall rate at Top-1 over 90\\%. Also, it can generalize\nwell to unknown environments, achieving recall rates at Top-1\\% over 80\\% and\n90\\%, when localizing monocular images and stereo images on point cloud maps,\nrespectively.\n","authors":["Yixuan Li","Shuhang Zheng","Zhu Yu","Beinan Yu","Si-Yuan Cao","Lun Luo","Hui-Liang Shen"],"pdf_url":"https://arxiv.org/pdf/2303.01043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.11294v2","updated":"2023-03-02T07:51:07Z","published":"2022-09-22T20:14:43Z","title":"T2FPV: Dataset and Method for Correcting First-Person View Errors in\n  Pedestrian Trajectory Prediction","summary":"  Predicting pedestrian motion is essential for developing socially-aware\nrobots that interact in a crowded environment. While the natural visual\nperspective for a social interaction setting is an egocentric view, the\nmajority of existing work in trajectory prediction therein has been\ninvestigated purely in the top-down trajectory space. To support first-person\nview trajectory prediction research, we present T2FPV, a method for\nconstructing high-fidelity first-person view (FPV) datasets given a real-world,\ntop-down trajectory dataset; we showcase our approach on the ETH/UCY pedestrian\ndataset to generate the egocentric visual data of all interacting pedestrians,\ncreating the T2FPV-ETH dataset. In this setting, FPV-specific errors arise due\nto imperfect detection and tracking, occlusions, and field-of-view (FOV)\nlimitations of the camera. To address these errors, we propose CoFE, a module\nthat further refines the imputation of missing data in an end-to-end manner\nwith trajectory forecasting algorithms. Our method reduces the impact of such\nFPV errors on downstream prediction performance, decreasing displacement error\nby more than 10% on average. To facilitate research engagement, we release our\nT2FPV-ETH dataset and software tools.\n","authors":["Benjamin Stoler","Meghdeep Jana","Soonmin Hwang","Jean Oh"],"pdf_url":"https://arxiv.org/pdf/2209.11294v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01038v1","updated":"2023-03-02T07:50:41Z","published":"2023-03-02T07:50:41Z","title":"Neural Intrinsic Embedding for Non-rigid Point Cloud Matching","summary":"  As a primitive 3D data representation, point clouds are prevailing in 3D\nsensing, yet short of intrinsic structural information of the underlying\nobjects. Such discrepancy poses great challenges on directly establishing\ncorrespondences between point clouds sampled from deformable shapes. In light\nof this, we propose Neural Intrinsic Embedding (NIE) to embed each vertex into\na high-dimensional space in a way that respects the intrinsic structure. Based\nupon NIE, we further present a weakly-supervised learning framework for\nnon-rigid point cloud registration. Unlike the prior works, we do not require\nexpansive and sensitive off-line basis construction (e.g., eigen-decomposition\nof Laplacians), nor do we require ground-truth correspondence labels for\nsupervision. We empirically show that our framework performs on par with or\neven better than the state-of-the-art baselines, which generally require more\nsupervision and/or more structural geometric input.\n","authors":["Puhua Jiang","Mingze Sun","Ruqi Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01038v1.pdf","comment":"To appear at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01036v1","updated":"2023-03-02T07:47:07Z","published":"2023-03-02T07:47:07Z","title":"Validated respiratory drug deposition predictions from 2D and 3D medical\n  images with statistical shape models and convolutional neural networks","summary":"  For the one billion sufferers of respiratory disease, managing their disease\nwith inhalers crucially influences their quality of life. Generic treatment\nplans could be improved with the aid of computational models that account for\npatient-specific features such as breathing pattern, lung pathology and\nmorphology. Therefore, we aim to develop and validate an automated\ncomputational framework for patient-specific deposition modelling. To that end,\nan image processing approach is proposed that could produce 3D patient\nrespiratory geometries from 2D chest X-rays and 3D CT images. We evaluated the\nairway and lung morphology produced by our image processing framework, and\nassessed deposition compared to in vivo data. The 2D-to-3D image processing\nreproduces airway diameter to 9% median error compared to ground truth\nsegmentations, but is sensitive to outliers of up to 33% due to lung outline\nnoise. Predicted regional deposition gave 5% median error compared to in vivo\nmeasurements. The proposed framework is capable of providing patient-specific\ndeposition measurements for varying treatments, to determine which treatment\nwould best satisfy the needs imposed by each patient (such as disease and\nlung/airway morphology). Integration of patient-specific modelling into\nclinical practice as an additional decision-making tool could optimise\ntreatment plans and lower the burden of respiratory diseases.\n","authors":["Josh Williams","Haavard Ahlqvist","Alexander Cunningham","Andrew Kirby","Ira Katz","John Fleming","Joy Conway","Steve Cunningham","Ali Ozel","Uwe Wolfram"],"pdf_url":"https://arxiv.org/pdf/2303.01036v1.pdf","comment":"37 pages main text (including frontmatter). 9 figures. Additional\n  supplementary material"},{"id":"http://arxiv.org/abs/2303.01032v1","updated":"2023-03-02T07:42:07Z","published":"2023-03-02T07:42:07Z","title":"ESceme: Vision-and-Language Navigation with Episodic Scene Memory","summary":"  Vision-and-language navigation (VLN) simulates a visual agent that follows\nnatural-language navigation instructions in real-world scenes. Existing\napproaches have made enormous progress in navigation in new environments, such\nas beam search, pre-exploration, and dynamic or hierarchical history encoding.\nTo balance generalization and efficiency, we resort to memorizing visited\nscenarios apart from the ongoing route while navigating. In this work, we\nintroduce a mechanism of Episodic Scene memory (ESceme) for VLN that wakes an\nagent's memories of past visits when it enters the current scene. The episodic\nscene memory allows the agent to envision a bigger picture of the next\nprediction. In this way, the agent learns to make the most of currently\navailable information instead of merely adapting to the seen environments. We\nprovide a simple yet effective implementation by enhancing the observation\nfeatures of candidate nodes during training. We verify the superiority of\nESceme on three VLN tasks, including short-horizon navigation (R2R),\nlong-horizon navigation (R4R), and vision-and-dialog navigation (CVDN), and\nachieve a new state-of-the-art. Code is available:\n\\url{https://github.com/qizhust/esceme}.\n","authors":["Qi Zheng","Daqing Liu","Chaoyue Wang","Jing Zhang","Dadong Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.01032v1.pdf","comment":"Tech. report"},{"id":"http://arxiv.org/abs/2209.14610v3","updated":"2023-03-02T07:41:55Z","published":"2022-09-29T08:01:04Z","title":"Dynamic Prompt Learning via Policy Gradient for Semi-structured\n  Mathematical Reasoning","summary":"  Mathematical reasoning, a core ability of human intelligence, presents unique\nchallenges for machines in abstract thinking and logical reasoning. Recent\nlarge pre-trained language models such as GPT-3 have achieved remarkable\nprogress on mathematical reasoning tasks written in text form, such as math\nword problems (MWP). However, it is unknown if the models can handle more\ncomplex problems that involve math reasoning over heterogeneous information,\nsuch as tabular data. To fill the gap, we present Tabular Math Word Problems\n(TabMWP), a new dataset containing 38,431 open-domain grade-level problems that\nrequire mathematical reasoning on both textual and tabular data. Each question\nin TabMWP is aligned with a tabular context, which is presented as an image,\nsemi-structured text, and a structured table. There are two types of questions:\nfree-text and multi-choice, and each problem is annotated with gold solutions\nto reveal the multi-step reasoning process. We evaluate different pre-trained\nmodels on TabMWP, including the GPT-3 model in a few-shot setting. As earlier\nstudies suggest, since few-shot GPT-3 relies on the selection of in-context\nexamples, its performance is unstable and can degrade to near chance. The\nunstable issue is more severe when handling complex problems like TabMWP. To\nmitigate this, we further propose a novel approach, PromptPG, which utilizes\npolicy gradient to learn to select in-context examples from a small amount of\ntraining data and then constructs the corresponding prompt for the test\nexample. Experimental results show that our method outperforms the best\nbaseline by 5.31% on the accuracy metric and reduces the prediction variance\nsignificantly compared to random selection, which verifies its effectiveness in\nselecting in-context examples.\n","authors":["Pan Lu","Liang Qiu","Kai-Wei Chang","Ying Nian Wu","Song-Chun Zhu","Tanmay Rajpurohit","Peter Clark","Ashwin Kalyan"],"pdf_url":"https://arxiv.org/pdf/2209.14610v3.pdf","comment":"ICLR 2023. 26 pages and 18 figures. The data and code are available\n  at https://promptpg.github.io"},{"id":"http://arxiv.org/abs/2207.00193v2","updated":"2023-03-02T07:39:00Z","published":"2022-07-01T03:50:26Z","title":"Reading and Writing: Discriminative and Generative Modeling for\n  Self-Supervised Text Recognition","summary":"  Existing text recognition methods usually need large-scale training data.\nMost of them rely on synthetic training data due to the lack of annotated real\nimages. However, there is a domain gap between the synthetic data and real\ndata, which limits the performance of the text recognition models. Recent\nself-supervised text recognition methods attempted to utilize unlabeled real\nimages by introducing contrastive learning, which mainly learns the\ndiscrimination of the text images. Inspired by the observation that humans\nlearn to recognize the texts through both reading and writing, we propose to\nlearn discrimination and generation by integrating contrastive learning and\nmasked image modeling in our self-supervised method. The contrastive learning\nbranch is adopted to learn the discrimination of text images, which imitates\nthe reading behavior of humans. Meanwhile, masked image modeling is firstly\nintroduced for text recognition to learn the context generation of the text\nimages, which is similar to the writing behavior. The experimental results show\nthat our method outperforms previous self-supervised text recognition methods\nby 10.2%-20.2% on irregular scene text recognition datasets. Moreover, our\nproposed text recognizer exceeds previous state-of-the-art text recognition\nmethods by averagely 5.3% on 11 benchmarks, with similar model size. We also\ndemonstrate that our pre-trained model can be easily applied to other\ntext-related tasks with obvious performance gain. The code is available at\nhttps://github.com/ayumiymk/DiG.\n","authors":["Mingkun Yang","Minghui Liao","Pu Lu","Jing Wang","Shenggao Zhu","Hualin Luo","Qi Tian","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2207.00193v2.pdf","comment":"Accepted by ACM MM 2022. The code is available at\n  https://github.com/ayumiymk/DiG"},{"id":"http://arxiv.org/abs/2002.03328v5","updated":"2023-03-02T06:56:26Z","published":"2020-02-09T09:54:12Z","title":"Kullback-Leibler Divergence-Based Out-of-Distribution Detection with\n  Flow-Based Generative Models","summary":"  Recent research has revealed that deep generative models including flow-based\nmodels and Variational Autoencoders may assign higher likelihoods to\nout-of-distribution (OOD) data than in-distribution (ID) data. However, we\ncannot sample OOD data from the model. This counterintuitive phenomenon has not\nbeen satisfactorily explained and brings obstacles to OOD detection with\nflow-based models. In this paper, we prove theorems to investigate the\nKullback-Leibler divergence in flow-based model and give two explanations for\nthe above phenomenon. Based on our theoretical analysis, we propose a new\nmethod \\PADmethod\\ to leverage KL divergence and local pixel dependence of\nrepresentations to perform anomaly detection. Experimental results on prevalent\nbenchmarks demonstrate the effectiveness and robustness of our method. For\ngroup anomaly detection, our method achieves 98.1\\% AUROC on average with a\nsmall batch size of 5. On the contrary, the baseline typicality test-based\nmethod only achieves 64.6\\% AUROC on average due to its failure on challenging\nproblems. Our method also outperforms the state-of-the-art method by 9.1\\%\nAUROC. For point-wise anomaly detection, our method achieves 90.7\\% AUROC on\naverage and outperforms the baseline by 5.2\\% AUROC. Besides, our method has\nthe least notable failures and is the most robust one.\n","authors":["Yufeng Zhang","Jialu Pan","Wanwei Liu","Zhenbang Chen","Ji Wang","Zhiming Liu","Kenli Li","Hongmei Wei"],"pdf_url":"https://arxiv.org/pdf/2002.03328v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01003v1","updated":"2023-03-02T06:44:21Z","published":"2023-03-02T06:44:21Z","title":"Target Domain Data induces Negative Transfer in Mixed Domain Training\n  with Disjoint Classes","summary":"  In practical scenarios, it is often the case that the available training data\nwithin the target domain only exist for a limited number of classes, with the\nremaining classes only available within surrogate domains. We show that\nincluding the target domain in training when there exist disjoint classes\nbetween the target and surrogate domains creates significant negative transfer,\nand causes performance to significantly decrease compared to training without\nthe target domain at all. We hypothesize that this negative transfer is due to\nan intermediate shortcut that only occurs when multiple source domains are\npresent, and provide experimental evidence that this may be the case. We show\nthat this phenomena occurs on over 25 distinct domain shifts, both synthetic\nand real, and in many cases deteriorates the performance to well worse than\nrandom, even when using state-of-the-art domain adaptation methods.\n","authors":["Eryk Banatt","Vickram Rajendran","Liam Packer"],"pdf_url":"https://arxiv.org/pdf/2303.01003v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2107.13429v2","updated":"2023-03-02T06:39:53Z","published":"2021-07-28T15:21:01Z","title":"Task-Specific Normalization for Continual Learning of Blind Image\n  Quality Models","summary":"  The computational vision community has recently paid attention to continual\nlearning for blind image quality assessment (BIQA). The primary challenge is to\ncombat catastrophic forgetting of previously-seen IQA datasets (i.e., tasks).\nIn this paper, we present a simple yet effective continual learning method for\nBIQA with improved quality prediction accuracy, plasticity-stability trade-off,\nand task-order/-length robustness. The key step in our approach is to freeze\nall convolution filters of a pre-trained deep neural network (DNN) for an\nexplicit promise of stability, and learn task-specific normalization parameters\nfor plasticity. We assign each new task a prediction head, and load the\ncorresponding normalization parameters to produce a quality score. The final\nquality estimate is computed by a weighted summation of predictions from all\nheads with a lightweight K-means gating mechanism, without leveraging the\ntest-time oracle. Extensive experiments on six IQA datasets demonstrate the\nadvantages of the proposed method in comparison to previous training techniques\nfor BIQA.\n","authors":["Weixia Zhang","Kede Ma","Guangtao Zhai","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2107.13429v2.pdf","comment":"Revise the performance metrics, methodological updates, and new\n  experimental results"},{"id":"http://arxiv.org/abs/2205.14083v3","updated":"2023-03-02T06:39:34Z","published":"2022-05-27T16:32:43Z","title":"Sharpness-Aware Training for Free","summary":"  Modern deep neural networks (DNNs) have achieved state-of-the-art\nperformances but are typically over-parameterized. The over-parameterization\nmay result in undesirably large generalization error in the absence of other\ncustomized training strategies. Recently, a line of research under the name of\nSharpness-Aware Minimization (SAM) has shown that minimizing a sharpness\nmeasure, which reflects the geometry of the loss landscape, can significantly\nreduce the generalization error. However, SAM-like methods incur a two-fold\ncomputational overhead of the given base optimizer (e.g. SGD) for approximating\nthe sharpness measure. In this paper, we propose Sharpness-Aware Training for\nFree, or SAF, which mitigates the sharp landscape at almost zero additional\ncomputational cost over the base optimizer. Intuitively, SAF achieves this by\navoiding sudden drops in the loss in the sharp local minima throughout the\ntrajectory of the updates of the weights. Specifically, we suggest a novel\ntrajectory loss, based on the KL-divergence between the outputs of DNNs with\nthe current weights and past weights, as a replacement of the SAM's sharpness\nmeasure. This loss captures the rate of change of the training loss along the\nmodel's update trajectory. By minimizing it, SAF ensures the convergence to a\nflat minimum with improved generalization capabilities. Extensive empirical\nresults show that SAF minimizes the sharpness in the same way that SAM does,\nyielding better results on the ImageNet dataset with essentially the same\ncomputational cost as the base optimizer.\n","authors":["Jiawei Du","Daquan Zhou","Jiashi Feng","Vincent Y. F. Tan","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2205.14083v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01000v1","updated":"2023-03-02T06:33:33Z","published":"2023-03-02T06:33:33Z","title":"X&Fuse: Fusing Visual Information in Text-to-Image Generation","summary":"  We introduce X&Fuse, a general approach for conditioning on visual\ninformation when generating images from text. We demonstrate the potential of\nX&Fuse in three different text-to-image generation scenarios. (i) When a bank\nof images is available, we retrieve and condition on a related image\n(Retrieve&Fuse), resulting in significant improvements on the MS-COCO\nbenchmark, gaining a state-of-the-art FID score of 6.65 in zero-shot settings.\n(ii) When cropped-object images are at hand, we utilize them and perform\nsubject-driven generation (Crop&Fuse), outperforming the textual inversion\nmethod while being more than x100 faster. (iii) Having oracle access to the\nimage scene (Scene&Fuse), allows us to achieve an FID score of 5.03 on MS-COCO\nin zero-shot settings. Our experiments indicate that X&Fuse is an effective,\neasy-to-adapt, simple, and general approach for scenarios in which the model\nmay benefit from additional visual information.\n","authors":["Yuval Kirstain","Omer Levy","Adam Polyak"],"pdf_url":"https://arxiv.org/pdf/2303.01000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05086v2","updated":"2023-03-02T06:14:19Z","published":"2023-02-10T07:08:13Z","title":"Making Substitute Models More Bayesian Can Enhance Transferability of\n  Adversarial Examples","summary":"  The transferability of adversarial examples across deep neural networks\n(DNNs) is the crux of many black-box attacks. Many prior efforts have been\ndevoted to improving the transferability via increasing the diversity in inputs\nof some substitute models. In this paper, by contrast, we opt for the diversity\nin substitute models and advocate to attack a Bayesian model for achieving\ndesirable transferability. Deriving from the Bayesian formulation, we develop a\nprincipled strategy for possible finetuning, which can be combined with many\noff-the-shelf Gaussian posterior approximations over DNN parameters. Extensive\nexperiments have been conducted to verify the effectiveness of our method, on\ncommon benchmark datasets, and the results demonstrate that our method\noutperforms recent state-of-the-arts by large margins (roughly 19% absolute\nincrease in average attack success rate on ImageNet), and, by combining with\nthese recent methods, further performance gain can be obtained. Our code:\nhttps://github.com/qizhangli/MoreBayesian-attack.\n","authors":["Qizhang Li","Yiwen Guo","Wangmeng Zuo","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2302.05086v2.pdf","comment":"Accepted by ICLR 2023, fix typos"},{"id":"http://arxiv.org/abs/2303.00996v1","updated":"2023-03-02T06:10:13Z","published":"2023-03-02T06:10:13Z","title":"Unsupervised Meta-Learning via Few-shot Pseudo-supervised Contrastive\n  Learning","summary":"  Unsupervised meta-learning aims to learn generalizable knowledge across a\ndistribution of tasks constructed from unlabeled data. Here, the main challenge\nis how to construct diverse tasks for meta-learning without label information;\nrecent works have proposed to create, e.g., pseudo-labeling via pretrained\nrepresentations or creating synthetic samples via generative models. However,\nsuch a task construction strategy is fundamentally limited due to heavy\nreliance on the immutable pseudo-labels during meta-learning and the quality of\nthe representations or the generated samples. To overcome the limitations, we\npropose a simple yet effective unsupervised meta-learning framework, coined\nPseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired\nby the recent self-supervised learning literature; PsCo utilizes a momentum\nnetwork and a queue of previous batches to improve pseudo-labeling and\nconstruct diverse tasks in a progressive manner. Our extensive experiments\ndemonstrate that PsCo outperforms existing unsupervised meta-learning methods\nunder various in-domain and cross-domain few-shot classification benchmarks. We\nalso validate that PsCo is easily scalable to a large-scale benchmark, while\nrecent prior-art meta-schemes are not.\n","authors":["Huiwon Jang","Hankook Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2303.00996v1.pdf","comment":"Accepted to ICLR 2023 (Spotlight). The first two authors contributed\n  equally. The code is available at https://github.com/alinlab/PsCo"},{"id":"http://arxiv.org/abs/2303.00983v1","updated":"2023-03-02T05:28:35Z","published":"2023-03-02T05:28:35Z","title":"Using simulation to quantify the performance of automotive perception\n  systems","summary":"  The design and evaluation of complex systems can benefit from a software\nsimulation - sometimes called a digital twin. The simulation can be used to\ncharacterize system performance or to test its performance under conditions\nthat are difficult to measure (e.g., nighttime for automotive perception\nsystems). We describe the image system simulation software tools that we use to\nevaluate the performance of image systems for object (automobile) detection. We\ndescribe experiments with 13 different cameras with a variety of optics and\npixel sizes. To measure the impact of camera spatial resolution, we designed a\ncollection of driving scenes that had cars at many different distances. We\nquantified system performance by measuring average precision and we report a\ntrend relating system resolution and object detection performance. We also\nquantified the large performance degradation under nighttime conditions,\ncompared to daytime, for all cameras and a COCO pre-trained network.\n","authors":["Zhenyi Liu","Devesh Shah","Alireza Rahimpour","Devesh Upadhyay","Joyce Farrell","Brian A Wandell"],"pdf_url":"https://arxiv.org/pdf/2303.00983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00979v1","updated":"2023-03-02T05:20:36Z","published":"2023-03-02T05:20:36Z","title":"Multi-Source Soft Pseudo-Label Learning with Domain Similarity-based\n  Weighting for Semantic Segmentation","summary":"  This paper describes a method of domain adaptive training for semantic\nsegmentation using multiple source datasets that are not necessarily relevant\nto the target dataset. We propose a soft pseudo-label generation method by\nintegrating predicted object probabilities from multiple source models. The\nprediction of each source model is weighted based on the estimated domain\nsimilarity between the source and the target datasets to emphasize contribution\nof a model trained on a source that is more similar to the target and generate\nreasonable pseudo-labels. We also propose a training method using the soft\npseudo-labels considering their entropy to fully exploit information from the\nsource datasets while suppressing the influence of possibly misclassified\npixels. The experiments show comparative or better performance than our\nprevious work and another existing multi-source domain adaptation method, and\napplicability to a variety of target environments.\n","authors":["Shigemichi Matsuzaki","Hiroaki Masuzawa","Jun Miura"],"pdf_url":"https://arxiv.org/pdf/2303.00979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00977v1","updated":"2023-03-02T05:19:31Z","published":"2023-03-02T05:19:31Z","title":"Ego-Vehicle Action Recognition based on Semi-Supervised Contrastive\n  Learning","summary":"  In recent years, many automobiles have been equipped with cameras, which have\naccumulated an enormous amount of video footage of driving scenes. Autonomous\ndriving demands the highest level of safety, for which even unimaginably rare\ndriving scenes have to be collected in training data to improve the recognition\naccuracy for specific scenes. However, it is prohibitively costly to find very\nfew specific scenes from an enormous amount of videos. In this article, we show\nthat proper video-to-video distances can be defined by focusing on ego-vehicle\nactions. It is well known that existing methods based on supervised learning\ncannot handle videos that do not fall into predefined classes, though they work\nwell in defining video-to-video distances in the embedding space between\nlabeled videos. To tackle this problem, we propose a method based on\nsemi-supervised contrastive learning. We consider two related but distinct\ncontrastive learning: standard graph contrastive learning and our proposed\nSOIA-based contrastive learning. We observe that the latter approach can\nprovide more sensible video-to-video distances between unlabeled videos. Next,\nthe effectiveness of our method is quantified by evaluating the classification\nperformance of the ego-vehicle action recognition using HDD dataset, which\nshows that our method including unlabeled data in training significantly\noutperforms the existing methods using only labeled data in training.\n","authors":["Chihiro Noguchi","Toshihiro Tanizawa"],"pdf_url":"https://arxiv.org/pdf/2303.00977v1.pdf","comment":"19 pages, 17 figures"},{"id":"http://arxiv.org/abs/2303.00973v1","updated":"2023-03-02T05:10:57Z","published":"2023-03-02T05:10:57Z","title":"Image Labels Are All You Need for Coarse Seagrass Segmentation","summary":"  Seagrass meadows serve as critical carbon sinks, but accurately estimating\nthe amount of carbon they store requires knowledge of the seagrass species\npresent. Using underwater and surface vehicles equipped with machine learning\nalgorithms can help to accurately estimate the composition and extent of\nseagrass meadows at scale. However, previous approaches for seagrass detection\nand classification have required full supervision from patch-level labels. In\nthis paper, we reframe seagrass classification as a weakly supervised coarse\nsegmentation problem where image-level labels are used during training (25\ntimes fewer labels compared to patch-level labeling) and patch-level outputs\nare obtained at inference time. To this end, we introduce SeaFeats, an\narchitecture that uses unsupervised contrastive pretraining and feature\nsimilarity to separate background and seagrass patches, and SeaCLIP, a model\nthat showcases the effectiveness of large language models as a supervisory\nsignal in domain-specific applications. We demonstrate that an ensemble of\nSeaFeats and SeaCLIP leads to highly robust performance, with SeaCLIP\nconservatively predicting the background class to avoid false seagrass\nmisclassifications in blurry or dark patches. Our method outperforms previous\napproaches that require patch-level labels on the multi-species 'DeepSeagrass'\ndataset by 6.8% (absolute) for the class-weighted F1 score, and by 12.1%\n(absolute) F1 score for seagrass presence/absence on the 'Global Wetlands'\ndataset. We also present two case studies for real-world deployment: outlier\ndetection on the Global Wetlands dataset, and application of our method on\nimagery collected by FloatyBoat, an autonomous surface vehicle.\n","authors":["Scarlett Raine","Ross Marchant","Brano Kusy","Frederic Maire","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2303.00973v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.00972v1","updated":"2023-03-02T05:10:31Z","published":"2023-03-02T05:10:31Z","title":"Practical Network Acceleration with Tiny Sets: Hypothesis, Theory, and\n  Algorithm","summary":"  Due to data privacy issues, accelerating networks with tiny training sets has\nbecome a critical need in practice. Previous methods achieved promising results\nempirically by filter-level pruning. In this paper, we both study this problem\ntheoretically and propose an effective algorithm aligning well with our\ntheoretical results. First, we propose the finetune convexity hypothesis to\nexplain why recent few-shot compression algorithms do not suffer from\noverfitting problems. Based on it, a theory is further established to explain\nthese methods for the first time. Compared to naively finetuning a pruned\nnetwork, feature mimicking is proved to achieve a lower variance of parameters\nand hence enjoys easier optimization. With our theoretical conclusions, we\nclaim dropping blocks is a fundamentally superior few-shot compression scheme\nin terms of more convex optimization and a higher acceleration ratio. To choose\nwhich blocks to drop, we propose a new metric, recoverability, to effectively\nmeasure the difficulty of recovering the compressed network. Finally, we\npropose an algorithm named PRACTISE to accelerate networks using only tiny\ntraining sets. PRACTISE outperforms previous methods by a significant margin.\nFor 22% latency reduction, it surpasses previous methods by on average 7\npercentage points on ImageNet-1k. It also works well under data-free or\nout-of-domain data settings. Our code is at\nhttps://github.com/DoctorKey/Practise\n","authors":["Guo-Hua Wang","Jianxin Wu"],"pdf_url":"https://arxiv.org/pdf/2303.00972v1.pdf","comment":"under review for TPAMI"},{"id":"http://arxiv.org/abs/2303.00971v1","updated":"2023-03-02T05:10:23Z","published":"2023-03-02T05:10:23Z","title":"Disentangling Orthogonal Planes for Indoor Panoramic Room Layout\n  Estimation with Cross-Scale Distortion Awareness","summary":"  Based on the Manhattan World assumption, most existing indoor layout\nestimation schemes focus on recovering layouts from vertically compressed 1D\nsequences. However, the compression procedure confuses the semantics of\ndifferent planes, yielding inferior performance with ambiguous\ninterpretability.\n  To address this issue, we propose to disentangle this 1D representation by\npre-segmenting orthogonal (vertical and horizontal) planes from a complex\nscene, explicitly capturing the geometric cues for indoor layout estimation.\nConsidering the symmetry between the floor boundary and ceiling boundary, we\nalso design a soft-flipping fusion strategy to assist the pre-segmentation.\nBesides, we present a feature assembling mechanism to effectively integrate\nshallow and deep features with distortion distribution awareness. To compensate\nfor the potential errors in pre-segmentation, we further leverage triple\nattention to reconstruct the disentangled sequences for better performance.\nExperiments on four popular benchmarks demonstrate our superiority over\nexisting SoTA solutions, especially on the 3DIoU metric. The code is available\nat \\url{https://github.com/zhijieshen-bjtu/DOPNet}.\n","authors":["Zhijie Shen","Zishuo Zheng","Chunyu Lin","Lang Nie","Kang Liao","Yao Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.00971v1.pdf","comment":"Accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2207.13298v3","updated":"2023-03-02T04:54:00Z","published":"2022-07-27T05:09:54Z","title":"Is Attention All That NeRF Needs?","summary":"  We present Generalizable NeRF Transformer (GNT), a transformer-based\narchitecture that reconstructs Neural Radiance Fields (NeRFs) and learns to\nrenders novel views on the fly from source views. While prior works on NeRFs\noptimize a scene representation by inverting a handcrafted rendering equation,\nGNT achieves neural representation and rendering that generalizes across scenes\nusing transformers at two stages. (1) The view transformer leverages multi-view\ngeometry as an inductive bias for attention-based scene representation, and\npredicts coordinate-aligned features by aggregating information from epipolar\nlines on the neighboring views. (2) The ray transformer renders novel views\nusing attention to decode the features from the view transformer along the\nsampled points during ray marching. Our experiments demonstrate that when\noptimized on a single scene, GNT can successfully reconstruct NeRF without an\nexplicit rendering formula due to the learned ray renderer. When trained on\nmultiple scenes, GNT consistently achieves state-of-the-art performance when\ntransferring to unseen scenes and outperform all other methods by ~10% on\naverage. Our analysis of the learned attention maps to infer depth and\nocclusion indicate that attention enables learning a physically-grounded\nrendering. Our results show the promise of transformers as a universal modeling\ntool for graphics. Please refer to our project page for video results:\nhttps://vita-group.github.io/GNT/.\n","authors":["Mukund Varma T","Peihao Wang","Xuxi Chen","Tianlong Chen","Subhashini Venugopalan","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2207.13298v3.pdf","comment":"International Conference on Learning Representations (ICLR), 2023"},{"id":"http://arxiv.org/abs/2212.03125v4","updated":"2023-03-02T04:44:43Z","published":"2022-12-06T16:42:22Z","title":"Self-supervised and Weakly Supervised Contrastive Learning for\n  Frame-wise Action Representations","summary":"  Previous work on action representation learning focused on global\nrepresentations for short video clips. In contrast, many practical\napplications, such as video alignment, strongly demand learning the intensive\nrepresentation of long videos. In this paper, we introduce a new framework of\ncontrastive action representation learning (CARL) to learn frame-wise action\nrepresentation in a self-supervised or weakly-supervised manner, especially for\nlong videos. Specifically, we introduce a simple but effective video encoder\nthat considers both spatial and temporal context by combining convolution and\ntransformer. Inspired by the recent massive progress in self-supervised\nlearning, we propose a new sequence contrast loss (SCL) applied to two related\nviews obtained by expanding a series of spatio-temporal data in two versions.\nOne is the self-supervised version that optimizes embedding space by minimizing\nKL-divergence between sequence similarity of two augmented views and prior\nGaussian distribution of timestamp distance. The other is the weakly-supervised\nversion that builds more sample pairs among videos using video-level labels by\ndynamic time wrapping (DTW). Experiments on FineGym, PennAction, and Pouring\ndatasets show that our method outperforms previous state-of-the-art by a large\nmargin for downstream fine-grained action classification and even faster\ninference. Surprisingly, although without training on paired videos like in\nprevious works, our self-supervised version also shows outstanding performance\nin video alignment and fine-grained frame retrieval tasks.\n","authors":["Minghao Chen","Renbo Tu","Chenxi Huang","Yuqi Lin","Boxi Wu","Deng Cai"],"pdf_url":"https://arxiv.org/pdf/2212.03125v4.pdf","comment":"author conflicts"},{"id":"http://arxiv.org/abs/2303.00952v1","updated":"2023-03-02T04:12:53Z","published":"2023-03-02T04:12:53Z","title":"MuscleMap: Towards Video-based Activated Muscle Group Estimation","summary":"  In this paper, we tackle the new task of video-based Activated Muscle Group\nEstimation (AMGE) aiming at identifying currently activated muscular regions of\nhumans performing a specific activity. Video-based AMGE is an important yet\noverlooked problem. To this intent, we provide the MuscleMap136 featuring >15K\nvideo clips with 136 different activities and 20 labeled muscle groups. This\ndataset opens the vistas to multiple video-based applications in sports and\nrehabilitation medicine. We further complement the main MuscleMap136 dataset,\nwhich specifically targets physical exercise, with Muscle-UCF90 and\nMuscle-HMDB41, which are new variants of the well-known activity recognition\nbenchmarks extended with AMGE annotations. With MuscleMap136, we discover\nlimitations of state-of-the-art architectures for human activity recognition\nwhen dealing with multi-label muscle annotations and good generalization to\nunseen activities is required. To address this, we propose a new multimodal\ntransformer-based model, TransM3E, which surpasses current activity recognition\nmodels for AMGE, especially as it comes to dealing with previously unseen\nactivities. The datasets and code will be publicly available at\nhttps://github.com/KPeng9510/MuscleMap.\n","authors":["Kunyu Peng","David Schneider","Alina Roitberg","Kailun Yang","Jiaming Zhang","M. Saquib Sarfraz","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2303.00952v1.pdf","comment":"The datasets and code will be publicly available at\n  https://github.com/KPeng9510/MuscleMap"},{"id":"http://arxiv.org/abs/2209.15076v4","updated":"2023-03-02T03:58:57Z","published":"2022-09-29T19:54:13Z","title":"3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical\n  Transformer for Medical Image Segmentation","summary":"  The recent 3D medical ViTs (e.g., SwinUNETR) achieve the state-of-the-art\nperformances on several 3D volumetric data benchmarks, including 3D medical\nimage segmentation. Hierarchical transformers (e.g., Swin Transformers)\nreintroduced several ConvNet priors and further enhanced the practical\nviability of adapting volumetric segmentation in 3D medical datasets. The\neffectiveness of hybrid approaches is largely credited to the large receptive\nfield for non-local self-attention and the large number of model parameters. In\nthis work, we propose a lightweight volumetric ConvNet, termed 3D UX-Net, which\nadapts the hierarchical transformer using ConvNet modules for robust volumetric\nsegmentation. Specifically, we revisit volumetric depth-wise convolutions with\nlarge kernel size (e.g. starting from $7\\times7\\times7$) to enable the larger\nglobal receptive fields, inspired by Swin Transformer. We further substitute\nthe multi-layer perceptron (MLP) in Swin Transformer blocks with pointwise\ndepth convolutions and enhance model performances with fewer normalization and\nactivation layers, thus reducing the number of model parameters. 3D UX-Net\ncompetes favorably with current SOTA transformers (e.g. SwinUNETR) using three\nchallenging public datasets on volumetric brain and abdominal imaging: 1)\nMICCAI Challenge 2021 FLARE, 2) MICCAI Challenge 2021 FeTA, and 3) MICCAI\nChallenge 2022 AMOS. 3D UX-Net consistently outperforms SwinUNETR with\nimprovement from 0.929 to 0.938 Dice (FLARE2021) and 0.867 to 0.874 Dice\n(Feta2021). We further evaluate the transfer learning capability of 3D UX-Net\nwith AMOS2022 and demonstrates another improvement of $2.27\\%$ Dice (from 0.880\nto 0.900). The source code with our proposed model are available at\nhttps://github.com/MASILab/3DUX-Net.\n","authors":["Ho Hin Lee","Shunxing Bao","Yuankai Huo","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2209.15076v4.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00944v1","updated":"2023-03-02T03:40:05Z","published":"2023-03-02T03:40:05Z","title":"Attention-based Graph Convolution Fusing Latent Structures and Multiple\n  Features for Graph Neural Networks","summary":"  We present an attention-based spatial graph convolution (AGC) for graph\nneural networks (GNNs). Existing AGCs focus on only using node-wise features\nand utilizing one type of attention function when calculating attention\nweights. Instead, we propose two methods to improve the representational power\nof AGCs by utilizing 1) structural information in a high-dimensional space and\n2) multiple attention functions when calculating their weights. The first\nmethod computes a local structure representation of a graph in a\nhigh-dimensional space. The second method utilizes multiple attention functions\nsimultaneously in one AGC. Both approaches can be combined. We also propose a\nGNN for the classification of point clouds and that for the prediction of point\nlabels in a point cloud based on the proposed AGC. According to experiments,\nthe proposed GNNs perform better than existing methods. Our codes open at\nhttps://github.com/liyang-tuat/SFAGC.\n","authors":["Yang Li","Yuichi Tanaka"],"pdf_url":"https://arxiv.org/pdf/2303.00944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00943v1","updated":"2023-03-02T03:36:15Z","published":"2023-03-02T03:36:15Z","title":"Evolutionary Computation in Action: Hyperdimensional Deep Embedding\n  Spaces of Gigapixel Pathology Images","summary":"  One of the main obstacles of adopting digital pathology is the challenge of\nefficient processing of hyperdimensional digitized biopsy samples, called whole\nslide images (WSIs). Exploiting deep learning and introducing compact WSI\nrepresentations are urgently needed to accelerate image analysis and facilitate\nthe visualization and interpretability of pathology results in a postpandemic\nworld. In this paper, we introduce a new evolutionary approach for WSI\nrepresentation based on large-scale multi-objective optimization (LSMOP) of\ndeep embeddings. We start with patch-based sampling to feed KimiaNet , a\nhistopathology-specialized deep network, and to extract a multitude of feature\nvectors. Coarse multi-objective feature selection uses the reduced search space\nstrategy guided by the classification accuracy and the number of features. In\nthe second stage, the frequent features histogram (FFH), a novel WSI\nrepresentation, is constructed by multiple runs of coarse LSMOP. Fine\nevolutionary feature selection is then applied to find a compact (short-length)\nfeature vector based on the FFH and contributes to a more robust deep-learning\napproach to digital pathology supported by the stochastic power of evolutionary\nalgorithms. We validate the proposed schemes using The Cancer Genome Atlas\n(TCGA) images in terms of WSI representation, classification accuracy, and\nfeature quality. Furthermore, a novel decision space for multicriteria decision\nmaking in the LSMOP field is introduced. Finally, a patch-level visualization\napproach is proposed to increase the interpretability of deep features. The\nproposed evolutionary algorithm finds a very compact feature vector to\nrepresent a WSI (almost 14,000 times smaller than the original feature vectors)\nwith 8% higher accuracy compared to the codes provided by the state-of-the-art\nmethods.\n","authors":["Azam Asilian Bidgoli","Shahryar Rahnamayan","Taher Dehkharghanian","Abtin Riasatian","H. R. Tizhoosh"],"pdf_url":"https://arxiv.org/pdf/2303.00943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00942v1","updated":"2023-03-02T03:34:28Z","published":"2023-03-02T03:34:28Z","title":"Meta-information-aware Dual-path Transformer for Differential Diagnosis\n  of Multi-type Pancreatic Lesions in Multi-phase CT","summary":"  Pancreatic cancer is one of the leading causes of cancer-related death.\nAccurate detection, segmentation, and differential diagnosis of the full\ntaxonomy of pancreatic lesions, i.e., normal, seven major types of lesions, and\nother lesions, is critical to aid the clinical decision-making of patient\nmanagement and treatment. However, existing works focus on segmentation and\nclassification for very specific lesion types (PDAC) or groups. Moreover, none\nof the previous work considers using lesion prevalence-related non-imaging\npatient information to assist the differential diagnosis. To this end, we\ndevelop a meta-information-aware dual-path transformer and exploit the\nfeasibility of classification and segmentation of the full taxonomy of\npancreatic lesions. Specifically, the proposed method consists of a CNN-based\nsegmentation path (S-path) and a transformer-based classification path\n(C-path). The S-path focuses on initial feature extraction by semantic\nsegmentation using a UNet-based network. The C-path utilizes both the extracted\nfeatures and meta-information for patient-level classification based on stacks\nof dual-path transformer blocks that enhance the modeling of global contextual\ninformation. A large-scale multi-phase CT dataset of 3,096 patients with\npathology-confirmed pancreatic lesion class labels, voxel-wise manual\nannotations of lesions from radiologists, and patient meta-information, was\ncollected for training and evaluations. Our results show that our method can\nenable accurate classification and segmentation of the full taxonomy of\npancreatic lesions, approaching the accuracy of the radiologist's report and\nsignificantly outperforming previous baselines. Results also show that adding\nthe common meta-information, i.e., gender and age, can boost the model's\nperformance, thus demonstrating the importance of meta-information for aiding\npancreatic disease diagnosis.\n","authors":["Bo Zhou","Yingda Xia","Jiawen Yao","Le Lu","Jingren Zhou","Chi Liu","James S. Duncan","Ling Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00942v1.pdf","comment":"Accepted at Information Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/2303.00941v1","updated":"2023-03-02T03:29:16Z","published":"2023-03-02T03:29:16Z","title":"ParaFormer: Parallel Attention Transformer for Efficient Feature\n  Matching","summary":"  Heavy computation is a bottleneck limiting deep-learningbased feature\nmatching algorithms to be applied in many realtime applications. However,\nexisting lightweight networks optimized for Euclidean data cannot address\nclassical feature matching tasks, since sparse keypoint based descriptors are\nexpected to be matched. This paper tackles this problem and proposes two\nconcepts: 1) a novel parallel attention model entitled ParaFormer and 2) a\ngraph based U-Net architecture with attentional pooling. First, ParaFormer\nfuses features and keypoint positions through the concept of amplitude and\nphase, and integrates self- and cross-attention in a parallel manner which\nachieves a win-win performance in terms of accuracy and efficiency. Second,\nwith U-Net architecture and proposed attentional pooling, the ParaFormer-U\nvariant significantly reduces computational complexity, and minimize\nperformance loss caused by downsampling. Sufficient experiments on various\napplications, including homography estimation, pose estimation, and image\nmatching, demonstrate that ParaFormer achieves state-of-the-art performance\nwhile maintaining high efficiency. The efficient ParaFormer-U variant achieves\ncomparable performance with less than 50% FLOPs of the existing attention-based\nmodels.\n","authors":["Xiaoyong Lu","Yaping Yan","Bin Kang","Songlin Du"],"pdf_url":"https://arxiv.org/pdf/2303.00941v1.pdf","comment":"Have been accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.00939v1","updated":"2023-03-02T03:24:21Z","published":"2023-03-02T03:24:21Z","title":"Spatial Layout Consistency for 3D Semantic Segmentation","summary":"  Due to the aged nature of much of the utility network infrastructure,\ndeveloping a robust and trustworthy computer vision system capable of\ninspecting it with minimal human intervention has attracted considerable\nresearch attention. The airborne laser terrain mapping (ALTM) system quickly\nbecomes the central data collection system among the numerous available\nsensors. Its ability to penetrate foliage with high-powered energy provides\nwide coverage and achieves survey-grade ranging accuracy. However, the\npost-data acquisition process for classifying the ALTM's dense and irregular\npoint clouds is a critical bottleneck that must be addressed to improve\nefficiency and accuracy. We introduce a novel deep convolutional neural network\n(DCNN) technique for achieving voxel-based semantic segmentation of the ALTM's\npoint clouds. The suggested deep learning method, Semantic Utility Network\n(SUNet) is a multi-dimensional and multi-resolution network. SUNet combines two\nnetworks: one classifies point clouds at multi-resolution with object\ncategories in three dimensions and another predicts two-dimensional regional\nlabels distinguishing corridor regions from non-corridors. A significant\ninnovation of the SUNet is that it imposes spatial layout consistency on the\noutcomes of voxel-based and regional segmentation results. The proposed\nmulti-dimensional DCNN combines hierarchical context for spatial layout\nembedding with a coarse-to-fine strategy. We conducted a comprehensive ablation\nstudy to test SUNet's performance using 67 km x 67 km of utility corridor data\nat a density of 5pp/m2. Our experiments demonstrated that SUNet's spatial\nlayout consistency and a multi-resolution feature aggregation could\nsignificantly improve performance, outperforming the SOTA baseline network and\nachieving a good F1 score for pylon 89%, ground 99%, vegetation 99% and\npowerline 98% classes.\n","authors":["Maryam Jameela","Gunho Sohn"],"pdf_url":"https://arxiv.org/pdf/2303.00939v1.pdf","comment":"12th IAPR International Workshop on Pattern Recognition in Remote\n  Sensing, ICPR 2022"},{"id":"http://arxiv.org/abs/2303.00938v1","updated":"2023-03-02T03:23:18Z","published":"2023-03-02T03:23:18Z","title":"UniDexGrasp: Universal Robotic Dexterous Grasping via Learning Diverse\n  Proposal Generation and Goal-Conditioned Policy","summary":"  In this work, we tackle the problem of learning universal robotic dexterous\ngrasping from a point cloud observation under a table-top setting. The goal is\nto grasp and lift up objects in high-quality and diverse ways and generalize\nacross hundreds of categories and even the unseen. Inspired by successful\npipelines used in parallel gripper grasping, we split the task into two stages:\n1) grasp proposal (pose) generation and 2) goal-conditioned grasp execution.\nFor the first stage, we propose a novel probabilistic model of grasp pose\nconditioned on the point cloud observation that factorizes rotation from\ntranslation and articulation. Trained on our synthesized large-scale dexterous\ngrasp dataset, this model enables us to sample diverse and high-quality\ndexterous grasp poses for the object in the point cloud. For the second stage,\nwe propose to replace the motion planning used in parallel gripper grasping\nwith a goal-conditioned grasp policy, due to the complexity involved in\ndexterous grasping execution. Note that it is very challenging to learn this\nhighly generalizable grasp policy that only takes realistic inputs without\noracle states. We thus propose several important innovations, including state\ncanonicalization, object curriculum, and teacher-student distillation.\nIntegrating the two stages, our final pipeline becomes the first to achieve\nuniversal generalization for dexterous grasping, demonstrating an average\nsuccess rate of more than 60% on thousands of object instances, which\nsignificantly out performs all baselines, meanwhile showing only a minimal\ngeneralization gap.\n","authors":["Yinzhen Xu","Weikang Wan","Jialiang Zhang","Haoran Liu","Zikang Shan","Hao Shen","Ruicheng Wang","Haoran Geng","Yijia Weng","Jiayi Chen","Tengyu Liu","Li Yi","He Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00938v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2107.10998v4","updated":"2023-03-02T03:11:04Z","published":"2021-07-23T02:18:00Z","title":"Pruning Ternary Quantization","summary":"  Inference time, model size, and accuracy are three key factors in deep model\ncompression.\n  Most of the existing work addresses these three key factors separately as it\nis difficult to optimize them all at the same time.\n  For example, low-bit quantization aims at obtaining a faster model; weight\nsharing quantization aims at improving compression ratio and accuracy; and\nmixed-precision quantization aims at balancing accuracy and inference time. To\nsimultaneously optimize bit-width, model size, and accuracy, we propose pruning\nternary quantization (PTQ): a simple, effective, symmetric ternary quantization\nmethod. We integrate L2 normalization, pruning, and the weight decay term to\nreduce the weight discrepancy in the gradient estimator during quantization,\nthus producing highly compressed ternary weights. Our method brings the highest\ntest accuracy and the highest compression ratio. For example, it produces a\n939kb (49$\\times$) 2bit ternary ResNet-18 model with only 4\\% accuracy drop on\nthe ImageNet dataset. It compresses 170MB Mask R-CNN to 5MB (34$\\times$) with\nonly 2.8\\% average precision drop. Our method is verified on image\nclassification, object detection/segmentation tasks with different network\nstructures such as ResNet-18, ResNet-50, and MobileNetV2.\n","authors":["Dan Liu","Xi Chen","Jie Fu","Chen Ma","Xue Liu"],"pdf_url":"https://arxiv.org/pdf/2107.10998v4.pdf","comment":"old version"},{"id":"http://arxiv.org/abs/2210.03310v3","updated":"2023-03-02T03:08:10Z","published":"2022-10-07T03:52:27Z","title":"Scaling Forward Gradient With Local Losses","summary":"  Forward gradient learning computes a noisy directional gradient and is a\nbiologically plausible alternative to backprop for learning deep neural\nnetworks. However, the standard forward gradient algorithm, when applied\nnaively, suffers from high variance when the number of parameters to be learned\nis large. In this paper, we propose a series of architectural and algorithmic\nmodifications that together make forward gradient learning practical for\nstandard deep learning benchmark tasks. We show that it is possible to\nsubstantially reduce the variance of the forward gradient estimator by applying\nperturbations to activations rather than weights. We further improve the\nscalability of forward gradient by introducing a large number of local greedy\nloss functions, each of which involves only a small number of learnable\nparameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more\nsuitable for local learning. Our approach matches backprop on MNIST and\nCIFAR-10 and significantly outperforms previously proposed backprop-free\nalgorithms on ImageNet.\n","authors":["Mengye Ren","Simon Kornblith","Renjie Liao","Geoffrey Hinton"],"pdf_url":"https://arxiv.org/pdf/2210.03310v3.pdf","comment":"31 pages, ICLR 2023"},{"id":"http://arxiv.org/abs/2207.00215v2","updated":"2023-03-02T03:07:47Z","published":"2022-07-01T05:52:14Z","title":"Polarized Color Image Denoising using Pocoformer","summary":"  Polarized color photography provides both visual textures and object\nsurficial information in one single snapshot. However, the use of the\ndirectional polarizing filter array causes extremely lower photon count and SNR\ncompared to conventional color imaging. Thus, the feature essentially leads to\nunpleasant noisy images and destroys polarization analysis performance. It is a\nchallenge for traditional image processing pipelines owing to the fact that the\nphysical constraints exerted implicitly in the channels are excessively\ncomplicated. To address this issue, we propose a learning-based approach to\nsimultaneously restore clean signals and precise polarization information. A\nreal-world polarized color image dataset of paired raw short-exposed noisy and\nlong-exposed reference images are captured to support the learning-based\npipeline. Moreover, we embrace the development of vision Transformer and\npropose a hybrid transformer model for the Polarized Color image denoising,\nnamely PoCoformer, for a better restoration performance. Abundant experiments\ndemonstrate the effectiveness of proposed method and key factors that affect\nresults are analyzed.\n","authors":["Zhuoxiao Li","Haiyang Jiang","Yinqiang Zheng"],"pdf_url":"https://arxiv.org/pdf/2207.00215v2.pdf","comment":"New version is accpeted by CVPR 2023 and great modifications are\n  taken"},{"id":"http://arxiv.org/abs/2210.00788v2","updated":"2023-03-02T03:00:36Z","published":"2022-10-03T09:54:39Z","title":"Towards a Unified View on Visual Parameter-Efficient Transfer Learning","summary":"  Parameter efficient transfer learning (PETL) aims at making good use of the\nrepresentation knowledge in the pre-trained large models by fine-tuning a small\nnumber of parameters. Recently, taking inspiration from the natural language\nprocessing (NLP) domain, popular PETL techniques such as prompt-tuning and\nAdapter have also been successfully applied to the vision domain. However,\nprefix-tuning remains under-explored for vision tasks. In this work, we intend\nto adapt large vision models (LVMs) to downstream tasks with a good\nparameter-accuracy trade-off. Towards this goal, we propose a framework with a\nunified view of PETL called visual-PETL (V-PETL) to investigate the effects of\ndifferent PETL techniques, data scales of downstream domains, positions of\ntrainable parameters, and other aspects affecting the trade-off. Specifically,\nwe analyze the positional importance of trainable parameters and differences\nbetween NLP and vision tasks in terms of data structures and pre-training\nmechanisms while implementing various PETL techniques, especially for the\nunder-explored prefix-tuning technique. Based on a comprehensive understanding\nof the differences between NLP and vision data, we propose a new variation of\nthe prefix-tuning module called parallel attention (PATT) for vision downstream\ntasks. An extensive empirical analysis on vision tasks via different frozen\nLVMs has been carried and the findings show that the proposed PATT can\neffectively contribute to other PETL techniques. An effective scheme Swin-BAPAT\nderived from the proposed V-PETL framework achieves significantly better\nperformance than the state-of-the-art AdaptFormer-Swin with slightly more\nparameters and outperforms full-tuning with far fewer parameters. Code and data\nare available at: https://github.com/bruceyo/V-PETL.\n","authors":["Bruce X. B. Yu","Jianlong Chang","Lingbo Liu","Qi Tian","Chang Wen Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00788v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2303.00563v2","updated":"2023-03-02T02:26:07Z","published":"2023-03-01T15:09:45Z","title":"ROCO: A Roundabout Traffic Conflict Dataset","summary":"  Traffic conflicts have been studied by the transportation research community\nas a surrogate safety measure for decades. However, due to the rarity of\ntraffic conflicts, collecting large-scale real-world traffic conflict data\nbecomes extremely challenging. In this paper, we introduce and analyze ROCO - a\nreal-world roundabout traffic conflict dataset. The data is collected at a\ntwo-lane roundabout at the intersection of State St. and W. Ellsworth Rd. in\nAnn Arbor, Michigan. We use raw video dataflow captured from four fisheye\ncameras installed at the roundabout as our input data source. We adopt a\nlearning-based conflict identification algorithm from video to find potential\ntraffic conflicts, and then manually label them for dataset collection and\nannotation. In total 557 traffic conflicts and 17 traffic crashes are collected\nfrom August 2021 to October 2021. We provide trajectory data of the traffic\nconflict scenes extracted using our roadside perception system. Taxonomy based\non traffic conflict severity, reason for the traffic conflict, and its effect\non the traffic flow is provided. With the traffic conflict data collected, we\ndiscover that failure to yield to circulating vehicles when entering the\nroundabout is the largest contributing reason for traffic conflicts. ROCO\ndataset will be made public in the short future.\n","authors":["Depu Meng","Owen Sayer","Rusheng Zhang","Shengyin Shen","Houqiang Li","Henry X. Liu"],"pdf_url":"https://arxiv.org/pdf/2303.00563v2.pdf","comment":"Accepted by TRBAM 2023 presentation"},{"id":"http://arxiv.org/abs/2303.00917v1","updated":"2023-03-02T02:26:04Z","published":"2023-03-02T02:26:04Z","title":"Enhancing General Face Forgery Detection via Vision Transformer with\n  Low-Rank Adaptation","summary":"  Nowadays, forgery faces pose pressing security concerns over fake news,\nfraud, impersonation, etc. Despite the demonstrated success in intra-domain\nface forgery detection, existing detection methods lack generalization\ncapability and tend to suffer from dramatic performance drops when deployed to\nunforeseen domains. To mitigate this issue, this paper designs a more general\nfake face detection model based on the vision transformer(ViT) architecture. In\nthe training phase, the pretrained ViT weights are freezed, and only the\nLow-Rank Adaptation(LoRA) modules are updated. Additionally, the Single Center\nLoss(SCL) is applied to supervise the training process, further improving the\ngeneralization capability of the model. The proposed method achieves\nstate-of-the-arts detection performances in both cross-manipulation and\ncross-dataset evaluations.\n","authors":["Chenqi Kong","Haoliang Li","Shiqi Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00915v1","updated":"2023-03-02T02:20:04Z","published":"2023-03-02T02:20:04Z","title":"Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language\n  Processing","summary":"  Contrastive pretraining on parallel image-text data has attained great\nsuccess in vision-language processing (VLP), as exemplified by CLIP and related\nmethods. However, prior explorations tend to focus on general domains in the\nweb. Biomedical images and text are rather different, but publicly available\ndatasets are small and skew toward chest X-ray, thus severely limiting\nprogress. In this paper, we conducted by far the largest study on biomedical\nVLP, using 15 million figure-caption pairs extracted from biomedical research\narticles in PubMed Central. Our dataset (PMC-15M) is two orders of magnitude\nlarger than existing biomedical image-text datasets such as MIMIC-CXR, and\nspans a diverse range of biomedical images. The standard CLIP method is\nsuboptimal for the biomedical domain. We propose BiomedCLIP with\ndomain-specific adaptations tailored to biomedical VLP. We conducted extensive\nexperiments and ablation studies on standard biomedical imaging tasks from\nretrieval to classification to visual question-answering (VQA). BiomedCLIP\nestablished new state of the art in a wide range of standard datasets,\nsubstantially outperformed prior VLP approaches. Surprisingly, BiomedCLIP even\noutperformed radiology-specific state-of-the-art models such as BioViL on\nradiology-specific tasks such as RSNA pneumonia detection, thus highlighting\nthe utility in large-scale pretraining across all biomedical image types. We\nwill release our models at https://aka.ms/biomedclip to facilitate future\nresearch in biomedical VLP.\n","authors":["Sheng Zhang","Yanbo Xu","Naoto Usuyama","Jaspreet Bagga","Robert Tinn","Sam Preston","Rajesh Rao","Mu Wei","Naveen Valluri","Cliff Wong","Matthew P. Lungren","Tristan Naumann","Hoifung Poon"],"pdf_url":"https://arxiv.org/pdf/2303.00915v1.pdf","comment":"The models will be released soon at https://aka.ms/biomedclip"},{"id":"http://arxiv.org/abs/2303.00914v1","updated":"2023-03-02T02:18:56Z","published":"2023-03-02T02:18:56Z","title":"Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation","summary":"  Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. We take\ninspiration from the biological plausibility learning where the neuron\nresponses are tuned based on a local synapse-change procedure and activated by\ncompetitive lateral inhibition rules. Based on these feed-forward learning\nrules, we design a soft Hebbian learning process which provides an unsupervised\nand effective mechanism for online adaptation. We observe that the performance\nof this feed-forward Hebbian learning for fully test-time adaptation can be\nsignificantly improved by incorporating a feedback neuro-modulation layer. It\nis able to fine-tune the neuron responses based on the external feedback\ngenerated by the error back-propagation from the top inference layers. This\nleads to our proposed neuro-modulated Hebbian learning (NHL) method for fully\ntest-time adaptation. With the unsupervised feed-forward soft Hebbian learning\nbeing combined with a learned neuro-modulator to capture feedback from external\nresponses, the source model can be effectively adapted during the testing\nprocess. Experimental results on benchmark datasets demonstrate that our\nproposed method can significantly improve the adaptation performance of network\nmodels and outperforms existing state-of-the-art methods.\n","authors":["Yushun Tang","Ce Zhang","Heng Xu","Shuoshuo Chen","Jie Cheng","Luziwei Leng","Qinghai Guo","Zhihai He"],"pdf_url":"https://arxiv.org/pdf/2303.00914v1.pdf","comment":"CVPR2023 accepted"},{"id":"http://arxiv.org/abs/2302.14557v2","updated":"2023-03-02T02:01:19Z","published":"2023-02-28T13:26:24Z","title":"GRAN: Ghost Residual Attention Network for Single Image Super Resolution","summary":"  Recently, many works have designed wider and deeper networks to achieve\nhigher image super-resolution performance. Despite their outstanding\nperformance, they still suffer from high computational resources, preventing\nthem from directly applying to embedded devices. To reduce the computation\nresources and maintain performance, we propose a novel Ghost Residual Attention\nNetwork (GRAN) for efficient super-resolution. This paper introduces Ghost\nResidual Attention Block (GRAB) groups to overcome the drawbacks of the\nstandard convolutional operation, i.e., redundancy of the intermediate feature.\nGRAB consists of the Ghost Module and Channel and Spatial Attention Module\n(CSAM) to alleviate the generation of redundant features. Specifically, Ghost\nModule can reveal information underlying intrinsic features by employing linear\noperations to replace the standard convolutions. Reducing redundant features by\nthe Ghost Module, our model decreases memory and computing resource\nrequirements in the network. The CSAM pays more comprehensive attention to\nwhere and what the feature extraction is, which is critical to recovering the\nimage details. Experiments conducted on the benchmark datasets demonstrate the\nsuperior performance of our method in both qualitative and quantitative.\nCompared to the baseline models, we achieve higher performance with lower\ncomputational resources, whose parameters and FLOPs have decreased by more than\nten times.\n","authors":["Axi Niu","Pei Wang","Yu Zhu","Jinqiu Sun","Qingsen Yan","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14557v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00905v1","updated":"2023-03-02T01:55:10Z","published":"2023-03-02T01:55:10Z","title":"Open-World Object Manipulation using Pre-trained Vision-Language Models","summary":"  For robots to follow instructions from people, they must be able to connect\nthe rich semantic information in human vocabulary, e.g. \"can you get me the\npink stuffed whale?\" to their sensory observations and actions. This brings up\na notably difficult challenge for robots: while robot learning approaches allow\nrobots to learn many different behaviors from first-hand experience, it is\nimpractical for robots to have first-hand experiences that span all of this\nsemantic information. We would like a robot's policy to be able to perceive and\npick up the pink stuffed whale, even if it has never seen any data interacting\nwith a stuffed whale before. Fortunately, static data on the internet has vast\nsemantic information, and this information is captured in pre-trained\nvision-language models. In this paper, we study whether we can interface robot\npolicies with these pre-trained models, with the aim of allowing robots to\ncomplete instructions involving object categories that the robot has never seen\nfirst-hand. We develop a simple approach, which we call Manipulation of\nOpen-World Objects (MOO), which leverages a pre-trained vision-language model\nto extract object-identifying information from the language command and image,\nand conditions the robot policy on the current image, the instruction, and the\nextracted object information. In a variety of experiments on a real mobile\nmanipulator, we find that MOO generalizes zero-shot to a wide range of novel\nobject categories and environments. In addition, we show how MOO generalizes to\nother, non-language-based input modalities to specify the object of interest\nsuch as finger pointing, and how it can be further extended to enable\nopen-world navigation and manipulation. The project's website and evaluation\nvideos can be found at https://robot-moo.github.io/\n","authors":["Austin Stone","Ted Xiao","Yao Lu","Keerthana Gopalakrishnan","Kuang-Huei Lee","Quan Vuong","Paul Wohlhart","Brianna Zitkovich","Fei Xia","Chelsea Finn","Karol Hausman"],"pdf_url":"https://arxiv.org/pdf/2303.00905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05423v4","updated":"2023-03-02T01:52:48Z","published":"2022-10-11T13:04:59Z","title":"Learning to Locate Visual Answer in Video Corpus Using Question","summary":"  We introduce a new task, named video corpus visual answer localization\n(VCVAL), which aims to locate the visual answer in a large collection of\nuntrimmed instructional videos using a natural language question. This task\nrequires a range of skills - the interaction between vision and language, video\nretrieval, passage comprehension, and visual answer localization. In this\npaper, we propose a cross-modal contrastive global-span (CCGS) method for the\nVCVAL, jointly training the video corpus retrieval and visual answer\nlocalization subtasks with the global-span matrix. We have reconstructed a\ndataset named MedVidCQA, on which the VCVAL task is benchmarked. Experimental\nresults show that the proposed method outperforms other competitive methods\nboth in the video corpus retrieval and visual answer localization subtasks.\nMost importantly, we perform detailed analyses on extensive experiments, paving\na new path for understanding the instructional videos, which ushers in further\nresearch.\n","authors":["Bin Li","Yixuan Weng","Bin Sun","Shutao Li"],"pdf_url":"https://arxiv.org/pdf/2210.05423v4.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00900v1","updated":"2023-03-02T01:48:05Z","published":"2023-03-02T01:48:05Z","title":"Transmission-Guided Bayesian Generative Model for Smoke Segmentation","summary":"  Smoke segmentation is essential to precisely localize wildfire so that it can\nbe extinguished in an early phase. Although deep neural networks have achieved\npromising results on image segmentation tasks, they are prone to be\noverconfident for smoke segmentation due to its non-rigid shape and transparent\nappearance. This is caused by both knowledge level uncertainty due to limited\ntraining data for accurate smoke segmentation and labeling level uncertainty\nrepresenting the difficulty in labeling ground-truth. To effectively model the\ntwo types of uncertainty, we introduce a Bayesian generative model to\nsimultaneously estimate the posterior distribution of model parameters and its\npredictions. Further, smoke images suffer from low contrast and ambiguity,\ninspired by physics-based image dehazing methods, we design a\ntransmission-guided local coherence loss to guide the network to learn\npair-wise relationships based on pixel distance and the transmission feature.\nTo promote the development of this field, we also contribute a high-quality\nsmoke segmentation dataset, SMOKE5K, consisting of 1,400 real and 4,000\nsynthetic images with pixel-wise annotation. Experimental results on benchmark\ntesting datasets illustrate that our model achieves both accurate predictions\nand reliable uncertainty maps representing model ignorance about its\nprediction. Our code and dataset are publicly available at:\nhttps://github.com/redlessme/Transmission-BVM.\n","authors":["Siyuan Yan","Jing Zhang","Nick Barnes"],"pdf_url":"https://arxiv.org/pdf/2303.00900v1.pdf","comment":"Accepted by AAAI2022"},{"id":"http://arxiv.org/abs/2204.07946v2","updated":"2023-03-02T01:42:42Z","published":"2022-04-17T07:20:50Z","title":"Integrated In-vehicle Monitoring System Using 3D Human Pose Estimation\n  and Seat Belt Segmentation","summary":"  Recently, along with interest in autonomous vehicles, the importance of\nmonitoring systems for both drivers and passengers inside vehicles has been\nincreasing. This paper proposes a novel in-vehicle monitoring system the\ncombines 3D pose estimation, seat-belt segmentation, and seat-belt status\nclassification networks. Our system outputs various information necessary for\nmonitoring by accurately considering the data characteristics of the in-vehicle\nenvironment. Specifically, the proposed 3D pose estimation directly estimates\nthe absolute coordinates of keypoints for a driver and passengers, and the\nproposed seat-belt segmentation is implemented by applying a structure based on\nthe feature pyramid. In addition, we propose a classification task to\ndistinguish between normal and abnormal states of wearing a seat belt using\nresults that combine 3D pose estimation with seat-belt segmentation. These\ntasks can be learned simultaneously and operate in real-time. Our method was\nevaluated on a private dataset we newly created and annotated. The experimental\nresults show that our method has significantly high performance that can be\napplied directly to real in-vehicle monitoring systems.\n","authors":["Ginam Kim","Hyunsung Kim","Joseph Kihoon Kim","Sung-Sik Cho","Yeong-Hun Park","Suk-Ju Kang"],"pdf_url":"https://arxiv.org/pdf/2204.07946v2.pdf","comment":"AAAI 2022 workshop AI for Transportation accepted"},{"id":"http://arxiv.org/abs/2303.00175v2","updated":"2023-03-02T01:40:50Z","published":"2023-03-01T02:07:48Z","title":"A Deep Neural Architecture for Harmonizing 3-D Input Data Analysis and\n  Decision Making in Medical Imaging","summary":"  Harmonizing the analysis of data, especially of 3-D image volumes, consisting\nof different number of slices and annotated per volume, is a significant\nproblem in training and using deep neural networks in various applications,\nincluding medical imaging. Moreover, unifying the decision making of the\nnetworks over different input datasets is crucial for the generation of rich\ndata-driven knowledge and for trusted usage in the applications. This paper\npresents a new deep neural architecture, named RACNet, which includes routing\nand feature alignment steps and effectively handles different input lengths and\nsingle annotations of the 3-D image inputs, whilst providing highly accurate\ndecisions. In addition, through latent variable extraction from the trained\nRACNet, a set of anchors are generated providing further insight on the\nnetwork's decision making. These can be used to enrich and unify data-driven\nknowledge extracted from different datasets. An extensive experimental study\nillustrates the above developments, focusing on COVID-19 diagnosis through\nanalysis of 3-D chest CT scans from databases generated in different countries\nand medical centers.\n","authors":["Dimitrios Kollias","Anastasios Arsenos","Stefanos Kollias"],"pdf_url":"https://arxiv.org/pdf/2303.00175v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00180v2","updated":"2023-03-02T01:32:53Z","published":"2023-03-01T02:14:20Z","title":"FaceRNET: a Facial Expression Intensity Estimation Network","summary":"  This paper presents our approach for Facial Expression Intensity Estimation\nfrom videos. It includes two components: i) a representation extractor network\nthat extracts various emotion descriptors (valence-arousal, action units and\nbasic expressions) from each videoframe; ii) a RNN that captures temporal\ninformation in the data, followed by a mask layer which enables handling\nvarying input video lengths through dynamic routing. This approach has been\ntested on the Hume-Reaction dataset yielding excellent results.\n","authors":["Dimitrios Kollias","Andreas Psaroudakis","Anastasios Arsenos","Paraskeui Theofilou"],"pdf_url":"https://arxiv.org/pdf/2303.00180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00369v2","updated":"2023-03-02T01:23:23Z","published":"2023-03-01T09:50:39Z","title":"Indescribable Multi-modal Spatial Evaluator","summary":"  Multi-modal image registration spatially aligns two images with different\ndistributions. One of its major challenges is that images acquired from\ndifferent imaging machines have different imaging distributions, making it\ndifficult to focus only on the spatial aspect of the images and ignore\ndifferences in distributions. In this study, we developed a self-supervised\napproach, Indescribable Multi-model Spatial Evaluator (IMSE), to address\nmulti-modal image registration. IMSE creates an accurate multi-modal spatial\nevaluator to measure spatial differences between two images, and then optimizes\nregistration by minimizing the error predicted of the evaluator. To optimize\nIMSE performance, we also proposed a new style enhancement method called\nShuffle Remap which randomizes the image distribution into multiple segments,\nand then randomly disorders and remaps these segments, so that the distribution\nof the original image is changed. Shuffle Remap can help IMSE to predict the\ndifference in spatial location from unseen target distributions. Our results\nshow that IMSE outperformed the existing methods for registration using T1-T2\nand CT-MRI datasets. IMSE also can be easily integrated into the traditional\nregistration process, and can provide a convenient way to evaluate and\nvisualize registration results. IMSE also has the potential to be used as a new\nparadigm for image-to-image translation. Our code is available at\nhttps://github.com/Kid-Liet/IMSE.\n","authors":["Lingke Kong","X. Sharon Qi","Qijin Shen","Jiacheng Wang","Jingyi Zhang","Yanle Hu","Qichao Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.00369v2.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.00891v1","updated":"2023-03-02T01:14:32Z","published":"2023-03-02T01:14:32Z","title":"MoSS: Monocular Shape Sensing for Continuum Robots","summary":"  Continuum robots are promising candidates for interactive tasks in various\napplications due to their unique shape, compliance, and miniaturization\ncapability. Accurate and real-time shape sensing is essential for such tasks\nyet remains a challenge. Embedded shape sensing has high hardware complexity\nand cost, while vision-based methods require stereo setup and struggle to\nachieve real-time performance. This paper proposes the first eye-to-hand\nmonocular approach to continuum robot shape sensing. Utilizing a deep\nencoder-decoder network, our method, MoSSNet, eliminates the computation cost\nof stereo matching and reduces requirements on sensing hardware. In particular,\nMoSSNet comprises an encoder and three parallel decoders to uncover spatial,\nlength, and contour information from a single RGB image, and then obtains the\n3D shape through curve fitting. A two-segment tendon-driven continuum robot is\nused for data collection and testing, demonstrating accurate (mean shape error\nof 0.91 mm, or 0.36% of robot length) and real-time (70 fps) shape sensing on\nreal-world data. Additionally, the method is optimized end-to-end and does not\nrequire fiducial markers, manual segmentation, or camera calibration. Code and\ndatasets will be made available at\nhttps://github.com/ContinuumRoboticsLab/MoSSNet.\n","authors":["Chengnan Shentu","Enxu Li","Chaojun Chen","Puspita Triana Dewi","David B. Lindell","Jessica Burgner-Kahrs"],"pdf_url":"https://arxiv.org/pdf/2303.00891v1.pdf","comment":"8 pages, 6 figures, submitted to IROS 2023"},{"id":"http://arxiv.org/abs/2206.06487v3","updated":"2023-03-02T01:12:05Z","published":"2022-06-13T21:34:21Z","title":"The Modality Focusing Hypothesis: Towards Understanding Crossmodal\n  Knowledge Distillation","summary":"  Crossmodal knowledge distillation (KD) extends traditional knowledge\ndistillation to the area of multimodal learning and demonstrates great success\nin various applications. To achieve knowledge transfer across modalities, a\npretrained network from one modality is adopted as the teacher to provide\nsupervision signals to a student network learning from another modality. In\ncontrast to the empirical success reported in prior works, the working\nmechanism of crossmodal KD remains a mystery. In this paper, we present a\nthorough understanding of crossmodal KD. We begin with two case studies and\ndemonstrate that KD is not a universal cure in crossmodal knowledge transfer.\nWe then present the modality Venn diagram to understand modality relationships\nand the modality focusing hypothesis revealing the decisive factor in the\nefficacy of crossmodal KD. Experimental results on 6 multimodal datasets help\njustify our hypothesis, diagnose failure cases, and point directions to improve\ncrossmodal knowledge transfer in the future.\n","authors":["Zihui Xue","Zhengqi Gao","Sucheng Ren","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2206.06487v3.pdf","comment":"Accepted by ICLR 2023 (top-5%). The first three authors contribute\n  equally. Project website: https://zihuixue.github.io/MFH/index.html"},{"id":"http://arxiv.org/abs/2303.00886v1","updated":"2023-03-02T01:06:35Z","published":"2023-03-02T01:06:35Z","title":"Photovoltaic Panel Defect Detection Based on Ghost Convolution with\n  BottleneckCSP and Tiny Target Prediction Head Incorporating YOLOv5","summary":"  Photovoltaic (PV) panel surface-defect detection technology is crucial for\nthe PV industry to perform smart maintenance. Using computer vision technology\nto detect PV panel surface defects can ensure better accuracy while reducing\nthe workload of traditional worker field inspections. However, multiple tiny\ndefects on the PV panel surface and the high similarity between different\ndefects make it challenging to {accurately identify and detect such defects}.\nThis paper proposes an approach named Ghost convolution with BottleneckCSP and\na tiny target prediction head incorporating YOLOv5 (GBH-YOLOv5) for PV panel\ndefect detection. To ensure better accuracy on multiscale targets, the\nBottleneckCSP module is introduced to add a prediction head for tiny target\ndetection to alleviate tiny defect misses, using Ghost convolution to improve\nthe model inference speed and reduce the number of parameters. First, the\noriginal image is compressed and cropped to enlarge the defect size physically.\nThen, the processed images are input into GBH-YOLOv5, and the depth features\nare extracted through network processing based on Ghost convolution, the\napplication of the BottleneckCSP module, and the prediction head of tiny\ntargets. Finally, the extracted features are classified by a Feature Pyramid\nNetwork (FPN) and a Path Aggregation Network (PAN) structure. Meanwhile, we\ncompare our method with state-of-the-art methods to verify the effectiveness of\nthe proposed method. The proposed PV panel surface-defect detection network\nimproves the mAP performance by at least 27.8%.\n","authors":["Longlong Li","Zhifeng Wang","Tingting Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00886v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.00885v1","updated":"2023-03-02T01:02:18Z","published":"2023-03-02T01:02:18Z","title":"Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision","summary":"  Deep neural networks have demonstrated promising performance on image\nrecognition tasks. However, they may heavily rely on confounding factors, using\nirrelevant artifacts or bias within the dataset as the cue to improve\nperformance. When a model performs decision-making based on these spurious\ncorrelations, it can become untrustable and lead to catastrophic outcomes when\ndeployed in the real-world scene. In this paper, we explore and try to solve\nthis problem in the context of skin cancer diagnosis. We introduce a\nhuman-in-the-loop framework in the model training process such that users can\nobserve and correct the model's decision logic when confounding behaviors\nhappen. Specifically, our method can automatically discover confounding factors\nby analyzing the co-occurrence behavior of the samples. It is capable of\nlearning confounding concepts using easily obtained concept exemplars. By\nmapping the black-box model's feature representation onto an explainable\nconcept space, human users can interpret the concept and intervene via first\norder-logic instruction. We systematically evaluate our method on our newly\ncrafted, well-controlled skin lesion dataset and several public skin lesion\ndatasets. Experiments show that our method can effectively detect and remove\nconfounding factors from datasets without any prior knowledge about the\ncategory distribution and does not require fully annotated concept labels. We\nalso show that our method enables the model to focus on clinical-related\nconcepts, improving the model's performance and trustworthiness during model\ninference.\n","authors":["Siyuan Yan","Zhen Yu","Xuelin Zhang","Dwarikanath Mahapatra","Shekhar S. Chandra","Monika Janda","Peter Soyer","Zongyuan Ge"],"pdf_url":"https://arxiv.org/pdf/2303.00885v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00882v1","updated":"2023-03-02T00:52:41Z","published":"2023-03-02T00:52:41Z","title":"X-Ray2EM: Uncertainty-Aware Cross-Modality Image Reconstruction from\n  X-Ray to Electron Microscopy in Connectomics","summary":"  Comprehensive, synapse-resolution imaging of the brain will be crucial for\nunderstanding neuronal computations and function. In connectomics, this has\nbeen the sole purview of volume electron microscopy (EM), which entails an\nexcruciatingly difficult process because it requires cutting tissue into many\nthin, fragile slices that then need to be imaged, aligned, and reconstructed.\nUnlike EM, hard X-ray imaging is compatible with thick tissues, eliminating the\nneed for thin sectioning, and delivering fast acquisition, intrinsic alignment,\nand isotropic resolution. Unfortunately, current state-of-the-art X-ray\nmicroscopy provides much lower resolution, to the extent that segmenting\nmembranes is very challenging. We propose an uncertainty-aware 3D\nreconstruction model that translates X-ray images to EM-like images with\nenhanced membrane segmentation quality, showing its potential for developing\nsimpler, faster, and more accurate X-ray based connectomics pipelines.\n","authors":["Yicong Li","Yaron Meirovitch","Aaron T. Kuan","Jasper S. Phelps","Alexandra Pacureanu","Wei-Chung Allen Lee","Nir Shavit","Lu Mi"],"pdf_url":"https://arxiv.org/pdf/2303.00882v1.pdf","comment":"Accepted by ISBI 2023 conference. Supplementary material is available\n  in this arXiv version"},{"id":"http://arxiv.org/abs/2203.08382v3","updated":"2023-03-02T00:32:44Z","published":"2022-03-16T04:10:45Z","title":"Dual Diffusion Implicit Bridges for Image-to-Image Translation","summary":"  Common image-to-image translation methods rely on joint training over data\nfrom both source and target domains. The training process requires concurrent\naccess to both datasets, which hinders data separation and privacy protection;\nand existing models cannot be easily adapted for translation of new domain\npairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation\nmethod based on diffusion models, that circumvents training on domain pairs.\nImage translation with DDIBs relies on two diffusion models trained\nindependently on each domain, and is a two-step process: DDIBs first obtain\nlatent encodings for source images with the source diffusion model, and then\ndecode such encodings using the target model to construct target images. Both\nsteps are defined via ordinary differential equations (ODEs), thus the process\nis cycle consistent only up to discretization errors of the ODE solvers.\nTheoretically, we interpret DDIBs as concatenation of source to latent, and\nlatent to target Schrodinger Bridges, a form of entropy-regularized optimal\ntransport, to explain the efficacy of the method. Experimentally, we apply\nDDIBs on synthetic and high-resolution image datasets, to demonstrate their\nutility in a wide variety of translation tasks and their inherent optimal\ntransport properties.\n","authors":["Xuan Su","Jiaming Song","Chenlin Meng","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2203.08382v3.pdf","comment":"18 pages, 12 figures, in the Eleventh International Conference on\n  Learning Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2205.13192v2","updated":"2023-03-02T00:27:11Z","published":"2022-05-26T07:08:32Z","title":"Tree Reconstruction using Topology Optimisation","summary":"  Generating accurate digital tree models from scanned environments is\ninvaluable for forestry, agriculture, and other outdoor industries in tasks\nsuch as identifying biomass, fall hazards and traversability, as well as\ndigital applications such as animation and gaming. Existing methods for tree\nreconstruction rely on feature identification (trunk, crown, etc) to\nheuristically segment a forest into individual trees and generate a branch\nstructure graph, limiting their application to sparse trees and uniform\nforests. However, the natural world is a messy place in which trees present\nwith significant heterogeneity and are frequently encroached upon by the\nsurrounding environment. We present a general method for extracting the branch\nstructure of trees from point cloud data, which estimates the structure of\ntrees by adapting the methods of structural topology optimisation to find the\noptimal material distribution to support wind-loading. We present the results\nof this optimisation over a wide variety of scans, and discuss the benefits and\ndrawbacks of this novel approach to tree structure reconstruction. Despite the\nhigh variability of datasets containing trees, and the high rate of occlusions,\nour method generates detailed and accurate tree structures in most cases.\n","authors":["Thomas Lowe","Joshua Pinskier"],"pdf_url":"https://arxiv.org/pdf/2205.13192v2.pdf","comment":"The datasets generated and used in the current study are available in\n  the Tree Reconstructions from Pointclouds Scanned in Pullenvale QLD\n  repository, https://doi.org/10.25919/yt2m-9373"},{"id":"http://arxiv.org/abs/2303.00874v1","updated":"2023-03-02T00:21:15Z","published":"2023-03-02T00:21:15Z","title":"Geometric Visual Similarity Learning in 3D Medical Image Self-supervised\n  Pre-training","summary":"  Learning inter-image similarity is crucial for 3D medical images\nself-supervised pre-training, due to their sharing of numerous same semantic\nregions. However, the lack of the semantic prior in metrics and the\nsemantic-independent variation in 3D medical images make it challenging to get\na reliable measurement for the inter-image similarity, hindering the learning\nof consistent representation for same semantics. We investigate the challenging\nproblem of this task, i.e., learning a consistent representation between images\nfor a clustering effect of same semantic features. We propose a novel visual\nsimilarity learning paradigm, Geometric Visual Similarity Learning, which\nembeds the prior of topological invariance into the measurement of the\ninter-image similarity for consistent representation of semantic regions. To\ndrive this paradigm, we further construct a novel geometric matching head, the\nZ-matching head, to collaboratively learn the global and local similarity of\nsemantic regions, guiding the efficient representation learning for different\nscale-level inter-image semantic features. Our experiments demonstrate that the\npre-training with our learning of inter-image similarity yields more powerful\ninner-scene, inter-scene, and global-local transferring ability on four\nchallenging 3D medical image tasks. Our codes and pre-trained models will be\npublicly available on https://github.com/YutingHe-list/GVSL.\n","authors":["Yuting He","Guanyu Yang","Rongjun Ge","Yang Chen","Jean-Louis Coatrieux","Boyu Wang","Shuo Li"],"pdf_url":"https://arxiv.org/pdf/2303.00874v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00871v1","updated":"2023-03-02T00:01:13Z","published":"2023-03-02T00:01:13Z","title":"Bayesian Deep Learning for Affordance Segmentation in images","summary":"  Affordances are a fundamental concept in robotics since they relate available\nactions for an agent depending on its sensory-motor capabilities and the\nenvironment. We present a novel Bayesian deep network to detect affordances in\nimages, at the same time that we quantify the distribution of the aleatoric and\nepistemic variance at the spatial level. We adapt the Mask-RCNN architecture to\nlearn a probabilistic representation using Monte Carlo dropout. Our results\noutperform the state-of-the-art of deterministic networks. We attribute this\nimprovement to a better probabilistic feature space representation on the\nencoder and the Bayesian variability induced at the mask generation, which\nadapts better to the object contours. We also introduce the new\nProbability-based Mask Quality measure that reveals the semantic and spatial\ndifferences on a probabilistic instance segmentation model. We modify the\nexisting Probabilistic Detection Quality metric by comparing the binary masks\nrather than the predicted bounding boxes, achieving a finer-grained evaluation\nof the probabilistic segmentation. We find aleatoric variance in the contours\nof the objects due to the camera noise, while epistemic variance appears in\nvisual challenging pixels.\n","authors":["Lorenzo Mur-Labadia","Ruben Martinez-Cantin","Jose J. Guerrero"],"pdf_url":"https://arxiv.org/pdf/2303.00871v1.pdf","comment":"2023 IEEE International Conference on Robotics and Automation (ICRA)"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.01297v1","updated":"2023-03-02T14:23:27Z","published":"2023-03-02T14:23:27Z","title":"Creating Synthetic Datasets for Collaborative Filtering Recommender\n  Systems using Generative Adversarial Networks","summary":"  Research and education in machine learning needs diverse, representative, and\nopen datasets that contain sufficient samples to handle the necessary training,\nvalidation, and testing tasks. Currently, the Recommender Systems area includes\na large number of subfields in which accuracy and beyond accuracy quality\nmeasures are continuously improved. To feed this research variety, it is\nnecessary and convenient to reinforce the existing datasets with synthetic\nones. This paper proposes a Generative Adversarial Network (GAN)-based method\nto generate collaborative filtering datasets in a parameterized way, by\nselecting their preferred number of users, items, samples, and stochastic\nvariability. This parameterization cannot be made using regular GANs. Our GAN\nmodel is fed with dense, short, and continuous embedding representations of\nitems and users, instead of sparse, large, and discrete vectors, to make an\naccurate and quick learning, compared to the traditional approach based on\nlarge and sparse input vectors. The proposed architecture includes a DeepMF\nmodel to extract the dense user and item embeddings, as well as a clustering\nprocess to convert from the dense GAN generated samples to the discrete and\nsparse ones, necessary to create each required synthetic dataset. The results\nof three different source datasets show adequate distributions and expected\nquality values and evolutions on the generated datasets compared to the source\nones. Synthetic datasets and source codes are available to researchers.\n","authors":["Jesús Bobadilla","Abraham Gutiérrez","Raciel Yera","Luis Martínez"],"pdf_url":"https://arxiv.org/pdf/2303.01297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.10258v3","updated":"2023-03-02T12:50:53Z","published":"2022-03-19T06:48:50Z","title":"TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased\n  Recommendations","summary":"  Bias is a common problem inherent in recommender systems, which is entangled\nwith users' preferences and poses a great challenge to unbiased learning. For\ndebiasing tasks, the doubly robust (DR) method and its variants show superior\nperformance due to the double robustness property, that is, DR is unbiased when\neither imputed errors or learned propensities are accurate. However, our\ntheoretical analysis reveals that DR usually has a large variance. Meanwhile,\nDR would suffer unexpectedly large bias and poor generalization caused by\ninaccurate imputed errors and learned propensities, which usually occur in\npractice. In this paper, we propose a principled approach that can effectively\nreduce bias and variance simultaneously for existing DR approaches when the\nerror imputation model is misspecified. In addition, we further propose a novel\nsemi-parametric collaborative learning approach that decomposes imputed errors\ninto parametric and nonparametric parts and updates them collaboratively,\nresulting in more accurate predictions. Both theoretical analysis and\nexperiments demonstrate the superiority of the proposed methods compared with\nexisting debiasing methods.\n","authors":["Haoxuan Li","Yan Lyu","Chunyuan Zheng","Peng Wu"],"pdf_url":"https://arxiv.org/pdf/2203.10258v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01200v1","updated":"2023-03-02T12:33:52Z","published":"2023-03-02T12:33:52Z","title":"Retrieval for Extremely Long Queries and Documents with RPRS: a Highly\n  Efficient and Effective Transformer-based Re-Ranker","summary":"  Retrieval with extremely long queries and documents is a well-known and\nchallenging task in information retrieval and is commonly known as\nQuery-by-Document (QBD) retrieval. Specifically designed Transformer models\nthat can handle long input sequences have not shown high effectiveness in QBD\ntasks in previous work. We propose a Re-Ranker based on the novel Proportional\nRelevance Score (RPRS) to compute the relevance score between a query and the\ntop-k candidate documents. Our extensive evaluation shows RPRS obtains\nsignificantly better results than the state-of-the-art models on five different\ndatasets. Furthermore, RPRS is highly efficient since all documents can be\npre-processed, embedded, and indexed before query time which gives our\nre-ranker the advantage of having a complexity of O(N) where N is the total\nnumber of sentences in the query and candidate documents. Furthermore, our\nmethod solves the problem of the low-resource training in QBD retrieval tasks\nas it does not need large amounts of training data, and has only three\nparameters with a limited range that can be optimized with a grid search even\nif a small amount of labeled data is available. Our detailed analysis shows\nthat RPRS benefits from covering the full length of candidate documents and\nqueries.\n","authors":["Arian Askari","Suzan Verberne","Amin Abolghasemi","Wessel Kraaij","Gabriella Pasi"],"pdf_url":"https://arxiv.org/pdf/2303.01200v1.pdf","comment":"Under peer review"},{"id":"http://arxiv.org/abs/2303.01136v1","updated":"2023-03-02T10:33:11Z","published":"2023-03-02T10:33:11Z","title":"Effective Visualization and Analysis of Recommender Systems","summary":"  Recommender system exists everywhere in the business world. From Goodreads to\nTikTok, customers of internet products become more addicted to the products\nthanks to the technology. Industrial practitioners focus on increasing the\ntechnical accuracy of recommender systems while at same time balancing other\nfactors such as diversity and serendipity. In spite of the length of the\nresearch and development history of recommender systems, there has been little\ndiscussion on how to take advantage of visualization techniques to facilitate\nthe algorithmic design of the technology. In this paper, we use a series of\ndata analysis and visualization techniques such as Takens Embedding,\nDeterminantal Point Process and Social Network Analysis to help people develop\neffective recommender systems by predicting intermediate computational cost and\noutput performance. Our work is pioneering in the field, as to our limited\nknowledge, there have been few publications (if any) on visualization of\nrecommender systems.\n","authors":["Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01130v1","updated":"2023-03-02T10:23:50Z","published":"2023-03-02T10:23:50Z","title":"Distillation from Heterogeneous Models for Top-K Recommendation","summary":"  Recent recommender systems have shown remarkable performance by using an\nensemble of heterogeneous models. However, it is exceedingly costly because it\nrequires resources and inference latency proportional to the number of models,\nwhich remains the bottleneck for production. Our work aims to transfer the\nensemble knowledge of heterogeneous teachers to a lightweight student model\nusing knowledge distillation (KD), to reduce the huge inference costs while\nretaining high accuracy. Through an empirical study, we find that the efficacy\nof distillation severely drops when transferring knowledge from heterogeneous\nteachers. Nevertheless, we show that an important signal to ease the difficulty\ncan be obtained from the teacher's training trajectory. This paper proposes a\nnew KD framework, named HetComp, that guides the student model by transferring\neasy-to-hard sequences of knowledge generated from the teachers' trajectories.\nTo provide guidance according to the student's learning state, HetComp uses\ndynamic knowledge construction to provide progressively difficult ranking\nknowledge and adaptive knowledge transfer to gradually transfer finer-grained\nranking information. Our comprehensive experiments show that HetComp\nsignificantly improves the distillation quality and the generalization of the\nstudent model.\n","authors":["SeongKu Kang","Wonbin Kweon","Dongha Lee","Jianxun Lian","Xing Xie","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01130v1.pdf","comment":"TheWebConf'23"},{"id":"http://arxiv.org/abs/2303.00995v1","updated":"2023-03-02T06:07:22Z","published":"2023-03-02T06:07:22Z","title":"Heterogeneous Graph Contrastive Learning for Recommendation","summary":"  Graph Neural Networks (GNNs) have become powerful tools in modeling\ngraph-structured data in recommender systems. However, real-life recommendation\nscenarios usually involve heterogeneous relationships (e.g., social-aware user\ninfluence, knowledge-aware item dependency) which contains fruitful information\nto enhance the user preference learning. In this paper, we study the problem of\nheterogeneous graph-enhanced relational learning for recommendation. Recently,\ncontrastive self-supervised learning has become successful in recommendation.\nIn light of this, we propose a Heterogeneous Graph Contrastive Learning (HGCL),\nwhich is able to incorporate heterogeneous relational semantics into the\nuser-item interaction modeling with contrastive learning-enhanced knowledge\ntransfer across different views. However, the influence of heterogeneous side\ninformation on interactions may vary by users and items. To move this idea\nforward, we enhance our heterogeneous graph contrastive learning with meta\nnetworks to allow the personalized knowledge transformer with adaptive\ncontrastive augmentation. The experimental results on three real-world datasets\ndemonstrate the superiority of HGCL over state-of-the-art recommendation\nmethods. Through ablation study, key components in HGCL method are validated to\nbenefit the recommendation performance improvement. The source code of the\nmodel implementation is available at the link https://github.com/HKUDS/HGCL.\n","authors":["Mengru Chen","Chao Huang","Lianghao Xia","Wei Wei","Yong Xu","Ronghua Luo"],"pdf_url":"https://arxiv.org/pdf/2303.00995v1.pdf","comment":"This paper has been published as a full paper at WSDM 2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2303.01500v1","updated":"2023-03-02T18:59:15Z","published":"2023-03-02T18:59:15Z","title":"Dropout Reduces Underfitting","summary":"  Introduced by Hinton et al. in 2012, dropout has stood the test of time as a\nregularizer for preventing overfitting in neural networks. In this study, we\ndemonstrate that dropout can also mitigate underfitting when used at the start\nof training. During the early phase, we find dropout reduces the directional\nvariance of gradients across mini-batches and helps align the mini-batch\ngradients with the entire dataset's gradient. This helps counteract the\nstochasticity of SGD and limit the influence of individual batches on model\ntraining. Our findings lead us to a solution for improving performance in\nunderfitting models - early dropout: dropout is applied only during the initial\nphases of training, and turned off afterwards. Models equipped with early\ndropout achieve lower final training loss compared to their counterparts\nwithout dropout. Additionally, we explore a symmetric technique for\nregularizing overfitting models - late dropout, where dropout is not used in\nthe early iterations and is only activated later in training. Experiments on\nImageNet and various vision tasks demonstrate that our methods consistently\nimprove generalization accuracy. Our results encourage more research on\nunderstanding regularization in deep learning and our methods can be useful\ntools for future neural network training, especially in the era of large data.\nCode is available at https://github.com/facebookresearch/dropout .\n","authors":["Zhuang Liu","Zhiqiu Xu","Joseph Jin","Zhiqiang Shen","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2303.01500v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2303.01498v1","updated":"2023-03-02T18:58:15Z","published":"2023-03-02T18:58:15Z","title":"ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit\n  Detection & Emotional Reaction Intensity Estimation Challenges","summary":"  The fifth Affective Behavior Analysis in-the-wild (ABAW) Competition is part\nof the respective ABAW Workshop which will be held in conjunction with IEEE\nComputer Vision and Pattern Recognition Conference (CVPR), 2023. The 5th ABAW\nCompetition is a continuation of the Competitions held at ECCV 2022, IEEE CVPR\n2022, ICCV 2021, IEEE FG 2020 and CVPR 2017 Conferences, and is dedicated at\nautomatically analyzing affect. For this year's Competition, we feature two\ncorpora: i) an extended version of the Aff-Wild2 database and ii) the\nHume-Reaction dataset. The former database is an audiovisual one of around 600\nvideos of around 3M frames and is annotated with respect to:a) two continuous\naffect dimensions -valence (how positive/negative a person is) and arousal (how\nactive/passive a person is)-; b) basic expressions (e.g. happiness, sadness,\nneutral state); and c) atomic facial muscle actions (i.e., action units). The\nlatter dataset is an audiovisual one in which reactions of individuals to\nemotional stimuli have been annotated with respect to seven emotional\nexpression intensities. Thus the 5th ABAW Competition encompasses four\nChallenges: i) uni-task Valence-Arousal Estimation, ii) uni-task Expression\nClassification, iii) uni-task Action Unit Detection, and iv) Emotional Reaction\nIntensity Estimation. In this paper, we present these Challenges, along with\ntheir corpora, we outline the evaluation metrics, we present the baseline\nsystems and illustrate their obtained performance.\n","authors":["Dimitrios Kollias","Panagiotis Tzirakis","Alice Baird","Alan Cowen","Stefanos Zafeiriou"],"pdf_url":"https://arxiv.org/pdf/2303.01498v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.10659"},{"id":"http://arxiv.org/abs/2303.01497v1","updated":"2023-03-02T18:57:38Z","published":"2023-03-02T18:57:38Z","title":"Teach a Robot to FISH: Versatile Imitation from One Minute of\n  Demonstrations","summary":"  While imitation learning provides us with an efficient toolkit to train\nrobots, learning skills that are robust to environment variations remains a\nsignificant challenge. Current approaches address this challenge by relying\neither on large amounts of demonstrations that span environment variations or\non handcrafted reward functions that require state estimates. Both directions\nare not scalable to fast imitation. In this work, we present Fast Imitation of\nSkills from Humans (FISH), a new imitation learning approach that can learn\nrobust visual skills with less than a minute of human demonstrations. Given a\nweak base-policy trained by offline imitation of demonstrations, FISH computes\nrewards that correspond to the \"match\" between the robot's behavior and the\ndemonstrations. These rewards are then used to adaptively update a residual\npolicy that adds on to the base-policy. Across all tasks, FISH requires at most\ntwenty minutes of interactive learning to imitate demonstrations on object\nconfigurations that were not seen in the demonstrations. Importantly, FISH is\nconstructed to be versatile, which allows it to be used across robot\nmorphologies (e.g. xArm, Allegro, Stretch) and camera configurations (e.g.\nthird-person, eye-in-hand). Our experimental evaluations on 9 different tasks\nshow that FISH achieves an average success rate of 93%, which is around 3.8x\nhigher than prior state-of-the-art methods.\n","authors":["Siddhant Haldar","Jyothish Pari","Anant Rai","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2303.01497v1.pdf","comment":"Code and robot videos are available at\n  https://fast-imitation.github.io/"},{"id":"http://arxiv.org/abs/2208.05424v5","updated":"2023-03-02T18:54:00Z","published":"2022-08-08T16:54:01Z","title":"Physics-Constrained Deep Learning for Climate Downscaling","summary":"  The availability of reliable, high-resolution climate and weather data is\nimportant to inform long-term decisions on climate adaptation and mitigation\nand to guide rapid responses to extreme events. Forecasting models are limited\nby computational costs and, therefore, often generate coarse-resolution\npredictions. Statistical downscaling, including super-resolution methods from\ndeep learning, can provide an efficient method of upsampling low-resolution\ndata. However, despite achieving visually compelling results in some cases,\nsuch models frequently violate conservation laws when predicting physical\nvariables. In order to conserve physical quantities, we develop methods that\nguarantee physical constraints are satisfied by a deep learning downscaling\nmodel while also improving their performance according to traditional metrics.\nWe compare different constraining approaches and demonstrate their\napplicability across different neural architectures as well as a variety of\nclimate and weather datasets. Besides enabling faster and more accurate climate\npredictions, we also show that our novel methodologies can improve\nsuper-resolution for satellite data and standard datasets.\n","authors":["Paula Harder","Venkatesh Ramesh","Alex Hernandez-Garcia","Qidong Yang","Prasanna Sattigeri","Daniela Szwarcman","Campbell Watson","David Rolnick"],"pdf_url":"https://arxiv.org/pdf/2208.05424v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01491v1","updated":"2023-03-02T18:52:31Z","published":"2023-03-02T18:52:31Z","title":"Transferring Models Trained on Natural Images to 3D MRI via Position\n  Encoded Slice Models","summary":"  Transfer learning has remarkably improved computer vision. These advances\nalso promise improvements in neuroimaging, where training set sizes are often\nsmall. However, various difficulties arise in directly applying models\npretrained on natural images to radiologic images, such as MRIs. In particular,\na mismatch in the input space (2D images vs. 3D MRIs) restricts the direct\ntransfer of models, often forcing us to consider only a few MRI slices as\ninput. To this end, we leverage the 2D-Slice-CNN architecture of Gupta et al.\n(2021), which embeds all the MRI slices with 2D encoders (neural networks that\ntake 2D image input) and combines them via permutation-invariant layers. With\nthe insight that the pretrained model can serve as the 2D encoder, we\ninitialize the 2D encoder with ImageNet pretrained weights that outperform\nthose initialized and trained from scratch on two neuroimaging tasks -- brain\nage prediction on the UK Biobank dataset and Alzheimer's disease detection on\nthe ADNI dataset. Further, we improve the modeling capabilities of 2D-Slice\nmodels by incorporating spatial information through position embeddings, which\ncan improve the performance in some cases.\n","authors":["Umang Gupta","Tamoghna Chattopadhyay","Nikhil Dhinagar","Paul M. Thompson","Greg Ver Steeg","The Alzheimer's Disease Neuroimaging Initiative"],"pdf_url":"https://arxiv.org/pdf/2303.01491v1.pdf","comment":"To appear at IEEE International Symposium on Biomedical Imaging 2023\n  (ISBI 2023). Code is available at\n  https://github.com/umgupta/2d-slice-set-networks"},{"id":"http://arxiv.org/abs/2207.08435v3","updated":"2023-03-02T18:51:38Z","published":"2022-07-18T08:41:00Z","title":"Robust Simulation-Based Inference in Cosmology with Bayesian Neural\n  Networks","summary":"  Simulation-based inference (SBI) is rapidly establishing itself as a standard\nmachine learning technique for analyzing data in cosmological surveys. Despite\ncontinual improvements to the quality of density estimation by learned models,\napplications of such techniques to real data are entirely reliant on the\ngeneralization power of neural networks far outside the training distribution,\nwhich is mostly unconstrained. Due to the imperfections in scientist-created\nsimulations, and the large computational expense of generating all possible\nparameter combinations, SBI methods in cosmology are vulnerable to such\ngeneralization issues. Here, we discuss the effects of both issues, and show\nhow using a Bayesian neural network framework for training SBI can mitigate\nbiases, and result in more reliable inference outside the training set. We\nintroduce cosmoSWAG, the first application of Stochastic Weight Averaging to\ncosmology, and apply it to SBI trained for inference on the cosmic microwave\nbackground.\n","authors":["Pablo Lemos","Miles Cranmer","Muntazir Abidi","ChangHoon Hahn","Michael Eickenberg","Elena Massara","David Yallup","Shirley Ho"],"pdf_url":"https://arxiv.org/pdf/2207.08435v3.pdf","comment":"5 pages, 3 figures. Preliminary version accepted at the ML4Astro\n  Machine Learning for Astrophysics Workshop at the Thirty-ninth International\n  Conference on Machine Learning (ICML 2022). Final version published at\n  Machine Learning: Science and Technology"},{"id":"http://arxiv.org/abs/2303.01488v1","updated":"2023-03-02T18:51:38Z","published":"2023-03-02T18:51:38Z","title":"Self-Improving Robots: End-to-End Autonomous Visuomotor Reinforcement\n  Learning","summary":"  In imitation and reinforcement learning, the cost of human supervision limits\nthe amount of data that robots can be trained on. An aspirational goal is to\nconstruct self-improving robots: robots that can learn and improve on their\nown, from autonomous interaction with minimal human supervision or oversight.\nSuch robots could collect and train on much larger datasets, and thus learn\nmore robust and performant policies. While reinforcement learning offers a\nframework for such autonomous learning via trial-and-error, practical\nrealizations end up requiring extensive human supervision for reward function\ndesign and repeated resetting of the environment between episodes of\ninteractions. In this work, we propose MEDAL++, a novel design for\nself-improving robotic systems: given a small set of expert demonstrations at\nthe start, the robot autonomously practices the task by learning to both do and\nundo the task, simultaneously inferring the reward function from the\ndemonstrations. The policy and reward function are learned end-to-end from\nhigh-dimensional visual inputs, bypassing the need for explicit state\nestimation or task-specific pre-training for visual encoders used in prior\nwork. We first evaluate our proposed algorithm on a simulated non-episodic\nbenchmark EARL, finding that MEDAL++ is both more data efficient and gets up to\n30% better final performance compared to state-of-the-art vision-based methods.\nOur real-robot experiments show that MEDAL++ can be applied to manipulation\nproblems in larger environments than those considered in prior work, and\nautonomous self-improvement can improve the success rate by 30-70% over\nbehavior cloning on just the expert data. Code, training and evaluation videos\nalong with a brief overview is available at:\nhttps://architsharma97.github.io/self-improving-robots/\n","authors":["Archit Sharma","Ahmed M. Ahmed","Rehaan Ahmad","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2303.01488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08965v2","updated":"2023-03-02T18:50:45Z","published":"2023-01-21T15:42:53Z","title":"Raw or Cooked? Object Detection on RAW Images","summary":"  Images fed to a deep neural network have in general undergone several\nhandcrafted image signal processing (ISP) operations, all of which have been\noptimized to produce visually pleasing images. In this work, we investigate the\nhypothesis that the intermediate representation of visually pleasing images is\nsub-optimal for downstream computer vision tasks compared to the RAW image\nrepresentation. We suggest that the operations of the ISP instead should be\noptimized towards the end task, by learning the parameters of the operations\njointly during training. We extend previous works on this topic and propose a\nnew learnable operation that enables an object detector to achieve superior\nperformance when compared to both previous works and traditional RGB images. In\nexperiments on the open PASCALRAW dataset, we empirically confirm our\nhypothesis.\n","authors":["William Ljungbergh","Joakim Johnander","Christoffer Petersson","Michael Felsberg"],"pdf_url":"https://arxiv.org/pdf/2301.08965v2.pdf","comment":"SCIA 2023"},{"id":"http://arxiv.org/abs/2303.01486v1","updated":"2023-03-02T18:47:51Z","published":"2023-03-02T18:47:51Z","title":"Understanding plasticity in neural networks","summary":"  Plasticity, the ability of a neural network to quickly change its predictions\nin response to new information, is essential for the adaptability and\nrobustness of deep reinforcement learning systems. Deep neural networks are\nknown to lose plasticity over the course of training even in relatively simple\nlearning problems, but the mechanisms driving this phenomenon are still poorly\nunderstood. This paper conducts a systematic empirical analysis into plasticity\nloss, with the goal of understanding the phenomenon mechanistically in order to\nguide the future development of targeted solutions. We find that loss of\nplasticity is deeply connected to changes in the curvature of the loss\nlandscape, but that it typically occurs in the absence of saturated units or\ndivergent gradient norms. Based on this insight, we identify a number of\nparameterization and optimization design choices which enable networks to\nbetter preserve plasticity over the course of training. We validate the utility\nof these findings in larger-scale learning problems by applying the\nbest-performing intervention, layer normalization, to a deep RL agent trained\non the Arcade Learning Environment.\n","authors":["Clare Lyle","Zeyu Zheng","Evgenii Nikishin","Bernardo Avila Pires","Razvan Pascanu","Will Dabney"],"pdf_url":"https://arxiv.org/pdf/2303.01486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01484v1","updated":"2023-03-02T18:45:02Z","published":"2023-03-02T18:45:02Z","title":"Predicting Motion Plans for Articulating Everyday Objects","summary":"  Mobile manipulation tasks such as opening a door, pulling open a drawer, or\nlifting a toilet lid require constrained motion of the end-effector under\nenvironmental and task constraints. This, coupled with partial information in\nnovel environments, makes it challenging to employ classical motion planning\napproaches at test time. Our key insight is to cast it as a learning problem to\nleverage past experience of solving similar planning problems to directly\npredict motion plans for mobile manipulation tasks in novel situations at test\ntime. To enable this, we develop a simulator, ArtObjSim, that simulates\narticulated objects placed in real scenes. We then introduce SeqIK+$\\theta_0$,\na fast and flexible representation for motion plans. Finally, we learn models\nthat use SeqIK+$\\theta_0$ to quickly predict motion plans for articulating\nnovel objects at test time. Experimental evaluation shows improved speed and\naccuracy at generating motion plans than pure search-based methods and pure\nlearning methods.\n","authors":["Arjun Gupta","Max E. Shepherd","Saurabh Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.01484v1.pdf","comment":"To Appear in ICRA 2023. Project webpage:\n  https://arjung128.github.io/mpao/"},{"id":"http://arxiv.org/abs/2303.01483v1","updated":"2023-03-02T18:44:18Z","published":"2023-03-02T18:44:18Z","title":"Auxiliary Functions as Koopman Observables: Data-Driven Polynomial\n  Optimization for Dynamical Systems","summary":"  We present a flexible data-driven method for dynamical system analysis that\ndoes not require explicit model discovery. The method is rooted in\nwell-established techniques for approximating the Koopman operator from data\nand is implemented as a semidefinite program that can be solved numerically.\nThe method is agnostic of whether data is generated through a deterministic or\nstochastic process, so its implementation requires no prior adjustments by the\nuser to accommodate these different scenarios. Rigorous convergence results\njustify the applicability of the method, while also extending and uniting\nsimilar results from across the literature. Examples on discovering Lyapunov\nfunctions and on performing ergodic optimization for both deterministic and\nstochastic dynamics exemplify these convergence results and demonstrate the\nperformance of the method.\n","authors":["Jason J. Bramburger","Giovanni Fantuzzi"],"pdf_url":"https://arxiv.org/pdf/2303.01483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01475v1","updated":"2023-03-02T18:37:34Z","published":"2023-03-02T18:37:34Z","title":"Over-training with Mixup May Hurt Generalization","summary":"  Mixup, which creates synthetic training instances by linearly interpolating\nrandom sample pairs, is a simple and yet effective regularization technique to\nboost the performance of deep models trained with SGD. In this work, we report\na previously unobserved phenomenon in Mixup training: on a number of standard\ndatasets, the performance of Mixup-trained models starts to decay after\ntraining for a large number of epochs, giving rise to a U-shaped generalization\ncurve. This behavior is further aggravated when the size of original dataset is\nreduced. To help understand such a behavior of Mixup, we show theoretically\nthat Mixup training may introduce undesired data-dependent label noises to the\nsynthesized data. Via analyzing a least-square regression problem with a random\nfeature model, we explain why noisy labels may cause the U-shaped curve to\noccur: Mixup improves generalization through fitting the clean patterns at the\nearly training stage, but as training progresses, Mixup becomes over-fitting to\nthe noise in the synthetic data. Extensive experiments are performed on a\nvariety of benchmark datasets, validating this explanation.\n","authors":["Zixuan Liu","Ziqiao Wang","Hongyu Guo","Yongyi Mao"],"pdf_url":"https://arxiv.org/pdf/2303.01475v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01471v1","updated":"2023-03-02T18:34:38Z","published":"2023-03-02T18:34:38Z","title":"Quantum Hamiltonian Descent","summary":"  Gradient descent is a fundamental algorithm in both theory and practice for\ncontinuous optimization. Identifying its quantum counterpart would be appealing\nto both theoretical and practical quantum applications. A conventional approach\nto quantum speedups in optimization relies on the quantum acceleration of\nintermediate steps of classical algorithms, while keeping the overall\nalgorithmic trajectory and solution quality unchanged. We propose Quantum\nHamiltonian Descent (QHD), which is derived from the path integral of dynamical\nsystems referring to the continuous-time limit of classical gradient descent\nalgorithms, as a truly quantum counterpart of classical gradient methods where\nthe contribution from classically-prohibited trajectories can significantly\nboost QHD's performance for non-convex optimization. Moreover, QHD is described\nas a Hamiltonian evolution efficiently simulatable on both digital and analog\nquantum computers. By embedding the dynamics of QHD into the evolution of the\nso-called Quantum Ising Machine (including D-Wave and others), we empirically\nobserve that the D-Wave-implemented QHD outperforms a selection of\nstate-of-the-art gradient-based classical solvers and the standard quantum\nadiabatic algorithm, based on the time-to-solution metric, on non-convex\nconstrained quadratic programming instances up to 75 dimensions. Finally, we\npropose a \"three-phase picture\" to explain the behavior of QHD, especially its\ndifference from the quantum adiabatic algorithm.\n","authors":["Jiaqi Leng","Ethan Hickman","Joseph Li","Xiaodi Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01471v1.pdf","comment":"71 pages, 13 figures, an accompanying website is at\n  https://jiaqileng.github.io/quantum-hamiltonian-descent/"},{"id":"http://arxiv.org/abs/2303.01469v1","updated":"2023-03-02T18:30:16Z","published":"2023-03-02T18:30:16Z","title":"Consistency Models","summary":"  Diffusion models have made significant breakthroughs in image, audio, and\nvideo generation, but they depend on an iterative generation process that\ncauses slow sampling speed and caps their potential for real-time applications.\nTo overcome this limitation, we propose consistency models, a new family of\ngenerative models that achieve high sample quality without adversarial\ntraining. They support fast one-step generation by design, while still allowing\nfor few-step sampling to trade compute for sample quality. They also support\nzero-shot data editing, like image inpainting, colorization, and\nsuper-resolution, without requiring explicit training on these tasks.\nConsistency models can be trained either as a way to distill pre-trained\ndiffusion models, or as standalone generative models. Through extensive\nexperiments, we demonstrate that they outperform existing distillation\ntechniques for diffusion models in one- and few-step generation. For example,\nwe achieve the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on\nImageNet 64x64 for one-step generation. When trained as standalone generative\nmodels, consistency models also outperform single-step, non-adversarial\ngenerative models on standard benchmarks like CIFAR-10, ImageNet 64x64 and LSUN\n256x256.\n","authors":["Yang Song","Prafulla Dhariwal","Mark Chen","Ilya Sutskever"],"pdf_url":"https://arxiv.org/pdf/2303.01469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01464v1","updated":"2023-03-02T18:27:00Z","published":"2023-03-02T18:27:00Z","title":"Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using\n  Online Function Approximation","summary":"  We present the OMG-CMDP! algorithm for regret minimization in adversarial\nContextual MDPs. The algorithm operates under the minimal assumptions of\nrealizable function class and access to online least squares and log loss\nregression oracles. Our algorithm is efficient (assuming efficient online\nregression oracles), simple and robust to approximation errors. It enjoys an\n$\\widetilde{O}(H^{2.5} \\sqrt{ T|S||A| ( \\mathcal{R}(\\mathcal{O}) + H\n\\log(\\delta^{-1}) )})$ regret guarantee, with $T$ being the number of episodes,\n$S$ the state space, $A$ the action space, $H$ the horizon and\n$\\mathcal{R}(\\mathcal{O}) = \\mathcal{R}(\\mathcal{O}_{\\mathrm{sq}}^\\mathcal{F})\n+ \\mathcal{R}(\\mathcal{O}_{\\mathrm{log}}^\\mathcal{P})$ is the sum of the\nregression oracles' regret, used to approximate the context-dependent rewards\nand dynamics, respectively. To the best of our knowledge, our algorithm is the\nfirst efficient rate optimal regret minimization algorithm for adversarial\nCMDPs that operates under the minimal standard assumption of online function\napproximation.\n","authors":["Orin Levy","Alon Cohen","Asaf Cassel","Yishay Mansour"],"pdf_url":"https://arxiv.org/pdf/2303.01464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01462v1","updated":"2023-03-02T18:24:26Z","published":"2023-03-02T18:24:26Z","title":"Benign Overfitting in Linear Classifiers and Leaky ReLU Networks from\n  KKT Conditions for Margin Maximization","summary":"  Linear classifiers and leaky ReLU networks trained by gradient flow on the\nlogistic loss have an implicit bias towards solutions which satisfy the\nKarush--Kuhn--Tucker (KKT) conditions for margin maximization. In this work we\nestablish a number of settings where the satisfaction of these KKT conditions\nimplies benign overfitting in linear classifiers and in two-layer leaky ReLU\nnetworks: the estimators interpolate noisy training data and simultaneously\ngeneralize well to test data. The settings include variants of the noisy\nclass-conditional Gaussians considered in previous work as well as new\ndistributional settings where benign overfitting has not been previously\nobserved. The key ingredient to our proof is the observation that when the\ntraining data is nearly-orthogonal, both linear classifiers and leaky ReLU\nnetworks satisfying the KKT conditions for their respective margin maximization\nproblems behave like a nearly uniform average of the training examples.\n","authors":["Spencer Frei","Gal Vardi","Peter L. Bartlett","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2303.01462v1.pdf","comment":"53 pages"},{"id":"http://arxiv.org/abs/2303.01456v1","updated":"2023-03-02T18:14:35Z","published":"2023-03-02T18:14:35Z","title":"The Double-Edged Sword of Implicit Bias: Generalization vs. Robustness\n  in ReLU Networks","summary":"  In this work, we study the implications of the implicit bias of gradient flow\non generalization and adversarial robustness in ReLU networks. We focus on a\nsetting where the data consists of clusters and the correlations between\ncluster means are small, and show that in two-layer ReLU networks gradient flow\nis biased towards solutions that generalize well, but are highly vulnerable to\nadversarial examples. Our results hold even in cases where the network has many\nmore parameters than training examples. Despite the potential for harmful\noverfitting in such overparameterized settings, we prove that the implicit bias\nof gradient flow prevents it. However, the implicit bias also leads to\nnon-robust solutions (susceptible to small adversarial $\\ell_2$-perturbations),\neven though robust networks that fit the data exist.\n","authors":["Spencer Frei","Gal Vardi","Peter L. Bartlett","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2303.01456v1.pdf","comment":"41 pages"},{"id":"http://arxiv.org/abs/2303.01455v1","updated":"2023-03-02T18:13:27Z","published":"2023-03-02T18:13:27Z","title":"Learning Contact-based Navigation in Crowds","summary":"  Navigation strategies that intentionally incorporate contact with humans\n(i.e. \"contact-based\" social navigation) in crowded environments are largely\nunexplored even though collision-free social navigation is a well studied\nproblem. Traditional social navigation frameworks require the robot to stop\nsuddenly or \"freeze\" whenever a collision is imminent. This paradigm poses two\nproblems: 1) freezing while navigating a crowd may cause people to trip and\nfall over the robot, resulting in more harm than the collision itself, and 2)\nin very dense social environments where collisions are unavoidable, such a\ncontrol scheme would render the robot unable to move and preclude the\nopportunity to study how humans incorporate robots into these environments.\nHowever, if robots are to be meaningfully included in crowded social spaces,\nsuch as busy streets, subways, stores, or other densely populated locales,\nthere may not exist trajectories that can guarantee zero collisions. Thus,\nadoption of robots in these environments requires the development of minimally\ndisruptive navigation plans that can safely plan for and respond to contacts.\nWe propose a learning-based motion planner and control scheme to navigate dense\nsocial environments using safe contacts for an omnidirectional mobile robot.\nThe planner is evaluated in simulation over 360 trials with crowd densities\nvarying between 0.0 and 1.6 people per square meter. Our navigation scheme is\nable to use contact to safely navigate in crowds of higher density than has\nbeen previously reported, to our knowledge.\n","authors":["Kyle Morgenstein","Junfeng Jiao","Luis Sentis"],"pdf_url":"https://arxiv.org/pdf/2303.01455v1.pdf","comment":"Presented at the Human Interactive Robot Learning worksop at HRI2023"},{"id":"http://arxiv.org/abs/2212.08570v2","updated":"2023-03-02T18:12:11Z","published":"2022-12-15T15:44:02Z","title":"Audio-based AI classifiers show no evidence of improved COVID-19\n  screening over simple symptoms checkers","summary":"  Recent work has reported that AI classifiers trained on audio recordings can\naccurately predict severe acute respiratory syndrome coronavirus 2 (SARSCoV2)\ninfection status. Here, we undertake a large scale study of audio-based deep\nlearning classifiers, as part of the UK governments pandemic response. We\ncollect and analyse a dataset of audio recordings from 67,842 individuals with\nlinked metadata, including reverse transcription polymerase chain reaction\n(PCR) test outcomes, of whom 23,514 tested positive for SARS CoV 2. Subjects\nwere recruited via the UK governments National Health Service Test-and-Trace\nprogramme and the REal-time Assessment of Community Transmission (REACT)\nrandomised surveillance survey. In an unadjusted analysis of our dataset AI\nclassifiers predict SARS-CoV-2 infection status with high accuracy (Receiver\nOperating Characteristic Area Under the Curve (ROCAUC) 0.846 [0.838, 0.854])\nconsistent with the findings of previous studies. However, after matching on\nmeasured confounders, such as age, gender, and self reported symptoms, our\nclassifiers performance is much weaker (ROC-AUC 0.619 [0.594, 0.644]). Upon\nquantifying the utility of audio based classifiers in practical settings, we\nfind them to be outperformed by simple predictive scores based on user reported\nsymptoms.\n","authors":["Harry Coppock","George Nicholson","Ivan Kiskin","Vasiliki Koutra","Kieran Baker","Jobie Budd","Richard Payne","Emma Karoune","David Hurley","Alexander Titcomb","Sabrina Egglestone","Ana Tendero Cañadas","Lorraine Butler","Radka Jersakova","Jonathon Mellor","Selina Patel","Tracey Thornley","Peter Diggle","Sylvia Richardson","Josef Packham","Björn W. Schuller","Davide Pigoli","Steven Gilmour","Stephen Roberts","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2212.08570v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01453v1","updated":"2023-03-02T18:11:39Z","published":"2023-03-02T18:11:39Z","title":"Improved Space Bounds for Learning with Experts","summary":"  We give improved tradeoffs between space and regret for the online learning\nwith expert advice problem over $T$ days with $n$ experts. Given a space budget\nof $n^{\\delta}$ for $\\delta \\in (0,1)$, we provide an algorithm achieving\nregret $\\tilde{O}(n^2 T^{1/(1+\\delta)})$, improving upon the regret bound\n$\\tilde{O}(n^2 T^{2/(2+\\delta)})$ in the recent work of [PZ23]. The improvement\nis particularly salient in the regime $\\delta \\rightarrow 1$ where the regret\nof our algorithm approaches $\\tilde{O}_n(\\sqrt{T})$, matching the $T$\ndependence in the standard online setting without space restrictions.\n","authors":["Anders Aamand","Justin Y. Chen","Huy Lê Nguyen","Sandeep Silwal"],"pdf_url":"https://arxiv.org/pdf/2303.01453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00654v2","updated":"2023-03-02T17:53:38Z","published":"2023-03-01T16:56:39Z","title":"How to DP-fy ML: A Practical Guide to Machine Learning with Differential\n  Privacy","summary":"  ML models are ubiquitous in real world applications and are a constant focus\nof research. At the same time, the community has started to realize the\nimportance of protecting the privacy of ML training data.\n  Differential Privacy (DP) has become a gold standard for making formal\nstatements about data anonymization. However, while some adoption of DP has\nhappened in industry, attempts to apply DP to real world complex ML models are\nstill few and far between. The adoption of DP is hindered by limited practical\nguidance of what DP protection entails, what privacy guarantees to aim for, and\nthe difficulty of achieving good privacy-utility-computation trade-offs for ML\nmodels. Tricks for tuning and maximizing performance are scattered among papers\nor stored in the heads of practitioners. Furthermore, the literature seems to\npresent conflicting evidence on how and whether to apply architectural\nadjustments and which components are \"safe\" to use with DP.\n  This work is a self-contained guide that gives an in-depth overview of the\nfield of DP ML and presents information about achieving the best possible DP ML\nmodel with rigorous privacy guarantees. Our target audience is both researchers\nand practitioners. Researchers interested in DP for ML will benefit from a\nclear overview of current advances and areas for improvement. We include\ntheory-focused sections that highlight important topics such as privacy\naccounting and its assumptions, and convergence. For a practitioner, we provide\na background in DP theory and a clear step-by-step guide for choosing an\nappropriate privacy definition and approach, implementing DP training,\npotentially updating the model architecture, and tuning hyperparameters. For\nboth researchers and practitioners, consistently and fully reporting privacy\nguarantees is critical, and so we propose a set of specific best practices for\nstating guarantees.\n","authors":["Natalia Ponomareva","Hussein Hazimeh","Alex Kurakin","Zheng Xu","Carson Denison","H. Brendan McMahan","Sergei Vassilvitskii","Steve Chien","Abhradeep Thakurta"],"pdf_url":"https://arxiv.org/pdf/2303.00654v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01433v1","updated":"2023-03-02T17:47:02Z","published":"2023-03-02T17:47:02Z","title":"Do Machine Learning Models Learn Common Sense?","summary":"  Machine learning models can make basic errors that are easily hidden within\nvast amounts of data. Such errors often run counter to human intuition referred\nto as \"common sense\". We thereby seek to characterize common sense for\ndata-driven models, and quantify the extent to which a model has learned common\nsense. We propose a framework that integrates logic-based methods with\nstatistical inference to derive common sense rules from a model's training data\nwithout supervision. We further show how to adapt models at test-time to reduce\ncommon sense rule violations and produce more coherent predictions. We evaluate\nour framework on datasets and models for three different domains. It generates\naround 250 to 300k rules over these datasets, and uncovers 1.5k to 26k\nviolations of those rules by state-of-the-art models for the respective\ndatasets. Test-time adaptation reduces these violations by up to 38% without\nimpacting overall model accuracy.\n","authors":["Aaditya Naik","Yinjun Wu","Mayur Naik","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2303.01433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00580v3","updated":"2023-03-02T17:43:38Z","published":"2022-10-02T17:41:01Z","title":"GFlowNets and variational inference","summary":"  This paper builds bridges between two families of probabilistic algorithms:\n(hierarchical) variational inference (VI), which is typically used to model\ndistributions over continuous spaces, and generative flow networks (GFlowNets),\nwhich have been used for distributions over discrete structures such as graphs.\nWe demonstrate that, in certain cases, VI algorithms are equivalent to special\ncases of GFlowNets in the sense of equality of expected gradients of their\nlearning objectives. We then point out the differences between the two families\nand show how these differences emerge experimentally. Notably, GFlowNets, which\nborrow ideas from reinforcement learning, are more amenable than VI to\noff-policy training without the cost of high gradient variance induced by\nimportance sampling. We argue that this property of GFlowNets can provide\nadvantages for capturing diversity in multimodal target distributions.\n","authors":["Nikolay Malkin","Salem Lahlou","Tristan Deleu","Xu Ji","Edward Hu","Katie Everett","Dinghuai Zhang","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2210.00580v3.pdf","comment":"ICLR 2023 final version; code: https://github.com/GFNOrg/GFN_vs_HVI"},{"id":"http://arxiv.org/abs/2206.05825v3","updated":"2023-03-02T17:37:59Z","published":"2022-06-12T19:49:14Z","title":"A Unified Approach to Reinforcement Learning, Quantal Response\n  Equilibria, and Two-Player Zero-Sum Games","summary":"  This work studies an algorithm, which we call magnetic mirror descent, that\nis inspired by mirror descent and the non-Euclidean proximal gradient\nalgorithm. Our contribution is demonstrating the virtues of magnetic mirror\ndescent as both an equilibrium solver and as an approach to reinforcement\nlearning in two-player zero-sum games. These virtues include: 1) Being the\nfirst quantal response equilibria solver to achieve linear convergence for\nextensive-form games with first order feedback; 2) Being the first standard\nreinforcement learning algorithm to achieve empirically competitive results\nwith CFR in tabular settings; 3) Achieving favorable performance in 3x3 Dark\nHex and Phantom Tic-Tac-Toe as a self-play deep reinforcement learning\nalgorithm.\n","authors":["Samuel Sokota","Ryan D'Orazio","J. Zico Kolter","Nicolas Loizou","Marc Lanctot","Ioannis Mitliagkas","Noam Brown","Christian Kroer"],"pdf_url":"https://arxiv.org/pdf/2206.05825v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01429v1","updated":"2023-03-02T17:32:11Z","published":"2023-03-02T17:32:11Z","title":"Optimal transfer protocol by incremental layer defrosting","summary":"  Transfer learning is a powerful tool enabling model training with limited\namounts of data. This technique is particularly useful in real-world problems\nwhere data availability is often a serious limitation. The simplest transfer\nlearning protocol is based on ``freezing\" the feature-extractor layers of a\nnetwork pre-trained on a data-rich source task, and then adapting only the last\nlayers to a data-poor target task. This workflow is based on the assumption\nthat the feature maps of the pre-trained model are qualitatively similar to the\nones that would have been learned with enough data on the target task. In this\nwork, we show that this protocol is often sub-optimal, and the largest\nperformance gain may be achieved when smaller portions of the pre-trained\nnetwork are kept frozen. In particular, we make use of a controlled framework\nto identify the optimal transfer depth, which turns out to depend non-trivially\non the amount of available training data and on the degree of source-target\ntask correlation. We then characterize transfer optimality by analyzing the\ninternal representations of two networks trained from scratch on the source and\nthe target task through multiple established similarity measures.\n","authors":["Federica Gerace","Diego Doimo","Stefano Sarao Mannelli","Luca Saglietti","Alessandro Laio"],"pdf_url":"https://arxiv.org/pdf/2303.01429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.11870v2","updated":"2023-03-02T17:27:13Z","published":"2022-08-25T04:52:21Z","title":"Fix-A-Step: Semi-supervised Learning from Uncurated Unlabeled Data","summary":"  Semi-supervised learning (SSL) promises improved accuracy compared to\ntraining classifiers on small labeled datasets by also training on many\nunlabeled images. In real applications like medical imaging, unlabeled data\nwill be collected for expediency and thus uncurated: possibly different from\nthe labeled set in classes or features. Unfortunately, modern deep SSL often\nmakes accuracy worse when given uncurated unlabeled data. Recent complex\nremedies try to detect out-of-distribution unlabeled images and then discard or\ndownweight them. Instead, we introduce Fix-A-Step, a simpler procedure that\nviews all uncurated unlabeled images as potentially helpful. Our first insight\nis that even uncurated images can yield useful augmentations of labeled data.\nSecond, we modify gradient descent updates to prevent optimizing a multi-task\nSSL loss from hurting labeled-set accuracy. Fix-A-Step can repair many common\ndeep SSL methods, improving accuracy on CIFAR benchmarks across all tested\nmethods and levels of artificial class mismatch. On a new medical SSL benchmark\ncalled Heart2Heart, Fix-A-Step can learn from 353,500 truly uncurated\nultrasound images to deliver gains that generalize across hospitals.\n","authors":["Zhe Huang","Mary-Joy Sidhom","Benjamin S. Wessler","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2208.11870v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2205.13303v2","updated":"2023-03-02T17:21:48Z","published":"2022-05-26T12:25:24Z","title":"Gaussian Universality of Perceptrons with Random Labels","summary":"  While classical in many theoretical settings - and in particular in\nstatistical physics-inspired works - the assumption of Gaussian i.i.d. input\ndata is often perceived as a strong limitation in the context of statistics and\nmachine learning. In this study, we redeem this line of work in the case of\ngeneralized linear classification, a.k.a. the perceptron model, with random\nlabels. We argue that there is a large universality class of high-dimensional\ninput data for which we obtain the same minimum training loss as for Gaussian\ndata with corresponding data covariance. In the limit of vanishing\nregularization, we further demonstrate that the training loss is independent of\nthe data covariance. On the theoretical side, we prove this universality for an\narbitrary mixture of homogeneous Gaussian clouds. Empirically, we show that the\nuniversality holds also for a broad range of real datasets.\n","authors":["Federica Gerace","Florent Krzakala","Bruno Loureiro","Ludovic Stephan","Lenka Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2205.13303v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16966v2","updated":"2023-03-02T17:21:16Z","published":"2022-10-30T22:24:43Z","title":"Interpretable Geometric Deep Learning via Learnable Randomness Injection","summary":"  Point cloud data is ubiquitous in scientific fields. Recently, geometric deep\nlearning (GDL) has been widely applied to solve prediction tasks with such\ndata. However, GDL models are often complicated and hardly interpretable, which\nposes concerns to scientists who are to deploy these models in scientific\nanalysis and experiments. This work proposes a general mechanism, learnable\nrandomness injection (LRI), which allows building inherently interpretable\nmodels based on general GDL backbones. LRI-induced models, once trained, can\ndetect the points in the point cloud data that carry information indicative of\nthe prediction label. We also propose four datasets from real scientific\napplications that cover the domains of high-energy physics and biochemistry to\nevaluate the LRI mechanism. Compared with previous post-hoc interpretation\nmethods, the points detected by LRI align much better and stabler with the\nground-truth patterns that have actual scientific meanings. LRI is grounded by\nthe information bottleneck principle, and thus LRI-induced models are also more\nrobust to distribution shifts between training and test scenarios. Our code and\ndatasets are available at \\url{https://github.com/Graph-COM/LRI}.\n","authors":["Siqi Miao","Yunan Luo","Mia Liu","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2210.16966v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01421v1","updated":"2023-03-02T17:15:02Z","published":"2023-03-02T17:15:02Z","title":"Semiparametric Language Models Are Scalable Continual Learners","summary":"  Semiparametric language models (LMs) have shown promise in continuously\nlearning from new text data by combining a parameterized neural LM with a\ngrowable non-parametric memory for memorizing new content. However,\nconventional semiparametric LMs will finally become prohibitive for computing\nand storing if they are applied to continual learning over streaming data,\nbecause the non-parametric memory grows linearly with the amount of data they\nlearn from over time. To address the issue of scalability, we present a simple\nand intuitive approach called Selective Memorization (SeMem), which only\nmemorizes difficult samples that the model is likely to struggle with. We\ndemonstrate that SeMem improves the scalability of semiparametric LMs for\ncontinual learning over streaming data in two ways: (1) data-wise scalability:\nas the model becomes stronger through continual learning, it will encounter\nfewer difficult cases that need to be memorized, causing the growth of the\nnon-parametric memory to slow down over time rather than growing at a linear\nrate with the size of training data; (2) model-wise scalability: SeMem allows a\nlarger model to memorize fewer samples than its smaller counterpart because it\nis rarer for a larger model to encounter incomprehensible cases, resulting in a\nnon-parametric memory that does not scale linearly with model size. We conduct\nextensive experiments in language modeling and downstream tasks to test SeMem's\nresults, showing SeMem enables a semiparametric LM to be a scalable continual\nlearner with little forgetting.\n","authors":["Guangyue Peng","Tao Ge","Si-Qing Chen","Furu Wei","Houfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01421v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.03439v4","updated":"2023-03-02T17:04:51Z","published":"2023-02-07T12:51:20Z","title":"Ensemble Value Functions for Efficient Exploration in Multi-Agent\n  Reinforcement Learning","summary":"  Cooperative multi-agent reinforcement learning (MARL) requires agents to\nexplore to learn to cooperate. Existing value-based MARL algorithms commonly\nrely on random exploration, such as $\\epsilon$-greedy, which is inefficient in\ndiscovering multi-agent cooperation. Additionally, the environment in MARL\nappears non-stationary to any individual agent due to the simultaneous training\nof other agents, leading to highly variant and thus unstable optimisation\nsignals. In this work, we propose ensemble value functions for multi-agent\nexploration (EMAX), a general framework to extend any value-based MARL\nalgorithm. EMAX trains ensembles of value functions for each agent to address\nthe key challenges of exploration and non-stationarity: (1) The uncertainty of\nvalue estimates across the ensemble is used in a UCB policy to guide the\nexploration of agents to parts of the environment which require cooperation.\n(2) Average value estimates across the ensemble serve as target values. These\ntargets exhibit lower variance compared to commonly applied target networks and\nwe show that they lead to more stable gradients during the optimisation. We\ninstantiate three value-based MARL algorithms with EMAX, independent DQN, VDN\nand QMIX, and evaluate them in 21 tasks across four environments. Using\nensembles of five value functions, EMAX improves sample efficiency and final\nevaluation returns of these algorithms by 54%, 55%, and 844%, respectively,\naveraged all 21 tasks.\n","authors":["Lukas Schäfer","Oliver Slumbers","Stephen McAleer","Yali Du","Stefano V. Albrecht","David Mguni"],"pdf_url":"https://arxiv.org/pdf/2302.03439v4.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2303.01412v1","updated":"2023-03-02T17:03:02Z","published":"2023-03-02T17:03:02Z","title":"Hyperparameter Tuning and Model Evaluation in Causal Effect Estimation","summary":"  The performance of most causal effect estimators relies on accurate\npredictions of high-dimensional non-linear functions of the observed data. The\nremarkable flexibility of modern Machine Learning (ML) methods is perfectly\nsuited to this task. However, data-driven hyperparameter tuning of ML methods\nrequires effective model evaluation to avoid large errors in causal estimates,\na task made more challenging because causal inference involves unavailable\ncounterfactuals. Multiple performance-validation metrics have recently been\nproposed such that practitioners now not only have to make complex decisions\nabout which causal estimators, ML learners and hyperparameters to choose, but\nalso about which evaluation metric to use. This paper, motivated by unclear\nrecommendations, investigates the interplay between the four different aspects\nof model evaluation for causal effect estimation. We develop a comprehensive\nexperimental setup that involves many commonly used causal estimators, ML\nmethods and evaluation approaches and apply it to four well-known causal\ninference benchmark datasets. Our results suggest that optimal hyperparameter\ntuning of ML learners is enough to reach state-of-the-art performance in effect\nestimation, regardless of estimators and learners. We conclude that most causal\nestimators are roughly equivalent in performance if tuned thoroughly enough. We\nalso find hyperparameter tuning and model evaluation are much more important\nthan causal estimators and ML methods. Finally, from the significant gap we\nfind in estimation performance of popular evaluation metrics compared with\noptimal model selection choices, we call for more research into causal model\nevaluation to unlock the optimum performance not currently being delivered even\nby state-of-the-art procedures.\n","authors":["Damian Machlanski","Spyridon Samothrakis","Paul Clarke"],"pdf_url":"https://arxiv.org/pdf/2303.01412v1.pdf","comment":"36 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.01406v1","updated":"2023-03-02T16:53:51Z","published":"2023-03-02T16:53:51Z","title":"Sparse-penalized deep neural networks estimator under weak dependence","summary":"  We consider the nonparametric regression and the classification problems for\n$\\psi$-weakly dependent processes. This weak dependence structure is more\ngeneral than conditions such as, mixing, association, $\\ldots$. A penalized\nestimation method for sparse deep neural networks is performed. In both\nnonparametric regression and binary classification problems, we establish\noracle inequalities for the excess risk of the sparse-penalized deep neural\nnetworks estimators. Convergence rates of the excess risk of these estimators\nare also derived. The simulation results displayed show that, the proposed\nestimators overall work well than the non penalized estimators.\n","authors":["William Kengne","Modou Wade"],"pdf_url":"https://arxiv.org/pdf/2303.01406v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02830v3","updated":"2023-03-02T16:49:52Z","published":"2023-01-07T11:37:32Z","title":"Advanced Data Augmentation Approaches: A Comprehensive Survey and Future\n  directions","summary":"  Deep learning (DL) algorithms have shown significant performance in various\ncomputer vision tasks. However, having limited labelled data lead to a network\noverfitting problem, where network performance is bad on unseen data as\ncompared to training data. Consequently, it limits performance improvement. To\ncope with this problem, various techniques have been proposed such as dropout,\nnormalization and advanced data augmentation. Among these, data augmentation,\nwhich aims to enlarge the dataset size by including sample diversity, has been\na hot topic in recent times. In this article, we focus on advanced data\naugmentation techniques. we provide a background of data augmentation, a novel\nand comprehensive taxonomy of reviewed data augmentation techniques, and the\nstrengths and weaknesses (wherever possible) of each technique. We also provide\ncomprehensive results of the data augmentation effect on three popular computer\nvision tasks, such as image classification, object detection and semantic\nsegmentation. For results reproducibility, we compiled available codes of all\ndata augmentation techniques. Finally, we discuss the challenges and\ndifficulties, and possible future direction for the research community. We\nbelieve, this survey provides several benefits i) readers will understand the\ndata augmentation working mechanism to fix overfitting problems ii) results\nwill save the searching time of the researcher for comparison purposes. iii)\nCodes of the mentioned data augmentation techniques are available at\nhttps://github.com/kmr2017/Advanced-Data-augmentation-codes iv) Future work\nwill spark interest in research community.\n","authors":["Teerath Kumar","Alessandra Mileo","Rob Brennan","Malika Bendechache"],"pdf_url":"https://arxiv.org/pdf/2301.02830v3.pdf","comment":"We need to make a lot changes to make its quality better"},{"id":"http://arxiv.org/abs/2302.07817v2","updated":"2023-03-02T16:41:45Z","published":"2023-02-15T17:58:10Z","title":"Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction","summary":"  Modern methods for vision-centric autonomous driving perception widely adopt\nthe bird's-eye-view (BEV) representation to describe a 3D scene. Despite its\nbetter efficiency than voxel representation, it has difficulty describing the\nfine-grained 3D structure of a scene with a single plane. To address this, we\npropose a tri-perspective view (TPV) representation which accompanies BEV with\ntwo additional perpendicular planes. We model each point in the 3D space by\nsumming its projected features on the three planes. To lift image features to\nthe 3D TPV space, we further propose a transformer-based TPV encoder\n(TPVFormer) to obtain the TPV features effectively. We employ the attention\nmechanism to aggregate the image features corresponding to each query in each\nTPV plane. Experiments show that our model trained with sparse supervision\neffectively predicts the semantic occupancy for all voxels. We demonstrate for\nthe first time that using only camera inputs can achieve comparable performance\nwith LiDAR-based methods on the LiDAR segmentation task on nuScenes. Code:\nhttps://github.com/wzzheng/TPVFormer.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Yunpeng Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2302.07817v2.pdf","comment":"Accepted to CVPR 2023. Code is available at\n  https://github.com/wzzheng/TPVFormer"},{"id":"http://arxiv.org/abs/2303.01391v1","updated":"2023-03-02T16:20:46Z","published":"2023-03-02T16:20:46Z","title":"The Ladder in Chaos: A Simple and Effective Improvement to General DRL\n  Algorithms by Policy Path Trimming and Boosting","summary":"  Knowing the learning dynamics of policy is significant to unveiling the\nmysteries of Reinforcement Learning (RL). It is especially crucial yet\nchallenging to Deep RL, from which the remedies to notorious issues like sample\ninefficiency and learning instability could be obtained. In this paper, we\nstudy how the policy networks of typical DRL agents evolve during the learning\nprocess by empirically investigating several kinds of temporal change for each\npolicy parameter. On typical MuJoCo and DeepMind Control Suite (DMC)\nbenchmarks, we find common phenomena for TD3 and RAD agents: 1) the activity of\npolicy network parameters is highly asymmetric and policy networks advance\nmonotonically along very few major parameter directions; 2) severe detours\noccur in parameter update and harmonic-like changes are observed for all minor\nparameter directions. By performing a novel temporal SVD along policy learning\npath, the major and minor parameter directions are identified as the columns of\nright unitary matrix associated with dominant and insignificant singular values\nrespectively. Driven by the discoveries above, we propose a simple and\neffective method, called Policy Path Trimming and Boosting (PPTB), as a general\nplug-in improvement to DRL algorithms. The key idea of PPTB is to periodically\ntrim the policy learning path by canceling the policy updates in minor\nparameter directions, while boost the learning path by encouraging the advance\nin major directions. In experiments, we demonstrate the general and significant\nperformance improvements brought by PPTB, when combined with TD3 and RAD in\nMuJoCo and DMC environments respectively.\n","authors":["Hongyao Tang","Min Zhang","Jianye Hao"],"pdf_url":"https://arxiv.org/pdf/2303.01391v1.pdf","comment":"Rudimentary version. Work in progress"},{"id":"http://arxiv.org/abs/2303.01389v1","updated":"2023-03-02T16:19:24Z","published":"2023-03-02T16:19:24Z","title":"Machine Learning-Based Detection of Parkinson's Disease From\n  Resting-State EEG: A Multi-Center Study","summary":"  Resting-state EEG (rs-EEG) has been demonstrated to aid in Parkinson's\ndisease (PD) diagnosis. In particular, the power spectral density (PSD) of\nlow-frequency bands ({\\delta} and {\\theta}) and high-frequency bands ({\\alpha}\nand \\b{eta}) has been shown to be significantly different in patients with PD\nas compared to subjects without PD (non-PD). However, rs-EEG feature extraction\nand the interpretation thereof can be time-intensive and prone to examiner\nvariability. Machine learning (ML) has the potential to automatize the analysis\nof rs-EEG recordings and provides a supportive tool for clinicians to ease\ntheir workload. In this work, we use rs-EEG recordings of 84 PD and 85 non-PD\nsubjects pooled from four datasets obtained at different centers. We propose an\nend-to-end pipeline consisting of preprocessing, extraction of PSD features\nfrom clinically validated frequency bands, and feature selection before\nevaluating the classification ability of the features via ML algorithms to\nstratify between PD and non-PD subjects. Further, we evaluate the effect of\nfeature harmonization, given the multi-center nature of the datasets. Our\nvalidation results show, on average, an improvement in PD detection ability\n(69.6% vs. 75.5% accuracy) by logistic regression when harmonizing the features\nand performing univariate feature selection (k = 202 features). Our final\nresults show an average global accuracy of 72.2% with balanced accuracy results\nfor all the centers included in the study: 60.6%, 68.7%, 77.7%, and 82.2%,\nrespectively.\n","authors":["Anna Kurbatskaya","Alberto Jaramillo-Jimenez","John Fredy Ochoa-Gomez","Kolbjørn Brønnick","Alvaro Fernandez-Quilez"],"pdf_url":"https://arxiv.org/pdf/2303.01389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01388v1","updated":"2023-03-02T16:18:00Z","published":"2023-03-02T16:18:00Z","title":"Reinforced Labels: Multi-Agent Deep Reinforcement Learning for\n  Point-feature Label Placement","summary":"  Over the past few years, Reinforcement Learning combined with Deep Learning\ntechniques has successfully proven to solve complex problems in various domains\nincluding robotics, self-driving cars, finance, and gaming. In this paper, we\nare introducing Reinforcement Learning (RL) to another domain - visualization.\nOur novel point-feature label placement method utilizes Multi-Agent Deep\nReinforcement Learning (MADRL) to learn label placement strategy, which is the\nfirst machine-learning-driven labeling method in contrast to existing\nhand-crafted algorithms designed by human experts. To facilitate the RL\nlearning paradigm, we developed an environment where an agent acts as a proxy\nfor a label, a short textual annotation that augments visualizations like\ngeographical maps, illustrations, and technical drawings. Our results\ndemonstrate that the strategy trained by our method significantly outperforms\nthe random strategy of an untrained agent and also performs superior to the\ncompared methods designed by human experts in terms of completeness (i.e., the\nnumber of placed labels). The trade-off is increased computation time, making\nthe proposed method slower than compared methods. Nevertheless, our method is\nideal for situations where the labeling can be computed in advance, and\ncompleteness is essential, such as cartographic maps, technical drawings, and\nmedical atlases. Additionally, we conducted a user study to assess the\nperceived performance. The outcomes revealed that the participants considered\nthe proposed method to be significantly better than the other examined methods.\nThis indicates that the improved completeness is not just reflected in the\nquantitative metrics but also in the subjective evaluation of the participants.\n","authors":["Petr Bobák","Ladislav Čmolík","Martin Čadík"],"pdf_url":"https://arxiv.org/pdf/2303.01388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01384v1","updated":"2023-03-02T16:08:23Z","published":"2023-03-02T16:08:23Z","title":"DAVA: Disentangling Adversarial Variational Autoencoder","summary":"  The use of well-disentangled representations offers many advantages for\ndownstream tasks, e.g. an increased sample efficiency, or better\ninterpretability. However, the quality of disentangled interpretations is often\nhighly dependent on the choice of dataset-specific hyperparameters, in\nparticular the regularization strength. To address this issue, we introduce\nDAVA, a novel training procedure for variational auto-encoders. DAVA completely\nalleviates the problem of hyperparameter selection. We compare DAVA to models\nwith optimal hyperparameters. Without any hyperparameter tuning, DAVA is\ncompetitive on a diverse range of commonly used datasets. Underlying DAVA, we\ndiscover a necessary condition for unsupervised disentanglement, which we call\nPIPE. We demonstrate the ability of PIPE to positively predict the performance\nof downstream models in abstract reasoning. We also thoroughly investigate\ncorrelations with existing supervised and unsupervised metrics. The code is\navailable at https://github.com/besterma/dava.\n","authors":["Benjamin Estermann","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.01384v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01378v1","updated":"2023-03-02T16:03:12Z","published":"2023-03-02T16:03:12Z","title":"A Vision for Semantically Enriched Data Science","summary":"  The recent efforts in automation of machine learning or data science has\nachieved success in various tasks such as hyper-parameter optimization or model\nselection. However, key areas such as utilizing domain knowledge and data\nsemantics are areas where we have seen little automation. Data Scientists have\nlong leveraged common sense reasoning and domain knowledge to understand and\nenrich data for building predictive models. In this paper we discuss important\nshortcomings of current data science and machine learning solutions. We then\nenvision how leveraging \"semantic\" understanding and reasoning on data in\ncombination with novel tools for data science automation can help with\nconsistent and explainable data augmentation and transformation. Additionally,\nwe discuss how semantics can assist data scientists in a new manner by helping\nwith challenges related to trust, bias, and explainability in machine learning.\nSemantic annotation can also help better explore and organize large data\nsources.\n","authors":["Udayan Khurana","Kavitha Srinivas","Sainyam Galhotra","Horst Samulowitz"],"pdf_url":"https://arxiv.org/pdf/2303.01378v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2205.08018"},{"id":"http://arxiv.org/abs/2303.01377v1","updated":"2023-03-02T16:02:55Z","published":"2023-03-02T16:02:55Z","title":"BEL: A Bag Embedding Loss for Transformer enhances Multiple Instance\n  Whole Slide Image Classification","summary":"  Multiple Instance Learning (MIL) has become the predominant approach for\nclassification tasks on gigapixel histopathology whole slide images (WSIs).\nWithin the MIL framework, single WSIs (bags) are decomposed into patches\n(instances), with only WSI-level annotation available. Recent MIL approaches\nproduce highly informative bag level representations by utilizing the\ntransformer architecture's ability to model the dependencies between instances.\nHowever, when applied to high magnification datasets, problems emerge due to\nthe large number of instances and the weak supervisory learning signal. To\naddress this problem, we propose to additionally train transformers with a\nnovel Bag Embedding Loss (BEL). BEL forces the model to learn a discriminative\nbag-level representation by minimizing the distance between bag embeddings of\nthe same class and maximizing the distance between different classes. We\nevaluate BEL with the Transformer architecture TransMIL on two publicly\navailable histopathology datasets, BRACS and CAMELYON17. We show that with BEL,\nTransMIL outperforms the baseline models on both datasets, thus contributing to\nthe clinically highly relevant AI-based tumor classification of histological\npatient material.\n","authors":["Daniel Sens","Ario Sadafi","Francesco Paolo Casale","Nassir Navab","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2303.01377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01372v1","updated":"2023-03-02T15:58:09Z","published":"2023-03-02T15:58:09Z","title":"High-dimensional analysis of double descent for linear regression with\n  random projections","summary":"  We consider linear regression problems with a varying number of random\nprojections, where we provably exhibit a double descent curve for a fixed\nprediction problem, with a high-dimensional analysis based on random matrix\ntheory. We first consider the ridge regression estimator and re-interpret\nearlier results using classical notions from non-parametric statistics, namely\ndegrees of freedom, also known as effective dimensionality. In particular, we\nshow that the random design performance of ridge regression with a specific\nregularization parameter matches the classical bias and variance expressions\ncoming from the easier fixed design analysis but for another larger implicit\nregularization parameter. We then compute asymptotic equivalents of the\ngeneralization performance (in terms of bias and variance) of the minimum norm\nleast-squares fit with random projections, providing simple expressions for the\ndouble descent phenomenon.\n","authors":["Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2303.01372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.10314v6","updated":"2023-03-02T15:56:26Z","published":"2021-07-21T19:23:56Z","title":"Small-Text: Active Learning for Text Classification in Python","summary":"  We introduce small-text, an easy-to-use active learning library, which offers\npool-based active learning for single- and multi-label text classification in\nPython. It features numerous pre-implemented state-of-the-art query strategies,\nincluding some that leverage the GPU. Standardized interfaces allow the\ncombination of a variety of classifiers, query strategies, and stopping\ncriteria, facilitating a quick mix and match, and enabling a rapid and\nconvenient development of both active learning experiments and applications.\nWith the objective of making various classifiers and query strategies\naccessible for active learning, small-text integrates several well-known\nmachine learning libraries, namely scikit-learn, PyTorch, and Hugging Face\ntransformers. The latter integrations are optionally installable extensions, so\nGPUs can be used but are not required. Using this new library, we investigate\nthe performance of the recently published SetFit training paradigm, which we\ncompare to vanilla transformer fine-tuning, finding that it matches the latter\nin classification accuracy while outperforming it in area under the curve. The\nlibrary is available under the MIT License at\nhttps://github.com/webis-de/small-text, in version 1.3.0 at the time of\nwriting.\n","authors":["Christopher Schröder","Lydia Müller","Andreas Niekler","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2107.10314v6.pdf","comment":"EACL 2023 System Demonstrations (camera-ready)"},{"id":"http://arxiv.org/abs/2203.08089v3","updated":"2023-03-02T15:53:20Z","published":"2022-03-15T17:18:48Z","title":"On Suspicious Coincidences and Pointwise Mutual Information","summary":"  Barlow (1985) hypothesized that the co-occurrence of two events $A$ and $B$\nis \"suspicious\" if $P(A,B) \\gg P(A) P(B)$. We first review classical measures\nof association for $2 \\times 2$ contingency tables, including Yule's $Y$ (Yule,\n1912), which depends only on the odds ratio $\\lambda$, and is independent of\nthe marginal probabilities of the table. We then discuss the mutual information\n(MI) and pointwise mutual information (PMI), which depend on the ratio\n$P(A,B)/P(A)P(B)$, as measures of association. We show that, once the effect of\nthe marginals is removed, MI and PMI behave similarly to $Y$ as functions of\n$\\lambda$. The pointwise mutual information is used extensively in some\nresearch communities for flagging suspicious coincidences, but it is important\nto bear in mind the sensitivity of the PMI to the marginals, with increased\nscores for sparser events.\n","authors":["Christopher K. I. Williams"],"pdf_url":"https://arxiv.org/pdf/2203.08089v3.pdf","comment":"9 pages, 1 figure. Addendum added March 2023"},{"id":"http://arxiv.org/abs/2302.01518v2","updated":"2023-03-02T15:36:08Z","published":"2023-02-03T03:26:08Z","title":"LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex\n  Geometry","summary":"  We present a novel loss formulation for efficient learning of complex\ndynamics from governing physics, typically described by partial differential\nequations (PDEs), using physics-informed neural networks (PINNs). In our\nexperiments, existing versions of PINNs are seen to learn poorly in many\nproblems, especially for complex geometries, as it becomes increasingly\ndifficult to establish appropriate sampling strategy at the near boundary\nregion. Overly dense sampling can adversely impede training convergence if the\nlocal gradient behaviors are too complex to be adequately modelled by PINNs. On\nthe other hand, if the samples are too sparse, existing PINNs tend to overfit\nthe near boundary region, leading to incorrect solution. To prevent such\nissues, we propose a new Boundary Connectivity (BCXN) loss function which\nprovides linear local structure approximation (LSA) to the gradient behaviors\nat the boundary for PINN. Our BCXN-loss implicitly imposes local structure\nduring training, thus facilitating fast physics-informed learning across entire\nproblem domains with order of magnitude sparser training samples. This LSA-PINN\nmethod shows a few orders of magnitude smaller errors than existing methods in\nterms of the standard L2-norm metric, while using dramatically fewer training\nsamples and iterations. Our proposed LSA-PINN does not pose any requirement on\nthe differentiable property of the networks, and we demonstrate its benefits\nand ease of implementation on both multi-layer perceptron and convolutional\nneural network versions as commonly used in current PINN literature.\n","authors":["Jian Cheng Wong","Pao-Hsiung Chiu","Chinchun Ooi","My Ha Dao","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2302.01518v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.01353v1","updated":"2023-03-02T15:33:18Z","published":"2023-03-02T15:33:18Z","title":"Penalising the biases in norm regularisation enforces sparsity","summary":"  Controlling the parameters' norm often yields good generalisation when\ntraining neural networks. Beyond simple intuitions, the relation between\nparameters' norm and obtained estimators theoretically remains misunderstood.\nFor one hidden ReLU layer networks with unidimensional data, this work shows\nthe minimal parameters' norm required to represent a function is given by the\ntotal variation of its second derivative, weighted by a $\\sqrt{1+x^2}$ factor.\nAs a comparison, this $\\sqrt{1+x^2}$ weighting disappears when the norm of the\nbias terms are ignored. This additional weighting is of crucial importance,\nsince it is shown in this work to enforce uniqueness and sparsity (in number of\nkinks) of the minimal norm interpolator. On the other hand, omitting the bias'\nnorm allows for non-sparse solutions. Penalising the bias terms in the\nregularisation, either explicitly or implicitly, thus leads to sparse\nestimators. This sparsity might take part in the good generalisation of neural\nnetworks that is empirically observed.\n","authors":["Etienne Boursier","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2303.01353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07624v2","updated":"2023-03-02T15:33:06Z","published":"2022-12-15T05:54:16Z","title":"Neuroevolution Surpasses Stochastic Gradient Descent for\n  Physics-Informed Neural Networks","summary":"  The potential of learned models for fundamental scientific research and\ndiscovery is drawing increasing attention. Physics-informed neural networks\n(PINNs), where the loss function directly embeds governing equations of\nscientific phenomena, is one of the key techniques at the forefront of recent\nadvances. These models are typically trained using stochastic gradient descent,\nakin to their standard deep learning counterparts. However, in this paper, we\ncarry out a simple analysis showing that the loss functions arising in PINNs\nlead to a high degree of complexity and ruggedness that may not be conducive\nfor gradient-descent and its variants. It is therefore clear that the use of\nneuro-evolutionary algorithms as alternatives to gradient descent for PINNs may\nbe a better choice. Our claim is strongly supported herein by benchmark\nproblems and baseline results demonstrating that convergence rates achieved by\nneuroevolution can indeed surpass that of gradient descent for PINN training.\nFurthermore, implementing neuroevolution with JAX leads to orders of magnitude\nspeedup relative to standard implementations.\n","authors":["Nicholas Sung Wei Yong","Jian Cheng Wong","Pao-Hsiung Chiu","Abhishek Gupta","Chinchun Ooi","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2212.07624v2.pdf","comment":"10 pages, 9 figures, 5 tables"},{"id":"http://arxiv.org/abs/2303.01346v1","updated":"2023-03-02T15:24:24Z","published":"2023-03-02T15:24:24Z","title":"Co-learning Planning and Control Policies Using Differentiable Formal\n  Task Constraints","summary":"  This paper presents a hierarchical reinforcement learning algorithm\nconstrained by differentiable signal temporal logic. Previous work on\nlogic-constrained reinforcement learning consider encoding these constraints\nwith a reward function, constraining policy updates with a sample-based policy\ngradient. However, such techniques oftentimes tend to be inefficient because of\nthe significant number of samples required to obtain accurate policy gradients.\nIn this paper, instead of implicitly constraining policy search with\nsample-based policy gradients, we directly constrain policy search by\nbackpropagating through formal constraints, enabling training hierarchical\npolicies with substantially fewer training samples. The use of hierarchical\npolicies is recognized as a crucial component of reinforcement learning with\ntask constraints. We show that we can stably constrain policy updates, thus\nenabling different levels of the policy to be learned simultaneously, yielding\nsuperior performance compared with training them separately. Experiment results\non several simulated high-dimensional robot dynamics and a real-world\ndifferential drive robot (TurtleBot3) demonstrate the effectiveness of our\napproach on five different types of task constraints. Demo videos, code, and\nmodels can be found at our project website: https://sites.google.com/view/dscrl\n","authors":["Zikang Xiong","Joe Eappen","Daniel Lawson","Ahmed H. Qureshi","Suresh Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2303.01346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01335v1","updated":"2023-03-02T15:13:37Z","published":"2023-03-02T15:13:37Z","title":"Model agnostic methods meta-learn despite misspecifications","summary":"  Due to its empirical success on few shot classification and reinforcement\nlearning, meta-learning recently received a lot of interest. Meta-learning\nleverages data from previous tasks to quickly learn a new task, despite limited\ndata. In particular, model agnostic methods look for initialisation points from\nwhich gradient descent quickly adapts to any new task. Although it has been\nempirically suggested that such methods learn a good shared representation\nduring training, there is no strong theoretical evidence of such behavior. More\nimportantly, it is unclear whether these methods truly are model agnostic,\ni.e., whether they still learn a shared structure despite architecture\nmisspecifications. To fill this gap, this work shows in the limit of an\ninfinite number of tasks that first order ANIL with a linear two-layer network\narchitecture successfully learns a linear shared representation. Moreover, this\nresult holds despite misspecifications: having a large width with respect to\nthe hidden dimension of the shared representation does not harm the algorithm\nperformance. The learnt parameters then allow to get a small test loss after a\nsingle gradient step on any new task. Overall this illustrates how well model\nagnostic methods can adapt to any (unknown) model structure.\n","authors":["Oguz Yuksel","Etienne Boursier","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2303.01335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07254v2","updated":"2023-03-02T15:10:12Z","published":"2022-11-14T10:32:51Z","title":"The Role of Local Alignment and Uniformity in Image-Text Contrastive\n  Learning on Medical Images","summary":"  Image-text contrastive learning has proven effective for pretraining medical\nimage models. When targeting localized downstream tasks like semantic\nsegmentation or object detection, additional local contrastive losses that\nalign image regions with sentences have shown promising results. We study how\nlocal contrastive losses are related to global (per-sample) contrastive losses\nand which effects they have on localized medical downstream tasks. Based on a\ntheoretical comparison, we propose to remove some components of local losses\nand replace others by a novel distribution prior which enforces uniformity of\nrepresentations within each sample. We empirically study this approach on chest\nX-ray tasks and find it to be very effective, outperforming methods without\nlocal losses on 12 of 18 tasks.\n","authors":["Philip Müller","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2211.07254v2.pdf","comment":"NeurIPS 2022 Workshop: Self-Supervised Learning - Theory and Practice\n  (Reason for updated version: correction of a typo in Eq. (2) and (3))"},{"id":"http://arxiv.org/abs/2303.01332v1","updated":"2023-03-02T15:10:08Z","published":"2023-03-02T15:10:08Z","title":"Self-Supervised Few-Shot Learning for Ischemic Stroke Lesion\n  Segmentation","summary":"  Precise ischemic lesion segmentation plays an essential role in improving\ndiagnosis and treatment planning for ischemic stroke, one of the prevalent\ndiseases with the highest mortality rate. While numerous deep neural network\napproaches have recently been proposed to tackle this problem, these methods\nrequire large amounts of annotated regions during training, which can be\nimpractical in the medical domain where annotated data is scarce. As a remedy,\nwe present a prototypical few-shot segmentation approach for ischemic lesion\nsegmentation using only one annotated sample during training. The proposed\napproach leverages a novel self-supervised training mechanism that is tailored\nto the task of ischemic stroke lesion segmentation by exploiting color-coded\nparametric maps generated from Computed Tomography Perfusion scans. We\nillustrate the benefits of our proposed training mechanism, leading to\nconsiderable improvements in performance in the few-shot setting. Given a\nsingle annotated patient, an average Dice score of 0.58 is achieved for the\nsegmentation of ischemic lesions.\n","authors":["Luca Tomasetti","Stine Hansen","Mahdieh Khanmohammadi","Kjersti Engan","Liv Jorunn Høllesli","Kathinka Dæhli Kurz","Michael Kampffmeyer"],"pdf_url":"https://arxiv.org/pdf/2303.01332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01331v1","updated":"2023-03-02T15:09:25Z","published":"2023-03-02T15:09:25Z","title":"Canonical mapping as a general-purpose object descriptor for robotic\n  manipulation","summary":"  Perception is an essential part of robotic manipulation in a semi-structured\nenvironment. Traditional approaches produce a narrow task-specific prediction\n(e.g., object's 6D pose), that cannot be adapted to other tasks and is\nill-suited for deformable objects. In this paper, we propose using canonical\nmapping as a near-universal and flexible object descriptor. We demonstrate that\ncommon object representations can be derived from a single pre-trained\ncanonical mapping model, which in turn can be generated with minimal manual\neffort using an automated data generation and training pipeline. We perform a\nmulti-stage experiment using two robot arms that demonstrate the robustness of\nthe perception approach and the ways it can inform the manipulation strategy,\nthus serving as a powerful foundation for general-purpose robotic manipulation.\n","authors":["Benjamin Joffe","Konrad Ahlin"],"pdf_url":"https://arxiv.org/pdf/2303.01331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.07027v2","updated":"2023-03-02T14:49:06Z","published":"2022-07-14T15:59:03Z","title":"MedFuse: Multi-modal fusion with clinical time-series data and chest\n  X-ray images","summary":"  Multi-modal fusion approaches aim to integrate information from different\ndata sources. Unlike natural datasets, such as in audio-visual applications,\nwhere samples consist of \"paired\" modalities, data in healthcare is often\ncollected asynchronously. Hence, requiring the presence of all modalities for a\ngiven sample is not realistic for clinical tasks and significantly limits the\nsize of the dataset during training. In this paper, we propose MedFuse, a\nconceptually simple yet promising LSTM-based fusion module that can accommodate\nuni-modal as well as multi-modal input. We evaluate the fusion method and\nintroduce new benchmark results for in-hospital mortality prediction and\nphenotype classification, using clinical time-series data in the MIMIC-IV\ndataset and corresponding chest X-ray images in MIMIC-CXR. Compared to more\ncomplex multi-modal fusion strategies, MedFuse provides a performance\nimprovement by a large margin on the fully paired test set. It also remains\nrobust across the partially paired test set containing samples with missing\nchest X-ray images. We release our code for reproducibility and to enable the\nevaluation of competing models in the future.\n","authors":["Nasir Hayat","Krzysztof J. Geras","Farah E. Shamout"],"pdf_url":"https://arxiv.org/pdf/2207.07027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.10313v2","updated":"2023-03-02T14:47:43Z","published":"2021-12-20T03:06:08Z","title":"Semi-Decentralized Federated Edge Learning with Data and Device\n  Heterogeneity","summary":"  Federated edge learning (FEEL) has attracted much attention as a\nprivacy-preserving paradigm to effectively incorporate the distributed data at\nthe network edge for training deep learning models. Nevertheless, the limited\ncoverage of a single edge server results in an insufficient number of\nparticipated client nodes, which may impair the learning performance. In this\npaper, we investigate a novel framework of FEEL, namely semi-decentralized\nfederated edge learning (SD-FEEL), where multiple edge servers are employed to\ncollectively coordinate a large number of client nodes. By exploiting the\nlow-latency communication among edge servers for efficient model sharing,\nSD-FEEL can incorporate more training data, while enjoying much lower latency\ncompared with conventional federated learning. We detail the training algorithm\nfor SD-FEEL with three main steps, including local model update, intra-cluster,\nand inter-cluster model aggregations. The convergence of this algorithm is\nproved on non-independent and identically distributed (non-IID) data, which\nalso helps to reveal the effects of key parameters on the training efficiency\nand provides practical design guidelines. Meanwhile, the heterogeneity of edge\ndevices may cause the straggler effect and deteriorate the convergence speed of\nSD-FEEL. To resolve this issue, we propose an asynchronous training algorithm\nwith a staleness-aware aggregation scheme for SD-FEEL, of which, the\nconvergence performance is also analyzed. The simulation results demonstrate\nthe effectiveness and efficiency of the proposed algorithms for SD-FEEL and\ncorroborate our analysis.\n","authors":["Yuchang Sun","Jiawei Shao","Yuyi Mao","Jessie Hui Wang","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2112.10313v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.11602v2","updated":"2023-03-02T14:42:41Z","published":"2021-12-22T01:04:50Z","title":"Identifying Mixtures of Bayesian Network Distributions","summary":"  A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random\nvariables (the vertices); a Bayesian Network Distribution (BND) is a\nprobability distribution on the random variables that is Markovian on the\ngraph. A finite $k$-mixture of such models is graphically represented by a\nlarger graph which has an additional ``hidden'' (or ``latent'') random variable\n$U$, ranging in $\\{1,\\ldots,k\\}$, and a directed edge from $U$ to every other\nvertex. Models of this type are fundamental to causal inference, where $U$\nmodels an unobserved confounding effect of multiple populations, obscuring the\ncausal relationships in the observable DAG. By solving the mixture problem and\nrecovering the joint probability distribution on $U$, traditionally\nunidentifiable causal relationships become identifiable. Using a reduction to\nthe more well-studied ``product'' case on empty graphs, we give the first\nalgorithm to learn mixtures of non-empty DAGs.\n","authors":["Spencer L. Gordon","Bijan Mazaheri","Yuval Rabani","Leonard J. Schulman"],"pdf_url":"https://arxiv.org/pdf/2112.11602v2.pdf","comment":"Paper accepted and to appear in CLEAR 2023"},{"id":"http://arxiv.org/abs/2205.15434v4","updated":"2023-03-02T14:39:09Z","published":"2022-05-30T21:20:30Z","title":"A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems","summary":"  In order for agents in multi-agent systems (MAS) to be safe, they need to\ntake into account the risks posed by the actions of other agents. However, the\ndominant paradigm in game theory (GT) assumes that agents are not affected by\nrisk from other agents and only strive to maximise their expected utility. For\nexample, in hybrid human-AI driving systems, it is necessary to limit large\ndeviations in reward resulting from car crashes. Although there are equilibrium\nconcepts in game theory that take into account risk aversion, they either\nassume that agents are risk-neutral with respect to the uncertainty caused by\nthe actions of other agents, or they are not guaranteed to exist. We introduce\na new GT-based Risk-Averse Equilibrium (RAE) that always produces a solution\nthat minimises the potential variance in reward accounting for the strategy of\nother agents. Theoretically and empirically, we show RAE shares many properties\nwith a Nash Equilibrium (NE), establishing convergence properties and\ngeneralising to risk-dominant NE in certain cases. To tackle large-scale\nproblems, we extend RAE to the PSRO multi-agent reinforcement learning (MARL)\nframework. We empirically demonstrate the minimum reward variance benefits of\nRAE in matrix games with high-risk outcomes. Results on MARL experiments show\nRAE generalises to risk-dominant NE in a trust dilemma game and that it reduces\ninstances of crashing by 7x in an autonomous driving setting versus the best\nperforming baseline.\n","authors":["Oliver Slumbers","David Henry Mguni","Stephen Marcus McAleer","Stefano B. Blumberg","Jun Wang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2205.15434v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.13180v3","updated":"2023-03-02T14:31:28Z","published":"2021-11-25T17:22:22Z","title":"Variational Gibbs inference for statistical model estimation from\n  incomplete data","summary":"  Statistical models are central to machine learning with broad applicability\nacross a range of downstream tasks. The models are controlled by free\nparameters that are typically estimated from data by maximum-likelihood\nestimation or approximations thereof. However, when faced with real-world\ndatasets many of the models run into a critical issue: they are formulated in\nterms of fully-observed data, whereas in practice the datasets are plagued with\nmissing data. The theory of statistical model estimation from incomplete data\nis conceptually similar to the estimation of latent-variable models, where\npowerful tools such as variational inference (VI) exist. However, in contrast\nto standard latent-variable models, parameter estimation with incomplete data\noften requires estimating exponentially-many conditional distributions of the\nmissing variables, hence making standard VI methods intractable. We address\nthis gap by introducing variational Gibbs inference (VGI), a new\ngeneral-purpose method to estimate the parameters of statistical models from\nincomplete data. We validate VGI on a set of synthetic and real-world\nestimation tasks, estimating important machine learning models such as VAEs and\nnormalising flows from incomplete data. The proposed method, whilst\ngeneral-purpose, achieves competitive or better performance than existing\nmodel-specific estimation methods.\n","authors":["Vaidotas Simkus","Benjamin Rhodes","Michael U. Gutmann"],"pdf_url":"https://arxiv.org/pdf/2111.13180v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01297v1","updated":"2023-03-02T14:23:27Z","published":"2023-03-02T14:23:27Z","title":"Creating Synthetic Datasets for Collaborative Filtering Recommender\n  Systems using Generative Adversarial Networks","summary":"  Research and education in machine learning needs diverse, representative, and\nopen datasets that contain sufficient samples to handle the necessary training,\nvalidation, and testing tasks. Currently, the Recommender Systems area includes\na large number of subfields in which accuracy and beyond accuracy quality\nmeasures are continuously improved. To feed this research variety, it is\nnecessary and convenient to reinforce the existing datasets with synthetic\nones. This paper proposes a Generative Adversarial Network (GAN)-based method\nto generate collaborative filtering datasets in a parameterized way, by\nselecting their preferred number of users, items, samples, and stochastic\nvariability. This parameterization cannot be made using regular GANs. Our GAN\nmodel is fed with dense, short, and continuous embedding representations of\nitems and users, instead of sparse, large, and discrete vectors, to make an\naccurate and quick learning, compared to the traditional approach based on\nlarge and sparse input vectors. The proposed architecture includes a DeepMF\nmodel to extract the dense user and item embeddings, as well as a clustering\nprocess to convert from the dense GAN generated samples to the discrete and\nsparse ones, necessary to create each required synthetic dataset. The results\nof three different source datasets show adequate distributions and expected\nquality values and evolutions on the generated datasets compared to the source\nones. Synthetic datasets and source codes are available to researchers.\n","authors":["Jesús Bobadilla","Abraham Gutiérrez","Raciel Yera","Luis Martínez"],"pdf_url":"https://arxiv.org/pdf/2303.01297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01295v1","updated":"2023-03-02T14:21:54Z","published":"2023-03-02T14:21:54Z","title":"Iterative Assessment and Improvement of DNN Operational Accuracy","summary":"  Deep Neural Networks (DNN) are nowadays largely adopted in many application\ndomains thanks to their human-like, or even superhuman, performance in specific\ntasks. However, due to unpredictable/unconsidered operating conditions,\nunexpected failures show up on field, making the performance of a DNN in\noperation very different from the one estimated prior to release. In the life\ncycle of DNN systems, the assessment of accuracy is typically addressed in two\nways: offline, via sampling of operational inputs, or online, via\npseudo-oracles. The former is considered more expensive due to the need for\nmanual labeling of the sampled inputs. The latter is automatic but less\naccurate. We believe that emerging iterative industrial-strength life cycle\nmodels for Machine Learning systems, like MLOps, offer the possibility to\nleverage inputs observed in operation not only to provide faithful estimates of\na DNN accuracy, but also to improve it through remodeling/retraining actions.\nWe propose DAIC (DNN Assessment and Improvement Cycle), an approach which\ncombines ''low-cost'' online pseudo-oracles and ''high-cost'' offline sampling\ntechniques to estimate and improve the operational accuracy of a DNN in the\niterations of its life cycle. Preliminary results show the benefits of\ncombining the two approaches and integrating them in the DNN life cycle.\n","authors":["Antonio Guerriero","Roberto Pietrantuono","Stefano Russo"],"pdf_url":"https://arxiv.org/pdf/2303.01295v1.pdf","comment":"Paper accepted at 45th International Conference on Software\n  Engineering (ICSE'23 NIER), May 2023"},{"id":"http://arxiv.org/abs/2303.01289v1","updated":"2023-03-02T14:11:54Z","published":"2023-03-02T14:11:54Z","title":"Rethinking the Effect of Data Augmentation in Adversarial Contrastive\n  Learning","summary":"  Recent works have shown that self-supervised learning can achieve remarkable\nrobustness when integrated with adversarial training (AT). However, the\nrobustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT)\nremains significant. Motivated by this observation, we revisit existing self-AT\nmethods and discover an inherent dilemma that affects self-AT robustness:\neither strong or weak data augmentations are harmful to self-AT, and a medium\nstrength is insufficient to bridge the gap. To resolve this dilemma, we propose\na simple remedy named DYNACL (Dynamic Adversarial Contrastive Learning). In\nparticular, we propose an augmentation schedule that gradually anneals from a\nstrong augmentation to a weak one to benefit from both extreme cases. Besides,\nwe adopt a fast post-processing stage for adapting it to downstream tasks.\nThrough extensive experiments, we show that DYNACL can improve state-of-the-art\nself-AT robustness by 8.84% under Auto-Attack on the CIFAR-10 dataset, and can\neven outperform vanilla supervised adversarial training for the first time. Our\ncode is available at \\url{https://github.com/PKU-ML/DYNACL}.\n","authors":["Rundong Luo","Yifei Wang","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01289v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2205.14589v2","updated":"2023-03-02T14:10:40Z","published":"2022-05-29T07:32:00Z","title":"Masked Distillation with Receptive Tokens","summary":"  Distilling from the feature maps can be fairly effective for dense prediction\ntasks since both the feature discriminability and localization priors can be\nwell transferred. However, not every pixel contributes equally to the\nperformance, and a good student should learn from what really matters to the\nteacher. In this paper, we introduce a learnable embedding dubbed receptive\ntoken to localize those pixels of interests (PoIs) in the feature map, with a\ndistillation mask generated via pixel-wise attention. Then the distillation\nwill be performed on the mask via pixel-wise reconstruction. In this way, a\ndistillation mask actually indicates a pattern of pixel dependencies within\nfeature maps of teacher. We thus adopt multiple receptive tokens to investigate\nmore sophisticated and informative pixel dependencies to further enhance the\ndistillation. To obtain a group of masks, the receptive tokens are learned via\nthe regular task loss but with teacher fixed, and we also leverage a Dice loss\nto enrich the diversity of learned masks. Our method dubbed MasKD is simple and\npractical, and needs no priors of tasks in application. Experiments show that\nour MasKD can achieve state-of-the-art performance consistently on object\ndetection and semantic segmentation benchmarks. Code is available at:\nhttps://github.com/hunto/MasKD .\n","authors":["Tao Huang","Yuan Zhang","Shan You","Fei Wang","Chen Qian","Jian Cao","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2205.14589v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00105v2","updated":"2023-03-02T14:05:50Z","published":"2023-02-28T22:09:12Z","title":"Scalability and Sample Efficiency Analysis of Graph Neural Networks for\n  Power System State Estimation","summary":"  Data-driven state estimation (SE) is becoming increasingly important in\nmodern power systems, as it allows for more efficient analysis of system\nbehaviour using real-time measurement data. This paper thoroughly evaluates a\nphasor measurement unit-only state estimator based on graph neural networks\n(GNNs) applied over factor graphs. To assess the sample efficiency of the GNN\nmodel, we perform multiple training experiments on various training set sizes.\nAdditionally, to evaluate the scalability of the GNN model, we conduct\nexperiments on power systems of various sizes. Our results show that the\nGNN-based state estimator exhibits high accuracy and efficient use of data.\nAdditionally, it demonstrated scalability in terms of both memory usage and\ninference time, making it a promising solution for data-driven SE in modern\npower systems.\n","authors":["Ognjen Kundacina","Gorana Gojic","Mirsad Cosovic","Dragisa Miskovic","Dejan Vukobratovic"],"pdf_url":"https://arxiv.org/pdf/2303.00105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01277v1","updated":"2023-03-02T14:02:39Z","published":"2023-03-02T14:02:39Z","title":"Boosting Distributed Full-graph GNN Training with Asynchronous One-bit\n  Communication","summary":"  Training Graph Neural Networks (GNNs) on large graphs is challenging due to\nthe conflict between the high memory demand and limited GPU memory. Recently,\ndistributed full-graph GNN training has been widely adopted to tackle this\nproblem. However, the substantial inter-GPU communication overhead can cause\nsevere throughput degradation. Existing communication compression techniques\nmainly focus on traditional DNN training, whose bottleneck lies in\nsynchronizing gradients and parameters. We find they do not work well in\ndistributed GNN training as the barrier is the layer-wise communication of\nfeatures during the forward pass & feature gradients during the backward pass.\nTo this end, we propose an efficient distributed GNN training framework Sylvie,\nwhich employs one-bit quantization technique in GNNs and further pipelines the\ncurtailed communication with computation to enormously shrink the overhead\nwhile maintaining the model quality. In detail, Sylvie provides a lightweight\nLow-bit Module to quantize the sent data and dequantize the received data back\nto full precision values in each layer. Additionally, we propose a Bounded\nStaleness Adaptor to control the introduced staleness to achieve further\nperformance enhancement. We conduct theoretical convergence analysis and\nextensive experiments on various models & datasets to demonstrate Sylvie can\nconsiderably boost the training throughput by up to 28.1x.\n","authors":["Meng Zhang","Qinghao Hu","Peng Sun","Yonggang Wen","Tianwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01274v1","updated":"2023-03-02T13:59:07Z","published":"2023-03-02T13:59:07Z","title":"Measuring axiomatic soundness of counterfactual image models","summary":"  We present a general framework for evaluating image counterfactuals. The\npower and flexibility of deep generative models make them valuable tools for\nlearning mechanisms in structural causal models. However, their flexibility\nmakes counterfactual identifiability impossible in the general case. Motivated\nby these issues, we revisit Pearl's axiomatic definition of counterfactuals to\ndetermine the necessary constraints of any counterfactual inference model:\ncomposition, reversibility, and effectiveness. We frame counterfactuals as\nfunctions of an input variable, its parents, and counterfactual parents and use\nthe axiomatic constraints to restrict the set of functions that could represent\nthe counterfactual, thus deriving distance metrics between the approximate and\nideal functions. We demonstrate how these metrics can be used to compare and\nchoose between different approximate counterfactual inference models and to\nprovide insight into a model's shortcomings and trade-offs.\n","authors":["Miguel Monteiro","Fabio De Sousa Ribeiro","Nick Pawlowski","Daniel C. Castro","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2303.01274v1.pdf","comment":"Counterfactual inference, Generative Models, Computer Vision,\n  Published in ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01272v1","updated":"2023-03-02T13:58:06Z","published":"2023-03-02T13:58:06Z","title":"Navigating the Metric Maze: A Taxonomy of Evaluation Metrics for Anomaly\n  Detection in Time Series","summary":"  The field of time series anomaly detection is constantly advancing, with\nseveral methods available, making it a challenge to determine the most\nappropriate method for a specific domain. The evaluation of these methods is\nfacilitated by the use of metrics, which vary widely in their properties.\nDespite the existence of new evaluation metrics, there is limited agreement on\nwhich metrics are best suited for specific scenarios and domain, and the most\ncommonly used metrics have faced criticism in the literature. This paper\nprovides a comprehensive overview of the metrics used for the evaluation of\ntime series anomaly detection methods, and also defines a taxonomy of these\nbased on how they are calculated. By defining a set of properties for\nevaluation metrics and a set of specific case studies and experiments, twenty\nmetrics are analyzed and discussed in detail, highlighting the unique\nsuitability of each for specific tasks. Through extensive experimentation and\nanalysis, this paper argues that the choice of evaluation metric must be made\nwith care, taking into account the specific requirements of the task at hand.\n","authors":["Sondre Sørbø","Massimiliano Ruocco"],"pdf_url":"https://arxiv.org/pdf/2303.01272v1.pdf","comment":"29 pages, 28 figures and tables"},{"id":"http://arxiv.org/abs/2303.01265v1","updated":"2023-03-02T13:50:23Z","published":"2023-03-02T13:50:23Z","title":"Steering Graph Neural Networks with Pinning Control","summary":"  In the semi-supervised setting where labeled data are largely limited, it\nremains to be a big challenge for message passing based graph neural networks\n(GNNs) to learn feature representations for the nodes with the same class label\nthat is distributed discontinuously over the graph. To resolve the\ndiscontinuous information transmission problem, we propose a control principle\nto supervise representation learning by leveraging the prototypes (i.e., class\ncenters) of labeled data. Treating graph learning as a discrete dynamic process\nand the prototypes of labeled data as \"desired\" class representations, we\nborrow the pinning control idea from automatic control theory to design\nlearning feedback controllers for the feature learning process, attempting to\nminimize the differences between message passing derived features and the class\nprototypes in every round so as to generate class-relevant features.\nSpecifically, we equip every node with an optimal controller in each round\nthrough learning the matching relationships between nodes and the class\nprototypes, enabling nodes to rectify the aggregated information from\nincompatible neighbors in a graph with strong heterophily. Our experiments\ndemonstrate that the proposed PCGCN model achieves better performances than\ndeep GNNs and other competitive heterophily-oriented methods, especially when\nthe graph has very few labels and strong heterophily.\n","authors":["Acong Zhang","Ping Li","Guanrong Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01265v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2212.10390v3","updated":"2023-03-02T13:36:47Z","published":"2022-12-20T16:17:40Z","title":"ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic\n  Segmentation","summary":"  State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.\n","authors":["Ben Fei","Siyuan Huang","Jiakang Yuan","Botian Shi","Bo Zhang","Tao Chen","Min Dou","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.10390v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12245v2","updated":"2023-03-02T13:36:28Z","published":"2023-02-23T18:58:57Z","title":"Set Features for Fine-grained Anomaly Detection","summary":"  Fine-grained anomaly detection has recently been dominated by segmentation\nbased approaches. These approaches first classify each element of the sample\n(e.g., image patch) as normal or anomalous and then classify the entire sample\nas anomalous if it contains anomalous elements. However, such approaches do not\nextend to scenarios where the anomalies are expressed by an unusual combination\nof normal elements. In this paper, we overcome this limitation by proposing set\nfeatures that model each sample by the distribution its elements. We compute\nthe anomaly score of each sample using a simple density estimation method. Our\nsimple-to-implement approach outperforms the state-of-the-art in image-level\nlogical anomaly detection (+3.4%) and sequence-level time-series anomaly\ndetection (+2.4%).\n","authors":["Niv Cohen","Issar Tzachor","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2302.12245v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01256v1","updated":"2023-03-02T13:36:28Z","published":"2023-03-02T13:36:28Z","title":"Choosing Public Datasets for Private Machine Learning via Gradient\n  Subspace Distance","summary":"  Differentially private stochastic gradient descent privatizes model training\nby injecting noise into each iteration, where the noise magnitude increases\nwith the number of model parameters. Recent works suggest that we can reduce\nthe noise by leveraging public data for private machine learning, by projecting\ngradients onto a subspace prescribed by the public data. However, given a\nchoice of public datasets, it is not a priori clear which one may be most\nappropriate for the private task. We give an algorithm for selecting a public\ndataset by measuring a low-dimensional subspace distance between gradients of\nthe public and private examples. We provide theoretical analysis demonstrating\nthat the excess risk scales with this subspace distance. This distance is easy\nto compute and robust to modifications in the setting. Empirical evaluation\nshows that trained model accuracy is monotone in this distance.\n","authors":["Xin Gu","Gautam Kamath","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.13366v3","updated":"2023-03-02T13:33:41Z","published":"2022-04-28T09:17:50Z","title":"Semantic Information Recovery in Wireless Networks","summary":"  Motivated by the recent success of Machine Learning (ML) tools in wireless\ncommunications, the idea of semantic communication by Weaver from 1949 has\nreceived considerable attention. It breaks with the classic design paradigm of\nShannon by aiming to transmit the meaning of a message, i.e., semantics, rather\nthan its exact copy and thus allows for savings in information rate. In this\nwork, we extend the fundamental approach from Basu et al. for modeling\nsemantics to the complete communications Markov chain. Thus, we model semantics\nby means of hidden random variables and define the semantic communication task\nas the data-reduced and reliable transmission of messages over a communication\nchannel such that semantics is best preserved. We cast this task as an\nend-to-end Information Bottleneck problem allowing for compression while\npreserving relevant information at most. As a solution approach, we propose the\nML-based semantic communication system SINFONY and use it for a distributed\nmultipoint scenario: SINFONY communicates the meaning behind multiple messages\nthat are observed at different senders to a single receiver for semantic\nrecovery. We analyze SINFONY by processing images as message examples.\nNumerical results reveal a tremendous rate-normalized SNR shift up to 20 dB\ncompared to classically designed communication systems.\n","authors":["Edgar Beck","Carsten Bockelmann","Armin Dekorsy"],"pdf_url":"https://arxiv.org/pdf/2204.13366v3.pdf","comment":"Submitted for peer review"},{"id":"http://arxiv.org/abs/2303.01220v1","updated":"2023-03-02T13:04:47Z","published":"2023-03-02T13:04:47Z","title":"Evaluation of drain, a deep-learning approach to rain retrieval from gpm\n  passive microwave radiometer","summary":"  Retrieval of rain from Passive Microwave radiometers data has been a\nchallenge ever since the launch of the first Defense Meteorological Satellite\nProgram in the late 70s. Enormous progress has been made since the launch of\nthe Tropical Rainfall Measuring Mission (TRMM) in 1997 but until recently the\ndata were processed pixel-by-pixel or taking a few neighboring pixels into\naccount. Deep learning has obtained remarkable improvement in the computer\nvision field, and offers a whole new way to tackle the rain retrieval problem.\nThe Global Precipitation Measurement (GPM) Core satellite carries similarly to\nTRMM, a passive microwave radiometer and a radar that share part of their\nswath. The brightness temperatures measured in the 37 and 89 GHz channels are\nused like the RGB components of a regular image while rain rate from Dual\nFrequency radar provides the surface rain. A U-net is then trained on these\ndata to develop a retrieval algorithm: Deep-learning RAIN (DRAIN). With only\nfour brightness temperatures as an input and no other a priori information,\nDRAIN is offering similar or slightly better performances than GPROF, the GPM\nofficial algorithm, in most situations. These performances are assumed to be\ndue to the fact that DRAIN works on an image basis instead of the classical\npixel-by-pixel basis.\n","authors":["Nicolas Viltard","Vibolroth Sambath","Pierre Lepetit","Audrey Martini","Laurent Barthès","Cécile Mallet"],"pdf_url":"https://arxiv.org/pdf/2303.01220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01215v1","updated":"2023-03-02T12:56:52Z","published":"2023-03-02T12:56:52Z","title":"Why (and When) does Local SGD Generalize Better than SGD?","summary":"  Local SGD is a communication-efficient variant of SGD for large-scale\ntraining, where multiple GPUs perform SGD independently and average the model\nparameters periodically. It has been recently observed that Local SGD can not\nonly achieve the design goal of reducing the communication overhead but also\nlead to higher test accuracy than the corresponding SGD baseline (Lin et al.,\n2020b), though the training regimes for this to happen are still in debate\n(Ortiz et al., 2021). This paper aims to understand why (and when) Local SGD\ngeneralizes better based on Stochastic Differential Equation (SDE)\napproximation. The main contributions of this paper include (i) the derivation\nof an SDE that captures the long-term behavior of Local SGD in the small\nlearning rate regime, showing how noise drives the iterate to drift and diffuse\nafter it has reached close to the manifold of local minima, (ii) a comparison\nbetween the SDEs of Local SGD and SGD, showing that Local SGD induces a\nstronger drift term that can result in a stronger effect of regularization,\ne.g., a faster reduction of sharpness, and (iii) empirical evidence validating\nthat having a small learning rate and long enough training time enables the\ngeneralization improvement over SGD but removing either of the two conditions\nleads to no improvement.\n","authors":["Xinran Gu","Kaifeng Lyu","Longbo Huang","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2303.01215v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01213v1","updated":"2023-03-02T12:54:12Z","published":"2023-03-02T12:54:12Z","title":"Dodging the Sparse Double Descent","summary":"  This paper presents an approach to addressing the issue of\nover-parametrization in deep neural networks, more specifically by avoiding the\n``sparse double descent'' phenomenon. The authors propose a learning framework\nthat allows avoidance of this phenomenon and improves generalization, an\nentropy measure to provide more insights on its insurgence, and provide a\ncomprehensive quantitative analysis of various factors such as\nre-initialization methods, model width and depth, and dataset noise. The\nproposed approach is supported by experimental results achieved using typical\nadversarial learning setups. The source code to reproduce the experiments is\nprovided in the supplementary materials and will be publicly released upon\nacceptance of the paper.\n","authors":["Victor Quétu","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2303.01213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01211v1","updated":"2023-03-02T12:52:22Z","published":"2023-03-02T12:52:22Z","title":"Learning From Yourself: A Self-Distillation Method for Fake Speech\n  Detection","summary":"  In this paper, we propose a novel self-distillation method for fake speech\ndetection (FSD), which can significantly improve the performance of FSD without\nincreasing the model complexity. For FSD, some fine-grained information is very\nimportant, such as spectrogram defects, mute segments, and so on, which are\noften perceived by shallow networks. However, shallow networks have much noise,\nwhich can not capture this very well. To address this problem, we propose using\nthe deepest network instruct shallow network for enhancing shallow networks.\nSpecifically, the networks of FSD are divided into several segments, the\ndeepest network being used as the teacher model, and all shallow networks\nbecome multiple student models by adding classifiers. Meanwhile, the\ndistillation path between the deepest network feature and shallow network\nfeatures is used to reduce the feature difference. A series of experimental\nresults on the ASVspoof 2019 LA and PA datasets show the effectiveness of the\nproposed method, with significant improvements compared to the baseline.\n","authors":["Jun Xue","Cunhang Fan","Jiangyan Yi","Chenglong Wang","Zhengqi Wen","Dan Zhang","Zhao Lv"],"pdf_url":"https://arxiv.org/pdf/2303.01211v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2203.10258v3","updated":"2023-03-02T12:50:53Z","published":"2022-03-19T06:48:50Z","title":"TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased\n  Recommendations","summary":"  Bias is a common problem inherent in recommender systems, which is entangled\nwith users' preferences and poses a great challenge to unbiased learning. For\ndebiasing tasks, the doubly robust (DR) method and its variants show superior\nperformance due to the double robustness property, that is, DR is unbiased when\neither imputed errors or learned propensities are accurate. However, our\ntheoretical analysis reveals that DR usually has a large variance. Meanwhile,\nDR would suffer unexpectedly large bias and poor generalization caused by\ninaccurate imputed errors and learned propensities, which usually occur in\npractice. In this paper, we propose a principled approach that can effectively\nreduce bias and variance simultaneously for existing DR approaches when the\nerror imputation model is misspecified. In addition, we further propose a novel\nsemi-parametric collaborative learning approach that decomposes imputed errors\ninto parametric and nonparametric parts and updates them collaboratively,\nresulting in more accurate predictions. Both theoretical analysis and\nexperiments demonstrate the superiority of the proposed methods compared with\nexisting debiasing methods.\n","authors":["Haoxuan Li","Yan Lyu","Chunyuan Zheng","Peng Wu"],"pdf_url":"https://arxiv.org/pdf/2203.10258v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.08817v4","updated":"2023-03-02T12:50:24Z","published":"2021-02-17T15:22:38Z","title":"Dissecting Supervised Contrastive Learning","summary":"  Minimizing cross-entropy over the softmax scores of a linear map composed\nwith a high-capacity encoder is arguably the most popular choice for training\nneural networks on supervised learning tasks. However, recent works show that\none can directly optimize the encoder instead, to obtain equally (or even more)\ndiscriminative representations via a supervised variant of a contrastive\nobjective. In this work, we address the question whether there are fundamental\ndifferences in the sought-for representation geometry in the output space of\nthe encoder at minimal loss. Specifically, we prove, under mild assumptions,\nthat both losses attain their minimum once the representations of each class\ncollapse to the vertices of a regular simplex, inscribed in a hypersphere. We\nprovide empirical evidence that this configuration is attained in practice and\nthat reaching a close-to-optimal state typically indicates good generalization\nperformance. Yet, the two losses show remarkably different optimization\nbehavior. The number of iterations required to perfectly fit to data scales\nsuperlinearly with the amount of randomly flipped labels for the supervised\ncontrastive loss. This is in contrast to the approximately linear scaling\npreviously reported for networks trained with cross-entropy.\n","authors":["Florian Graf","Christoph D. Hofer","Marc Niethammer","Roland Kwitt"],"pdf_url":"https://arxiv.org/pdf/2102.08817v4.pdf","comment":"v4 updates: - updated appendix section S1.3 - this includes fixing an\n  oversight in the proofs (Lemma 1 missed an equality condition, which now\n  appears in Lemma 2) - improved figure quality"},{"id":"http://arxiv.org/abs/2111.13802v4","updated":"2023-03-02T12:40:23Z","published":"2021-11-27T03:34:13Z","title":"Factorized Fourier Neural Operators","summary":"  We propose the Factorized Fourier Neural Operator (F-FNO), a learning-based\napproach for simulating partial differential equations (PDEs). Starting from a\nrecently proposed Fourier representation of flow fields, the F-FNO bridges the\nperformance gap between pure machine learning approaches to that of the best\nnumerical or hybrid solvers. This is achieved with new representations -\nseparable spectral layers and improved residual connections - and a combination\nof training strategies such as the Markov assumption, Gaussian noise, and\ncosine learning rate decay. On several challenging benchmark PDEs on regular\ngrids, structured meshes, and point clouds, the F-FNO can scale to deeper\nnetworks and outperform both the FNO and the geo-FNO, reducing the error by 83%\non the Navier-Stokes problem, 31% on the elasticity problem, 57% on the airfoil\nflow problem, and 60% on the plastic forging problem. Compared to the\nstate-of-the-art pseudo-spectral method, the F-FNO can take a step size that is\nan order of magnitude larger in time and achieve an order of magnitude speedup\nto produce the same solution quality.\n","authors":["Alasdair Tran","Alexander Mathews","Lexing Xie","Cheng Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2111.13802v4.pdf","comment":"Published in The Eleventh International Conference on Learning\n  Representations (2023). Code is available at\n  https://github.com/alasdairtran/fourierflow"},{"id":"http://arxiv.org/abs/2303.01201v1","updated":"2023-03-02T12:34:38Z","published":"2023-03-02T12:34:38Z","title":"Average of Pruning: Improving Performance and Stability of\n  Out-of-Distribution Detection","summary":"  Detecting Out-of-distribution (OOD) inputs have been a critical issue for\nneural networks in the open world. However, the unstable behavior of OOD\ndetection along the optimization trajectory during training has not been\nexplored clearly. In this paper, we first find the performance of OOD detection\nsuffers from overfitting and instability during training: 1) the performance\ncould decrease when the training error is near zero, and 2) the performance\nwould vary sharply in the final stage of training. Based on our findings, we\npropose Average of Pruning (AoP), consisting of model averaging and pruning, to\nmitigate the unstable behaviors. Specifically, model averaging can help achieve\na stable performance by smoothing the landscape, and pruning is certified to\neliminate the overfitting by eliminating redundant features. Comprehensive\nexperiments on various datasets and architectures are conducted to verify the\neffectiveness of our method.\n","authors":["Zhen Cheng","Fei Zhu","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12502v2","updated":"2023-03-02T12:33:10Z","published":"2022-05-25T05:40:00Z","title":"The Dialog Must Go On: Improving Visual Dialog via Generative\n  Self-Training","summary":"  Visual dialog (VisDial) is a task of answering a sequence of questions\ngrounded in an image, using the dialog history as context. Prior work has\ntrained the dialog agents solely on VisDial data via supervised learning or\nleveraged pre-training on related vision-and-language datasets. This paper\npresents a semi-supervised learning approach for visually-grounded dialog,\ncalled Generative Self-Training (GST), to leverage unlabeled images on the Web.\nSpecifically, GST first retrieves in-domain images through out-of-distribution\ndetection and generates synthetic dialogs regarding the images via multimodal\nconditional text generation. GST then trains a dialog agent on the synthetic\nand the original VisDial data. As a result, GST scales the amount of training\ndata up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For\nrobust training of the synthetic dialogs, we also propose perplexity-based data\nselection and multimodal consistency regularization. Evaluation on VisDial v1.0\nand v0.9 datasets shows that GST achieves new state-of-the-art results on both\ndatasets. We further observe the robustness of GST against both visual and\ntextual adversarial attacks. Finally, GST yields strong performance gains in\nthe low-data regime. Code is available at\nhttps://github.com/gicheonkang/gst-visdial.\n","authors":["Gi-Cheon Kang","Sungdong Kim","Jin-Hwa Kim","Donghyun Kwak","Byoung-Tak Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.12502v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2210.12048v2","updated":"2023-03-02T12:31:39Z","published":"2022-10-21T15:40:49Z","title":"Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework","summary":"  Bridging geometry and topology, curvature is a powerful and expressive\ninvariant. While the utility of curvature has been theoretically and\nempirically confirmed in the context of manifolds and graphs, its\ngeneralization to the emerging domain of hypergraphs has remained largely\nunexplored. On graphs, the Ollivier-Ricci curvature measures differences\nbetween random walks via Wasserstein distances, thus grounding a geometric\nconcept in ideas from probability theory and optimal transport. We develop O\nRCHID, a flexible framework generalizing Ollivier-Ricci curvature to\nhypergraphs, and prove that the resulting curvatures have favorable theoretical\nproperties. Through extensive experiments on synthetic and real-world\nhypergraphs from different domains, we demonstrate that ORCHID curvatures are\nboth scalable and useful to perform a variety of hypergraph tasks in practice.\n","authors":["Corinna Coupette","Sebastian Dalleiger","Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2210.12048v2.pdf","comment":"Accepted at ICLR 2023 (https://openreview.net/forum?id=sPCKNl5qDps)"},{"id":"http://arxiv.org/abs/2303.01193v1","updated":"2023-03-02T12:16:24Z","published":"2023-03-02T12:16:24Z","title":"Interpretable System Identification and Long-term Prediction on\n  Time-Series Data","summary":"  Time-series prediction has drawn considerable attention during the past\ndecades fueled by the emerging advances of deep learning methods. However, most\nneural network based methods lack interpretability and fail in extracting the\nhidden mechanism of the targeted physical system. To overcome these\nshortcomings, an interpretable sparse system identification method without any\nprior knowledge is proposed in this study. This method adopts the Fourier\ntransform to reduces the irrelevant items in the dictionary matrix, instead of\nindiscriminate usage of polynomial functions in most system identification\nmethods. It shows an interpretable system representation and greatly reduces\ncomputing cost. With the adoption of $l_1$ norm in regularizing the parameter\nmatrix, a sparse description of the system model can be achieved. Moreover,\nThree data sets including the water conservancy data, global temperature data\nand financial data are used to test the performance of the proposed method.\nAlthough no prior knowledge was known about the physical background,\nexperimental results show that our method can achieve long-term prediction\nregardless of the noise and incompleteness in the original data more accurately\nthan the widely-used baseline data-driven methods. This study may provide some\ninsight into time-series prediction investigations, and suggests that an\nwhite-box system identification method may extract the easily overlooked yet\ninherent periodical features and may beat neural-network based black-box\nmethods on long-term prediction tasks.\n","authors":["Xiaoyi Liu","Duxin Chen","Wenjia Wei","Xia Zhu","Wenwu Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01181v1","updated":"2023-03-02T11:51:54Z","published":"2023-03-02T11:51:54Z","title":"iSAGE: An Incremental Version of SAGE for Online Explanation on Data\n  Streams","summary":"  Explainable Artificial Intelligence (XAI) focuses mainly on batch learning\nscenarios. In the static learning tasks, various XAI methods, like SAGE, have\nbeen proposed that distribute the importance of a model on its input features.\nHowever, models are often applied in ever-changing dynamic environments like\nincremental learning. As a result, we propose iSAGE as a direct\nincrementalization of SAGE suited for dynamic learning environments. We further\nprovide an efficient approximation method to model feature removal based on the\nconditional data distribution in an incremental setting. We formally analyze\nour explanation method to show that it is an unbiased estimator and construct\nconfidence bounds for the point estimates. Lastly, we evaluate our approach in\na thorough experimental analysis based on well-established data sets and\nconcept drift streams.\n","authors":["Maximilian Muschalik","Fabian Fumagalli","Barbara Hammer","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2303.01181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01179v1","updated":"2023-03-02T11:49:05Z","published":"2023-03-02T11:49:05Z","title":"SHAP-IQ: Unified Approximation of any-order Shapley Interactions","summary":"  Predominately in explainable artificial intelligence (XAI) research, the\nShapley value (SV) is applied to determine feature importance scores for any\nblack box model. Shapley interaction indices extend the Shapley value to define\nany-order feature interaction scores. Defining a unique Shapley interaction\nindex is an open research question and, so far, three definitions have been\nproposed, which differ by their choice of axioms. Moreover, each definition\nrequires a specific approximation technique. We, however, propose SHAPley\nInteraction Quantification (SHAP-IQ), an efficient sampling-based approximator\nto compute Shapley interactions for all three definitions, as well as all other\nthat satisfy the linearity, symmetry and dummy axiom. SHAP-IQ is based on a\nnovel representation and, in contrast to existing methods, we provide\ntheoretical guarantees for its approximation quality, as well as estimates for\nthe variance of the point estimates. For the special case of SV, our approach\nreveals a novel representation of the SV and corresponds to Unbiased KernelSHAP\nwith a greatly simplified calculation. We illustrate the computational\nefficiency and effectiveness by explaining state-of-the-art language models\namong high-dimensional synthetic models.\n","authors":["Fabian Fumagalli","Maximilian Muschalik","Patrick Kolpaczki","Eyke Hüllermeier","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2303.01179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01173v1","updated":"2023-03-02T11:35:59Z","published":"2023-03-02T11:35:59Z","title":"Resource-Constrained Station-Keeping for Helium Balloons using\n  Reinforcement Learning","summary":"  High altitude balloons have proved useful for ecological aerial surveys,\natmospheric monitoring, and communication relays. However, due to weight and\npower constraints, there is a need to investigate alternate modes of propulsion\nto navigate in the stratosphere. Very recently, reinforcement learning has been\nproposed as a control scheme to maintain the balloon in the region of a fixed\nlocation, facilitated through diverse opposing wind-fields at different\naltitudes. Although air-pump based station keeping has been explored, there is\nno research on the control problem for venting and ballasting actuated\nballoons, which is commonly used as a low-cost alternative. We show how\nreinforcement learning can be used for this type of balloon. Specifically, we\nuse the soft actor-critic algorithm, which on average is able to station-keep\nwithin 50\\;km for 25\\% of the flight, consistent with state-of-the-art.\nFurthermore, we show that the proposed controller effectively minimises the\nconsumption of resources, thereby supporting long duration flights. We frame\nthe controller as a continuous control reinforcement learning problem, which\nallows for a more diverse range of trajectories, as opposed to current\nstate-of-the-art work, which uses discrete action spaces. Furthermore, through\ncontinuous control, we can make use of larger ascent rates which are not\npossible using air-pumps. The desired ascent-rate is decoupled into desired\naltitude and time-factor to provide a more transparent policy, compared to\nlow-level control commands used in previous works. Finally, by applying the\nequations of motion, we establish appropriate thresholds for venting and\nballasting to prevent the agent from exploiting the environment. More\nspecifically, we ensure actions are physically feasible by enforcing\nconstraints on venting and ballasting.\n","authors":["Jack Saunders","Loïc Prenevost","Özgür Şimşek","Alan Hunter","Wenbin Li"],"pdf_url":"https://arxiv.org/pdf/2303.01173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07850v4","updated":"2023-03-02T11:33:24Z","published":"2022-09-16T10:43:10Z","title":"FairGBM: Gradient Boosting with Fairness Constraints","summary":"  Tabular data is prevalent in many high stakes domains, such as financial\nservices or public policy. Gradient boosted decision trees (GBDT) are popular\nin these settings due to performance guarantees and low cost. However, in\nconsequential decision-making fairness is a foremost concern. Despite GBDT's\npopularity, existing in-processing Fair ML methods are either inapplicable to\nGBDT, or incur in significant train time overhead, or are inadequate for\nproblems with high class imbalance -- a typical issue in these domains. We\npresent FairGBM, a dual ascent learning framework for training GBDT under\nfairness constraints, with little to no impact on predictive performance when\ncompared to unconstrained GBDT. Since observational fairness metrics are\nnon-differentiable, we have to employ a \"proxy-Lagrangian\" formulation using\nsmooth convex error rate proxies to enable gradient-based optimization. Our\nimplementation shows an order of magnitude speedup in training time when\ncompared with related work, a pivotal aspect to foster the widespread adoption\nof FairGBM by real-world practitioners.\n","authors":["André F Cruz","Catarina Belém","Sérgio Jesus","João Bravo","Pedro Saleiro","Pedro Bizarro"],"pdf_url":"https://arxiv.org/pdf/2209.07850v4.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2206.00470v3","updated":"2023-03-02T11:24:51Z","published":"2022-06-01T13:02:19Z","title":"Good Intentions: Adaptive Parameter Management via Intent Signaling","summary":"  Parameter management is essential for distributed training of large machine\nlearning (ML) tasks. Some ML tasks are hard to distribute because common\napproaches to parameter management can be highly inefficient. Advanced\nparameter management approaches -- such as selective replication or dynamic\nparameter allocation -- can improve efficiency, but to do so, they typically\nneed to be integrated manually into each task's implementation and they require\nexpensive upfront experimentation to tune correctly. In this work, we explore\nwhether these two problems can be avoided. We first propose a novel intent\nsignaling mechanism that integrates naturally into existing ML stacks and\nprovides the parameter manager with crucial information about parameter\naccesses. We then describe AdaPM, a fully adaptive, zero-tuning parameter\nmanager based on this mechanism. In contrast to prior systems, this approach\nseparates providing information (simple, done by the task) from exploiting it\neffectively (hard, done automatically by AdaPM). In our experimental\nevaluation, AdaPM matched or outperformed state-of-the-art parameter managers\nout of the box, suggesting that automatic parameter management is possible.\n","authors":["Alexander Renz-Wieland","Andreas Kieslinger","Robert Gericke","Rainer Gemulla","Zoi Kaoudi","Volker Markl"],"pdf_url":"https://arxiv.org/pdf/2206.00470v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01170v1","updated":"2023-03-02T11:21:03Z","published":"2023-03-02T11:21:03Z","title":"Expert-Free Online Transfer Learning in Multi-Agent Reinforcement\n  Learning","summary":"  Transfer learning in Reinforcement Learning (RL) has been widely studied to\novercome training issues of Deep-RL, i.e., exploration cost, data availability\nand convergence time, by introducing a way to enhance training phase with\nexternal knowledge. Generally, knowledge is transferred from expert-agents to\nnovices. While this fixes the issue for a novice agent, a good understanding of\nthe task on expert agent is required for such transfer to be effective. As an\nalternative, in this paper we propose Expert-Free Online Transfer Learning\n(EF-OnTL), an algorithm that enables expert-free real-time dynamic transfer\nlearning in multi-agent system. No dedicated expert exists, and transfer source\nagent and knowledge to be transferred are dynamically selected at each transfer\nstep based on agents' performance and uncertainty. To improve uncertainty\nestimation, we also propose State Action Reward Next-State Random Network\nDistillation (sars-RND), an extension of RND that estimates uncertainty from RL\nagent-environment interaction. We demonstrate EF-OnTL effectiveness against a\nno-transfer scenario and advice-based baselines, with and without expert\nagents, in three benchmark tasks: Cart-Pole, a grid-based Multi-Team\nPredator-Prey (mt-pp) and Half Field Offense (HFO). Our results show that\nEF-OnTL achieve overall comparable performance when compared against\nadvice-based baselines while not requiring any external input nor threshold\ntuning. EF-OnTL outperforms no-transfer with an improvement related to the\ncomplexity of the task addressed.\n","authors":["Alberto Castagna","Ivana Dusparic"],"pdf_url":"https://arxiv.org/pdf/2303.01170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01169v1","updated":"2023-03-02T11:19:44Z","published":"2023-03-02T11:19:44Z","title":"Risk-aware Path Planning via Probabilistic Fusion of Traversability\n  Prediction for Planetary Rovers on Heterogeneous Terrains","summary":"  Machine learning (ML) plays a crucial role in assessing traversability for\nautonomous rover operations on deformable terrains but suffers from inevitable\nprediction errors. Especially for heterogeneous terrains where the geological\nfeatures vary from place to place, erroneous traversability prediction can\nbecome more apparent, increasing the risk of unrecoverable rover's wheel slip\nand immobilization. In this work, we propose a new path planning algorithm that\nexplicitly accounts for such erroneous prediction. The key idea is the\nprobabilistic fusion of distinctive ML models for terrain type classification\nand slip prediction into a single distribution. This gives us a multimodal slip\ndistribution accounting for heterogeneous terrains and further allows\nstatistical risk assessment to be applied to derive risk-aware traversing costs\nfor path planning. Extensive simulation experiments have demonstrated that the\nproposed method is able to generate more feasible paths on heterogeneous\nterrains compared to existing methods.\n","authors":["Masafumi Endo","Tatsunori Taniai","Ryo Yonetani","Genya Ishigami"],"pdf_url":"https://arxiv.org/pdf/2303.01169v1.pdf","comment":"7 pages, 4 figures. Accepted article for presentation at the 2023\n  IEEE International Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2303.01158v1","updated":"2023-03-02T11:05:10Z","published":"2023-03-02T11:05:10Z","title":"Iterative Circuit Repair Against Formal Specifications","summary":"  We present a deep learning approach for repairing sequential circuits against\nformal specifications given in linear-time temporal logic (LTL). Given a\ndefective circuit and its formal specification, we train Transformer models to\noutput circuits that satisfy the corresponding specification. We propose a\nseparated hierarchical Transformer for multimodal representation learning of\nthe formal specification and the circuit. We introduce a data generation\nalgorithm that enables generalization to more complex specifications and\nout-of-distribution datasets. In addition, our proposed repair mechanism\nsignificantly improves the automated synthesis of circuits from LTL\nspecifications with Transformers. It improves the state-of-the-art by $6.8$\npercentage points on held-out instances and $11.8$ percentage points on an\nout-of-distribution dataset from the annual reactive synthesis competition.\n","authors":["Matthias Cosler","Frederik Schmitt","Christopher Hahn","Bernd Finkbeiner"],"pdf_url":"https://arxiv.org/pdf/2303.01158v1.pdf","comment":"To appear at ICLR'23"},{"id":"http://arxiv.org/abs/2303.01156v1","updated":"2023-03-02T11:01:49Z","published":"2023-03-02T11:01:49Z","title":"A Notion of Feature Importance by Decorrelation and Detection of Trends\n  by Random Forest Regression","summary":"  In many studies, we want to determine the influence of certain features on a\ndependent variable. More specifically, we are interested in the strength of the\ninfluence -- i.e., is the feature relevant? -- and, if so, how the feature\ninfluences the dependent variable. Recently, data-driven approaches such as\n\\emph{random forest regression} have found their way into applications\n(Boulesteix et al., 2012). These models allow to directly derive measures of\nfeature importance, which are a natural indicator of the strength of the\ninfluence. For the relevant features, the correlation or rank correlation\nbetween the feature and the dependent variable has typically been used to\ndetermine the nature of the influence. More recent methods, some of which can\nalso measure interactions between features, are based on a modeling approach.\nIn particular, when machine learning models are used, SHAP scores are a recent\nand prominent method to determine these trends (Lundberg et al., 2017).\n  In this paper, we introduce a novel notion of feature importance based on the\nwell-studied Gram-Schmidt decorrelation method. Furthermore, we propose two\nestimators for identifying trends in the data using random forest regression,\nthe so-called absolute and relative transversal rate. We empirically compare\nthe properties of our estimators with those of well-established estimators on a\nvariety of synthetic and real-world datasets.\n","authors":["Yannick Gerstorfer","Lena Krieg","Max Hahn-Klimroth"],"pdf_url":"https://arxiv.org/pdf/2303.01156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13956v2","updated":"2023-03-02T10:53:40Z","published":"2022-11-25T08:39:12Z","title":"Learning General Audio Representations with Large-Scale Training of\n  Patchout Audio Transformers","summary":"  The success of supervised deep learning methods is largely due to their\nability to learn relevant features from raw data. Deep Neural Networks (DNNs)\ntrained on large-scale datasets are capable of capturing a diverse set of\nfeatures, and learning a representation that can generalize onto unseen tasks\nand datasets that are from the same domain. Hence, these models can be used as\npowerful feature extractors, in combination with shallower models as\nclassifiers, for smaller tasks and datasets where the amount of training data\nis insufficient for learning an end-to-end model from scratch. During the past\nyears, Convolutional Neural Networks (CNNs) have largely been the method of\nchoice for audio processing. However, recently attention-based transformer\nmodels have demonstrated great potential in supervised settings, outperforming\nCNNs. In this work, we investigate the use of audio transformers trained on\nlarge-scale datasets to learn general-purpose representations. We study how the\ndifferent setups in these audio transformers affect the quality of their\nembeddings. We experiment with the models' time resolution, extracted embedding\nlevel, and receptive fields in order to see how they affect performance on a\nvariety of tasks and datasets, following the HEAR 2021 NeurIPS challenge\nevaluation setup. Our results show that representations extracted by audio\ntransformers outperform CNN representations. Furthermore, we will show that\ntransformers trained on Audioset can be extremely effective representation\nextractors for a wide range of downstream tasks.\n","authors":["Khaled Koutini","Shahed Masoudian","Florian Schmid","Hamid Eghbal-zadeh","Jan Schlüter","Gerhard Widmer"],"pdf_url":"https://arxiv.org/pdf/2211.13956v2.pdf","comment":"will apear in HEAR: Holistic Evaluation of Audio Representations\n  Proceedings of Machine Learning Research PMLR 166. Source code:\n  https://github.com/kkoutini/passt_hear21"},{"id":"http://arxiv.org/abs/2212.14441v3","updated":"2023-03-02T10:48:12Z","published":"2022-12-29T19:32:20Z","title":"Fruit Ripeness Classification: a Survey","summary":"  Fruit is a key crop in worldwide agriculture feeding millions of people. The\nstandard supply chain of fruit products involves quality checks to guarantee\nfreshness, taste, and, most of all, safety. An important factor that determines\nfruit quality is its stage of ripening. This is usually manually classified by\nfield experts, making it a labor-intensive and error-prone process. Thus, there\nis an arising need for automation in fruit ripeness classification. Many\nautomatic methods have been proposed that employ a variety of feature\ndescriptors for the food item to be graded. Machine learning and deep learning\ntechniques dominate the top-performing methods. Furthermore, deep learning can\noperate on raw data and thus relieve the users from having to compute complex\nengineered features, which are often crop-specific. In this survey, we review\nthe latest methods proposed in the literature to automatize fruit ripeness\nclassification, highlighting the most common feature descriptors they operate\non.\n","authors":["Matteo Rizzo","Matteo Marcuzzo","Alessandro Zangari","Andrea Gasparetto","Andrea Albarelli"],"pdf_url":"https://arxiv.org/pdf/2212.14441v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01141v1","updated":"2023-03-02T10:40:50Z","published":"2023-03-02T10:40:50Z","title":"DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint\n  Satisfaction","summary":"  As machine learning models, specifically neural networks, are becoming\nincreasingly popular, there are concerns regarding their trustworthiness,\nspecially in safety-critical applications, e.g. actions of an autonomous\nvehicle must be safe. There are approaches that can train neural networks where\nsuch domain requirements are enforced as constraints, but they either cannot\nguarantee that the constraint will be satisfied by all possible predictions\n(even on unseen data) or they are limited in the type of constraints that can\nbe enforced. In this paper, we present an approach to train neural networks\nwhich can enforce a wide variety of constraints and guarantee that the\nconstraint is satisfied by all possible predictions. The approach builds on\nearlier work where learning linear models is formulated as a constraint\nsatisfaction problem (CSP). To make this idea applicable to neural networks,\ntwo crucial new elements are added: constraint propagation over the network\nlayers, and weight updates based on a mix of gradient descent and CSP solving.\nEvaluation on various machine learning tasks demonstrates that our approach is\nflexible enough to enforce a wide variety of domain constraints and is able to\nguarantee them in neural networks.\n","authors":["Kshitij Goyal","Sebastijan Dumancic","Hendrik Blockeel"],"pdf_url":"https://arxiv.org/pdf/2303.01141v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2303.01140v1","updated":"2023-03-02T10:39:13Z","published":"2023-03-02T10:39:13Z","title":"Cardinality Estimation over Knowledge Graphs with Embeddings and Graph\n  Neural Networks","summary":"  Cardinality Estimation over Knowledge Graphs (KG) is crucial for query\noptimization, yet remains a challenging task due to the semi-structured nature\nand complex correlations of typical Knowledge Graphs. In this work, we propose\nGNCE, a novel approach that leverages knowledge graph embeddings and Graph\nNeural Networks (GNN) to accurately predict the cardinality of conjunctive\nqueries. GNCE first creates semantically meaningful embeddings for all entities\nin the KG, which are then integrated into the given query, which is processed\nby a GNN to estimate the cardinality of the query. We evaluate GNCE on several\nKGs in terms of q-Error and demonstrate that it outperforms state-of-the-art\napproaches based on sampling, summaries, and (machine) learning in terms of\nestimation accuracy while also having lower execution time and less parameters.\nAdditionally, we show that GNCE can inductively generalise to unseen entities,\nmaking it suitable for use in dynamic query processing scenarios. Our proposed\napproach has the potential to significantly improve query optimization and\nrelated applications that rely on accurate cardinality estimates of conjunctive\nqueries.\n","authors":["Tim Schwabe","Maribel Acosta"],"pdf_url":"https://arxiv.org/pdf/2303.01140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.03880v2","updated":"2023-03-02T10:39:10Z","published":"2022-09-08T15:35:42Z","title":"Learning Sparse Graphon Mean Field Games","summary":"  Although the field of multi-agent reinforcement learning (MARL) has made\nconsiderable progress in the last years, solving systems with a large number of\nagents remains a hard challenge. Graphon mean field games (GMFGs) enable the\nscalable analysis of MARL problems that are otherwise intractable. By the\nmathematical structure of graphons, this approach is limited to dense graphs\nwhich are insufficient to describe many real-world networks such as power law\ngraphs. Our paper introduces a novel formulation of GMFGs, called LPGMFGs,\nwhich leverages the graph theoretical concept of $L^p$ graphons and provides a\nmachine learning tool to efficiently and accurately approximate solutions for\nsparse network problems. This especially includes power law networks which are\nempirically observed in various application areas and cannot be captured by\nstandard graphons. We derive theoretical existence and convergence guarantees\nand give empirical examples that demonstrate the accuracy of our learning\napproach for systems with many agents. Furthermore, we extend the Online Mirror\nDescent (OMD) learning algorithm to our setup to accelerate learning speed,\nempirically show its capabilities, and conduct a theoretical analysis using the\nnovel concept of smoothed step graphons. In general, we provide a scalable,\nmathematically well-founded machine learning approach to a large class of\notherwise intractable problems of great relevance in numerous research fields.\n","authors":["Christian Fabian","Kai Cui","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2209.03880v2.pdf","comment":"accepted for publication at the International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2023"},{"id":"http://arxiv.org/abs/2210.09186v4","updated":"2023-03-02T10:37:17Z","published":"2022-10-17T15:38:41Z","title":"Implicit models, latent compression, intrinsic biases, and cheap lunches\n  in community detection","summary":"  The task of community detection, which aims to partition a network into\nclusters of nodes to summarize its large-scale structure, has spawned the\ndevelopment of many competing algorithms with varying objectives. Some\ncommunity detection methods are inferential, explicitly deriving the clustering\nobjective through a probabilistic generative model, while other methods are\ndescriptive, dividing a network according to an objective motivated by a\nparticular application, making it challenging to compare these methods on the\nsame scale. Here we present a solution to this problem that associates any\ncommunity detection objective, inferential or descriptive, with its\ncorresponding implicit network generative model. This allows us to compute the\ndescription length of a network and its partition under arbitrary objectives,\nproviding a principled measure to compare the performance of different\nalgorithms without the need for \"ground truth\" labels. Our approach also gives\naccess to instances of the community detection problem that are optimal to any\ngiven algorithm, and in this way reveals intrinsic biases in popular\ndescriptive methods, explaining their tendency to overfit. Using our framework,\nwe compare a number of community detection methods on artificial networks, and\non a corpus of over 500 structurally diverse empirical networks. We find that\nmore expressive community detection methods exhibit consistently superior\ncompression performance on structured data instances, without having degraded\nperformance on a minority of situations where more specialized algorithms\nperform optimally. Our results undermine the implications of the \"no free\nlunch\" theorem for community detection, both conceptually and in practice,\nsince it is confined to unstructured data instances, unlike relevant community\ndetection problems which are structured by requirement.\n","authors":["Tiago P. Peixoto","Alec Kirkley"],"pdf_url":"https://arxiv.org/pdf/2210.09186v4.pdf","comment":"27 pages, 17 figures"},{"id":"http://arxiv.org/abs/2303.01135v1","updated":"2023-03-02T10:31:58Z","published":"2023-03-02T10:31:58Z","title":"Tight Risk Bounds for Gradient Descent on Separable Data","summary":"  We study the generalization properties of unregularized gradient methods\napplied to separable linear classification -- a setting that has received\nconsiderable attention since the pioneering work of Soudry et al. (2018). We\nestablish tight upper and lower (population) risk bounds for gradient descent\nin this setting, for any smooth loss function, expressed in terms of its tail\ndecay rate. Our bounds take the form $\\Theta(r_{\\ell,T}^2 / \\gamma^2 T +\nr_{\\ell,T}^2 / \\gamma^2 n)$, where $T$ is the number of gradient steps, $n$ is\nsize of the training set, $\\gamma$ is the data margin, and $r_{\\ell,T}$ is a\ncomplexity term that depends on the (tail decay rate) of the loss function (and\non $T$). Our upper bound matches the best known upper bounds due to Shamir\n(2021); Schliserman and Koren (2022), while extending their applicability to\nvirtually any smooth loss function and relaxing technical assumptions they\nimpose. Our risk lower bounds are the first in this context and establish the\ntightness of our upper bounds for any given tail decay rate and in all\nparameter regimes. The proof technique used to show these results is also\nmarkedly simpler compared to previous work, and is straightforward to extend to\nother gradient methods; we illustrate this by providing analogous results for\nStochastic Gradient Descent.\n","authors":["Matan Schliserman","Tomer Koren"],"pdf_url":"https://arxiv.org/pdf/2303.01135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01134v1","updated":"2023-03-02T10:30:52Z","published":"2023-03-02T10:30:52Z","title":"Error mitigation of entangled states using brainbox quantum autoencoders","summary":"  Current quantum hardware is subject to various sources of noise that limits\nthe access to multi-qubit entangled states. Quantum autoencoder circuits with a\nsingle qubit bottleneck have shown capability to correct error in noisy\nentangled state. By introducing slightly more complex structures in the\nbottleneck, the so-called brainboxes, the denoising process can take place\nfaster and for stronger noise channels. Choosing the most suitable brainbox for\nthe bottleneck is the result of a trade-off between noise intensity on the\nhardware, and the training impedance. Finally, by studying R\\'enyi entropy flow\nthroughout the networks we demonstrate that the localization of entanglement\nplays a central role in denoising through learning.\n","authors":["Joséphine Pazem","Mohammad H. Ansari"],"pdf_url":"https://arxiv.org/pdf/2303.01134v1.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2303.01125v1","updated":"2023-03-02T10:09:11Z","published":"2023-03-02T10:09:11Z","title":"Distilling Multi-Level X-vector Knowledge for Small-footprint Speaker\n  Verification","summary":"  Deep speaker models yield low error rates in speaker verification.\nNonetheless, the high performance tends to be exchanged for model size and\ncomputation time, making these models challenging to run under limited\nconditions. We focus on small-footprint deep speaker embedding extraction,\nleveraging knowledge distillation. While prior work on this topic has addressed\nspeaker embedding extraction at the utterance level, we propose to combine\nembeddings from various levels of the x-vector model (teacher network) to train\nsmall-footprint student networks. Results indicate the usefulness of\nframe-level information, with the student models being 85%-91% smaller than\ntheir teacher, depending on the size of the teacher embeddings. Concatenation\nof teacher embeddings results in student networks that reach comparable\nperformance along with the teacher while utilizing a 75% relative size\nreduction from the teacher. The findings and analogies are furthered to other\nx-vector variants.\n","authors":["Xuechen Liu","Md Sahidullah","Tomi Kinnunen"],"pdf_url":"https://arxiv.org/pdf/2303.01125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01117v1","updated":"2023-03-02T10:00:37Z","published":"2023-03-02T10:00:37Z","title":"In all LikelihoodS: How to Reliably Select Pseudo-Labeled Data for\n  Self-Training in Semi-Supervised Learning","summary":"  Self-training is a simple yet effective method within semi-supervised\nlearning. The idea is to iteratively enhance training data by adding\npseudo-labeled data. Its generalization performance heavily depends on the\nselection of these pseudo-labeled data (PLS). In this paper, we aim at\nrendering PLS more robust towards the involved modeling assumptions. To this\nend, we propose to select pseudo-labeled data that maximize a multi-objective\nutility function. The latter is constructed to account for different sources of\nuncertainty, three of which we discuss in more detail: model selection,\naccumulation of errors and covariate shift. In the absence of second-order\ninformation on such uncertainties, we furthermore consider the generic approach\nof the generalized Bayesian alpha-cut updating rule for credal sets. As a\npractical proof of concept, we spotlight the application of three of our robust\nextensions on simulated and real-world data. Results suggest that in particular\nrobustness w.r.t. model choice can lead to substantial accuracy gains.\n","authors":["Julian Rodemann","Christoph Jansen","Georg Schollmeyer","Thomas Augustin"],"pdf_url":"https://arxiv.org/pdf/2303.01117v1.pdf","comment":"9 pages, 1 figure, under review"},{"id":"http://arxiv.org/abs/2303.01112v1","updated":"2023-03-02T09:47:28Z","published":"2023-03-02T09:47:28Z","title":"Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves","summary":"  Formula-driven supervised learning (FDSL) has been shown to be an effective\nmethod for pre-training vision transformers, where ExFractalDB-21k was shown to\nexceed the pre-training effect of ImageNet-21k. These studies also indicate\nthat contours mattered more than textures when pre-training vision\ntransformers. However, the lack of a systematic investigation as to why these\ncontour-oriented synthetic datasets can achieve the same accuracy as real\ndatasets leaves much room for skepticism. In the present work, we develop a\nnovel methodology based on circular harmonics for systematically investigating\nthe design space of contour-oriented synthetic datasets. This allows us to\nefficiently search the optimal range of FDSL parameters and maximize the\nvariety of synthetic images in the dataset, which we found to be a critical\nfactor. When the resulting new dataset VisualAtom-21k is used for pre-training\nViT-Base, the top-1 accuracy reached 83.7% when fine-tuning on ImageNet-1k.\nThis is close to the top-1 accuracy (84.2%) achieved by JFT-300M pre-training,\nwhile the number of images is 1/14. Unlike JFT-300M which is a static dataset,\nthe quality of synthetic datasets will continue to improve, and the current\nwork is a testament to this possibility. FDSL is also free of the common issues\nassociated with real images, e.g. privacy/copyright issues, labeling\ncosts/errors, and ethical biases.\n","authors":["Sora Takashima","Ryo Hayamizu","Nakamasa Inoue","Hirokatsu Kataoka","Rio Yokota"],"pdf_url":"https://arxiv.org/pdf/2303.01112v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01111v1","updated":"2023-03-02T09:47:14Z","published":"2023-03-02T09:47:14Z","title":"Predicting Stock Price Movement as an Image Classification Problem","summary":"  The paper studies intraday price movement of stocks that is considered as an\nimage classification problem. Using a CNN-based model we make a compelling case\nfor the high-level relationship between the first hour of trading and the\nclose. The algorithm managed to adequately separate between the two opposing\nclasses and investing according to the algorithm's predictions outperformed all\nalternative constructs but the theoretical maximum. To support the thesis, we\nran several additional tests. The findings in the paper highlight the\nsuitability of computer vision techniques for studying financial markets and in\nparticular prediction of stock price movements.\n","authors":["Matej Steinbacher"],"pdf_url":"https://arxiv.org/pdf/2303.01111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.07766v2","updated":"2023-03-02T09:43:58Z","published":"2022-06-15T19:04:02Z","title":"Pareto Invariant Risk Minimization: Towards Mitigating the Optimization\n  Dilemma in Out-of-Distribution Generalization","summary":"  Recently, there has been a growing surge of interest in enabling machine\nlearning systems to generalize well to Out-of-Distribution (OOD) data. Most\nefforts are devoted to advancing optimization objectives that regularize models\nto capture the underlying invariance; however, there often are compromises in\nthe optimization process of these OOD objectives: i) Many OOD objectives have\nto be relaxed as penalty terms of Empirical Risk Minimization (ERM) for the\nease of optimization, while the relaxed forms can weaken the robustness of the\noriginal objective; ii) The penalty terms also require careful tuning of the\npenalty weights due to the intrinsic conflicts between ERM and OOD objectives.\nConsequently, these compromises could easily lead to suboptimal performance of\neither the ERM or OOD objective. To address these issues, we introduce a\nmulti-objective optimization (MOO) perspective to understand the OOD\noptimization process, and propose a new optimization scheme called PAreto\nInvariant Risk Minimization (PAIR). PAIR improves the robustness of OOD\nobjectives by cooperatively optimizing with other OOD objectives, thereby\nbridging the gaps caused by the relaxations. Then PAIR approaches a Pareto\noptimal solution that trades off the ERM and OOD objectives properly. Extensive\nexperiments on challenging benchmarks, WILDS, show that PAIR alleviates the\ncompromises and yields top OOD performances.\n","authors":["Yongqiang Chen","Kaiwen Zhou","Yatao Bian","Binghui Xie","Bingzhe Wu","Yonggang Zhang","Kaili Ma","Han Yang","Peilin Zhao","Bo Han","James Cheng"],"pdf_url":"https://arxiv.org/pdf/2206.07766v2.pdf","comment":"ICLR 2023, 50 pages, 58 figures"},{"id":"http://arxiv.org/abs/2210.14648v3","updated":"2023-03-02T09:42:58Z","published":"2022-10-26T11:49:30Z","title":"Masked Modeling Duo: Learning Representations by Encouraging Both\n  Networks to Model the Input","summary":"  Masked Autoencoders is a simple yet powerful self-supervised learning method.\nHowever, it learns representations indirectly by reconstructing masked input\npatches. Several methods learn representations directly by predicting\nrepresentations of masked patches; however, we think using all patches to\nencode training signal representations is suboptimal. We propose a new method,\nMasked Modeling Duo (M2D), that learns representations directly while obtaining\ntraining signals using only masked patches. In the M2D, the online network\nencodes visible patches and predicts masked patch representations, and the\ntarget network, a momentum encoder, encodes masked patches. To better predict\ntarget representations, the online network should model the input well, while\nthe target network should also model it well to agree with online predictions.\nThen the learned representations should better model the input. We validated\nthe M2D by learning general-purpose audio representations, and M2D set new\nstate-of-the-art performance on tasks such as UrbanSound8K, VoxCeleb1,\nAudioSet20K, GTZAN, and SpeechCommandsV2. We additionally validate the\neffectiveness of M2D for images using ImageNet-1K in the appendix.\n","authors":["Daisuke Niizumi","Daiki Takeuchi","Yasunori Ohishi","Noboru Harada","Kunio Kashino"],"pdf_url":"https://arxiv.org/pdf/2210.14648v3.pdf","comment":"6 pages, 3 figures, and 6 tables. To appear at ICASSP2023"},{"id":"http://arxiv.org/abs/2302.13259v3","updated":"2023-03-02T09:40:17Z","published":"2023-02-26T08:12:28Z","title":"Can we avoid Double Descent in Deep Neural Networks?","summary":"  Finding the optimal size of deep learning models is very actual and of broad\nimpact, especially in energy-saving schemes. Very recently, an unexpected\nphenomenon, the ``double descent'', has caught the attention of the deep\nlearning community. As the model's size grows, the performance gets first\nworse, and then goes back to improving. It raises serious questions about the\noptimal model's size to maintain high generalization: the model needs to be\nsufficiently over-parametrized, but adding too many parameters wastes training\nresources. Is it possible to find, in an efficient way, the best trade-off? Our\nwork shows that the double descent phenomenon is potentially avoidable with\nproper conditioning of the learning problem, but a final answer is yet to be\nfound. We empirically observe that there is hope to dodge the double descent in\ncomplex scenarios with proper regularization, as a simple $\\ell_2$\nregularization is already positively contributing to such a perspective.\n","authors":["Victor Quétu","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2302.13259v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01105v1","updated":"2023-03-02T09:37:56Z","published":"2023-03-02T09:37:56Z","title":"Evidence-empowered Transfer Learning for Alzheimer's Disease","summary":"  Transfer learning has been widely utilized to mitigate the data scarcity\nproblem in the field of Alzheimer's disease (AD). Conventional transfer\nlearning relies on re-using models trained on AD-irrelevant tasks such as\nnatural image classification. However, it often leads to negative transfer due\nto the discrepancy between the non-medical source and target medical domains.\nTo address this, we present evidence-empowered transfer learning for AD\ndiagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary\ntask, namely morphological change prediction, without requiring additional MRI\ndata. In this auxiliary task, the diagnosis model learns the evidential and\ntransferable knowledge from morphological features in MRI scans. Experimental\nresults demonstrate that our framework is not only effective in improving\ndetection performance regardless of model capacity, but also more\ndata-efficient and faithful.\n","authors":["Kai Tzu-iunn Ong","Hana Kim","Minjin Kim","Jinseong Jang","Beomseok Sohn","Yoon Seong Choi","Dosik Hwang","Seong Jae Hwang","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.01105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.00743v4","updated":"2023-03-02T09:31:50Z","published":"2021-11-01T07:39:38Z","title":"Towards the Generalization of Contrastive Self-Supervised Learning","summary":"  Recently, self-supervised learning has attracted great attention, since it\nonly requires unlabeled data for model training. Contrastive learning is one\npopular method for self-supervised learning and has achieved promising\nempirical performance. However, the theoretical understanding of its\ngeneralization ability is still limited. To this end, we define a kind of\n$(\\sigma,\\delta)$-measure to mathematically quantify the data augmentation, and\nthen provide an upper bound of the downstream classification error rate based\non the measure. It reveals that the generalization ability of contrastive\nself-supervised learning is related to three key factors: alignment of positive\nsamples, divergence of class centers, and concentration of augmented data. The\nfirst two factors are properties of learned representations, while the third\none is determined by pre-defined data augmentation. We further investigate two\ncanonical contrastive losses, InfoNCE and cross-correlation, to show how they\nprovably achieve the first two factors. Moreover, we conduct experiments to\nstudy the third factor, and observe a strong correlation between downstream\nperformance and the concentration of augmented data.\n","authors":["Weiran Huang","Mingyang Yi","Xuyang Zhao","Zihao Jiang"],"pdf_url":"https://arxiv.org/pdf/2111.00743v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2211.10445v3","updated":"2023-03-02T09:28:25Z","published":"2022-11-18T14:59:42Z","title":"Building a Subspace of Policies for Scalable Continual Learning","summary":"  The ability to continuously acquire new knowledge and skills is crucial for\nautonomous agents. Existing methods are typically based on either fixed-size\nmodels that struggle to learn a large number of diverse behaviors, or\ngrowing-size models that scale poorly with the number of tasks. In this work,\nwe aim to strike a better balance between an agent's size and performance by\ndesigning a method that grows adaptively depending on the task sequence. We\nintroduce Continual Subspace of Policies (CSP), a new approach that\nincrementally builds a subspace of policies for training a reinforcement\nlearning agent on a sequence of tasks. The subspace's high expressivity allows\nCSP to perform well for many different tasks while growing sublinearly with the\nnumber of tasks. Our method does not suffer from forgetting and displays\npositive transfer to new tasks. CSP outperforms a number of popular baselines\non a wide range of scenarios from two challenging domains, Brax (locomotion)\nand Continual World (manipulation).\n","authors":["Jean-Baptiste Gaya","Thang Doan","Lucas Caccia","Laure Soulier","Ludovic Denoyer","Roberta Raileanu"],"pdf_url":"https://arxiv.org/pdf/2211.10445v3.pdf","comment":"Accepted at ICLR2023 (notable-top-25%). website:\n  https://continual-subspace-policies-streamlit-app-gofujp.streamlit.app/ code:\n  https://github.com/facebookresearch/salina/tree/main/salina_cl"},{"id":"http://arxiv.org/abs/2303.01092v1","updated":"2023-03-02T09:26:20Z","published":"2023-03-02T09:26:20Z","title":"ArCL: Enhancing Contrastive Learning with Augmentation-Robust\n  Representations","summary":"  Self-Supervised Learning (SSL) is a paradigm that leverages unlabeled data\nfor model training. Empirical studies show that SSL can achieve promising\nperformance in distribution shift scenarios, where the downstream and training\ndistributions differ. However, the theoretical understanding of its\ntransferability remains limited. In this paper, we develop a theoretical\nframework to analyze the transferability of self-supervised contrastive\nlearning, by investigating the impact of data augmentation on it. Our results\nreveal that the downstream performance of contrastive learning depends largely\non the choice of data augmentation. Moreover, we show that contrastive learning\nfails to learn domain-invariant features, which limits its transferability.\nBased on these theoretical insights, we propose a novel method called\nAugmentation-robust Contrastive Learning (ArCL), which guarantees to learn\ndomain-invariant features and can be easily integrated with existing\ncontrastive learning algorithms. We conduct experiments on several datasets and\nshow that ArCL significantly improves the transferability of contrastive\nlearning.\n","authors":["Xuyang Zhao","Tianqi Du","Yisen Wang","Jun Yao","Weiran Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01092v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.13417v2","updated":"2023-03-02T09:13:05Z","published":"2023-02-26T22:10:23Z","title":"Training neural networks with structured noise improves classification\n  and generalization","summary":"  The beneficial role of noise in learning is nowadays a consolidated concept\nin the field of artificial neural networks. The training-with-noise algorithm\nproposed by Gardner and collaborators is an emblematic example of a noise\ninjection procedure in recurrent networks. We show how adding structure into\nnoisy training data can substantially improve memory performance, allowing to\napproach perfect classification and maximal basins of attraction. We also prove\nthat the so-called unlearning rule coincides with the training-with-noise\nalgorithm when noise is maximal and data are fixed points of the network\ndynamics. Moreover, a sampling scheme for optimal noisy data is proposed and\nimplemented to outperform both the training-with-noise and the unlearning\nprocedures.\n","authors":["Marco Benedetti","Enrico Ventura"],"pdf_url":"https://arxiv.org/pdf/2302.13417v2.pdf","comment":"20 pages, 18 figures, main text and appendices"},{"id":"http://arxiv.org/abs/2206.04624v3","updated":"2023-03-02T09:11:34Z","published":"2022-06-09T17:16:43Z","title":"Factuality Enhanced Language Models for Open-Ended Text Generation","summary":"  Pretrained language models (LMs) are susceptible to generate text with\nnonfactual information. In this work, we measure and improve the factual\naccuracy of large-scale LMs for open-ended text generation. We design the\nFactualityPrompts test set and metrics to measure the factuality of LM\ngenerations. Based on that, we study the factual accuracy of LMs with parameter\nsizes ranging from 126M to 530B. Interestingly, we find that larger LMs are\nmore factual than smaller ones, although a previous study suggests that larger\nLMs can be less truthful in terms of misconceptions. In addition, popular\nsampling algorithms (e.g., top-p) in open-ended text generation can harm the\nfactuality due to the ''uniform randomness'' introduced at every sampling step.\nWe propose the factual-nucleus sampling algorithm that dynamically adapts the\nrandomness to improve the factuality of generation while maintaining quality.\nFurthermore, we analyze the inefficiencies of the standard training method in\nlearning correct associations between entities from factual text corpus (e.g.,\nWikipedia). We propose a factuality-enhanced training method that uses\nTopicPrefix for better awareness of facts and sentence completion as the\ntraining objective, which can vastly reduce the factual errors. We release our\ncode and FactualityPrompts benchmark at:\nhttps://github.com/nayeon7lee/FactualityPrompt.\n","authors":["Nayeon Lee","Wei Ping","Peng Xu","Mostofa Patwary","Pascale Fung","Mohammad Shoeybi","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2206.04624v3.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.09748v2","updated":"2023-03-02T09:06:55Z","published":"2022-12-19T18:59:58Z","title":"Scalable Diffusion Models with Transformers","summary":"  We explore a new class of diffusion models based on the transformer\narchitecture. We train latent diffusion models of images, replacing the\ncommonly-used U-Net backbone with a transformer that operates on latent\npatches. We analyze the scalability of our Diffusion Transformers (DiTs)\nthrough the lens of forward pass complexity as measured by Gflops. We find that\nDiTs with higher Gflops -- through increased transformer depth/width or\nincreased number of input tokens -- consistently have lower FID. In addition to\npossessing good scalability properties, our largest DiT-XL/2 models outperform\nall prior diffusion models on the class-conditional ImageNet 512x512 and\n256x256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.\n","authors":["William Peebles","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2212.09748v2.pdf","comment":"Code, project page and videos available at\n  https://www.wpeebles.com/DiT"},{"id":"http://arxiv.org/abs/2303.01082v1","updated":"2023-03-02T09:04:35Z","published":"2023-03-02T09:04:35Z","title":"GBMST: An Efficient Minimum Spanning Tree Clustering Based on\n  Granular-Ball","summary":"  Most of the existing clustering methods are based on a single granularity of\ninformation, such as the distance and density of each data. This most\nfine-grained based approach is usually inefficient and susceptible to noise.\nTherefore, we propose a clustering algorithm that combines multi-granularity\nGranular-Ball and minimum spanning tree (MST). We construct coarsegrained\ngranular-balls, and then use granular-balls and MST to implement the clustering\nmethod based on \"large-scale priority\", which can greatly avoid the influence\nof outliers and accelerate the construction process of MST. Experimental\nresults on several data sets demonstrate the power of the algorithm. All codes\nhave been released at https://github.com/xjnine/GBMST.\n","authors":["Jiang Xie","Shuyin Xia","Guoyin Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2303.01082v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01076v1","updated":"2023-03-02T08:57:35Z","published":"2023-03-02T08:57:35Z","title":"Hallucinated Adversarial Control for Conservative Offline Policy\n  Evaluation","summary":"  We study the problem of conservative off-policy evaluation (COPE) where given\nan offline dataset of environment interactions, collected by other agents, we\nseek to obtain a (tight) lower bound on a policy's performance. This is crucial\nwhen deciding whether a given policy satisfies certain minimal\nperformance/safety criteria before it can be deployed in the real world. To\nthis end, we introduce HAMBO, which builds on an uncertainty-aware learned\nmodel of the transition dynamics. To form a conservative estimate of the\npolicy's performance, HAMBO hallucinates worst-case trajectories that the\npolicy may take, within the margin of the models' epistemic confidence regions.\nWe prove that the resulting COPE estimates are valid lower bounds, and, under\nregularity conditions, show their convergence to the true expected return.\nFinally, we discuss scalable variants of our approach based on Bayesian Neural\nNetworks and empirically demonstrate that they yield reliable and tight lower\nbounds in various continuous control environments.\n","authors":["Jonas Rothfuss","Bhavya Sukhija","Tobias Birchler","Parnian Kassraie","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2303.01076v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2303.01074v1","updated":"2023-03-02T08:56:12Z","published":"2023-03-02T08:56:12Z","title":"Learning not to Regret","summary":"  Regret minimization is a key component of many algorithms for finding Nash\nequilibria in imperfect-information games. To scale to games that cannot fit in\nmemory, we can use search with value functions. However, calling the value\nfunctions repeatedly in search can be expensive. Therefore, it is desirable to\nminimize regret in the search tree as fast as possible. We propose to\naccelerate the regret minimization by introducing a general ``learning not to\nregret'' framework, where we meta-learn the regret minimizer. The resulting\nalgorithm is guaranteed to minimize regret in arbitrary settings and is\n(meta)-learned to converge fast on a selected distribution of games. Our\nexperiments show that meta-learned algorithms converge substantially faster\nthan prior regret minimization algorithms.\n","authors":["David Sychrovsky","Michal Sustr","Elnaz Davoodi","Marc Lanctot","Martin Schmid"],"pdf_url":"https://arxiv.org/pdf/2303.01074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01070v1","updated":"2023-03-02T08:45:49Z","published":"2023-03-02T08:45:49Z","title":"GHQ: Grouped Hybrid Q Learning for Heterogeneous Cooperative Multi-agent\n  Reinforcement Learning","summary":"  Previous deep multi-agent reinforcement learning (MARL) algorithms have\nachieved impressive results, typically in homogeneous scenarios. However,\nheterogeneous scenarios are also very common and usually harder to solve. In\nthis paper, we mainly discuss cooperative heterogeneous MARL problems in\nStarcraft Multi-Agent Challenges (SMAC) environment. We firstly define and\ndescribe the heterogeneous problems in SMAC. In order to comprehensively reveal\nand study the problem, we make new maps added to the original SMAC maps. We\nfind that baseline algorithms fail to perform well in those heterogeneous maps.\nTo address this issue, we propose the Grouped Individual-Global-Max Consistency\n(GIGM) and a novel MARL algorithm, Grouped Hybrid Q Learning (GHQ). GHQ\nseparates agents into several groups and keeps individual parameters for each\ngroup, along with a novel hybrid structure for factorization. To enhance\ncoordination between groups, we maximize the Inter-group Mutual Information\n(IGMI) between groups' trajectories. Experiments on original and new\nheterogeneous maps show the fabulous performance of GHQ compared to other\nstate-of-the-art algorithms.\n","authors":["Xiaoyang Yu","Youfang Lin","Xiangsen Wang","Sheng Han","Kai Lv"],"pdf_url":"https://arxiv.org/pdf/2303.01070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01069v1","updated":"2023-03-02T08:43:40Z","published":"2023-03-02T08:43:40Z","title":"Implicit Neural Representations for Modeling of Abdominal Aortic\n  Aneurysm Progression","summary":"  Abdominal aortic aneurysms (AAAs) are progressive dilatations of the\nabdominal aorta that, if left untreated, can rupture with lethal consequences.\nImaging-based patient monitoring is required to select patients eligible for\nsurgical repair. In this work, we present a model based on implicit neural\nrepresentations (INRs) to model AAA progression. We represent the AAA wall over\ntime as the zero-level set of a signed distance function (SDF), estimated by a\nmultilayer perception that operates on space and time. We optimize this INR\nusing automatically extracted segmentation masks in longitudinal CT data. This\nnetwork is conditioned on spatiotemporal coordinates and represents the AAA\nsurface at any desired resolution at any moment in time. Using regularization\non spatial and temporal gradients of the SDF, we ensure proper interpolation of\nthe AAA shape. We demonstrate the network's ability to produce AAA\ninterpolations with average surface distances ranging between 0.72 and 2.52 mm\nfrom images acquired at highly irregular intervals. The results indicate that\nour model can accurately interpolate AAA shapes over time, with potential\nclinical value for a more personalised assessment of AAA progression.\n","authors":["Dieuwertje Alblas","Marieke Hofman","Christoph Brune","Kak Khee Yeung","Jelmer M. Wolterink"],"pdf_url":"https://arxiv.org/pdf/2303.01069v1.pdf","comment":"FIMH 2023 (submitted)"},{"id":"http://arxiv.org/abs/2303.01068v1","updated":"2023-03-02T08:43:30Z","published":"2023-03-02T08:43:30Z","title":"Targeted Adversarial Attacks against Neural Machine Translation","summary":"  Neural Machine Translation (NMT) systems are used in various applications.\nHowever, it has been shown that they are vulnerable to very small perturbations\nof their inputs, known as adversarial attacks. In this paper, we propose a new\ntargeted adversarial attack against NMT models. In particular, our goal is to\ninsert a predefined target keyword into the translation of the adversarial\nsentence while maintaining similarity between the original sentence and the\nperturbed one in the source domain. To this aim, we propose an optimization\nproblem, including an adversarial loss term and a similarity term. We use\ngradient projection in the embedding space to craft an adversarial sentence.\nExperimental results show that our attack outperforms Seq2Sick, the other\ntargeted adversarial attack against NMT models, in terms of success rate and\ndecrease in translation quality. Our attack succeeds in inserting a keyword\ninto the translation for more than 75% of sentences while similarity with the\noriginal sentence stays preserved.\n","authors":["Sahar Sadrizadeh","AmirHossein Dabiri Aghdam","Ljiljana Dolamic","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2303.01068v1.pdf","comment":"ICASSP 2023, Code available at:\n  http://github.com/sssadrizadeh/NMT-targeted-attack"},{"id":"http://arxiv.org/abs/2207.13856v2","updated":"2023-03-02T08:38:26Z","published":"2022-07-28T02:15:47Z","title":"Imbalanced Semi-supervised Learning with Bias Adaptive Classifier","summary":"  Pseudo-labeling has proven to be a promising semi-supervised learning (SSL)\nparadigm. Existing pseudo-labeling methods commonly assume that the class\ndistributions of training data are balanced. However, such an assumption is far\nfrom realistic scenarios and thus severely limits the performance of current\npseudo-labeling methods under the context of class-imbalance. To alleviate this\nproblem, we design a bias adaptive classifier that targets the imbalanced SSL\nsetups. The core idea is to automatically assimilate the training bias caused\nby class imbalance via the bias adaptive classifier, which is composed of a\nnovel bias attractor and the original linear classifier. The bias attractor is\ndesigned as a light-weight residual network and optimized through a bi-level\nlearning framework. Such a learning strategy enables the bias adaptive\nclassifier to fit imbalanced training data, while the linear classifier can\nprovide unbiased label prediction for each class. We conduct extensive\nexperiments under various imbalanced semi-supervised setups, and the results\ndemonstrate that our method can be applied to different pseudo-labeling models\nand is superior to current state-of-the-art methods.\n","authors":["Renzhen Wang","Xixi Jia","Quanziang Wang","Yichen Wu","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2207.13856v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.12095v3","updated":"2023-03-02T08:33:04Z","published":"2023-02-22T11:01:20Z","title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution\n  Perspective","summary":"  ChatGPT is a recent chatbot service released by OpenAI and is receiving\nincreasing attention over the past few months. While evaluations of various\naspects of ChatGPT have been done, its robustness, i.e., the performance to\nunexpected inputs, is still unclear to the public. Robustness is of particular\nconcern in responsible AI, especially for safety-critical applications. In this\npaper, we conduct a thorough evaluation of the robustness of ChatGPT from the\nadversarial and out-of-distribution (OOD) perspective. To do so, we employ the\nAdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart\nreview and DDXPlus medical diagnosis datasets for OOD evaluation. We select\nseveral popular foundation models as baselines. Results show that ChatGPT shows\nconsistent advantages on most adversarial and OOD classification and\ntranslation tasks. However, the absolute performance is far from perfection,\nwhich suggests that adversarial and OOD robustness remains a significant threat\nto foundation models. Moreover, ChatGPT shows astounding performance in\nunderstanding dialogue-related texts and we find that it tends to provide\ninformal suggestions for medical tasks instead of definitive answers. Finally,\nwe present in-depth discussions of possible research directions.\n","authors":["Jindong Wang","Xixu Hu","Wenxin Hou","Hao Chen","Runkai Zheng","Yidong Wang","Linyi Yang","Haojun Huang","Wei Ye","Xiubo Geng","Binxin Jiao","Yue Zhang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2302.12095v3.pdf","comment":"Technical report; code is at:\n  https://github.com/microsoft/robustlearn"},{"id":"http://arxiv.org/abs/2205.14592v2","updated":"2023-03-02T08:25:36Z","published":"2022-05-29T07:44:09Z","title":"GBC: An Efficient and Adaptive Clustering Algorithm Based on\n  Granular-Ball","summary":"  Existing clustering methods are based on a single granularity of information,\nsuch as the distance and density of each data. This most fine-grained based\napproach is usually inefficient and susceptible to noise. Inspired by adaptive\nprocess of granular-ball division and differentiation, we present a novel\nclustering approach that retains the speed and efficiency of K-means clustering\nwhile out-performing time-tested density clustering approaches widely used in\nindustry today. Our simple, robust, adaptive granular-ball clustering method\ncan efficiently recognize clusters with unknown and complex shapes without the\nuse of extra parameters. Moreover, the proposed method provides an efficient,\nadaptive way to depict the world, and will promote the research and development\nof adaptive and efficient AI technologies, especially density computing models,\nand improve the efficiency of many existing clustering methods.\n","authors":["Shuyin Xia","Jiang Xie","Guoyin Wang"],"pdf_url":"https://arxiv.org/pdf/2205.14592v2.pdf","comment":"5 pages, 1 figures"},{"id":"http://arxiv.org/abs/2303.01055v1","updated":"2023-03-02T08:24:27Z","published":"2023-03-02T08:24:27Z","title":"Physics-informed neural networks for solving forward and inverse\n  problems in complex beam systems","summary":"  This paper proposes a new framework using physics-informed neural networks\n(PINNs) to simulate complex structural systems that consist of single and\ndouble beams based on Euler-Bernoulli and Timoshenko theory, where the double\nbeams are connected with a Winkler foundation. In particular, forward and\ninverse problems for the Euler-Bernoulli and Timoshenko partial differential\nequations (PDEs) are solved using nondimensional equations with the\nphysics-informed loss function. Higher-order complex beam PDEs are efficiently\nsolved for forward problems to compute the transverse displacements and\ncross-sectional rotations with less than 1e-3 percent error. Furthermore,\ninverse problems are robustly solved to determine the unknown dimensionless\nmodel parameters and applied force in the entire space-time domain, even in the\ncase of noisy data. The results suggest that PINNs are a promising strategy for\nsolving problems in engineering structures and machines involving beam systems.\n","authors":["Taniya Kapoor","Hongrui Wang","Alfredo Nunez","Rolf Dollevoet"],"pdf_url":"https://arxiv.org/pdf/2303.01055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01052v1","updated":"2023-03-02T08:18:22Z","published":"2023-03-02T08:18:22Z","title":"Demystifying Causal Features on Adversarial Examples and Causal\n  Inoculation for Robust Network by Adversarial Instrumental Variable\n  Regression","summary":"  The origin of adversarial examples is still inexplicable in research fields,\nand it arouses arguments from various viewpoints, albeit comprehensive\ninvestigations. In this paper, we propose a way of delving into the unexpected\nvulnerability in adversarially trained networks from a causal perspective,\nnamely adversarial instrumental variable (IV) regression. By deploying it, we\nestimate the causal relation of adversarial prediction under an unbiased\nenvironment dissociated from unknown confounders. Our approach aims to\ndemystify inherent causal features on adversarial examples by leveraging a\nzero-sum optimization game between a casual feature estimator (i.e., hypothesis\nmodel) and worst-case counterfactuals (i.e., test function) disturbing to find\ncausal features. Through extensive analyses, we demonstrate that the estimated\ncausal features are highly related to the correct prediction for adversarial\nrobustness, and the counterfactuals exhibit extreme features significantly\ndeviating from the correct prediction. In addition, we present how to\neffectively inoculate CAusal FEatures (CAFE) into defense networks for\nimproving adversarial robustness.\n","authors":["Junho Kim. Byung-Kwan Lee","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2303.01052v1.pdf","comment":"Accepted in CVPR 2023"},{"id":"http://arxiv.org/abs/2209.15278v3","updated":"2023-03-02T08:08:49Z","published":"2022-09-30T07:31:49Z","title":"Rethinking skip connection model as a learnable Markov chain","summary":"  Over past few years afterward the birth of ResNet, skip connection has become\nthe defacto standard for the design of modern architectures due to its\nwidespread adoption, easy optimization and proven performance. Prior work has\nexplained the effectiveness of the skip connection mechanism from different\nperspectives. In this work, we deep dive into the model's behaviors with skip\nconnections which can be formulated as a learnable Markov chain. An efficient\nMarkov chain is preferred as it always maps the input data to the target domain\nin a better way. However, while a model is explained as a Markov chain, it is\nnot guaranteed to be optimized following an efficient Markov chain by existing\nSGD-based optimizers which are prone to get trapped in local optimal points. In\norder to towards a more efficient Markov chain, we propose a simple routine of\npenal connection to make any residual-like model become a learnable Markov\nchain. Aside from that, the penal connection can also be viewed as a particular\nmodel regularization and can be easily implemented with one line of code in the\nmost popular deep learning frameworks~\\footnote{Source code:\n\\url{https://github.com/densechen/penal-connection}}. The encouraging\nexperimental results in multi-modal translation and image recognition\nempirically confirm our conjecture of the learnable Markov chain view and\ndemonstrate the superiority of the proposed penal connection.\n","authors":["Dengsheng Chen","Jie Hu","Wenwen Qiang","Xiaoming Wei","Enhua Wu"],"pdf_url":"https://arxiv.org/pdf/2209.15278v3.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.00409v2","updated":"2023-03-02T08:04:03Z","published":"2023-03-01T11:00:20Z","title":"RePAD2: Real-Time, Lightweight, and Adaptive Anomaly Detection for\n  Open-Ended Time Series","summary":"  An open-ended time series refers to a series of data points indexed in time\norder without an end. Such a time series can be found everywhere due to the\nprevalence of Internet of Things. Providing lightweight and real-time anomaly\ndetection for open-ended time series is highly desirable to industry and\norganizations since it allows immediate response and avoids potential financial\nloss. In the last few years, several real-time time series anomaly detection\napproaches have been introduced. However, they might exhaust system resources\nwhen they are applied to open-ended time series for a long time. To address\nthis issue, in this paper we propose RePAD2, a lightweight real-time anomaly\ndetection approach for open-ended time series by improving its predecessor\nRePAD, which is one of the state-of-the-art anomaly detection approaches. We\nconducted a series of experiments to compare RePAD2 with RePAD and another\nsimilar detection approach based on real-world time series datasets, and\ndemonstrated that RePAD2 can address the mentioned resource exhaustion issue\nwhile offering comparable detection accuracy and slightly less time\nconsumption.\n","authors":["Ming-Chang Lee","Jia-Chun Lin"],"pdf_url":"https://arxiv.org/pdf/2303.00409v2.pdf","comment":"10 pages, 11 figures, and 10 tables, the paper is accepted by 8th\n  International Conference on Internet of Things, Big Data and Security (IoTBDS\n  2023)"},{"id":"http://arxiv.org/abs/2303.00351v2","updated":"2023-03-02T07:59:22Z","published":"2023-03-01T09:27:08Z","title":"An end-to-end SE(3)-equivariant segmentation network","summary":"  Convolutional neural networks (CNNs) allow for parameter sharing and\ntranslational equivariance by using convolutional kernels in their linear\nlayers. By restricting these kernels to be SO(3)-steerable, CNNs can further\nimprove parameter sharing and equivariance. These equivariant convolutional\nlayers have several advantages over standard convolutional layers, including\nincreased robustness to unseen poses, smaller network size, and improved sample\nefficiency. Despite this, most segmentation networks used in medical image\nanalysis continue to rely on standard convolutional kernels. In this paper, we\npresent a new family of segmentation networks that use equivariant voxel\nconvolutions based on spherical harmonics, as well as equivariant pooling and\nnormalization operations. These SE(3)-equivariant volumetric segmentation\nnetworks, which are robust to data poses not seen during training, do not\nrequire rotation-based data augmentation during training. In addition, we\ndemonstrate improved segmentation performance in MRI brain tumor and healthy\nbrain structure segmentation tasks, with enhanced robustness to reduced amounts\nof training data and improved parameter efficiency. Code to reproduce our\nresults, and to implement the equivariant segmentation networks for other tasks\nis available at http://github.com/SCAN-NRAD/e3nn_Unet\n","authors":["Ivan Diaz","Mario Geiger","Richard Iain McKinley"],"pdf_url":"https://arxiv.org/pdf/2303.00351v2.pdf","comment":"19 pages, 10 figures, submitted to the Journal of Machine Learning\n  for Biomedical Imaging"},{"id":"http://arxiv.org/abs/2210.11466v2","updated":"2023-03-02T07:56:13Z","published":"2022-10-20T17:59:15Z","title":"Surgical Fine-Tuning Improves Adaptation to Distribution Shifts","summary":"  A common approach to transfer learning under distribution shift is to\nfine-tune the last few layers of a pre-trained model, preserving learned\nfeatures while also adapting to the new task. This paper shows that in such\nsettings, selectively fine-tuning a subset of layers (which we term surgical\nfine-tuning) matches or outperforms commonly used fine-tuning approaches.\nMoreover, the type of distribution shift influences which subset is more\neffective to tune: for example, for image corruptions, fine-tuning only the\nfirst few layers works best. We validate our findings systematically across\nseven real-world data tasks spanning three types of distribution shifts.\nTheoretically, we prove that for two-layer neural networks in an idealized\nsetting, first-layer tuning can outperform fine-tuning all layers. Intuitively,\nfine-tuning more parameters on a small target dataset can cause information\nlearned during pre-training to be forgotten, and the relevant information\ndepends on the type of shift.\n","authors":["Yoonho Lee","Annie S. Chen","Fahim Tajwar","Ananya Kumar","Huaxiu Yao","Percy Liang","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2210.11466v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01042v1","updated":"2023-03-02T07:55:52Z","published":"2023-03-02T07:55:52Z","title":"Reinforcement Learning Guided Multi-Objective Exam Paper Generation","summary":"  To reduce the repetitive and complex work of instructors, exam paper\ngeneration (EPG) technique has become a salient topic in the intelligent\neducation field, which targets at generating high-quality exam paper\nautomatically according to instructor-specified assessment criteria. The\ncurrent advances utilize the ability of heuristic algorithms to optimize\nseveral well-known objective constraints, such as difficulty degree, number of\nquestions, etc., for producing optimal solutions. However, in real scenarios,\nconsidering other equally relevant objectives (e.g., distribution of exam\nscores, skill coverage) is extremely important. Besides, how to develop an\nautomatic multi-objective solution that finds an optimal subset of questions\nfrom a huge search space of large-sized question datasets and thus composes a\nhigh-quality exam paper is urgent but non-trivial. To this end, we skillfully\ndesign a reinforcement learning guided Multi-Objective Exam Paper Generation\nframework, termed MOEPG, to simultaneously optimize three exam domain-specific\nobjectives including difficulty degree, distribution of exam scores, and skill\ncoverage. Specifically, to accurately measure the skill proficiency of the\nexaminee group, we first employ deep knowledge tracing to model the interaction\ninformation between examinees and response logs. We then design the flexible\nExam Q-Network, a function approximator, which automatically selects the\nappropriate question to update the exam paper composition process. Later, MOEPG\ndivides the decision space into multiple subspaces to better guide the updated\ndirection of the exam paper. Through extensive experiments on two real-world\ndatasets, we demonstrate that MOEPG is feasible in addressing the multiple\ndilemmas of exam paper generation scenario.\n","authors":["Yuhu Shang","Xuexiong Luo","Lihong Wang","Hao Peng","Xiankun Zhang","Yimeng Ren","Kun Liang"],"pdf_url":"https://arxiv.org/pdf/2303.01042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01034v1","updated":"2023-03-02T07:44:06Z","published":"2023-03-02T07:44:06Z","title":"Multi-Task Self-Supervised Time-Series Representation Learning","summary":"  Time-series representation learning can extract representations from data\nwith temporal dynamics and sparse labels. When labeled data are sparse but\nunlabeled data are abundant, contrastive learning, i.e., a framework to learn a\nlatent space where similar samples are close to each other while dissimilar\nones are far from each other, has shown outstanding performance. This strategy\ncan encourage varied consistency of time-series representations depending on\nthe positive pair selection and contrastive loss. We propose a new time-series\nrepresentation learning method by combining the advantages of self-supervised\ntasks related to contextual, temporal, and transformation consistency. It\nallows the network to learn general representations for various downstream\ntasks and domains. Specifically, we first adopt data preprocessing to generate\npositive and negative pairs for each self-supervised task. The model then\nperforms contextual, temporal, and transformation contrastive learning and is\noptimized jointly using their contrastive losses. We further investigate an\nuncertainty weighting approach to enable effective multi-task learning by\nconsidering the contribution of each consistency. We evaluate the proposed\nframework on three downstream tasks: time-series classification, forecasting,\nand anomaly detection. Experimental results show that our method not only\noutperforms the benchmark models on these downstream tasks, but also shows\nefficiency in cross-domain transfer learning.\n","authors":["Heejeong Choi","Pilsung Kang"],"pdf_url":"https://arxiv.org/pdf/2303.01034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14610v3","updated":"2023-03-02T07:41:55Z","published":"2022-09-29T08:01:04Z","title":"Dynamic Prompt Learning via Policy Gradient for Semi-structured\n  Mathematical Reasoning","summary":"  Mathematical reasoning, a core ability of human intelligence, presents unique\nchallenges for machines in abstract thinking and logical reasoning. Recent\nlarge pre-trained language models such as GPT-3 have achieved remarkable\nprogress on mathematical reasoning tasks written in text form, such as math\nword problems (MWP). However, it is unknown if the models can handle more\ncomplex problems that involve math reasoning over heterogeneous information,\nsuch as tabular data. To fill the gap, we present Tabular Math Word Problems\n(TabMWP), a new dataset containing 38,431 open-domain grade-level problems that\nrequire mathematical reasoning on both textual and tabular data. Each question\nin TabMWP is aligned with a tabular context, which is presented as an image,\nsemi-structured text, and a structured table. There are two types of questions:\nfree-text and multi-choice, and each problem is annotated with gold solutions\nto reveal the multi-step reasoning process. We evaluate different pre-trained\nmodels on TabMWP, including the GPT-3 model in a few-shot setting. As earlier\nstudies suggest, since few-shot GPT-3 relies on the selection of in-context\nexamples, its performance is unstable and can degrade to near chance. The\nunstable issue is more severe when handling complex problems like TabMWP. To\nmitigate this, we further propose a novel approach, PromptPG, which utilizes\npolicy gradient to learn to select in-context examples from a small amount of\ntraining data and then constructs the corresponding prompt for the test\nexample. Experimental results show that our method outperforms the best\nbaseline by 5.31% on the accuracy metric and reduces the prediction variance\nsignificantly compared to random selection, which verifies its effectiveness in\nselecting in-context examples.\n","authors":["Pan Lu","Liang Qiu","Kai-Wei Chang","Ying Nian Wu","Song-Chun Zhu","Tanmay Rajpurohit","Peter Clark","Ashwin Kalyan"],"pdf_url":"https://arxiv.org/pdf/2209.14610v3.pdf","comment":"ICLR 2023. 26 pages and 18 figures. The data and code are available\n  at https://promptpg.github.io"},{"id":"http://arxiv.org/abs/2303.01030v1","updated":"2023-03-02T07:40:40Z","published":"2023-03-02T07:40:40Z","title":"Node Embedding from Hamiltonian Information Propagation in Graph Neural\n  Networks","summary":"  Graph neural networks (GNNs) have achieved success in various inference tasks\non graph-structured data. However, common challenges faced by many GNNs in the\nliterature include the problem of graph node embedding under various geometries\nand the over-smoothing problem. To address these issues, we propose a novel\ngraph information propagation strategy called Hamiltonian Dynamic GNN (HDG)\nthat uses a Hamiltonian mechanics approach to learn node embeddings in a graph.\nThe Hamiltonian energy function in HDG is learnable and can adapt to the\nunderlying geometry of any given graph dataset. We demonstrate the ability of\nHDG to automatically learn the underlying geometry of graph datasets, even\nthose with complex and mixed geometries, through comprehensive evaluations\nagainst state-of-the-art baselines on various downstream tasks. We also verify\nthat HDG is stable against small perturbations and can mitigate the\nover-smoothing problem when stacking many layers.\n","authors":["Qiyu Kang","Kai Zhao","Yang Song","Sijie Wang","Rui She","Wee Peng Tay"],"pdf_url":"https://arxiv.org/pdf/2303.01030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01028v1","updated":"2023-03-02T07:36:23Z","published":"2023-03-02T07:36:23Z","title":"Specformer: Spectral Graph Neural Networks Meet Transformers","summary":"  Spectral graph neural networks (GNNs) learn graph representations via\nspectral-domain graph convolutions. However, most existing spectral graph\nfilters are scalar-to-scalar functions, i.e., mapping a single eigenvalue to a\nsingle filtered value, thus ignoring the global pattern of the spectrum.\nFurthermore, these filters are often constructed based on some fixed-order\npolynomials, which have limited expressiveness and flexibility. To tackle these\nissues, we introduce Specformer, which effectively encodes the set of all\neigenvalues and performs self-attention in the spectral domain, leading to a\nlearnable set-to-set spectral filter. We also design a decoder with learnable\nbases to enable non-local graph convolution. Importantly, Specformer is\nequivariant to permutation. By stacking multiple Specformer layers, one can\nbuild a powerful spectral GNN. On synthetic datasets, we show that our\nSpecformer can better recover ground-truth spectral filters than other spectral\nGNNs. Extensive experiments of both node-level and graph-level tasks on\nreal-world graph datasets show that our Specformer outperforms state-of-the-art\nGNNs and learns meaningful spectrum patterns. Code and data are available at\nhttps://github.com/bdy9527/Specformer.\n","authors":["Deyu Bo","Chuan Shi","Lele Wang","Renjie Liao"],"pdf_url":"https://arxiv.org/pdf/2303.01028v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01021v1","updated":"2023-03-02T07:22:26Z","published":"2023-03-02T07:22:26Z","title":"CADeSH: Collaborative Anomaly Detection for Smart Homes","summary":"  Although home IoT (Internet of Things) devices are typically plain and task\noriented, the context of their daily use may affect their traffic patterns. For\nthis reason, anomaly-based intrusion detection systems tend to suffer from a\nhigh false positive rate (FPR). To overcome this, we propose a two-step\ncollaborative anomaly detection method which first uses an autoencoder to\ndifferentiate frequent (`benign') and infrequent (possibly `malicious') traffic\nflows. Clustering is then used to analyze only the infrequent flows and\nclassify them as either known ('rare yet benign') or unknown (`malicious'). Our\nmethod is collaborative, in that (1) normal behaviors are characterized more\nrobustly, as they take into account a variety of user interactions and network\ntopologies, and (2) several features are computed based on a pool of identical\ndevices rather than just the inspected device.\n  We evaluated our method empirically, using 21 days of real-world traffic data\nthat emanated from eight identical IoT devices deployed on various networks,\none of which was located in our controlled lab where we implemented two popular\nIoT-related cyber-attacks. Our collaborative anomaly detection method achieved\na macro-average area under the precision-recall curve of 0.841, an F1 score of\n0.929, and an FPR of only 0.014. These promising results were obtained by using\nlabeled traffic data from our lab as the test set, while training the models on\nthe traffic of devices deployed outside the lab, and thus demonstrate a high\nlevel of generalizability. In addition to its high generalizability and\npromising performance, our proposed method also offers benefits such as privacy\npreservation, resource savings, and model poisoning mitigation. On top of that,\nas a contribution to the scientific community, our novel dataset is available\nonline.\n","authors":["Yair Meidan","Dan Avraham","Hanan Libhaber","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2303.01021v1.pdf","comment":"in IEEE Internet of Things Journal, 2022"},{"id":"http://arxiv.org/abs/2206.09670v3","updated":"2023-03-02T07:20:08Z","published":"2022-06-20T09:22:20Z","title":"Benchmarking Constraint Inference in Inverse Reinforcement Learning","summary":"  When deploying Reinforcement Learning (RL) agents into a physical system, we\nmust ensure that these agents are well aware of the underlying constraints. In\nmany real-world problems, however, the constraints are often hard to specify\nmathematically and unknown to the RL agents. To tackle these issues, Inverse\nConstrained Reinforcement Learning (ICRL) empirically estimates constraints\nfrom expert demonstrations. As an emerging research topic, ICRL does not have\ncommon benchmarks, and previous works tested algorithms under hand-crafted\nenvironments with manually-generated expert demonstrations. In this paper, we\nconstruct an ICRL benchmark in the context of RL application domains, including\nrobot control, and autonomous driving. For each environment, we design relevant\nconstraints and train expert agents to generate demonstration data. Besides,\nunlike existing baselines that learn a deterministic constraint, we propose a\nvariational ICRL method to model a posterior distribution of candidate\nconstraints. We conduct extensive experiments on these algorithms under our\nbenchmark and show how they can facilitate studying important research\nchallenges for ICRL. The benchmark, including the instructions for reproducing\nICRL algorithms, is available at\nhttps://github.com/Guiliang/ICRL-benchmarks-public.\n","authors":["Guiliang Liu","Yudong Luo","Ashish Gaurav","Kasra Rezaee","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2206.09670v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01130v4","updated":"2023-03-02T07:15:09Z","published":"2022-12-02T12:19:12Z","title":"Improving Pareto Front Learning via Multi-Sample Hypernetworks","summary":"  Pareto Front Learning (PFL) was recently introduced as an effective approach\nto obtain a mapping function from a given trade-off vector to a solution on the\nPareto front, which solves the multi-objective optimization (MOO) problem. Due\nto the inherent trade-off between conflicting objectives, PFL offers a flexible\napproach in many scenarios in which the decision makers can not specify the\npreference of one Pareto solution over another, and must switch between them\ndepending on the situation. However, existing PFL methods ignore the\nrelationship between the solutions during the optimization process, which\nhinders the quality of the obtained front. To overcome this issue, we propose a\nnovel PFL framework namely PHN-HVI, which employs a hypernetwork to generate\nmultiple solutions from a set of diverse trade-off preferences and enhance the\nquality of the Pareto front by maximizing the Hypervolume indicator defined by\nthese solutions. The experimental results on several MOO machine learning tasks\nshow that the proposed framework significantly outperforms the baselines in\nproducing the trade-off Pareto front.\n","authors":["Long P. Hoang","Dung D. Le","Tran Anh Tuan","Tran Ngoc Thang"],"pdf_url":"https://arxiv.org/pdf/2212.01130v4.pdf","comment":"Accepted to AAAI-23"},{"id":"http://arxiv.org/abs/2210.08761v2","updated":"2023-03-02T07:09:46Z","published":"2022-10-17T06:00:12Z","title":"Protein Sequence and Structure Co-Design with Equivariant Translation","summary":"  Proteins are macromolecules that perform essential functions in all living\norganisms. Designing novel proteins with specific structures and desired\nfunctions has been a long-standing challenge in the field of bioengineering.\nExisting approaches generate both protein sequence and structure using either\nautoregressive models or diffusion models, both of which suffer from high\ninference costs. In this paper, we propose a new approach capable of protein\nsequence and structure co-design, which iteratively translates both protein\nsequence and structure into the desired state from random initialization, based\non context features given a priori. Our model consists of a trigonometry-aware\nencoder that reasons geometrical constraints and interactions from context\nfeatures, and a roto-translation equivariant decoder that translates protein\nsequence and structure interdependently. Notably, all protein amino acids are\nupdated in one shot in each translation step, which significantly accelerates\nthe inference process. Experimental results across multiple tasks show that our\nmodel outperforms previous state-of-the-art baselines by a large margin, and is\nable to design proteins of high fidelity as regards both sequence and\nstructure, with running time orders of magnitude less than sampling-based\nmethods.\n","authors":["Chence Shi","Chuanrui Wang","Jiarui Lu","Bozitao Zhong","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2210.08761v2.pdf","comment":"Published as a conference paper at ICLR 2023, see\n  https://openreview.net/forum?id=pRCMXcfdihq"},{"id":"http://arxiv.org/abs/2303.01013v1","updated":"2023-03-02T06:57:35Z","published":"2023-03-02T06:57:35Z","title":"Domain Adaptation of Reinforcement Learning Agents based on Network\n  Service Proximity","summary":"  The dynamic and evolutionary nature of service requirements in wireless\nnetworks has motivated the telecom industry to consider intelligent\nself-adapting Reinforcement Learning (RL) agents for controlling the growing\nportfolio of network services. Infusion of many new types of services is\nanticipated with future adoption of 6G networks, and sometimes these services\nwill be defined by applications that are external to the network. An RL agent\ntrained for managing the needs of a specific service type may not be ideal for\nmanaging a different service type without domain adaptation. We provide a\nsimple heuristic for evaluating a measure of proximity between a new service\nand existing services, and show that the RL agent of the most proximal service\nrapidly adapts to the new service type through a well defined process of domain\nadaptation. Our approach enables a trained source policy to adapt to new\nsituations with changed dynamics without retraining a new policy, thereby\nachieving significant computing and cost-effectiveness. Such domain adaptation\ntechniques may soon provide a foundation for more generalized RL-based service\nmanagement under the face of rapidly evolving service types.\n","authors":["Kaushik Dey","Satheesh K. Perepu","Pallab Dasgupta","Abir Das"],"pdf_url":"https://arxiv.org/pdf/2303.01013v1.pdf","comment":"9 pages, Submitted to Netsoft 2023 conference"},{"id":"http://arxiv.org/abs/2002.03328v5","updated":"2023-03-02T06:56:26Z","published":"2020-02-09T09:54:12Z","title":"Kullback-Leibler Divergence-Based Out-of-Distribution Detection with\n  Flow-Based Generative Models","summary":"  Recent research has revealed that deep generative models including flow-based\nmodels and Variational Autoencoders may assign higher likelihoods to\nout-of-distribution (OOD) data than in-distribution (ID) data. However, we\ncannot sample OOD data from the model. This counterintuitive phenomenon has not\nbeen satisfactorily explained and brings obstacles to OOD detection with\nflow-based models. In this paper, we prove theorems to investigate the\nKullback-Leibler divergence in flow-based model and give two explanations for\nthe above phenomenon. Based on our theoretical analysis, we propose a new\nmethod \\PADmethod\\ to leverage KL divergence and local pixel dependence of\nrepresentations to perform anomaly detection. Experimental results on prevalent\nbenchmarks demonstrate the effectiveness and robustness of our method. For\ngroup anomaly detection, our method achieves 98.1\\% AUROC on average with a\nsmall batch size of 5. On the contrary, the baseline typicality test-based\nmethod only achieves 64.6\\% AUROC on average due to its failure on challenging\nproblems. Our method also outperforms the state-of-the-art method by 9.1\\%\nAUROC. For point-wise anomaly detection, our method achieves 90.7\\% AUROC on\naverage and outperforms the baseline by 5.2\\% AUROC. Besides, our method has\nthe least notable failures and is the most robust one.\n","authors":["Yufeng Zhang","Jialu Pan","Wanwei Liu","Zhenbang Chen","Ji Wang","Zhiming Liu","Kenli Li","Hongmei Wei"],"pdf_url":"https://arxiv.org/pdf/2002.03328v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12391v2","updated":"2023-03-02T06:54:15Z","published":"2023-02-24T01:43:17Z","title":"PITS: Variational Pitch Inference without Fundamental Frequency for\n  End-to-End Pitch-controllable TTS","summary":"  Previous pitch-controllable text-to-speech (TTS) models rely on directly\nmodeling fundamental frequency, leading to low variance in synthesized speech.\nTo address this issue, we propose PITS, an end-to-end pitch-controllable TTS\nmodel that utilizes variational inference to model pitch. Based on VITS, PITS\nincorporates the Yingram encoder, the Yingram decoder, and adversarial training\nof pitch-shifted synthesis to achieve pitch-controllability. Experiments\ndemonstrate that PITS generates high-quality speech that is indistinguishable\nfrom ground truth speech and has high pitch-controllability without quality\ndegradation. Code and audio samples will be available at\nhttps://github.com/anonymous-pits/pits.\n","authors":["Junhyeok Lee","Wonbin Jung","Hyunjae Cho","Jaeyeon Kim"],"pdf_url":"https://arxiv.org/pdf/2302.12391v2.pdf","comment":"5 pages, preprint"},{"id":"http://arxiv.org/abs/2303.01003v1","updated":"2023-03-02T06:44:21Z","published":"2023-03-02T06:44:21Z","title":"Target Domain Data induces Negative Transfer in Mixed Domain Training\n  with Disjoint Classes","summary":"  In practical scenarios, it is often the case that the available training data\nwithin the target domain only exist for a limited number of classes, with the\nremaining classes only available within surrogate domains. We show that\nincluding the target domain in training when there exist disjoint classes\nbetween the target and surrogate domains creates significant negative transfer,\nand causes performance to significantly decrease compared to training without\nthe target domain at all. We hypothesize that this negative transfer is due to\nan intermediate shortcut that only occurs when multiple source domains are\npresent, and provide experimental evidence that this may be the case. We show\nthat this phenomena occurs on over 25 distinct domain shifts, both synthetic\nand real, and in many cases deteriorates the performance to well worse than\nrandom, even when using state-of-the-art domain adaptation methods.\n","authors":["Eryk Banatt","Vickram Rajendran","Liam Packer"],"pdf_url":"https://arxiv.org/pdf/2303.01003v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2211.00854v2","updated":"2023-03-02T06:43:56Z","published":"2022-11-02T03:50:40Z","title":"More Speaking or More Speakers?","summary":"  Self-training (ST) and self-supervised learning (SSL) methods have\ndemonstrated strong improvements in automatic speech recognition (ASR). In\nspite of these advances, to the best of our knowledge, there is no analysis of\nhow the composition of the labelled and unlabelled datasets used in these\nmethods affects the results. In this work we aim to analyse the effect of\nnumber of speakers in the training data on a recent SSL algorithm (wav2vec\n2.0), and a recent ST algorithm (slimIPL). We perform a systematic analysis on\nboth labeled and unlabeled data by varying the number of speakers while keeping\nthe number of hours fixed and vice versa. Our findings suggest that SSL\nrequires a large amount of unlabeled data to produce high accuracy results,\nwhile ST requires a sufficient number of speakers in the labelled data,\nespecially in the low-regime setting. In this manner these two approaches\nimprove supervised learning in different regimes of data composition.\n","authors":["Dan Berrebbi","Ronan Collobert","Navdeep Jaitly","Tatiana Likhomanenko"],"pdf_url":"https://arxiv.org/pdf/2211.00854v2.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2205.13697v3","updated":"2023-03-02T06:43:05Z","published":"2022-05-27T01:19:22Z","title":"FedFormer: Contextual Federation with Attention in Reinforcement\n  Learning","summary":"  A core issue in multi-agent federated reinforcement learning is defining how\nto aggregate insights from multiple agents. This is commonly done by taking the\naverage of each participating agent's model weights into one common model\n(FedAvg). We instead propose FedFormer, a novel federation strategy that\nutilizes Transformer Attention to contextually aggregate embeddings from models\noriginating from different learner agents. In so doing, we attentively weigh\nthe contributions of other agents with respect to the current agent's\nenvironment and learned relationships, thus providing a more effective and\nefficient federation. We evaluate our methods on the Meta-World environment and\nfind that our approach yields significant improvements over FedAvg and\nnon-federated Soft Actor-Critic single-agent methods. Our results compared to\nSoft Actor-Critic show that FedFormer achieves higher episodic return while\nstill abiding by the privacy constraints of federated learning. Finally, we\nalso demonstrate improvements in effectiveness with increased agent pools\nacross all methods in certain tasks. This is contrasted by FedAvg, which fails\nto make noticeable improvements when scaled.\n","authors":["Liam Hebert","Lukasz Golab","Pascal Poupart","Robin Cohen"],"pdf_url":"https://arxiv.org/pdf/2205.13697v3.pdf","comment":"Our source code can be found at\n  https://github.com/liamhebert/FedFormer. Accepted at AAMAS 2023"},{"id":"http://arxiv.org/abs/2205.14083v3","updated":"2023-03-02T06:39:34Z","published":"2022-05-27T16:32:43Z","title":"Sharpness-Aware Training for Free","summary":"  Modern deep neural networks (DNNs) have achieved state-of-the-art\nperformances but are typically over-parameterized. The over-parameterization\nmay result in undesirably large generalization error in the absence of other\ncustomized training strategies. Recently, a line of research under the name of\nSharpness-Aware Minimization (SAM) has shown that minimizing a sharpness\nmeasure, which reflects the geometry of the loss landscape, can significantly\nreduce the generalization error. However, SAM-like methods incur a two-fold\ncomputational overhead of the given base optimizer (e.g. SGD) for approximating\nthe sharpness measure. In this paper, we propose Sharpness-Aware Training for\nFree, or SAF, which mitigates the sharp landscape at almost zero additional\ncomputational cost over the base optimizer. Intuitively, SAF achieves this by\navoiding sudden drops in the loss in the sharp local minima throughout the\ntrajectory of the updates of the weights. Specifically, we suggest a novel\ntrajectory loss, based on the KL-divergence between the outputs of DNNs with\nthe current weights and past weights, as a replacement of the SAM's sharpness\nmeasure. This loss captures the rate of change of the training loss along the\nmodel's update trajectory. By minimizing it, SAF ensures the convergence to a\nflat minimum with improved generalization capabilities. Extensive empirical\nresults show that SAF minimizes the sharpness in the same way that SAM does,\nyielding better results on the ImageNet dataset with essentially the same\ncomputational cost as the base optimizer.\n","authors":["Jiawei Du","Daquan Zhou","Jiashi Feng","Vincent Y. F. Tan","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2205.14083v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09138v2","updated":"2023-03-02T06:27:20Z","published":"2023-01-22T15:17:12Z","title":"Explaining Quantum Circuits with Shapley Values: Towards Explainable\n  Quantum Machine Learning","summary":"  Methods of artificial intelligence (AI) and especially machine learning (ML)\nhave been growing ever more complex, and at the same time have more and more\nimpact on people's lives. This leads to explainable AI (XAI) manifesting itself\nas an important research field that helps humans to better comprehend ML\nsystems. In parallel, quantum machine learning (QML) is emerging with the\nongoing improvement of quantum computing hardware combined with its increasing\navailability via cloud services. QML enables quantum-enhanced ML in which\nquantum mechanics is exploited to facilitate ML tasks, typically in form of\nquantum-classical hybrid algorithms that combine quantum and classical\nresources. Quantum gates constitute the building blocks of gate-based quantum\nhardware and form circuits that can be used for quantum computations. For QML\napplications, quantum circuits are typically parameterized and their parameters\nare optimized classically such that a suitably defined objective function is\nminimized. Inspired by XAI, we raise the question of explainability of such\ncircuits by quantifying the importance of (groups of) gates for specific goals.\nTo this end, we transfer and adapt the well-established concept of Shapley\nvalues to the quantum realm. The resulting attributions can be interpreted as\nexplanations for why a specific circuit works well for a given task, improving\nthe understanding of how to construct parameterized (or variational) quantum\ncircuits, and fostering their human interpretability in general. An\nexperimental evaluation on simulators and two superconducting quantum hardware\ndevices demonstrates the benefits of the proposed framework for classification,\ngenerative modeling, transpilation, and optimization. Furthermore, our results\nshed some light on the role of specific gates in popular QML approaches.\n","authors":["Raoul Heese","Thore Gerlach","Sascha Mücke","Sabine Müller","Matthias Jakobs","Nico Piatkowski"],"pdf_url":"https://arxiv.org/pdf/2301.09138v2.pdf","comment":"36 pages, 27 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.05086v2","updated":"2023-03-02T06:14:19Z","published":"2023-02-10T07:08:13Z","title":"Making Substitute Models More Bayesian Can Enhance Transferability of\n  Adversarial Examples","summary":"  The transferability of adversarial examples across deep neural networks\n(DNNs) is the crux of many black-box attacks. Many prior efforts have been\ndevoted to improving the transferability via increasing the diversity in inputs\nof some substitute models. In this paper, by contrast, we opt for the diversity\nin substitute models and advocate to attack a Bayesian model for achieving\ndesirable transferability. Deriving from the Bayesian formulation, we develop a\nprincipled strategy for possible finetuning, which can be combined with many\noff-the-shelf Gaussian posterior approximations over DNN parameters. Extensive\nexperiments have been conducted to verify the effectiveness of our method, on\ncommon benchmark datasets, and the results demonstrate that our method\noutperforms recent state-of-the-arts by large margins (roughly 19% absolute\nincrease in average attack success rate on ImageNet), and, by combining with\nthese recent methods, further performance gain can be obtained. Our code:\nhttps://github.com/qizhangli/MoreBayesian-attack.\n","authors":["Qizhang Li","Yiwen Guo","Wangmeng Zuo","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2302.05086v2.pdf","comment":"Accepted by ICLR 2023, fix typos"},{"id":"http://arxiv.org/abs/2210.15598v2","updated":"2023-03-02T06:12:50Z","published":"2022-10-27T16:37:52Z","title":"Provable Sim-to-real Transfer in Continuous Domain with Partial\n  Observations","summary":"  Sim-to-real transfer trains RL agents in the simulated environments and then\ndeploys them in the real world. Sim-to-real transfer has been widely used in\npractice because it is often cheaper, safer and much faster to collect samples\nin simulation than in the real world. Despite the empirical success of the\nsim-to-real transfer, its theoretical foundation is much less understood. In\nthis paper, we study the sim-to-real transfer in continuous domain with partial\nobservations, where the simulated environments and real-world environments are\nmodeled by linear quadratic Gaussian (LQG) systems. We show that a popular\nrobust adversarial training algorithm is capable of learning a policy from the\nsimulated environment that is competitive to the optimal policy in the\nreal-world environment. To achieve our results, we design a new algorithm for\ninfinite-horizon average-cost LQGs and establish a regret bound that depends on\nthe intrinsic complexity of the model class. Our algorithm crucially relies on\na novel history clipping scheme, which might be of independent interest.\n","authors":["Jiachen Hu","Han Zhong","Chi Jin","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2210.15598v2.pdf","comment":"Accepted at ICLR2023"},{"id":"http://arxiv.org/abs/2303.00996v1","updated":"2023-03-02T06:10:13Z","published":"2023-03-02T06:10:13Z","title":"Unsupervised Meta-Learning via Few-shot Pseudo-supervised Contrastive\n  Learning","summary":"  Unsupervised meta-learning aims to learn generalizable knowledge across a\ndistribution of tasks constructed from unlabeled data. Here, the main challenge\nis how to construct diverse tasks for meta-learning without label information;\nrecent works have proposed to create, e.g., pseudo-labeling via pretrained\nrepresentations or creating synthetic samples via generative models. However,\nsuch a task construction strategy is fundamentally limited due to heavy\nreliance on the immutable pseudo-labels during meta-learning and the quality of\nthe representations or the generated samples. To overcome the limitations, we\npropose a simple yet effective unsupervised meta-learning framework, coined\nPseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired\nby the recent self-supervised learning literature; PsCo utilizes a momentum\nnetwork and a queue of previous batches to improve pseudo-labeling and\nconstruct diverse tasks in a progressive manner. Our extensive experiments\ndemonstrate that PsCo outperforms existing unsupervised meta-learning methods\nunder various in-domain and cross-domain few-shot classification benchmarks. We\nalso validate that PsCo is easily scalable to a large-scale benchmark, while\nrecent prior-art meta-schemes are not.\n","authors":["Huiwon Jang","Hankook Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2303.00996v1.pdf","comment":"Accepted to ICLR 2023 (Spotlight). The first two authors contributed\n  equally. The code is available at https://github.com/alinlab/PsCo"},{"id":"http://arxiv.org/abs/2210.00189v2","updated":"2023-03-02T05:41:40Z","published":"2022-10-01T04:42:56Z","title":"Pitfalls of Gaussians as a noise distribution in NCE","summary":"  Noise Contrastive Estimation (NCE) is a popular approach for learning\nprobability density functions parameterized up to a constant of\nproportionality. The main idea is to design a classification problem for\ndistinguishing training data from samples from an easy-to-sample noise\ndistribution $q$, in a manner that avoids having to calculate a partition\nfunction. It is well-known that the choice of $q$ can severely impact the\ncomputational and statistical efficiency of NCE. In practice, a common choice\nfor $q$ is a Gaussian which matches the mean and covariance of the data.\n  In this paper, we show that such a choice can result in an exponentially bad\n(in the ambient dimension) conditioning of the Hessian of the loss, even for\nvery simple data distributions. As a consequence, both the statistical and\nalgorithmic complexity for such a choice of $q$ will be problematic in\npractice, suggesting that more complex noise distributions are essential to the\nsuccess of NCE.\n","authors":["Holden Lee","Chirag Pabbaraju","Anish Sevekari","Andrej Risteski"],"pdf_url":"https://arxiv.org/pdf/2210.00189v2.pdf","comment":"14 pages, 1 figure"},{"id":"http://arxiv.org/abs/2211.09981v2","updated":"2023-03-02T05:37:48Z","published":"2022-11-18T02:00:17Z","title":"Weighted Ensemble Self-Supervised Learning","summary":"  Ensembling has proven to be a powerful technique for boosting model\nperformance, uncertainty estimation, and robustness in supervised learning.\nAdvances in self-supervised learning (SSL) enable leveraging large unlabeled\ncorpora for state-of-the-art few-shot and supervised learning performance. In\nthis paper, we explore how ensemble methods can improve recent SSL techniques\nby developing a framework that permits data-dependent weighted cross-entropy\nlosses. We refrain from ensembling the representation backbone; this choice\nyields an efficient ensemble method that incurs a small training cost and\nrequires no architectural changes or computational overhead to downstream\nevaluation. The effectiveness of our method is demonstrated with two\nstate-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al.,\n2022). Our method outperforms both in multiple evaluation metrics on\nImageNet-1K, particularly in the few-shot setting. We explore several weighting\nschemes and find that those which increase the diversity of ensemble heads lead\nto better downstream evaluation results. Thorough experiments yield improved\nprior art baselines which our method still surpasses; e.g., our overall\nimprovement with MSN ViT-B/16 is 3.9 p.p. for 1-shot learning.\n","authors":["Yangjun Ruan","Saurabh Singh","Warren Morningstar","Alexander A. Alemi","Sergey Ioffe","Ian Fischer","Joshua V. Dillon"],"pdf_url":"https://arxiv.org/pdf/2211.09981v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00984v1","updated":"2023-03-02T05:29:27Z","published":"2023-03-02T05:29:27Z","title":"Encoding of data sets and algorithms","summary":"  In many high-impact applications, it is important to ensure the quality of\noutput of a machine learning algorithm as well as its reliability in comparison\nwith the complexity of the algorithm used. In this paper, we have initiated a\nmathematically rigorous theory to decide which models (algorithms applied on\ndata sets) are close to each other in terms of certain metrics, such as\nperformance and the complexity level of the algorithm. This involves creating a\ngrid on the hypothetical spaces of data sets and algorithms so as to identify a\nfinite set of probability distributions from which the data sets are sampled\nand a finite set of algorithms. A given threshold metric acting on this grid\nwill express the nearness (or statistical distance) from each algorithm and\ndata set of interest to any given application. A technically difficult part of\nthis project is to estimate the so-called metric entropy of a compact subset of\nfunctions of \\textbf{infinitely many variables} that arise in the definition of\nthese spaces.\n","authors":["Katarina Doctor","Tong Mao","Hrushikesh Mhaskar"],"pdf_url":"https://arxiv.org/pdf/2303.00984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14106v2","updated":"2023-03-02T05:23:15Z","published":"2022-12-28T22:05:32Z","title":"Robust Ranking Explanations","summary":"  Gradient-based explanation is the cornerstone of explainable deep networks,\nbut it has been shown to be vulnerable to adversarial attacks. However,\nexisting works measure the explanation robustness based on $\\ell_p$-norm, which\ncan be counter-intuitive to humans, who only pay attention to the top few\nsalient features. We propose explanation ranking thickness as a more suitable\nexplanation robustness metric. We then present a new practical adversarial\nattacking goal for manipulating explanation rankings. To mitigate the\nranking-based attacks while maintaining computational feasibility, we derive\nsurrogate bounds of the thickness that involve expensive sampling and\nintegration. We use a multi-objective approach to analyze the convergence of a\ngradient-based attack to confirm that the explanation robustness can be\nmeasured by the thickness metric. We conduct experiments on various network\narchitectures and diverse datasets to prove the superiority of the proposed\nmethods, while the widely accepted Hessian-based curvature smoothing approaches\nare not as robust as our method.\n","authors":["Chao Chen","Chenghua Guo","Guixiang Ma","Ming Zeng","Xi Zhang","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2212.14106v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2303.01457v1","updated":"2023-03-02T18:15:03Z","published":"2023-03-02T18:15:03Z","title":"AI as mediator between composers, sound designers, and creative media\n  producers","summary":"  Musical professionals who produce material for non-musical stakeholders often\nface communication challenges in the early ideation stage. Expressing musical\nideas can be difficult, especially when domain-specific vocabulary is lacking.\nThis position paper proposes the use of artificial intelligence to facilitate\ncommunication between stakeholders and accelerate the consensus-building\nprocess. Rather than fully or partially automating the creative process, the\naim is to give more time for creativity by reducing time spent on defining the\nexpected outcome. To demonstrate this point, the paper discusses two\napplication scenarios for interactive music systems that are based on the\nauthors' research into gesture-to-sound mapping.\n","authors":["Sebastian Löbbers","Mathieu Barthet","György Fazekas"],"pdf_url":"https://arxiv.org/pdf/2303.01457v1.pdf","comment":"Position paper submitted to Integrating AI in Human-Human\n  Collaborative Ideation workshop at the ACM CHI Conference on Human Factors in\n  Computing System"},{"id":"http://arxiv.org/abs/2303.01396v1","updated":"2023-03-02T16:26:14Z","published":"2023-03-02T16:26:14Z","title":"MLANet: Multi-Level Attention Network with Sub-instruction for\n  Continuous Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) aims to develop intelligent agents to\nnavigate in unseen environments only through language and vision supervision.\nIn the recently proposed continuous settings (continuous VLN), the agent must\nact in a free 3D space and faces tougher challenges like real-time execution,\ncomplex instruction understanding, and long action sequence prediction. For a\nbetter performance in continuous VLN, we design a multi-level instruction\nunderstanding procedure and propose a novel model, Multi-Level Attention\nNetwork (MLANet). The first step of MLANet is to generate sub-instructions\nefficiently. We design a Fast Sub-instruction Algorithm (FSA) to segment the\nraw instruction into sub-instructions and generate a new sub-instruction\ndataset named ``FSASub\". FSA is annotation-free and faster than the current\nmethod by 70 times, thus fitting the real-time requirement in continuous VLN.\nTo solve the complex instruction understanding problem, MLANet needs a global\nperception of the instruction and observations. We propose a Multi-Level\nAttention (MLA) module to fuse vision, low-level semantics, and high-level\nsemantics, which produce features containing a dynamic and global comprehension\nof the task. MLA also mitigates the adverse effects of noise words, thus\nensuring a robust understanding of the instruction. To correctly predict\nactions in long trajectories, MLANet needs to focus on what sub-instruction is\nbeing executed every step. We propose a Peak Attention Loss (PAL) to improve\nthe flexible and adaptive selection of the current sub-instruction. PAL\nbenefits the navigation agent by concentrating its attention on the local\ninformation, thus helping the agent predict the most appropriate actions. We\ntrain and test MLANet in the standard benchmark. Experiment results show MLANet\noutperforms baselines by a significant margin.\n","authors":["Zongtao He","Liuyi Wang","Shu Li","Qingqing Yan","Chengju Liu","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01217v1","updated":"2023-03-02T12:59:01Z","published":"2023-03-02T12:59:01Z","title":"Synthetic Misinformers: Generating and Combating Multimodal\n  Misinformation","summary":"  With the expansion of social media and the increasing dissemination of\nmultimedia content, the spread of misinformation has become a major concern.\nThis necessitates effective strategies for multimodal misinformation detection\n(MMD) that detect whether the combination of an image and its accompanying text\ncould mislead or misinform. Due to the data-intensive nature of deep neural\nnetworks and the labor-intensive process of manual annotation, researchers have\nbeen exploring various methods for automatically generating synthetic\nmultimodal misinformation - which we refer to as Synthetic Misinformers - in\norder to train MMD models. However, limited evaluation on real-world\nmisinformation and a lack of comparisons with other Synthetic Misinformers\nmakes difficult to assess progress in the field. To address this, we perform a\ncomparative study on existing and new Synthetic Misinformers that involves (1)\nout-of-context (OOC) image-caption pairs, (2) cross-modal named entity\ninconsistency (NEI) as well as (3) hybrid approaches and we evaluate them\nagainst real-world misinformation; using the COSMOS benchmark. The comparative\nstudy showed that our proposed CLIP-based Named Entity Swapping can lead to MMD\nmodels that surpass other OOC and NEI Misinformers in terms of multimodal\naccuracy and that hybrid approaches can lead to even higher detection accuracy.\nNevertheless, after alleviating information leakage from the COSMOS evaluation\nprotocol, low Sensitivity scores indicate that the task is significantly more\nchallenging than previous studies suggested. Finally, our findings showed that\nNEI-based Synthetic Misinformers tend to suffer from a unimodal bias, where\ntext-only MMDs can outperform multimodal ones.\n","authors":["Stefanos-Iordanis Papadopoulos","Christos Koutlis","Symeon Papadopoulos","Panagiotis C. Petrantonakis"],"pdf_url":"https://arxiv.org/pdf/2303.01217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01211v1","updated":"2023-03-02T12:52:22Z","published":"2023-03-02T12:52:22Z","title":"Learning From Yourself: A Self-Distillation Method for Fake Speech\n  Detection","summary":"  In this paper, we propose a novel self-distillation method for fake speech\ndetection (FSD), which can significantly improve the performance of FSD without\nincreasing the model complexity. For FSD, some fine-grained information is very\nimportant, such as spectrogram defects, mute segments, and so on, which are\noften perceived by shallow networks. However, shallow networks have much noise,\nwhich can not capture this very well. To address this problem, we propose using\nthe deepest network instruct shallow network for enhancing shallow networks.\nSpecifically, the networks of FSD are divided into several segments, the\ndeepest network being used as the teacher model, and all shallow networks\nbecome multiple student models by adding classifiers. Meanwhile, the\ndistillation path between the deepest network feature and shallow network\nfeatures is used to reduce the feature difference. A series of experimental\nresults on the ASVspoof 2019 LA and PA datasets show the effectiveness of the\nproposed method, with significant improvements compared to the baseline.\n","authors":["Jun Xue","Cunhang Fan","Jiangyan Yi","Chenglong Wang","Zhengqi Wen","Dan Zhang","Zhao Lv"],"pdf_url":"https://arxiv.org/pdf/2303.01211v1.pdf","comment":"Accepted by ICASSP 2023"}]}}